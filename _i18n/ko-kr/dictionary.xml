<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">법적 고지</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">법적 고지 사항은 저작권 선언, 상표, 특허 등에 대한 액세스를 제공합니다.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">저작권</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">상표</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, NetApp 로고, NetApp 상표 페이지에 나열된 마크는 NetApp Inc.의 상표입니다. 기타 회사 및 제품 이름은 해당 소유자의 상표일 수 있습니다.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">특허</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp 소유 특허 목록은 다음 사이트에서 확인할 수 있습니다.</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">개인 정보 보호 정책</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">오픈 소스</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">통지 파일은 NetApp 소프트웨어에 사용된 타사의 저작권 및 라이센스에 대한 정보를 제공합니다.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">ONTAP 9.13.1 참고 사항</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">ONTAP 9.12.1에 대한 고지 사항</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">ONTAP 9.12.0 참고 사항</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">ONTAP 9.11.1에 대한 고지 사항</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">ONTAP 9.10.1에 대한 고지 사항</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">ONTAP 9.10.0에 대한 고지 사항</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">ONTAP 9.9.1에 대한 참고 사항</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">ONTAP 9.8에 대한 고지 사항</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">ONTAP 9.7의 알림 사항</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">ONTAP 9.6 고지 사항</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">ONTAP 9.5 알림</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">ONTAP 9.4 고지 사항</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">ONTAP 9.3 공지 사항</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">ONTAP 9.2 관련 고지 사항</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">ONTAP 9.1에 대한 참고 사항</block>
  <block id="5672f5979be77bb31dd559817c9e1e76" category="paragraph"><block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block>
<block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block>
<block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block>
<block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block>
<block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block>
<block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block>
<block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block>
<block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block>
<block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block>
<block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block>
<block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block>
<block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block>
<block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block>
<block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block>
<block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="07ee2fe6f236deffba69a7cf80a680fd" category="section-title">MCC IP용 ONTAP 중재자</block>
  <block id="f089ab2b9f25f609795bdd46ae636f18" category="inline-link-macro">9.9.1 MCC IP용 ONTAP mediator에 대한 Notice</block>
  <block id="239794a299abe62705440f2dab3114cb" category="inline-link-macro">9.8 MCC IP용 ONTAP mediator에 대한 Notice</block>
  <block id="51fcca20d278d2d03192c01120f17442" category="inline-link-macro">9.7 MCC IP용 ONTAP mediator에 대한 알림</block>
  <block id="3ba2aeb22339424d5f5b15dafd2c3eca" category="paragraph"><block ref="c8696a7854fcd089ea112145e4968b10" category="inline-link-macro-rx"></block>
<block ref="4d19e06382f392d0f1a50df789d77c13" category="inline-link-macro-rx"></block>
<block ref="fe4ac88b6b3f1cb9f1dc6d5d4b5086ee" category="inline-link-macro-rx"></block></block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">정책</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">이는 데이터베이스에 공통적으로 적용됩니다. 비활성 블록을 포함하는 것으로 알려진 데이터베이스도 FabricPool 계층화의 후보입니다. 예를 들어 공급망 관리 데이터베이스에는 필요 시 사용할 수 있어야 하지만 정상 작업 중에는 액세스할 수 없는 내역 정보가 포함될 수 있습니다. FabricPool를 사용하여 비활성 블록을 선택적으로 재배치할 수 있습니다.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">예를 들어, 으로 FabricPool 볼륨에서 실행되는 데이터 파일이 여기에 해당합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 90일간 지난 90일 동안 액세스된 모든 블록을 성능 계층에서 유지합니다. 그러나 90일 동안 액세스하지 않은 모든 데이터는 용량 계층으로 재배치됩니다. 다른 경우에는 정상적인 애플리케이션 작업이 올바른 계층에서 올바른 블록을 보존합니다. 예를 들어 데이터베이스가 일반적으로 이전 60일 동안의 데이터를 정기적으로 처리하는 데 사용되는 경우 훨씬 더 낮습니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 애플리케이션의 자연적 활동으로 인해 블록이 조기에 재배치되지 않도록 하기 때문에 기간을 설정할 수 있다.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 정책은 데이터베이스에 주의하여 사용해야 합니다. 많은 데이터베이스에는 분기말 프로세스 또는 재인덱싱 작업 같은 주기적인 활동이 있습니다. 이 작업의 기간이 보다 큰 경우<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 성능 문제가 발생할 수 있습니다. 예를 들어, 분기말 처리에는 영향을 받지 않은 1TB의 데이터가 필요한 경우 해당 데이터가 용량 계층에 존재할 수 있습니다. 용량 계층에서 읽는 속도는 매우 빠르며 성능 문제를 일으키지 않지만 정확한 결과는 오브젝트 저장소 구성에 따라 달라집니다.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">를 클릭합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 정책은 성능 계층에 필요할 수 있는 파일을 보존할 수 있을 만큼 높게 설정해야 합니다. 예를 들어, 최적의 성능을 얻으려면 가장 최근 60일간의 데이터가 필요할 수 있는 데이터베이스가 필요할 경우 을 설정해야 합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 60일까지입니다. 파일의 액세스 패턴을 기준으로 비슷한 결과를 얻을 수도 있습니다. 예를 들어, 최근 90일 동안의 데이터가 필요하고 애플리케이션에서 90일 동안의 데이터에 액세스하는 경우 데이터는 성능 계층에 유지됩니다. 를 설정합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 기간 - 2일 동안 데이터의 사용 빈도가 낮아지면 데이터를 즉시 계층화합니다.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 에만 해당되기 때문에 이러한 블록을 계층화하는 데 정책이 필요합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 정책은 액티브 파일 시스템에 있는 블록에 영향을 줍니다.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">데이터에 대한 모든 액세스 유형은 열 지도 데이터를 재설정합니다. 따라서 데이터베이스 전체 테이블 검사 및 소스 파일을 읽는 백업 작업까지 필요할 때 계층화를 수행할 수 없습니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 임계값에 도달하지 않았습니다.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">LUN 리사이징이 용량을 증대하는 옵션이기는 하지만 Oracle ASM을 포함한 LVM을 사용하는 것이 대체로 더 낫습니다. LVM이 존재하는 주된 이유 중 하나는 LUN 리사이징이 필요하지 않도록 하는 것입니다. LVM은 여러 개의 LUN을 스토리지 가상 풀에 함께 바인딩합니다. 이 풀에서 생성된 논리적 볼륨은 LVM이 관리하며 쉽게 리사이징할 수 있습니다. 이 외에도 특정 논리적 볼륨을 가용 LUN 전반에 분산하여 특정 드라이브의 핫스폿을 피할 수 있다는 이점이 있습니다. 일반적으로 볼륨 관리자를 사용하여 투명한 마이그레이션을 수행함으로써 논리적 볼륨의 기본 익스텐트를 새 LUN에 재배치할 수 있습니다.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">수동으로 NVFAIL을 강제 적용합니다</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">이 섹션에서는 MetroCluster 관련 주제를 다루는 기본 ONTAP NVFAIL에 대한 설명을 확장합니다.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">MetroCluster를 사용할 경우, 쓰기가 하나 이상의 다른 컨트롤러의 로컬 NVRAM 및 NVRAM에 로그인되기 전까지는 승인되지 않습니다. 이렇게 하면 하드웨어 장애나 정전이 발생해도 전송 중인 I/O가 손실되지 않습니다 로컬 NVRAM에 장애가 발생하거나 다른 노드에 대한 연결이 실패하면 데이터가 더 이상 미러링되지 않습니다.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">로컬 NVRAM에 오류가 보고되면 노드가 종료됩니다. 이 종료를 통해 HA Pair를 사용할 경우 파트너 컨트롤러로 페일오버됩니다. MetroCluster를 사용할 경우 선택한 전체 구성에 따라 동작이 달라지지만 원격 메모로 자동 페일오버될 수 있습니다. 오류가 발생한 컨트롤러가 쓰기 작업을 인식하지 못했기 때문에 어떤 경우에도 데이터가 손실되지 않습니다.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">사이트 간 연결 실패가 NVRAM 복제를 원격 노드로 차단하는 경우에 더 복잡한 상황이 됩니다. 쓰기가 더 이상 원격 노드에 복제되지 않으므로 컨트롤러에서 심각한 오류가 발생할 경우 데이터가 손실될 수 있습니다. 더 중요한 것은 이러한 상황에서 다른 노드로 페일오버하려고 하면 데이터가 손실된다는 것입니다.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">제어 요소는 NVRAM의 동기화 여부입니다. NVRAM이 동기화되면 데이터 손실 위험 없이 노드 간 페일오버를 안전하게 수행할 수 있습니다. MetroCluster 구성에서 NVRAM 및 기본 애그리게이트 플렉스가 동기화되어 있는 경우 데이터 손실 위험 없이 전환을 진행해도 안전합니다.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP는 페일오버 또는 스위치오버가 강제 적용되지 않는 한 데이터가 동기화되지 않을 때 페일오버 또는 스위치오버를 허용하지 않습니다. 이러한 방식으로 조건을 강제로 변경하면 데이터가 원래 컨트롤러에 남겨질 수 있으며 데이터 손실이 허용되는 수준임을 알 수 있습니다.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">데이터베이스는 디스크에 더 큰 내부 데이터 캐시를 유지하기 때문에 페일오버나 스위치오버가 강제 적용되는 경우 손상에 특히 취약합니다. 강제 적용 페일오버 또는 스위치오버가 발생하면 이전에 승인되었던 변경사항이 효과적으로 폐기됩니다. 스토리지 어레이의 콘텐츠가 사실상 이전 시간으로 이동하며, 데이터베이스 캐시의 상태는 디스크에 있는 데이터의 상태를 더 이상 반영하지 않습니다.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">이 상황에서 애플리케이션을 보호하기 위해 ONTAP에서는 NVRAM 장애에 대비하여 특별한 보호를 제공하도록 볼륨을 구성할 수 있습니다. 이 보호 메커니즘이 트리거되면 볼륨이 NVFAIL이라는 상태로 전환됩니다. 이 상태에서는 애플리케이션 종료가 I/O 오류가 발생하여 오래된 데이터를 사용하지 않습니다. 확인된 쓰기가 스토리지 시스템에 계속 존재하고 데이터베이스의 경우 커밋된 트랜잭션 데이터가 로그에 있어야 하므로 데이터가 손실되지 않아야 합니다.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">일반적인 다음 단계는 관리자가 LUN 및 볼륨을 수동으로 다시 온라인 상태로 전환하기 전에 호스트를 완전히 종료하는 것입니다. 이러한 단계에는 일부 작업이 포함될 수 있지만 이 접근 방식은 데이터 무결성을 보장하는 가장 안전한 방법입니다. 모든 데이터에 이 보호가 필요한 것은 아니므로 NVFAIL 동작을 볼륨별로 구성할 수 있습니다.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">사이트 전체에 분산된 애플리케이션 클러스터(VMware, Oracle RAC 등 포함)를 사용하여 강제 전환할 수 있는 가장 안전한 옵션은 을 지정하는 것입니다<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> 명령줄에 입력합니다. 이 옵션은 캐시된 모든 데이터를 플러시하기 위한 긴급 조치로 사용할 수 있습니다. 호스트에서 원래 재해 복구 사이트에 있는 스토리지 리소스를 사용하는 경우 입출력 오류 또는 오래된 파일 핸들이 발생합니다 <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) 오류. Oracle 데이터베이스가 충돌하고 파일 시스템이 완전히 오프라인 상태가 되거나 읽기 전용 모드로 전환됩니다.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">전환이 완료된 후 은 을(를) 수행합니다<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> 플래그를 지워야 하며 LUN을 온라인 상태로 설정해야 합니다. 이 작업이 완료되면 데이터베이스를 다시 시작할 수 있습니다. 이러한 작업을 자동화하여 RTO를 줄일 수 있습니다.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail입니다</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">일반적인 안전 조치로 을 설정합니다<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> 정상 작업 중에 원격 사이트에서 액세스할 수 있는 모든 볼륨에 플래그를 표시하므로, 페일오버 전에 사용된 활동입니다. 이 설정의 결과로 선택한 원격 볼륨이 들어가면 사용할 수 없게 됩니다<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> 스위치오버 중에 전환이 완료된 후 은 을(를) 수행합니다<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> 플래그를 지워야 하며 LUN을 온라인 상태로 설정해야 합니다. 이러한 작업이 완료되면 응용 프로그램을 다시 시작할 수 있습니다. 이러한 작업을 자동화하여 RTO를 줄일 수 있습니다.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">결과는 을 사용하는 것과 같습니다<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> 수동 전환 플래그 그러나 영향을 받는 볼륨의 수는 오래된 캐시가 있는 애플리케이션이나 운영 체제에서 보호되어야 하는 볼륨으로만 제한될 수 있습니다.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">을 사용하지 않는 환경에는 두 가지 중요한 요구사항이 있습니다<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> 애플리케이션 볼륨에서:</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">강제 적용 스위치오버는 1차 사이트 손실 후 30초 이내여야 합니다.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">유지보수 작업 중 또는 SyncMirror 플렉스 또는 NVRAM 복제가 동기화되지 않는 기타 조건에서는 전환이 발생하지 않아야 합니다. 사이트 장애 발생 후 30초 이내에 전환을 수행하도록 구성된 Tiebreaker 소프트웨어를 사용하여 첫 번째 요구사항을 충족할 수 있습니다. 이 요구사항이 사이트 장애 감지 후 30초 이내에 전환을 수행해야 함을 의미하는 것은 아닙니다. 즉, 사이트가 작동 가능으로 확인된 후 30초가 경과하면 강제로 전환을 수행하는 것이 더 이상 안전하지 않습니다.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">MetroCluster 구성이 동기화되지 않은 것으로 알려진 경우 모든 자동 전환 기능을 비활성화하여 두 번째 요구 사항을 부분적으로 충족할 수 있습니다. 더 좋은 옵션은 NVRAM 복제 및 SyncMirror Plex의 상태를 모니터링할 수 있는 Tiebreaker 솔루션을 구축하는 것입니다. 클러스터가 완전히 동기화되지 않은 경우 Tiebreaker가 전환을 트리거해서는 안 됩니다.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">NetApp MCTB 소프트웨어는 동기화 상태를 모니터링할 수 없으므로 어떤 이유로든 MetroCluster가 동기화되지 않은 경우 이 기능을 비활성화해야 합니다. ClusterLion에는 NVRAM 모니터링 및 플렉스 모니터링 기능이 포함되어 있으며, MetroCluster 시스템이 완전히 동기화되는 것으로 확인되지 않는 한 전환을 트리거하지 않도록 구성할 수 있습니다.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">LUN 수입니다</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">LUN은 ONTAP의 가상화 오브젝트로서 호스팅 애그리게이트의 모든 드라이브에 존재합니다. 그 결과, LUN은 어떤 크기를 선택하든 애그리게이트의 잠재력을 최대한으로 활용하기 때문에 크기가 LUN의 성능에 영향을 미치지 않습니다.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">고객이 편의상 특정 크기의 LUN을 사용하려 할 수 있습니다. 예를 들어, 데이터베이스가 각각 1TB인 2개의 LUN으로 구성된 LVM 또는 Oracle ASM 디스크 그룹에 구축되어 있는 경우 이 디스크 그룹은 1TB의 증분으로 확장되어야 합니다. 디스크 그룹이 더 적은 증분으로 증가할 수 있도록 각각 500GB인 8개의 LUN으로 디스크 그룹을 구축하는 것이 더 낫습니다.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">범용 표준 LUN 크기를 설정하는 방법은 관리가 복잡할 수 있으므로 사용하지 않는 것이 좋습니다. 예를 들어, 100GB의 표준 LUN 크기는 1TB~2TB 범위의 데이터베이스에서는 효과적일 수 있지만 20TB 크기의 데이터베이스나 데이터 저장소에는 200개의 LUN이 필요할 것입니다. 이에 따라 서버 재부팅 시간이 길어지고, 다양한 UI에서 더 많은 오브젝트를 관리해야 하며, SnapCenter 같은 제품을 통해 여러 오브젝트를 탐색해야 합니다. LUN의 개수는 줄이고 크기는 늘리면 이 문제를 피할 수 있습니다.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">LUN 수가 LUN 크기보다 더 중요합니다.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">LUN 크기는 주로 LUN 개수 요구사항에 따라 결정됩니다.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">LUN을 필요한 것보다 많이 생성하지 마십시오.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">LUN 크기와 달리 LUN 개수는 성능에 영향을 미칩니다. 애플리케이션 성능은 SCSI 계층을 통해 병렬 I/O를 수행하는 능력에 따라 달라집니다. 그 결과 2개의 LUN이 1개의 LUN보다 나은 성능을 제공합니다. Veritas VxVM, Linux LVM2 또는 Oracle ASM 같은 LVM은 병렬 처리를 늘리는 가장 단순한 방법입니다.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">부하가 매우 큰 랜덤 I/O의 100% SSD 환경 테스트에서 최대 64개 LUN이라는 추가 개선이 입증되었음에도 NetApp 고객은 일반적으로 LUN의 개수가 16을 초과하여 증가할 때 최소한의 이점을 경험합니다.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">* NetApp는 * 다음을 권장합니다.</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">일반적으로 특정 데이터베이스 워크로드의 입출력 요구를 지원하는 데는 4~16개의 LUN으로 충분합니다. 4개 미만의 LUN은 호스트 SCSI 구현의 제한으로 인해 성능 제한이 발생할 수 있습니다.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">호스트 OS 설정</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">대부분의 응용 프로그램 공급업체 설명서에는 응용 프로그램이 최적의 상태로 작동하도록 하기 위한 특정 TCP 및 이더넷 설정이 포함되어 있습니다. 일반적으로 이러한 설정은 최적의 IP 기반 스토리지 성능을 제공하기에 충분합니다.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">이더넷 흐름 제어</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">이 기술을 통해 클라이언트는 발신자에게 데이터 전송을 일시적으로 중단할 것을 요청할 수 있습니다. 이 요청은 보통 수신자가 유입되는 데이터를 빠르게 처리할 수 없을 때 이루어집니다. 이와 동시에, 발신자에게 전송 중단을 요청할 때는 버퍼가 가득 차서 수신자가 패킷을 폐기할 때보다 중단 시간이 짧습니다. 이는 이제 오늘날 운영 체제에서 사용되는 TCP 스택의 사례가 아닙니다. 사실, 흐름 제어는 해결하는 문제보다 야기하는 문제가 더 많습니다.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">최근 들어 이더넷 흐름 제어가 초래하는 성능 문제가 증가해 왔는데 이는 이더넷 흐름 제어가 물리적 계층에서 작동하기 때문입니다. 네트워크 구성에서 호스트 운영 체제에서 이더넷 흐름 제어 요청을 스토리지 시스템으로 전송하도록 허용하는 경우, 연결된 모든 클라이언트의 I/O가 중지됩니다. 단일 스토리지 컨트롤러가 처리하는 클라이언트의 수가 증가하면 이러한 클라이언트가 하나 이상의 흐름 제어 요청을 보낼 가능성이 높아집니다. 방대한 운영 체제 가상화를 구현한 고객 사이트에서 문제가 자주 관찰되었습니다.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">NetApp 시스템의 NIC는 흐름 제어 요청을 수신하면 안 됩니다. 이러한 결과를 얻기 위해 사용하는 방법은 네트워크 스위치 제조업체에 따라 다릅니다. 대부분의 경우 이더넷 스위치의 흐름 제어는 으로 설정할 수 있습니다<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> 또는<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>다시 말해, 흐름 제어 요청이 스토리지 컨트롤러로 전달되지 않습니다. 스토리지 컨트롤러의 네트워크 연결이 흐름 제어 비활성화를 허용하지 않는 경우도 있습니다. 이 경우 호스트 서버 자체의 NIC 구성 또는 호스트 서버가 연결되는 스위치 포트를 변경하여 클라이언트가 흐름 제어 요청을 전송하지 않도록 구성해야 합니다.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">* NetApp는 NetApp 스토리지 컨트롤러가 이더넷 흐름 제어 패킷을 수신하지 않도록 하는 것을 권장합니다. 일반적으로는 컨트롤러가 연결될 스위치 포트를 설정하면 되지만 일부 스위치 하드웨어에는 제약이 있어 클라이언트 측 변경이 필요할 수 있습니다.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">MTU 크기</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">CPU와 네트워크 오버헤드를 줄여 1Gb 네트워크에서 성능을 개선하기 위해 점보 프레임이 사용되어온 것으로 나타났지만 대부분은 이점이 크지 않습니다.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp는 잠재적인 성능 이점을 실현하고 솔루션의 미래 경쟁력을 확보하기 위해 가능한 경우 점보 프레임을 구현하는 것을 권장합니다.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">10Gb 네트워크에서는 점보 프레임을 거의 의무적으로 사용해야 합니다. 대부분의 10Gb 구현에서 10Gb 표시에 도달하기 전에 점보 프레임이 없이는 초당 패킷 한계에 도달하기 때문입니다. 점보 프레임을 사용하면 OS, 서버, NIC, 스토리지 시스템에서 처리되는 패킷의 수가 줄어들었지만 크기가 더 커질 수 있기 때문에 TCP/IP 프로세싱의 효율성이 개선됩니다. NIC에 따라 달라지기는 하지만 상당한 성능 개선이 이루어집니다.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">점보 프레임 구현의 경우 연결된 모든 장치가 점보 프레임을 지원해야 하며 MTU 크기가 완전히 일치해야 한다는 잘못된 인식이 일반적입니다 연결을 설정할 때 2개의 네트워크 엔드 포인트는 상호 허용되는 최대 프레임 크기를 협상합니다. 일반적인 환경에서 네트워크 스위치는 MTU 크기 9216으로 설정되며 NetApp 컨트롤러는 9000, 클라이언트는 9000과 1514의 혼합으로 설정됩니다. 9000의 MTU를 지원하는 클라이언트는 점보 프레임을 사용할 수 있으며 1514만 지원하는 클라이언트는 더 낮은 값을 협상할 수 있습니다.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">이 방식의 문제는 완전히 스위칭된 환경에서는 자주 사용되지 않는다는 것입니다. 하지만 점보 프레임을 단편화하도록 강제 적용되는 중간 라우터가 없는 라우팅 환경에서는 주의하십시오.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">* NetApp는 다음을 * 구성할 것을 권장합니다.</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">1Gb 이더넷(GbE)에서 점보 프레임을 사용하면 좋지만 필수는 아닙니다.</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">10GbE 이상의 속도로 최대 성능을 얻으려면 점보 프레임이 필요합니다.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">TCP 매개 변수입니다</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">3가지 설정, 즉 TCP 타임스탬프, 선택적 승인(Selective Acknowledgment, SACK), TCP 윈도우 확장이 잘못 구성되는 경우가 많습니다. 인터넷상의 오래된 문서들은 이러한 매개 변수를 하나 이상 비활성화하여 성능을 개선할 것을 권장합니다. CPU 용량이 훨씬 낮았고 가능할 때마다 TCP 처리 오버헤드를 줄여 이점을 얻을 수 있었던 몇 해 전에는 이 권장사항이 어느 정도 가치가 있었습니다.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">그러나 최신 운영 체제에서 이러한 TCP 기능을 비활성화하면 일반적으로 어떤 이점도 얻을 수 없는 반면 성능 저하가 야기될 수도 있습니다. 성능 저하는 특히 가상화된 네트워킹 환경에서 발생할 가능성이 높은데 이들 기능이 패킷 손실을 효율적으로 처리하고 네트워크 품질을 바꾸는 데 필요하기 때문입니다</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">* NetApp는 호스트에서 TCP 타임스탬프, SACK 및 TCP 윈도우 확장을 활성화하는 것을 권장하며, 현재 모든 OS에서 이러한 매개 변수 세 개가 기본적으로 켜져 있어야 합니다.</block>
  <block id="72a921ac9177188a9be32ec711fc15d8" category="doc">경로 액세스</block>
  <block id="544c599da087dba677a820c3df344503" category="paragraph">SnapMirror Business Continuity(SM-BC)는 SAN을 위한 향상된 SnapMirror 기능으로, 호스트가 LUN을 호스팅하는 시스템과 복제본을 호스팅하는 시스템에서 LUN에 액세스할 수 있습니다.</block>
  <block id="6139cdabb39d5ceac18a60642497c6a7" category="paragraph">SM-BC 및 SnapMirror Sync(SM-S)는 복제 엔진을 공유하지만 SM-BC에는 엔터프라이즈 애플리케이션에 대한 투명한 애플리케이션 페일오버 및 페일백 등의 추가 기능이 포함되어 있습니다.</block>
  <block id="a73743f15de974052b0640c60f489d90" category="paragraph">실제로 이 솔루션은 개별 워크로드에 대해 선택적 세부 RPO=0 동기식 복제를 지원하여 MetroCluster의 세부 버전과 비슷하게 작동합니다. 하위 레벨의 경로 동작은 MetroCluster와 매우 다르지만 호스트 관점에서 최종 결과는 비슷합니다.</block>
  <block id="b3bf85c7b0a17286752c110f404a7035" category="paragraph">SM-BC는 운영 스토리지와 원격 스토리지 시스템 모두에서 스토리지 디바이스를 호스트 운영 체제에 표시할 수 있도록 합니다. 경로는 스토리지 시스템과 호스트 간에 최적화된 경로를 식별하기 위한 업계 표준 프로토콜인 ALUA(Asymmetric Logical Unit Access)를 통해 관리됩니다.</block>
  <block id="cbf0bd4f4096570f567049c984f8c9d3" category="paragraph">입출력에 가장 액세스하기 위한 디바이스 경로는 활성/최적화 경로로 간주되고 나머지 경로는 활성/최적화되지 않은 경로로 간주됩니다.</block>
  <block id="350b9208772a185e0d0943b105765d89" category="paragraph">SM-BC 관계는 서로 다른 클러스터에 있는 SVM 쌍 사이입니다. 두 SVM 모두 데이터를 제공할 수 있지만 ALUA는 LUN이 상주하는 드라이브를 현재 소유하는 SVM을 우선적으로 사용합니다. 원격 SVM에 대한 입출력은 SM-BC 상호 연결을 통해 프록시됩니다.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">오류: 그래픽 이미지가 없습니다</block>
  <block id="532db5273379dd6149d97b7ab6e420b6" category="paragraph"><block ref="532db5273379dd6149d97b7ab6e420b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">동기식 복제</block>
  <block id="8159c40a86db91b72e00c2eb5cf751fe" category="paragraph">정상 작동 시 원격 복제본은 항상 RPO=0 동기식 복제본이며 한 가지 예외가 있습니다. 데이터를 복제할 수 없는 경우 SM-BC는 데이터 복제 요구 사항을 해제하고 입출력 서비스를 재개합니다. 이 옵션은 복제 링크의 손실을 거의 재해에 가까운 문제로 간주하거나 데이터를 복제할 수 없을 때 비즈니스 작업이 중단되는 것을 원하지 않는 고객이 선호합니다.</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">스토리지 하드웨어</block>
  <block id="f0fd4c8ee2422af8e335cc85c485ccbf" category="paragraph">다른 스토리지 재해 복구 솔루션과 달리 SM-BC는 비대칭 플랫폼 유연성을 제공합니다. 각 사이트의 하드웨어는 동일할 필요가 없습니다. 이 기능을 사용하면 SM-BC를 지원하는 데 사용되는 하드웨어의 크기를 적절하게 조정할 수 있습니다. 전체 운영 워크로드를 지원해야 하는 경우 원격 스토리지 시스템이 기본 사이트와 동일할 수 있지만 재해로 인해 I/O가 감소할 경우 원격 사이트의 소규모 시스템보다 비용 효율적입니다.</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">ONTAP 중재자</block>
  <block id="b378eb5f2b386494f24a3f09afd8ae1f" category="paragraph">ONTAP 중재자는 NetApp 지원에서 다운로드되는 소프트웨어 응용 프로그램입니다. 중재자는 운영 및 원격 사이트 스토리지 클러스터 모두에 대한 페일오버 작업을 자동화합니다. 온프레미스 또는 클라우드에서 호스팅되는 소규모 가상 머신(VM)에 구축할 수 있습니다. 구성이 완료되면 두 사이트의 장애 조치 시나리오를 모니터링하는 세 번째 사이트 역할을 합니다.</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">SyncMirror를 사용한 데이터 보호</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">가장 간단한 수준인 동기식 복제는 미러링된 스토리지의 양쪽에서 변경 사항이 확인되기 전에 수행되어야 함을 의미합니다. 예를 들어, 데이터베이스에서 로그를 작성하거나 VMware 게스트에 패치를 적용하는 경우 쓰기가 손실되지 않아야 합니다. 프로토콜 레벨에서 스토리지 시스템은 두 사이트의 비휘발성 미디어에 커밋될 때까지 쓰기를 인증해서는 안 됩니다. 그래야만 데이터 손실의 위험 없이 진행하는 것이 안전합니다.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">동기식 복제 솔루션을 설계하고 관리하는 첫 번째 단계는 동기식 복제 기술을 사용하는 것입니다. 가장 중요한 고려 사항은 계획된 고장 시나리오와 예상치 못한 다양한 장애 시나리오 중에 발생할 수 있는 상황을 이해하는 것입니다. 모든 동기식 복제 솔루션이 동일한 기능을 제공하는 것은 아닙니다. 데이터 손실이 0인 복구 지점 목표(RPO)를 제공하는 솔루션이 필요한 경우 모든 장애 시나리오를 고려해야 합니다. 특히 사이트 간 연결 손실로 인해 복제가 불가능할 때 예상되는 결과는 무엇입니까?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">SyncMirror 데이터 가용성</block>
  <block id="bec293a9cf8e49ec40e6a4fdc02b9146" category="paragraph">MetroCluster 복제는 NetApp SyncMirror 기술을 기반으로 하며 동기식 모드로 효율적으로 전환하거나 아웃하도록 설계되었습니다. 이 기능은 동기식 복제를 필요로 하지만 데이터 서비스를 위해 고가용성이 필요한 고객의 요구사항을 충족합니다. 예를 들어 원격 사이트에 대한 연결이 끊긴 경우 일반적으로 스토리지 시스템이 복제되지 않은 상태로 계속 작동하도록 하는 것이 좋습니다.</block>
  <block id="9a9ce41f4b23474045b6c6e0ac7752af" category="paragraph">대부분의 동기식 복제 솔루션은 동기식 모드에서만 작동할 수 있습니다. 이러한 유형의 모든 또는 무관 복제를 도미노 모드라고도 합니다. 이러한 스토리지 시스템은 데이터의 로컬 및 원격 복제본이 동기화되지 않도록 하는 대신 데이터 제공을 중지합니다. 복제가 강제로 중단되면 재동기화는 시간이 매우 오래 걸리고 미러링이 다시 설정되는 동안 고객이 완전한 데이터 손실에 노출되도록 할 수 있습니다.</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">원격 사이트에 연결할 수 없는 경우 SyncMirror가 동기식 모드를 원활하게 전환할 수 있을 뿐만 아니라 연결이 복원되면 RPO=0 상태로 빠르게 다시 동기화할 수 있습니다. 또한 재동기화 중에 원격 사이트의 오래된 데이터 복제본을 사용 가능한 상태로 유지할 수 있으므로 데이터의 로컬 및 원격 복제본이 항상 존재합니다.</block>
  <block id="995f5151d2d1c0a4e8371b2b3c9b6e5b" category="paragraph">도미노 모드가 필요한 경우 NetApp은 SnapMirror Synchronous(SM-S)를 제공합니다. Oracle DataGuard 또는 호스트측 디스크 미러링의 시간 초과와 같은 애플리케이션 레벨 옵션도 있습니다. 자세한 정보와 옵션은 NetApp 또는 파트너 계정 팀에 문의하십시오.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">스냅샷 전용</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">를 클릭합니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> 액티브 파일 시스템과 공유되지 않는 블록에만 적용됩니다. 기본적으로 데이터베이스 백업의 계층화가 이루어집니다. 스냅샷이 생성되고 블록이 덮어써지면 블록이 계층화 대상이 되어 스냅샷 내에만 존재하는 블록이 됩니다. 이전 지연 시간<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 블록은 냉각된 것으로 간주됩니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 볼륨 설정입니다. ONTAP 9.8의 범위는 2-183일입니다.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">많은 데이터 세트의 변경률이 낮기 때문에 이 정책에서의 절약 효과가 최소화됩니다. 예를 들어 ONTAP에서 관찰되는 일반적인 데이터베이스의 변경률은 주당 5% 미만입니다. 데이터베이스 아카이브 로그는 광범위한 공간을 차지할 수 있지만 일반적으로 활성 파일 시스템에 계속 존재하므로 이 정책에 따라 계층화할 대상이 아닙니다.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">자동</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 계층화 정책을 통해 액티브 파일 시스템 내의 블록뿐만 아니라 스냅샷별 블록까지 계층화를 확장할 수 있습니다. 블록이 냉각된 것으로 간주되기 전의 지연은 에 의해 제어됩니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 볼륨 설정입니다. ONTAP 9.8의 범위는 2-183일입니다.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">이 접근 방식을 사용하면 에서 제공되지 않는 계층화 옵션을 사용할 수 있습니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 정책. 예를 들어, 데이터 보호 정책에서는 특정 로그 파일을 90일간 보존해야 할 수 있습니다. 냉각 기간을 3일로 설정하면 3일이 지난 로그 파일이 성능 계층에서 계층화됩니다. 이렇게 하면 성능 계층에서 상당한 공간을 확보하면서 90일 분량의 데이터를 확인하고 관리할 수 있습니다.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">없음</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">를 클릭합니다<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> 계층화 정책을 통해 추가 블록이 스토리지 계층에서 계층화되지 않게 하고, 용량 계층에 있는 데이터는 읽을 때까지 용량 계층에 유지됩니다. 블록이 읽히면 해당 블록을 다시 가져와 성능 계층에 배치합니다.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">을 사용하는 주된 이유<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> 계층화 정책은 블록이 계층화되지 않도록 하는 것이지만 시간이 지남에 따라 정책을 변경하는 것이 유용할 수 있습니다. 예를 들어, 특정 데이터 세트는 용량 계층에 광범위하게 계층화되지만, 전체 성능 기능에 대한 예기치 않은 요구사항이 발생한다고 가정해 보겠습니다. 추가 계층화를 방지하고 입출력이 증가함에 따라 다시 읽히는 모든 블록이 성능 계층에 유지되는지 확인하도록 정책을 변경할 수 있습니다.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">모두</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">를 클릭합니다<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 계층화 정책이 을 대체합니다<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> ONTAP 9.6 기준 정책. 를 클릭합니다<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> 정책은 데이터 보호 볼륨에만 적용됩니다. 즉, SnapMirror 또는 NetApp SnapVault 대상을 의미합니다. 를 클릭합니다<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 정책은 동일하게 작동하지만 데이터 보호 볼륨으로 제한되지 않습니다.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">이 정책을 사용하면 블록이 즉시 쿨 상태로 간주되어 용량 계층에 즉시 계층화할 수 있습니다.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">이 정책은 장기 백업에 특히 적합합니다. HSM(Hierarchical Storage Management)의 한 형태로도 사용할 수 있습니다. 이전에는 HSM을 사용하여 파일 자체를 파일 시스템에 표시하면서 파일의 데이터 블록을 테이프로 계층화했습니다. 를 포함하는 FabricPool 볼륨<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 정책을 사용하면 로컬 스토리지 계층에서 공간을 거의 사용하지 않으면서 표시 가능하고 관리 가능한 상태로 파일을 저장할 수 있습니다.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">조닝</block>
  <block id="79da1502ddfac887bfdf0d92f2428fe6" category="paragraph">여기에는 호스트와 스토리지 시스템 사이에 SAN에 충분한 대역폭이 존재하는지 확인하고, FC 스위치 공급업체에서 요구하는 FC 포트 설정을 사용하여 모든 필수 디바이스 간에 모든 SAN 경로가 존재하는지 확인하는 등의 일반적인 계획 조치가 포함됩니다. ISL 경합 방지 그리고 적절한 SAN 패브릭 모니터링을 사용합니다.</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">FC 존은 하나 이상의 이니시에이터를 포함할 수 없습니다. 이 방식은 처음에는 효과가 있는 것처럼 보이지만 이니시에이터 간 혼선이 결국에는 성능과 안정성을 저하시킵니다.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">여러 공급업체의 FC 타겟 포트 동작이 드물게 문제를 일으키기도 하지만 멀티타겟 존은 일반적으로 안전하다고 간주됩니다. 예를 들어, NetApp와 NetApp이 아닌 스토리지 어레이의 타겟 포트를 같은 존에 포함하지 마십시오. 또한, NetApp 스토리지 시스템과 테이프 장치를 같은 존에 배치하면 문제가 발생할 가능성이 더 높아집니다.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">ONTAP CLI에서 SVM은 스토리지의 기본 기능 단위로서, SVM을 VMware ESX 서버의 게스트에 비교하면 유용합니다.</block>
  <block id="9efbaa34de852e33319ca8ceb1861832" category="paragraph">ESX는 처음 설치했을 때 게스트 운영 체제의 호스팅이나 최종 사용자 애플리케이션 지원 같은 사전 구성된 기능을 제공하지 않으며 가상 머신(VM)이 정의될 때까지는 빈 컨테이너입니다. ONTAP도 비슷합니다. ONTAP를 처음 설치했을 때는 SVM이 생성될 때까지 데이터 제공 기능이 없습니다. 데이터 서비스를 정의하는 것은 SVM의 특성입니다.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">스토리지 아키텍처의 다른 측면과 마찬가지로 SVM 및 논리 인터페이스(LIF) 설계를 위한 최고의 옵션은 확장 요구사항과 비즈니스 요구사항에 크게 의존합니다.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">ONTAP용 SVM 프로비저닝을 위한 공식적인 모범 사례는 없습니다. 올바른 접근 방식은 관리 및 보안 요구 사항에 따라 달라집니다.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">대부분의 고객은 대부분의 일상적인 요구사항을 위해 하나의 1차 SVM을 작동하고, 이후 특별한 요구사항을 위해 소수의 SVM을 생성합니다. 예를 들어 다음을 만들 수 있습니다.</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">전문가 팀이 관리하는 주요 비즈니스 데이터베이스를 위한 SVM</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">자체 스토리지를 독립적으로 관리할 수 있는 전체 제어 권한을 부여받은 개발 그룹을 위한 SVM</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">관리 팀에 액세스 제한이 적용되어야 할 인사 관리 또는 재무 보고 데이터 등 민감한 비즈니스 데이터를 위한 SVM</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe를 참조하십시오</block>
  <block id="bd32656670155eb09690047819fc0971" category="paragraph">멀티 테넌트 환경에서는 각 테넌트의 데이터에 전용 SVM이 제공될 수 있습니다. 클러스터당 SVM 및 LIF 수의 제한은 사용되는 프로토콜, 노드 모델 및 ONTAP 버전에 따라 달라집니다.  을 참조하십시오 <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> 이 제한 사항에 대해 알아보겠습니다.</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">AFF 시스템을 포함한, SSD 애그리게이트</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">여유 공간은 실제 데이터에 사용되지 않는 모든 공간을 의미하며 애그리게이트 자체의 미할당 공간과 구성 볼륨 내의 미사용 공간을 포함합니다. 씬 프로비저닝도 고려해야 합니다. 예를 들어, 볼륨에 1TB LUN이 포함되어 있는데 그 중 50%만 실제 데이터에 의해 사용되고 있습니다. 씬 프로비저닝된 환경에서는 500GB의 공간이 사용되는 것으로 올바르게 표시되지만 완전히 프로비저닝된 환경에서는 1TB의 전체 용량이 사용 중인 것으로 표시되고 할당되지 않은 500GB의 공간은 숨겨집니다. 이 공간은 실제 데이터에 의해 사용되지 않으므로 총 여유 공간 계산 시 포함되어야 합니다.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">엔터프라이즈 애플리케이션에 사용되는 스토리지 시스템에 적용되는 NetApp 권장사항은 다음과 같습니다.</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">* NetApp는 * 최소 10%의 여유 공간을 권장합니다. 여기에는 애그리게이트 또는 볼륨 내 여유 공간은 물론, 완전 프로비저닝 사용으로 인해 할당은 되었으나 실제 데이터에 의해 사용되지 않고 있는 여유 공간을 포함해 모든 미사용 공간이 포함됩니다. 논리적 공간은 중요하지 않습니다. 문제는 데이터 스토리지에 사용할 수 있는 실제 사용 가능한 물리적 공간의 양입니다.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">10%의 여유 공간은 보수적인 권장사항입니다. SSD 애그리게이트는 활용률 수준이 높을 때에도 성능에 영향을 주지 않고 워크로드를 지원할 수 있습니다. 하지만 활용률을 신중하게 모니터링하지 않으면 애그리게이트의 활용률이 높아질수록 공간이 소진될 위험도 높아집니다. 또한 99% 용량으로 시스템을 실행하는 경우 성능 저하가 발생하지 않지만, 추가 하드웨어를 주문하는 동안 시스템이 완전히 채워지지 않도록 관리 노력이 필요하며, 추가 드라이브를 구입하고 설치하는 데 시간이 걸릴 수 있습니다.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Flash Pool 애그리게이트를 포함한, HDD 애그리게이트</block>
  <block id="7302e9f16fb8c5bc30f6035fe4098b52" category="admonition">*NetApp는 회전식 드라이브를 사용할 때 최소 15%의 여유 공간을 사용할 것을 권장합니다. 여기에는 애그리게이트 또는 볼륨 내 여유 공간은 물론, 완전 프로비저닝 사용으로 인해 할당은 되었으나 실제 데이터에 의해 사용되지 않고 있는 여유 공간을 포함해 모든 미사용 공간이 포함됩니다. 10%에 달하는 자유 음성이 성능에 영향을 미칩니다.</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 정책은 백업 데이터에 가장 적합한 정책입니다. 이렇게 하면 파일이 삭제되었거나 운영 파일 시스템에 계속 존재하는지에 관계없이 냉각 임계값에 도달한 경우 프롬프트 계층화가 보장됩니다. 액티브 파일 시스템의 한 위치에 잠재적으로 필요한 모든 파일을 저장하면 관리가 간편해집니다. 복원해야 하는 파일을 찾기 위해 스냅샷을 검색할 이유가 없습니다.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">를 클릭합니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 정책을 적용할 수 있지만 이 정책은 더 이상 액티브 파일 시스템에 없는 블록에만 적용됩니다. 따라서 데이터를 계층화하기 전에 NFS 또는 SMB 공유의 파일을 먼저 삭제해야 합니다.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">LUN에서 파일을 삭제하면 파일 시스템 메타데이터에서 파일 참조만 제거되기 때문에 이 정책은 LUN 구성에서는 훨씬 효율적입니다. LUN의 실제 블록은 덮어쓸 때까지 그대로 유지됩니다. 이 경우 파일이 삭제된 시간과 블록이 덮어써지고 계층화 대상이 되는 시간 사이에 긴 지연이 발생할 수 있습니다. 을(를) 옮기면 몇 가지 이점이 있습니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 블록을 용량 계층으로 이동하지만 백업 데이터의 FabricPool 관리는 에서 가장 잘 작동합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 정책.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">이러한 접근 방식은 사용자가 백업에 필요한 공간을 보다 효율적으로 관리하는 데 도움이 되지만 FabricPool 자체는 백업 기술이 아닙니다. 백업 파일을 오브젝트 저장소로 계층화하면 파일이 원래 스토리지 시스템에 계속 표시되지만 오브젝트 저장소 대상의 데이터 블록은 원본 스토리지 시스템에 따라 다르므로 관리가 간소화됩니다. 소스 볼륨이 손실되면 오브젝트 저장소 데이터를 더 이상 사용할 수 없습니다.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">ONTAP 시스템에서 스토리지는 4KB 장치로 구성됩니다. 데이터베이스 또는 파일 시스템 8KB 블록은 정확히 2개의 4KB 블록에 매핑되어야 합니다. LUN 구성 오류로 인해 정렬이 어느 방향으로든 1KB 이동되면 각 8KB 블록은 2개가 아닌 3개의 서로 다른 4KB 스토리지 블록에 존재하게 됩니다. 이 방식은 스토리지 시스템 내에서 지연 시간이 늘어나고 추가적인 I/O가 수행되도록 합니다.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">정렬은 LVM 아키텍처에도 영향을 미칩니다. 논리적 볼륨 그룹 내의 물리적 볼륨은 전체 드라이브 장치에서 정의되며(생성되는 파티션 없음), LUN의 첫 번째 4KB 블록이 스토리지 시스템의 첫 번째 4KB 블록에 맞춰 정렬됩니다. 이것이 올바른 정렬입니다. 문제는 파티션에서 발생하는데, 운영 체제가 LUN을 사용하는 시작 위치를 파티션이 바꾸기 때문입니다. 오프셋이 4KB 단위로 이동하는 한 LUN은 정렬됩니다.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">Linux 환경에서는 전체 드라이브 장치에 논리적 볼륨 그룹이 구축됩니다. 파티션이 필요하면 를 실행하여 정렬을 점검합니다<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> 각 파티션의 시작이 8의 배수인지 확인합니다. 이는 8개의 512바이트 섹터를 곱한 값인 4KB에서 파티션이 시작된다는 뜻입니다.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">사이트 장애 방지: NVRAM 및 MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster는 NVRAM 데이터 보호를 다음과 같은 방식으로 확장합니다.</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">2노드 구성에서는 ISL(Inter-Switch Link)을 사용하여 NVRAM 데이터를 원격 파트너에게 복제합니다.</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">HA 쌍 구성에서는 NVRAM 데이터가 로컬 파트너와 원격 파트너 모두에 복제됩니다.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">쓰기가 모든 파트너에게 복제될 때까지 확인되지 않습니다. 이 아키텍처는 NVRAM 데이터를 원격 파트너에게 복제하여 전송 중인 I/O를 사이트 장애로부터 보호합니다. 이 프로세스는 드라이브 수준 데이터 복제와 관련되지 않습니다. 애그리게이트를 소유한 컨트롤러는 애그리게이트의 두 플렉스에 쓰기를 통해 데이터 복제를 담당하지만, 사이트 손실 시 전송 중인 I/O 손실에 대한 보호가 여전히 필요합니다. 복제된 NVRAM 데이터는 파트너 컨트롤러가 장애가 발생한 컨트롤러를 인수해야 하는 경우에만 사용됩니다.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">사이트 및 쉘프 장애 보호: SyncMirror 및 플렉스</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror는 RAID DP 또는 RAID-TEC를 향상하지만 대체하지는 않는 미러링 기술입니다. 2개의 독립적인 RAID 그룹의 콘텐츠를 미러링합니다. 논리적 구성은 다음과 같습니다.</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">드라이브는 위치에 따라 두 개의 풀로 구성됩니다. 하나의 풀은 사이트 A의 모든 드라이브로 구성되고, 두 번째 풀은 사이트 B의 모든 드라이브로 구성됩니다</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">그런 다음 애그리게이트라고 하는 공통 스토리지 풀이 RAID 그룹의 미러링된 세트를 기반으로 생성됩니다. 각 사이트에서 동일한 수의 드라이브가 그려집니다. 예를 들어, 20개 드라이브로 구성된 SyncMirror 애그리게이트는 사이트 A의 드라이브 10개와 사이트 B의 드라이브 10개로 구성됩니다</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">특정 사이트의 각 드라이브 세트는 미러링 사용과 상관없이 하나 이상의 완전히 이중화된 RAID DP 또는 RAID-TEC 그룹으로 자동으로 구성됩니다. 이와 같이 미러링에서 RAID를 사용하면 사이트 손실 후에도 데이터를 보호할 수 있습니다.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">위 그림은 SyncMirror 구성의 예를 보여 줍니다. 24-드라이브 애그리게이트가 사이트 A에 할당된 쉘프의 드라이브 12개와 사이트 B에 할당된 쉘프의 드라이브 12개로 컨트롤러에서 생성되었습니다 드라이브는 두 개의 미러링된 RAID 그룹으로 그룹화되었습니다. RAID 그룹 0에는 사이트 A의 6개 드라이브 플렉스가 사이트 B의 6개 드라이브 플렉스에 미러링됩니다 마찬가지로, RAID 그룹 1에는 사이트 A의 6개 드라이브 플렉스가 사이트 B의 6개 드라이브 플렉스에 미러링됩니다</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">SyncMirror는 일반적으로 각 사이트에 하나의 데이터 복사본으로 MetroCluster 시스템에 원격 미러링을 제공하는 데 사용됩니다. 경우에 따라 단일 시스템에서 추가 수준의 이중화를 제공하기 위해 사용되었습니다. 특히, 쉘프 레벨 이중화를 제공합니다. 드라이브 쉘프에는 이미 이중 전원 공급 장치와 컨트롤러가 포함되어 있으며 전반적으로 판금보다 조금 더 크지만, 경우에 따라 추가 보호가 필요할 수 있습니다. 예를 들어, 한 NetApp 고객은 자동차 테스트에 사용되는 모바일 실시간 분석 플랫폼용 SyncMirror를 구축했습니다. 시스템은 독립적인 전원 공급 장치와 독립적인 UPS 시스템이 함께 제공되는 두 개의 물리적 랙으로 분리되었습니다.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">이중화 실패: NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">앞서 설명한 것처럼, 쓰기는 하나 이상의 다른 컨트롤러에서 로컬 NVRAM 및 NVRAM에 로그인되기 전까지는 승인되지 않습니다. 이렇게 하면 하드웨어 장애나 정전이 발생해도 전송 중인 I/O가 손실되지 않습니다 로컬 NVRAM에 장애가 발생하거나 다른 노드에 대한 연결이 실패하면 데이터가 더 이상 미러링되지 않습니다.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">제어 요소는 NVRAM의 동기화 여부입니다. NVRAM이 동기화되면 데이터 손실 위험 없이 노드 간 페일오버를 안전하게 수행할 수 있습니다. MetroCluster 구성에서 NVRAM 및 기본 애그리게이트 플렉스가 동기화되어 있는 경우 데이터 손실의 위험 없이 전환을 진행해도 안전합니다.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">데이터베이스와 기타 애플리케이션은 디스크에 더 큰 내부 데이터 캐시를 유지하기 때문에 페일오버나 스위치오버가 강제 적용되는 경우 손상에 특히 취약합니다. 강제 적용 페일오버 또는 스위치오버가 발생하면 이전에 승인되었던 변경사항이 효과적으로 폐기됩니다. 스토리지 어레이의 콘텐츠가 사실상 이전 시간으로 이동하며, 캐시의 상태는 디스크에 있는 데이터의 상태를 더 이상 반영하지 않습니다.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">이러한 상황을 방지하기 위해 ONTAP에서는 NVRAM 장애에 대한 특별 보호를 위해 볼륨을 구성할 수 있습니다. 이 보호 메커니즘이 트리거되면 볼륨이 NVFAIL이라는 상태로 전환됩니다. 이 상태에서는 애플리케이션 충돌을 일으키는 I/O 오류가 발생합니다. 이 충돌로 인해 애플리케이션이 종료되어 오래된 데이터를 사용하지 않습니다. 커밋된 트랜잭션 데이터가 로그에 있어야 하므로 데이터가 손실되지 않아야 합니다. 일반적인 다음 단계는 관리자가 LUN 및 볼륨을 수동으로 다시 온라인 상태로 전환하기 전에 호스트를 완전히 종료하는 것입니다. 이러한 단계에는 일부 작업이 포함될 수 있지만 이 접근 방식은 데이터 무결성을 보장하는 가장 안전한 방법입니다. 모든 데이터에 이 보호가 필요한 것은 아니므로 NVFAIL 동작을 볼륨별로 구성할 수 있습니다.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">HA Pair 및 MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster는 2노드 및 HA 쌍의 2가지 구성으로 사용할 수 있습니다. 2노드 구성은 NVRAM에 관한 HA 쌍과 동일하게 동작합니다. 갑작스러운 장애가 발생하는 경우 파트너 노드는 NVRAM 데이터를 재생하여 드라이브의 일관성을 유지하고 확인된 쓰기가 손실되지 않도록 할 수 있습니다.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">HA 쌍 구성은 NVRAM을 로컬 파트너 노드에 복제합니다. 컨트롤러 장애가 발생하면 MetroCluster 없이 독립 실행형 HA 쌍을 지원하는 경우처럼, 단순한 컨트롤러 장애가 파트너 노드에서 NVRAM이 재생됩니다. 갑작스러운 전체 사이트 손실이 발생하는 경우 원격 사이트에는 드라이브 일관성을 유지하고 데이터 제공을 시작하는 데 필요한 NVRAM이 있습니다.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">MetroCluster의 한 가지 중요한 측면은 원격 노드가 정상적인 운영 조건에서는 파트너 데이터에 액세스할 수 없다는 것입니다. 각 사이트는 기본적으로 반대편의 사이트의 성격을 상정할 수 있는 독립적인 시스템으로서 기능한다. 이 프로세스를 스위치오버라고 하며 계획된 스위치오버를 포함합니다. 사이트 운영이 반대편 사이트로 중단 없이 마이그레이션됩니다. 또한, 재해 복구의 일부로 사이트가 손실되고 수동 또는 자동 전환이 필요한 계획되지 않은 상황이 포함됩니다.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">전환 및 스위치백</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">스위치오버 및 스위치백이란 MetroCluster 구성에서 원격 컨트롤러 간에 볼륨을 전환하는 프로세스를 의미합니다. 이 프로세스는 원격 노드에만 적용됩니다. MetroCluster를 4 볼륨 구성으로 사용할 경우 로컬 노드 페일오버는 앞에서 설명한 테이크오버 및 반환 프로세스가 동일합니다.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">계획된 전환 및 스위치백</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">계획된 스위치오버 또는 스위치백은 노드 간의 테이크오버 또는 반환과 비슷합니다. 이 프로세스에는 여러 단계가 있으며 몇 분이 소요되는 것처럼 보일 수 있지만 실제로 발생하는 것은 스토리지 및 네트워크 리소스의 다중 위상 원활한 전환입니다. 제어 전송이 전체 명령을 실행하는 데 필요한 시간보다 훨씬 빠르게 발생하는 순간입니다.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">Takeover/Giveback과 스위치오버/스위치백 간의 주된 차이점은 FC SAN 연결에 영향을 미치는 것입니다. 로컬 테이크오버/반환을 사용하면 호스트에서 로컬 노드에 대한 모든 FC 경로가 손실되고 네이티브 MPIO에 의존하여 사용 가능한 대체 경로로 변경됩니다. 포트는 재배치되지 않습니다. 스위치오버 및 스위치백을 사용하면 컨트롤러의 가상 FC 타겟 포트가 다른 사이트로 전환됩니다. 이러한 애플리케이션은 사실상 SAN에 잠시 존재하지 않게 된 다음 대체 컨트롤러에 다시 나타납니다.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">SyncMirror 시간 초과</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror는 쉘프 장애로부터 보호하는 ONTAP 미러링 기술입니다. 쉘프가 거리를 두고 분리되면 데이터를 원격으로 보호할 수 있습니다.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror는 범용 동기식 미러링을 제공하지 않습니다. 결과적으로 가용성이 향상됩니다. 일부 스토리지 시스템은 도미노 모드라고도 하는 일정한 전체 또는 무관 미러링을 사용합니다. 이러한 형태의 미러링은 원격 사이트에 대한 연결이 끊긴 경우 모든 쓰기 작업이 중단되어야 하므로 응용 프로그램에서 제한됩니다. 그렇지 않으면 한 사이트에 쓰기가 존재하지만 다른 사이트에는 쓰기가 존재하지 않습니다. 일반적으로 이러한 환경은 30초 이상 사이트와 사이트 간의 연결이 끊긴 경우 LUN을 오프라인 상태로 전환하도록 구성됩니다.</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">이 동작은 일부 환경의 하위 집합에 적합합니다. 그러나 대부분의 애플리케이션은 정상적인 작동 조건에서 동기식 복제를 보장하지만 복제를 일시 중지할 수 있는 솔루션이 필요합니다. 사이트 간 연결의 완전한 손실은 주로 재해에 가까운 상황으로 간주됩니다. 일반적으로 이러한 환경은 연결이 복구되거나 데이터 보호를 위해 환경을 종료하기로 결정할 때까지 온라인 상태로 유지되고 데이터를 제공합니다. 순수하게 원격 복제 실패로 인해 애플리케이션을 자동으로 종료해야 하는 요구사항은 특이합니다.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror는 시간 초과 방식의 유연성으로 동기식 미러링 요구사항을 지원합니다. 조종기 및/또는 플렉스에 대한 연결이 끊기면 30초 타이머가 카운트 다운을 시작합니다. 카운터가 0에 도달하면 로컬 데이터를 사용하여 쓰기 입출력 처리가 재개됩니다. 데이터의 원격 복제본을 사용할 수 있지만 연결이 복원될 때까지 시간이 지나면 동결됩니다. 재동기화는 애그리게이트 레벨 스냅샷을 활용하여 가능한 한 빨리 시스템을 동기식 모드로 되돌립니다.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">특히 대부분의 경우 이러한 종류의 범용 전체 또는 무관 도미노 모드 복제는 애플리케이션 계층에서 더 잘 구현됩니다. 예를 들어 Oracle DataGuard에는 모든 상황에서 장기 인스턴스 복제를 보장하는 최대 보호 모드가 포함되어 있습니다. 구성 가능한 시간 제한을 초과하는 기간 동안 복제 링크가 실패하면 데이터베이스가 종료됩니다.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">패브릭 연결 MetroCluster를 통한 자동 무인 전환</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">자동 무인 전환(AUSO)은 크로스 사이트 HA의 형태를 제공하는 패브릭 연결 MetroCluster 기능입니다. 앞서 설명했듯이, MetroCluster는 각 사이트의 단일 컨트롤러 또는 각 사이트의 HA 쌍 두 가지로 사용할 수 있습니다. HA 옵션의 주요 이점은 계획되었거나 계획되지 않은 컨트롤러 종료를 통해 모든 I/O를 로컬에 둘 수 있다는 것입니다. 단일 노드 옵션의 이점은 비용, 복잡성 및 인프라의 감소입니다.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">AUSO의 주요 가치는 Fabric Attached MetroCluster 시스템의 HA 기능을 개선하는 것입니다. 각 사이트가 반대 사이트의 상태를 모니터링하며, 데이터를 제공할 노드가 남아 있지 않으면 AUSO로 인해 빠른 전환이 발생합니다. 이 접근 방식은 가용성 측면에서 구성이 HA 쌍에 더 가깝게 배치되기 때문에 사이트당 단일 노드만을 사용하는 MetroCluster 구성에서 특히 유용합니다.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO는 HA 쌍 수준에서 포괄적인 모니터링을 제공할 수 없습니다. HA 쌍은 노드 간 직접 통신을 위한 이중화 물리적 케이블 2개가 포함되어 있기 때문에 매우 높은 가용성을 제공할 수 있습니다. 또한 HA 쌍의 두 노드는 이중 루프의 동일한 디스크 세트에 액세스할 수 있어, 한 노드에서 다른 노드의 상태를 모니터링할 수 있는 또 다른 경로를 제공합니다.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">MetroCluster 클러스터는 사이트 간 네트워크 연결을 통해 노드 간 통신과 디스크 액세스가 모두 필요한 사이트 전체에 존재합니다. 클러스터의 나머지 하트비트를 모니터링하는 기능은 제한되어 있습니다. AUSO는 네트워크 문제로 인해 다른 사이트가 사용할 수 없는 상황이 아니라 실제로 다운된 상황을 구분해야 합니다.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">그 결과, HA 쌍의 컨트롤러에서 시스템 패닉 같은 특정 이유로 컨트롤러 장애를 감지하면 테이크오버를 프롬프트 상태가 될 수 있습니다. 또한 하트비트 손실이라고도 하는 연결이 완전히 끊긴 경우 Takeover를 프롬프트할 수도 있습니다.</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">MetroCluster 시스템은 원래 사이트에서 특정 장애가 감지되는 경우에만 자동 전환을 안전하게 수행할 수 있습니다. 또한 스토리지 시스템의 소유권을 가져오는 컨트롤러는 디스크 및 NVRAM 데이터의 동기화를 보장할 수 있어야 합니다. 컨트롤러는 여전히 작동 가능한 소스 사이트와의 접촉이 끊겼다는 이유로 스위치오버의 안전을 보장할 수 없습니다. 스위치오버 자동화를 위한 추가 옵션은 다음 섹션에서 MetroCluster Tiebreaker(MCTB) 솔루션에 관한 정보를 참조하십시오.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">패브릭 연결 MetroCluster가 포함된 MetroCluster Tiebreaker</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">NetApp MetroCluster Tiebreaker의 약어입니다</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">NetApp Support 사이트</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">를 클릭합니다<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> 소프트웨어를 세 번째 사이트에서 실행하여 MetroCluster 환경의 상태를 모니터링하고, 알림을 보내고, 재해 상황에서 선택적으로 스위치오버를 수행할 수 있습니다. 타이브레이커에 대한 자세한 설명은 에서 확인할 수 있습니다<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>하지만 MetroCluster Tiebreaker의 주요 목적은 사이트 손실을 감지하는 것입니다. 또한 사이트 손실과 연결 손실 간에 구분해야 합니다. 예를 들어, Tiebreaker가 운영 사이트에 연결할 수 없기 때문에 전환이 발생하지 않아야 합니다. 따라서 Tiebreaker는 원격 사이트의 운영 사이트 접속 기능을 모니터링합니다.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">AUSO를 통한 자동 절체는 MCTB와도 호환됩니다. AUSO는 특정 장애 이벤트를 감지한 다음 NVRAM 및 SyncMirror 플렉스가 동기화되어 있는 경우에만 스위치오버를 호출하도록 설계되었기 때문에 매우 빠르게 대응합니다.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">반대로 타이브레이커는 원격으로 위치하므로 타이머가 경과할 때까지 기다린 후 사이트를 비활성화해야 합니다. Tiebreaker는 결국 AUSO에 포함된 일종의 컨트롤러 장애를 감지하지만, 일반적으로 AUSO는 이미 전환을 시작하고 Tiebreaker가 작동하기 전에 전환을 완료했을 수 있습니다. Tiebreaker에서 생성된 두 번째 switchover 명령은 거부됩니다.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">* 주의: * MCTB 소프트웨어는 전환을 강제 적용할 때 NVRAM이 동기화되었는지 또는 플렉스가 동기화되었는지 확인하지 않습니다. 자동 전환이 구성된 경우 유지 관리 활동 중에 NVRAM 또는 SyncMirror 플렉스의 동기화가 손실되는 것을 방지해야 합니다.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">또한 MCTB는 지속적인 재해를 처리하지 못해 다음과 같은 일련의 이벤트가 발생할 수 있습니다.</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">사이트 간 연결이 30초 이상 중단됩니다.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">SyncMirror 복제 시간이 초과되고 운영 사이트에서 작업이 계속되어 원격 복제본이 오래된 상태로 남습니다.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">기본 사이트가 손실되어 기본 사이트에 복제되지 않은 변경 내용이 있습니다. 이렇게 하면 다음과 같은 여러 가지 이유로 전환이 바람직하지 않을 수 있습니다.</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">기본 사이트에 중요 데이터가 있을 수 있으며 이 경우 해당 데이터를 복구할 수 있습니다. 애플리케이션의 지속적인 운영을 허용한 전환은 중요 데이터를 효과적으로 폐기합니다.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">사이트 손실 시 기본 사이트의 스토리지 리소스를 사용 중이던 정상적인 사이트의 애플리케이션이 데이터를 캐싱했을 수 있습니다. 스위치오버로 인해 캐시와 일치하지 않는 오래된 데이터가 생성됩니다.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">사이트 손실 시 기본 사이트의 스토리지 리소스를 사용하고 있었던 정상적인 사이트의 운영 체제에서는 데이터가 캐시되었을 수 있습니다. 스위치오버로 인해 캐시와 일치하지 않는 오래된 데이터가 생성됩니다. 가장 안전한 옵션은 사이트 장애가 감지되면 알림을 보내도록 Tiebreaker를 구성한 다음 사람이 전환을 강제 적용할 것인지 여부를 결정하도록 하는 것입니다. 캐시된 데이터를 지우려면 먼저 응용 프로그램 및/또는 운영 체제를 종료해야 할 수 있습니다. 또한 NVFAIL 설정을 사용하여 보호 기능을 추가하고 장애 조치 프로세스를 간소화할 수 있습니다.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">MetroCluster IP를 사용하는 ONTAP 중재자</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">ONTAP mediator는 MetroCluster IP 및 기타 특정 ONTAP 솔루션과 함께 사용됩니다. 위에서 설명한 MetroCluster Tiebreaker 소프트웨어와 마찬가지로 기존 Tiebreaker 서비스 역할을 하지만 자동 자동 전환을 수행하는 중요한 기능도 포함되어 있습니다.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">패브릭이 연결된 MetroCluster는 반대쪽 사이트의 스토리지 장치에 직접 액세스할 수 있습니다. 이를 통해 한 MetroCluster 컨트롤러가 드라이브에서 하트비트 데이터를 읽어 다른 컨트롤러의 상태를 모니터링할 수 있습니다. 이를 통해 한 컨트롤러가 다른 컨트롤러의 장애를 인식하고 전환을 수행할 수 있습니다.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">반면, MetroCluster IP 아키텍처는 컨트롤러-컨트롤러 연결을 통해서만 모든 I/O를 라우팅하며, 원격 사이트의 스토리지 장치에 직접 액세스할 수 없습니다. 이로 인해 컨트롤러가 장애를 감지하고 스위치오버를 수행할 수 없게 됩니다. 따라서 사이트 손실을 감지하고 자동으로 전환을 수행하기 위한 Tiebreaker 장치로 ONTAP 중재자가 필요합니다.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">ClusterLion이 포함된 가상 3번째 사이트</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion은 가상 3차 사이트로 작동하는 고급 MetroCluster 모니터링 어플라이언스입니다. 이 접근 방식을 통해 MetroCluster는 완전 자동화된 스위치오버 기능을 통해 2개 사이트 구성으로 안전하게 구축할 수 있습니다. 또한 ClusterLion은 추가 네트워크 수준 모니터를 수행하고 전환 후 작업을 실행할 수 있습니다. ProLion에서 전체 문서를 다운로드할 수 있습니다.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">ClusterLion 어플라이언스는 이더넷 및 직렬 케이블을 직접 연결하여 컨트롤러의 상태를 모니터링합니다.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">이 두 장비는 이중화 3G 무선 연결을 통해 서로 연결됩니다.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">ONTAP 컨트롤러의 전원은 내부 릴레이를 통해 배선됩니다. 사이트 장애가 발생할 경우 내부 UPS 시스템이 포함된 ClusterLion은 전환을 호출하기 전에 전원 연결을 끊습니다. 이 과정을 통해 브레인 분할 상태가 발생하지 않도록 합니다.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion은 30초 SyncMirror 타임아웃 내에 전환을 수행하거나 전혀 전환하지 않습니다.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">NVRAM 및 SyncMirror 플렉스의 상태가 동기화되어 있지 않으면 ClusterLion은 전환을 수행하지 않습니다.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">ClusterLion은 MetroCluster가 완전히 동기화된 경우에만 전환을 수행하기 때문에 NVFAIL은 필요하지 않습니다. 이렇게 구성하면 확장된 Oracle RAC와 같은 사이트 확장 환경이 계획되지 않은 전환 중에도 온라인 상태를 유지할 수 있습니다.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">여기에는 패브릭 연결 MetroCluster 및 MetroCluster IP가 모두 포함됩니다</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">정상 작동</block>
  <block id="16dd4928055f2caf6f6fb8119ef69bcc" category="paragraph">SM-BC는 두 가지 유형의 스토리지 페일오버 작업, 즉 계획된 작업과 계획되지 않은 작업을 지원하며, 이는 약간 다른 방식으로 작동합니다. 계획된 페일오버는 관리자가 원격 사이트로 빠르게 전환하기 위해 수동으로 시작하는 반면, 계획되지 않은 페일오버는 3차 사이트의 중재자가 자동으로 시작합니다. 계획된 페일오버의 주된 목적은 증분 패치 적용 및 업그레이드를 수행하고, 재해 복구 테스트를 수행하거나, 전체 비즈니스 연속성 기능을 검증하기 위해 1년 내내 사이트 간 운영을 전환하는 공식적인 정책을 채택하는 것입니다.</block>
  <block id="63d4f976530f4faffa1ecd40fe8843f4" category="paragraph">이 다이어그램은 정상, 장애 조치 및 장애 복구 작업 중에 발생하는 상황을 보여 줍니다. 쉽게 이해할 수 있도록 복제된 LUN을 설명합니다. 실제 SM-BC 구성에서는 각 볼륨에 하나 이상의 LUN이 포함되어 있는 볼륨을 기반으로 복제가 수행되지만 그림을 더 간단하게 만들기 위해 볼륨 계층이 제거되었습니다.</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">정상 작동 시 로컬 또는 원격 복제본에서 LUN에 액세스할 수 있습니다. 빨간색 선은 ALUA에서 광고한 최적화된 경로를 나타내며, 그 결과 입출력이 이 경로를 통해 우선적으로 전송되어야 합니다.</block>
  <block id="ef1d805ecb3b65664c42a1d32d8120d5" category="paragraph">녹색 선은 활성 경로이지만 해당 경로의 입출력이 SM-BC 경로를 통해 전달되어야 하므로 지연 시간이 더 많이 발생합니다. 추가 지연 시간은 SM-BC에 사용되는 사이트 간 상호 연결 속도에 따라 달라집니다.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">실패</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">계획되거나 계획되지 않은 페일오버 때문에 액티브 미러 복사본을 사용할 수 없게 되면 더 이상 사용할 수 없게 됩니다. 그러나 원격 시스템에는 동기식 복제본이 있고 원격 사이트에 대한 SAN 경로가 이미 존재합니다. 원격 시스템에서 해당 LUN에 대한 IO를 처리할 수 있습니다.</block>
  <block id="89a4933a199f7b0e286c8bcb1606905a" category="paragraph">원격 복제본이 즉시 사용되는지 여부는 SM-BC가 Sync 또는 StrictSync 모드로 작동되는지 여부에 따라 달라집니다.</block>
  <block id="af43c542f512c4f7dc1b137d5de49d40" category="paragraph"><block ref="af43c542f512c4f7dc1b137d5de49d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">페일오버</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">페일오버하면 원격 복제본이 활성 복제본이 됩니다. 경로가 Active에서 Active/Optimized로 변경되고 IO는 데이터 손실 없이 계속 처리됩니다.</block>
  <block id="52da4ea35ba60090f331eefab5d6c612" category="paragraph"><block ref="52da4ea35ba60090f331eefab5d6c612" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">복구</block>
  <block id="4f125c91283d9dc1751ad99a7a171420" category="paragraph">소스 시스템이 서비스로 반환되면 SM-BC는 복제를 다시 동기화하지만 다른 방향을 실행할 수 있습니다. 이제 이 구성은 기본적으로 시작점과 동일하지만 활성 미러 사이트가 대칭 이동된 경우는 예외입니다.</block>
  <block id="5c647f57a104a05d7d8b55d089efefbe" category="paragraph"><block ref="5c647f57a104a05d7d8b55d089efefbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">장애 복구</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">필요한 경우 관리자는 페일백을 수행한 후 LUN의 활성 복사본을 원래 컨트롤러로 다시 이동할 수 있습니다.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">데이터베이스 재실행/트랜잭션 로깅은 일반적으로 정렬되지 않은 I/O를 생성하여 ONTAP에서 정렬 불량 LUN과 관련된 경고를 야기할 수 있으며 이는 사용자를 호도할 수 있습니다.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">로깅은 다양한 크기의 쓰기로 로그 파일의 순차적 쓰기를 수행합니다. 4KB 경계에 맞춰 정렬되지 않는 로그 쓰기 작업은 일반적으로 성능 문제를 야기하지 않는데 다음 로그 쓰기 작업에서 블록이 완료되기 때문입니다. 결과적으로 4KB 블록이 완료되면 ONTAP은 거의 모든 쓰기를 처리할 수 있으며, 이는 일부 4KB 블록의 데이터가 2개의 개별 작업으로 작성되었더라도 마찬가지입니다.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">WAFL 정렬 확인</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">과 같은 유틸리티를 사용하여 정렬을 확인합니다<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> 또는<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 이를 통해 정의된 블록 크기로 I/O를 생성할 수 있습니다. 스토리지 시스템의 I/O 정렬 통계는 를 에서 확인할 수 있습니다<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> 명령. 을 참조하십시오 <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">대부분의 애플리케이션 데이터 세트는 날짜별로 구성되며 이러한 데이터가 대개 노후화되면 데이터에 액세스할 가능성이 더 적습니다. 예를 들어 은행에는 5년간의 고객 명세서가 포함된 PDF 파일 저장소가 있을 수 있지만 최근 몇 달만 활성 상태입니다. FabricPool를 사용하여 기존 데이터 파일을 용량 계층으로 재배치할 수 있습니다. 14일의 냉각 기간을 사용하면 더 최근의 14일 PDF 파일을 성능 계층에 유지할 수 있습니다. 또한 최소 14일마다 읽히는 파일은 핫 상태로 유지되므로 성능 계층에 유지됩니다.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">파일 기반 계층화 방식을 구현하려면 기록되고 이후에 수정되지 않는 파일이 있어야 합니다. 를 클릭합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 필요한 파일이 성능 계층에 유지되도록 정책을 충분히 높게 설정해야 합니다. 예를 들어, 최적의 성능을 위해 최근 60일간의 데이터 세트가 필요한 경우 로 설정된 것입니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 60까지. 파일 액세스 패턴을 기준으로 비슷한 결과를 얻을 수도 있습니다. 예를 들어, 최근 90일 동안의 데이터가 필요하고 애플리케이션에서 90일 동안의 데이터에 액세스하는 경우 데이터는 성능 계층에 유지됩니다. 를 설정합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 마침표 2를 사용하면 데이터의 활성 상태가 감소된 후에 곧바로 계층화할 수 있습니다.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">데이터에 대한 모든 액세스 유형은 열 지도 데이터를 재설정합니다. 바이러스 검사, 인덱싱, 심지어 소스 파일을 읽는 백업 활동으로 인해 계층화가 방지됩니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 임계값에 도달하지 않았습니다.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">기본값</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">모든 FabricPool 볼륨은 처음에 에서 설정됩니다<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>즉, 클라우드 검색 정책에 의해 동작이 제어됩니다. 정확한 동작은 사용된 계층화 정책에 따라 다릅니다.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– 임의로 읽은 데이터만 검색합니다</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– 순차 또는 임의로 읽은 데이터를 모두 검색합니다</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– 순차 또는 임의로 읽은 데이터를 모두 검색합니다</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>용량 계층에서 데이터를 검색하지 마십시오</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">온리드</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">설정<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> On-read를 선택하면 기본 동작이 재정의되므로 계층화된 데이터를 읽으면 해당 데이터가 성능 계층으로 반환됩니다.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">예를 들어, 볼륨을 오랫동안 가볍게 사용한 적이 있을 수 있습니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 계층화 정책과 대부분의 블록이 이제 계층화됩니다.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">예상치 못한 비즈니스 요구 사항이 변화함에 따라 특정 보고서를 준비하기 위해 일부 데이터를 반복적으로 스캔해야 하는 경우 를 변경하는 것이 바람직할 수 있습니다<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> 순차 및 랜덤 읽기 데이터를 모두 포함하여 읽히는 모든 데이터가 성능 계층으로 반환되도록 합니다. 이렇게 하면 볼륨에 대한 순차적 I/O 성능이 향상됩니다.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">승격</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">상향 이동 정책의 동작은 계층화 정책에 따라 다릅니다. 계층화 정책이 인 경우<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>를 선택한 다음 를 설정합니다<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> 다음 계층화 스캔 시 용량 계층의 모든 블록을 되돌립니다.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">계층화 정책이 인 경우<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>그리고 반환되는 유일한 블록은 액티브 파일 시스템과 연결된 블록입니다. 일반적으로 에서 계층화된 유일한 블록은 영향을 미치지 않습니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 정책은 스냅샷과 독점적으로 연결된 블록입니다. 액티브 파일 시스템에는 계층화된 블록이 없습니다.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">하지만 볼륨의 SnapRestore 또는 스냅샷의 파일 클론 작업에 의해 볼륨의 데이터가 복원된 경우 스냅샷에만 연결되기 때문에 계층화된 일부 블록이 이제 액티브 파일 시스템에 필요할 수 있습니다. 를 일시적으로 변경하는 것이 바람직할 수 있습니다<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> 정책 적용 대상<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> 로컬에 필요한 모든 블록을 신속하게 검색</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">안 함</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">용량 계층에서 블록을 검색하지 마십시오.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">있습니다</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool는 블록을 핫 또는 쿨 블록으로 분류하여 가장 적절한 스토리지 계층에 배치하는 계층화 기술입니다. 성능 계층은 가장 일반적으로 SSD 스토리지에 배치되며 핫 데이터 블록을 호스팅합니다. 용량 계층은 오브젝트 저장소에 있으며 쿨 데이터 블록을 호스팅합니다. 오브젝트 스토리지 지원에는 NetApp StorageGRID, ONTAP S3, Microsoft Azure Blob 스토리지, Alibaba 클라우드 오브젝트 스토리지 서비스, IBM 클라우드 오브젝트 스토리지, Google Cloud 스토리지, Amazon AWS S3가 포함됩니다.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">여러 계층화 정책을 사용하여 블록의 핫 또는 쿨 분류 방식을 제어하고, 볼륨별로 정책을 설정하고 필요에 따라 변경할 수 있습니다. 성능 계층과 용량 계층 간에는 데이터 블록만 이동됩니다. LUN 및 파일 시스템 구조를 정의하는 메타데이터는 항상 성능 계층에 유지됩니다. 결과적으로 관리가 ONTAP에서 중앙 집중화됩니다. 파일 및 LUN은 다른 ONTAP 구성에 저장된 데이터와 다르지 않습니다. NetApp AFF 또는 FAS 컨트롤러는 정의된 정책을 적용하여 데이터를 적절한 계층으로 이동합니다.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">오브젝트 저장소 공급자</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">오브젝트 스토리지 프로토콜은 다수의 데이터 오브젝트를 저장하기 위해 간단한 HTTP 또는 HTTPS 요청을 사용합니다. ONTAP에서 데이터에 액세스하는 것은 요청을 즉시 처리하는 데 좌우되므로 오브젝트 스토리지에 대한 액세스는 안정적이어야 합니다. 옵션에는 Amazon S3 Standard 및 빈도가 낮은 액세스 옵션과 Microsoft Azure Hot and Cool Blob Storage, IBM Cloud 및 Google Cloud가 있습니다. Amazon Glacier 및 Amazon Archive와 같은 아카이브 옵션은 데이터를 검색하는 데 필요한 시간이 호스트 운영 체제 및 애플리케이션의 허용 한도를 초과할 수 있기 때문에 지원되지 않습니다.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">NetApp StorageGRID는 또한 지원되며 최적의 엔터프라이즈급 솔루션입니다. 확장성이 뛰어나고 매우 안전한 오브젝트 스토리지 시스템으로, FabricPool 데이터와 엔터프라이즈 애플리케이션 환경에 포함될 가능성이 더 높은 기타 오브젝트 저장소 애플리케이션에 지리적 이중화를 제공할 수 있습니다.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">또한 StorageGRID은 많은 퍼블릭 클라우드 공급자가 데이터를 서비스에서 다시 읽으면서 부과하는 이그레스 비용을 방지하여 비용을 절감할 수 있습니다.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">데이터 및 메타데이터</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">여기서 "데이터"라는 용어는 메타데이터가 아닌 실제 데이터 블록에 적용됩니다. 데이터 블록만 계층화되며 메타데이터는 성능 계층에 유지됩니다. 또한 블록의 상태는 실제 데이터 블록을 읽기만 하면 핫 또는 쿨링으로 표시됩니다. 파일의 이름, 타임스탬프 또는 소유권 메타데이터를 읽기만 해도 기본 데이터 블록의 위치에 영향을 주지 않습니다.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">백업</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">FabricPool는 스토리지 설치 공간을 크게 줄일 수 있지만 이에 국한되지 않는 백업 솔루션입니다. NetApp WAFL 메타데이터는 항상 성능 계층에 유지됩니다. 심각한 재해로 인해 성능 계층이 폐기되는 경우 WAFL 메타데이터가 없으므로 용량 계층의 데이터를 사용하여 새로운 환경을 생성할 수 없습니다.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">하지만 FabricPool는 백업 전략의 일부가 될 수 있습니다. 예를 들어, FabricPool를 NetApp SnapMirror 복제 기술로 구성할 수 있습니다. 미러의 각 절반은 오브젝트 스토리지 타겟에 자체적으로 연결될 수 있습니다. 결과는 데이터의 독립적인 복사본 두 개가 됩니다. 운영 복제본은 성능 계층의 블록과 용량 계층의 관련 블록으로 구성되며 복제본은 두 번째 성능 및 용량 블록 집합입니다.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">압축</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">압축, 컴팩션, 중복제거와 같은 공간 효율성 기능은 지정된 양의 물리적 스토리지에 적합한 논리적 데이터의 양을 늘리기 위해 설계되었습니다. 결과적으로 비용과 관리 부담이 줄어듭니다.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">상위 수준에서 압축은 수학적 프로세스이며, 그 패턴은 공간 요구사항을 감소시키는 방식으로 데이터를 감지하고 인코딩합니다. 이와 반대로, 중복제거는 실제로 반복되는 데이터 블록을 감지하여 불필요한 복사본을 제거합니다. 컴팩션을 사용하면 여러 개의 논리적 데이터 블록이 미디어에서 동일한 물리적 블록을 공유할 수 있습니다.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">All-Flash 스토리지 시스템을 사용할 수 이전에는 어레이 기반 압축의 값이 제한되었습니다. 대부분의 I/O 집약적인 워크로드에는 허용되는 성능을 제공하기 위해 매우 많은 수의 스핀들이 필요했기 때문입니다. 스토리지 시스템에는 항상 많은 수의 드라이브가 부작용으로 필요한 것보다 훨씬 많은 용량이 포함되어 있습니다. 그러나 솔리드 스테이트 스토리지가 부상하면서 상황이 달라졌습니다. 이제 우수한 성능을 얻기 위해 드라이브를 엄청나게 오버 프로비저닝하지 않아도 됩니다. 스토리지 시스템의 드라이브 공간은 실제 용량 요구 사항과 일치할 수 있습니다.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">솔리드 스테이트 드라이브(SSD)의 IOPS 용량이 증가하면 대개 회전식 드라이브에 비해 비용이 절감되며 압축 덕분에 솔리드 스테이트 미디어의 실제 용량이 늘어나 추가 절감을 달성할 수 있습니다.</block>
  <block id="bd6c983943da8bf0ead08c643f0e75f3" category="paragraph">데이터를 압축하는 방법에는 여러 가지가 있습니다. 대부분의 데이터베이스에는 자체 압축 기능이 포함되어 있지만 고객 환경에서는 이런 일이 거의 발생하지 않습니다. 그 이유는 일반적으로 압축된 데이터를 * 변경 * 할 경우 성능이 저하되며 라이센스 비용이 많이 드는 경우가 많습니다. 마지막으로, 데이터베이스 작업의 전반적인 성능에 영향을 미칩니다. 실제 데이터베이스 작업이 아닌 데이터 압축과 압축 해제를 수행하는 CPU를 위해 CPU당 라이센스 비용으로 높은 금액을 지불하는 것은 합리적이지 않습니다. 더 좋은 옵션은 압축 작업을 스토리지 시스템으로 오프로드하는 것입니다.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">적응형 압축</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">적응형 압축은 지연 시간이 마이크로초 단위로 측정되는 All-Flash 환경에서조차 성능에 미치는 영향 없이 엔터프라이즈 워크로드로 철저히 테스트되었습니다. 심지어 일부 고객은 데이터가 캐시에 압축된 상태로 남아 있으므로 압축을 사용하여 성능이 향상되었다고 보고했습니다. 따라서 컨트롤러에서 가용 캐시의 양이 실질적으로 증가하기 때문입니다.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP는 4KB 유닛의 물리적 블록을 관리하며 적응형 압축은 기본 압축 블록 크기 8KB를 사용하며, 이는 데이터가 8KB 단위로 압축된다는 것을 의미합니다. 이 크기는 관계형 데이터베이스에서 가장 많이 사용되는 8KB 블록 크기와 일치합니다. 압축 알고리즘은 단일 유닛으로 더 많은 데이터가 압축되므로 효율성이 더욱 향상됩니다. 32KB의 압축 블록 크기는 8KB 압축 블록 유닛보다 더 공간 효율적입니다. 이는 기본 8KB 블록 크기를 사용하는 적응형 압축을 사용하면 효율성이 약간 낮지만 압축 블록 크기를 더 작게 만들면 큰 이점이 있습니다. 데이터베이스 워크로드에는 많은 양의 덮어쓰기 활동이 포함됩니다. 압축된 32KB 데이터 블록의 8KB를 덮어쓰려면 전체 32KB의 논리적 데이터를 다시 읽고, 압축을 풀고, 필요한 8KB 영역을 업데이트하고, 재압축을 수행한 다음 전체 32KB를 드라이브에 다시 써야 합니다. 이는 스토리지 시스템의 경우 매우 많은 비용이 드는 작업이며, 이로 인해 압축 블록 크기가 더 큰 경쟁 스토리지 어레이에서도 데이터베이스 워크로드의 성능이 크게 저하될 수 있습니다.</block>
  <block id="096cc7f8e7e1861c3ee0269a90fc27e3" category="admonition">적응형 압축에서 사용되는 블록 크기는 32KB까지 늘릴 수 있습니다. 이렇게 하면 스토리지 효율성이 향상될 수 있으며, 스토리지에 상당한 양의 데이터가 저장될 경우 아카이브 로그 및 백업 파일과 같은 대기 상태의 파일에 대해 고려해야 합니다. 경우에 따라 16KB 또는 32KB 블록 크기를 사용하는 액티브 데이터베이스가 이에 맞춰 적응형 압축의 블록 크기를 늘렸을 수도 있습니다. NetApp 또는 파트너 담당자에게 문의하여 이 솔루션이 현재 워크로드에 적합한지 여부를 확인하십시오.</block>
  <block id="f291779c724993ded5e79421d88f3e55" category="admonition">8KB보다 큰 압축 블록 크기는 스트리밍 백업 대상에서 중복제거와 함께 사용해서는 안 됩니다. 백업된 데이터의 작은 변화가 32KB 압축 기간에 영향을 미치기 때문입니다. 기간이 바뀌면 그에 따라 파일 전체에서 압축된 데이터가 달라집니다. 압축 후 중복제거가 발생하며, 이는 중복제거 엔진이 압축된 각 백업을 다르게 간주한다는 의미입니다. 스트리밍 백업(예: Oracle RMAN)의 중복제거가 필요한 경우 8KB 블록 적응형 압축만 사용해야 합니다. 더 작은 블록 크기를 사용할 수 있고 중복제거 효율성을 방해하지 않기 때문에 적응형 압축이 더 낫습니다. 유사한 이유로 호스트 측 압축도 중복제거 효율성에 지장을 줍니다.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">온도에 민감한 스토리지 효율성</block>
  <block id="78aa8c12abb3bf9f61a08df0f9b403de" category="paragraph">TSSE(Temperature Sensitive Storage Efficiency)는 블록 액세스 히트 맵을 사용하여 자주 액세스하지 않는 블록을 식별하고 보다 효율적으로 압축하는 ONTAP 9.8 이상에서 사용할 수 있습니다.</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">압축 정렬</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">데이터베이스 환경에서 적응형 압축을 수행할 때는 압축 블록 정렬과 관련된 몇 가지 사항을 고려해야 합니다. 이는 특정 블록의 랜덤 덮어쓰기가 데이터에 적용되는 경우만 해당합니다. 이 접근 방식은 파일 시스템의 시작이 4K 디바이스 경계에 맞춰 정렬되어야 하고 파일 시스템의 블록 크기가 4K의 배수여야 하는 전체 파일 시스템 정렬과 개념이 비슷합니다.</block>
  <block id="327a36f7ca539411197c2f867b501719" category="paragraph">예를 들어, 파일에 대한 8KB 쓰기는 파일 시스템 자체 내에서 8KB 경계와 일치하는 경우에만 압축됩니다. 즉 파일의 첫 번째 8KB에, 두 번째 8KB 에 그리고 그 이후로도 동일하게 포함되어야 합니다. RMAN 백업이나 아카이브 로그 같은 데이터는 압축된 여러 블록을 확장하는 순차적 쓰기 작업이며 따라서 정렬을 고려할 필요가 없습니다. I/O 패턴에서 고려해야 할 한 가지는 파일의 랜덤 덮어쓰기입니다.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS 를 참조하십시오</block>
  <block id="8dae8f7054353dae17cd9da8deb0e091" category="paragraph">NFS를 사용하여 파일 I/O를 맞춥니다. 파일의 각 블럭은 파일의 시작에 맞춰 정렬됩니다.</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">산</block>
  <block id="b0762e9957c8485f911e57bfd027eddb" category="paragraph">SAN 환경에서 최적의 압축을 위해서는 데이터가 8KB 경계에 맞춰 정렬되어야 합니다. SAN을 위한 정렬에는 LUN과 파일 시스템이라는 두 가지 측면이 있습니다. LUN은 8KB 경계에 맞춰 정렬된 전체 드라이브 장치(파티션 없음) 또는 파티션으로 구성해야 합니다.</block>
  <block id="ad16b6d5634739ef4ceb795c5beea659" category="admonition">압축 및 부분 예약 간의 상호 작용에 대한 설명은 씬 프로비저닝 섹션을 참조하십시오.</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">데이터 컴팩션</block>
  <block id="546168bb7b68da66be7b6c0e60a23460" category="paragraph">데이터 컴팩션은 ONTAP에 도입된 기술로, 압축 효율성을 개선합니다. 앞서 설명한 것처럼, 적응형 압축만 사용했을 때는 절감 비율이 최대 2:1입니다. 4KB WAFL 블록에 8KB I/O를 저장하도록 제한되어 있기 때문입니다. 블록 크기가 더 큰 압축 방법을 통해 효율성이 향상됩니다. 그러나 이러한 복사본은 작은 블록 덮어쓰기가 적용되는 데이터에는 적합하지 않습니다. 32KB 단위 데이터의 압축 해제, 8KB 부분 업데이트, 재압축, 드라이브에 다시 쓰기 작업은 오버헤드를 발생시킵니다.</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">데이터 컴팩션은 여러 논리적 블록이 물리적 블록 내에 저장될 수 있게 합니다. 예를 들어, 텍스트 또는 부분 전체 블록과 같이 고도로 압축 가능한 데이터가 포함된 데이터베이스는 8KB에서 1KB로 압축될 수 있습니다. 컴팩션을 적용하지 않으면 이 1KB 데이터는 여전히 4KB 블록 전체를 점유할 것입니다. 인라인 데이터 컴팩션에서는 압축된 데이터 1KB를 다른 압축된 데이터와 함께 단 1KB의 물리적 공간에 저장할 수 있습니다. 이 방식은 압축 기술이 아니라 그저 드라이브의 공간을 더 효율적으로 할당하는 것이며 감지할 수 있는 성능 영향을 발생시키지 않습니다.</block>
  <block id="07b153ed9b6a6f9f334f2ad1fe94651e" category="paragraph">이로써 얻어지는 절감의 수준은 다양합니다. 이미 압축되었거나 암호화된 데이터는 일반적으로 더 압축할 수 없기 때문에 이 데이터 세트는 컴팩션의 이점을 얻지 못합니다. 제로와 블록 메타데이터보다 조금 더 많이 포함하고 있으며 새롭게 초기화된 Oracle 데이터 파일의 경우 80:1까지 압축합니다. 따라서 가능성이 매우 광범위해집니다.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">중복 제거</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">중복 제거는 데이터 세트에서 중복된 블록 크기가 제거됩니다. 예를 들어, 동일한 4KB 블록이 10개 파일에 존재하면 중복제거는 파일 10개 전체에서 해당 4KB 블록을 동일한 4KB 물리적 블록으로 리디렉션합니다. 그 결과 데이터의 효율성이 10:1로 향상됩니다.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">VMware 게스트 부팅 LUN과 같은 데이터는 동일한 운영 체제 파일의 여러 복사본으로 구성되어 있기 때문에 중복 제거가 매우 용이합니다. 100:1 이상의 효율성이 관찰되었습니다.</block>
  <block id="c3ed34b88ac0b8efff210a99f19a4b9b" category="paragraph">일부 데이터에 중복 데이터가 없습니다. 예를 들어, Oracle 블록에는 데이터베이스에 관해 전역적으로 고유한 헤더와 거의 고유한 트레일러가 포함되어 있습니다. 따라서 Oracle 데이터베이스의 중복 제거 기능을 사용하면 1%를 넘는 비용을 절감하는 경우는 거의 없습니다.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">일부 경우 16KB 및 대형 블록 크기의 데이터베이스에서 공간이 최대 15% 절약되었습니다. 각 블록의 처음 4KB에는 전역적으로 고유한 헤더가 포함되어 있고 마지막 4KB 블록에는 거의 고유한 트레일러가 포함되어 있습니다. 실제로는 거의 전적으로 제로화 데이터의 중복제거에 기인하지만 내부 블록은 중복제거 후보입니다.</block>
  <block id="89d6ec0df0a54d3cdcc8f0573a6b37c5" category="paragraph">많은 경쟁업체의 어레이는 데이터베이스가 여러 차례 복사된다는 추정을 기반으로 Oracle 데이터베이스의 중복제거 기능을 내세웁니다. 이런 측면에서 NetApp 중복제거도 사용할 수 있지만 ONTAP은 더 나은 옵션인 NetApp FlexClone 기술을 제공합니다. 최종 결과는 같으며 기본 물리적 블록의 대부분을 공유하는 Oracle 데이터베이스의 복사본이 여러 개 생성됩니다. FlexClone ® 은 시간을 들여 데이터 파일을 복사한 다음 중복제거하는 것보다 훨씬 더 효율적입니다. 실제로 이는 중복제거가 아니라 비중복이라 할 수 있습니다. 애초에 중복을 생성하지 않기 때문입니다.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">효율성 및 씬 프로비저닝</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">효율성 기능은 씬 프로비저닝의 한 형태입니다. 예를 들어, 100GB 볼륨을 점유하는 100GB LUN은 50GB까지 압축할 수 있을 것이고 볼륨은 여전히 100GB이기 때문에 실제로 절감이 실현되지는 않았습니다. 먼저 볼륨의 크기를 줄여 절감된 공간을 시스템의 어느 곳에서든 사용할 수 있게 해야 합니다. 나중에 100GB LUN으로 변경하면 데이터 압축률이 줄어들어 LUN 크기가 커지고 볼륨을 가득 채울 수 있습니다.</block>
  <block id="20132d08f816a6401f40a29feb68df8d" category="paragraph">씬 프로비저닝은 관리를 단순화하는 동시에 가용 용량을 크게 개선하면서 비용을 절감할 수 있기 때문에 적극 권장합니다. 이유는 간단합니다. Oracle 환경에서는 많은 빈 공간, 많은 수의 볼륨 및 LUN, 압축 가능한 데이터가 포함되는 경우가 많습니다. 일반 프로비저닝은 언젠가 100% 채워지고 100% 압축할 수 없는 데이터가 포함될 경우에 대비해 볼륨 및 LUN에 대한 스토리지 공간을 예약합니다. 그런 일은 일어나지 않을 것입니다. 씬 프로비저닝을 사용하면 공간을 재확보하고 다른 위치에서 사용할 수 있으며 더 작은 볼륨 및 LUN이 아닌 스토리지 시스템 자체를 기반으로 용량을 관리할 수 있습니다.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">일부 고객은 특정 워크로드에 대해 또는 일반적으로 확립된 운영 및 조달 사례를 기반으로 일반 프로비저닝을 사용하는 것을 선호합니다.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">* 주의: * 볼륨이 일반 프로비저닝되면 압축 해제 및 를 사용한 중복 제거 제거를 포함하여 해당 볼륨에 대한 모든 효율성 기능을 완전히 비활성화하도록 주의해야 합니다<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> 명령. 볼륨은 에 나타나지 않아야 합니다<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> 출력. 그렇지 않을 경우, 효율성 기능을 위해 볼륨이 부분적으로 구성됩니다. 결과적으로 덮어쓰기 보장은 서로 다르게 동작하므로 구성 과다 사용으로 인해 볼륨의 공간이 예기치 않게 부족해져서 데이터베이스 I/O 오류가 발생할 가능성이 높아집니다.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">효율성 모범 사례</block>
  <block id="d67dd6ae62908b7781805cf297fa8d87" category="paragraph">NetApp는 ONTAP 9 이상에 대해 다음과 같은 권장사항을 제공합니다. ONTAP 9 이전 버전의 ONTAP의 경우 NetApp 담당자에게 문의하십시오.</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">AFF 기본값</block>
  <block id="38b7d52fb2d518d07c1c857b20ebbbd2" category="paragraph">All-Flash AFF 시스템에서 실행되는 ONTAP에서 생성된 볼륨은 모든 인라인 효율성 기능을 사용하는 씬 프로비저닝됩니다. Oracle 데이터베이스는 일반적으로 중복제거의 이점을 얻지 못하며 압축할 수 없는 데이터가 포함될 수 있지만 기본 설정은 거의 모든 워크로드에 적합합니다. ONTAP는 절감 여부와 관계없이 모든 유형의 데이터와 I/O 패턴을 효율적으로 처리하도록 설계되었습니다. 원인을 완전히 이해하고 편차가 있는 경우에만 기본값을 변경해야 합니다.</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">일반 권장 사항</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">볼륨 및/또는 LUN이 씬 프로비저닝되지 않는 경우 모든 효율성 설정을 비활성화해야 합니다. 이러한 기능을 사용하면 절약 효과가 없고 일반 프로비저닝과 공간 효율성이 활성화된 조합을 통해 공간 부족 오류를 포함하여 예기치 않은 동작이 발생할 수 있기 때문입니다.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">백업 또는 데이터베이스 트랜잭션 로그와 같이 데이터를 덮어쓰지 않는 경우 냉각 기간이 짧은 TSSE를 활성화하여 효율성을 높일 수 있습니다.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">일부 파일에는 압축할 수 없는 많은 양의 데이터가 포함되어 있을 수 있습니다. 예를 들어 파일의 응용 프로그램 수준에서 압축이 이미 활성화되어 있는 경우 암호화됩니다. 이러한 시나리오가 적용되는 경우 압축 데이터를 포함하는 다른 볼륨에서 더 효율적으로 작업할 수 있도록 압축을 해제하는 것이 좋습니다.</block>
  <block id="11845fef1d21077d7b23ce880868b556" category="list-text">데이터베이스 백업에 32KB 압축 및 중복제거를 모두 사용하지 마십시오. "" 섹션 참조<block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block>""을 참조하십시오.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">정책 - 로컬 스냅샷</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">FabricPool의 초기 릴리즈는 백업 활용 사례를 대상으로 합니다. 계층화할 수 있는 유일한 블록 유형은 액티브 파일 시스템의 데이터와 더 이상 관련되지 않은 블록이었습니다. 따라서 스냅샷 데이터 블록만 용량 계층으로 이동할 수 있습니다. 이는 성능에 영향을 미치지 않도록 해야 할 때 가장 안전한 계층화 옵션 중 하나로 남아 있습니다.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">비활성 스냅샷 블록을 용량 계층으로 계층화하는 두 가지 옵션이 있습니다. 첫째, 입니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 정책은 스냅샷 블록만 타겟으로 합니다. 하지만<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 정책에는 가 포함됩니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 블록 또한 액티브 파일 시스템의 블록을 계층화합니다. 이것은 바람직하지 않을 수 있습니다.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">를 클릭합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 값을 성능 계층에서 복원 중에 필요할 수 있는 데이터를 사용할 수 있도록 하는 기간으로 설정해야 합니다. 예를 들어 중요한 운영 데이터베이스의 대부분의 복원 시나리오에는 이전 며칠 동안의 특정 시점의 복원 지점이 포함됩니다. 설정 A<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 값을 3으로 설정하면 파일을 복원하면 즉시 최대 성능을 제공하는 파일이 만들어집니다. 활성 파일의 모든 블록은 용량 계층에서 복구할 필요 없이 고속 스토리지에 존재합니다.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">정책 - 복제된 스냅샷</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">SnapMirror 또는 SnapVault로 복제된 스냅샷으로, 복구에만 사용되는 스냅샷은 일반적으로 FabricPool을 사용해야 합니다<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 정책. 이 정책을 사용하면 메타데이터가 복제되지만 모든 데이터 블록이 용량 계층으로 즉시 전송되어 최고의 성능을 낼 수 있습니다. 대부분의 복구 프로세스에는 본질적으로 효율적인 순차적 I/O가 포함됩니다. 객체 저장소 대상으로부터의 복구 시간을 평가해야 하지만, 잘 설계된 아키텍처에서는 이 복구 프로세스가 로컬 데이터에서 복구하는 것보다 훨씬 느릴 필요가 없습니다.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">복제된 데이터도 클론 복제에 사용하도록 의도된 경우 는 를 참조하십시오<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 을 사용하면 정책이 더 적절합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 클론 복제 환경에서 정기적으로 사용될 것으로 예상되는 데이터를 포괄하는 값입니다. 예를 들어 데이터베이스의 활성 작업 집합에는 지난 3일 동안 읽거나 쓴 데이터가 포함될 수 있지만 6개월 동안의 기록 데이터도 포함될 수 있습니다. 그렇다면 를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> SnapMirror 대상에 대한 정책을 적용하면 성능 계층에서 작업 세트를 사용할 수 있습니다.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">IOPS QOS입니다</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">특히, All-Flash 스토리지의 채택이 늘어나면서 워크로드를 통합할 수 있었습니다. 회전식 미디어를 사용하는 스토리지 어레이는 구식 회전식 드라이브 기술로 인해 IOPS 용량에 제한이 있어 소수의 I/O 집약적인 워크로드만 지원하는 경향이 있었습니다. 고수준의 액티브 데이터베이스 1개 또는 2개로 인해 스토리지 컨트롤러가 한계에 도달하기 훨씬 전에 디스크가 한계에 다다르곤 했지만, 이런 현상이 바뀌었습니다. 상대적으로 적은 수의 SSD 드라이브가 가진 성능 용량이 가장 강력한 스토리지 컨트롤러도 포화시킬 수 있습니다. 이는 회전식 미디어 지연 시간이 급증할 때 갑작스러운 성능 하락을 걱정할 일 없이 컨트롤러의 최대 용량을 활용할 수 있다는 뜻입니다.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">참조할 만한 예를 들어보면, 단순한 2노드 HA AFF A800 시스템은 지연 시간이 1밀리초를 넘는 수준으로 증가하기 전에 최대 1백만 랜덤 IOPS를 충족할 수 있습니다. 이러한 수준에 도달하는 단일 워크로드도 거의 없을 것입니다. 이 AFF A800 시스템 어레이를 최대한 활용하려면 여러 워크로드를 호스팅하고 안전하게 수행하는 동시에 예측 가능성을 보장하기 위해 QoS 제어가 필요합니다.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">ONTAP에는 IOPS와 대역폭이라는 두 가지 서비스 품질(QoS) 유형이 있습니다. QoS 제어는 SVM, 볼륨, LUN, 파일에 적용됩니다.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">IOPS QoS 제어는 확실히 특정 리소스의 총 IOPS가 기준이 되지만 IOPS QoS는 직관적이지 않은 여러 측면을 가지고 있습니다. IOPS 임계값에 도달했을 때 지연 시간이 뚜렷이 증가되는 현상에 몇몇 고객은 초기에 혼란을 느꼈습니다. 지연 시간 증가는 IOPS 제한으로 인한 당연한 결과입니다. 논리적으로는 토큰 시스템과 비슷하게 작동합니다. 예를 들어, 특정 볼륨에 10K IOPS 제한이 있는 데이터 파일이 포함된 경우 유입되는 각 I/O에서 처리가 계속되려면 먼저 토큰이 수신되어야 합니다. 초당 10K 이상의 토큰이 소비되지 않는 한 지연은 없습니다. 입출력 작업이 토큰을 수신하기 위해 대기해야 하는 경우 이 대기는 추가 지연 시간으로 나타납니다. 워크로드가 QoS 제한에 근접할수록 각 IO는 해당 회전이 처리될 때까지 대기열에서 대기해야 하는 시간이 길어집니다. 이는 사용자에게 더 높은 지연 시간으로 나타납니다.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">데이터베이스 트랜잭션/재실행 로그 데이터에 QoS 제어를 적용할 때는 주의하십시오. 로깅 재실행의 성능 요구사항은 일반적으로 데이터 파일보다 훨씬 낮지만, 재실행 로그 활동은 폭주합니다. 입출력은 짧은 펄스로 이루어지며, 평균 REDO 입출력 레벨에 적합한 QoS 제한은 실제 요구 사항에 비해 너무 낮을 수 있습니다. 그 결과 QoS가 각 재실행 로그 버스트에 적용되므로 심각한 성능 제한이 발생할 수 있습니다. 일반적으로 재실행 및 아카이브 로깅은 QoS에 의해 제한되지 않습니다.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">대역폭 QoS</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">모든 I/O 크기가 같지는 않습니다. 예를 들어, 데이터베이스가 여러 개의 작은 블록 읽기를 수행하여 IOPS 임계값에 도달할 수 있고 또한 데이터베이스는 매우 적은 수의 대규모 블록 읽기로 구성된 전체 테이블 스캔 작업을 수행할 수도 있으며, 이는 대역폭은 많이, IOPS는 상대적으로 적게 소비합니다.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">마찬가지로 VMware 환경은 부팅 중에 매우 많은 수의 랜덤 IOPS를 구동할 수 있지만 외부 백업 중에는 적은 수의 입출력을 수행하지만 더 큰 입출력을 수행할 수 있습니다.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">성능을 효과적으로 관리하려면 IOPS 또는 대역폭 QoS 제한이나 둘 다 필요합니다.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">최소/QoS 보장</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">많은 고객들이 QoS 보장이 포함된 솔루션을 모색하는데, 이는 생각보다 달성하기 어렵고 낭비가 될 가능성이 있습니다. 예를 들어 10개의 데이터베이스를 10K IOPS 보장으로 배치하려면 10개의 데이터베이스 모두가 동시에 10K IOPS로 실행되는 시나리오의 경우 총 100,000에 대해 시스템을 사이징해야 합니다.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">최소 QoS 제어를 위한 최선의 사용은 중요 워크로드를 보호하는 것입니다. 예를 들어 최대 IOPS가 500K이고 운영 워크로드와 개발 워크로드를 혼합할 수 있는 ONTAP 컨트롤러를 가정해 보겠습니다. 특정 데이터베이스가 컨트롤러를 독점하지 못하도록 개발 워크로드에 최대 QoS 정책을 적용해야 합니다. 그런 다음 운영 워크로드에 최소 QoS 정책을 적용하여 필요할 때 항상 필요한 IOPS를 사용할 수 있도록 합니다.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">적응형 QoS</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">적응형 QoS는 QoS 제한이 스토리지 오브젝트의 용량을 기반으로 하는 ONTAP 기능을 가리킵니다. 일반적으로 데이터베이스 크기와 성능 요구사항 간에는 어떠한 링크도 없기 때문에 데이터베이스에는 거의 사용되지 않습니다. 대규모 데이터베이스는 거의 불활성 상태가 될 수 있지만, 작은 데이터베이스는 가장 IOPS를 많이 포함할 수 있습니다.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">적응형 QoS는 이러한 데이터 세트의 IOPS 요구사항이 데이터베이스의 총 크기와 상관하는 경향이 있기 때문에 가상화 데이터 저장소와 함께 매우 유용할 수 있습니다. 1TB의 VMDK 파일이 포함된 최신 데이터 저장소에는 2TB 데이터 저장소보다 절반의 성능이 필요할 수 있습니다. 적응형 QoS를 사용하면 데이터 저장소가 데이터로 채워질 때 QoS 제한을 자동으로 늘릴 수 있습니다.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">FabricPool를 사용하여 데이터 세트를 계층화하면 운영 스토리지 어레이와 오브젝트 저장소 계층 간에 종속성이 발생합니다. 다양한 수준의 가용성을 제공하는 수많은 오브젝트 스토리지 옵션이 있습니다. 운영 스토리지 어레이와 오브젝트 스토리지 계층 간에 연결 손실의 영향을 이해하는 것이 중요합니다.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">ONTAP로 발행된 I/O에 용량 계층의 데이터가 필요하고 ONTAP가 용량 계층에 연결하여 블록을 검색할 수 없는 경우 결국 I/O가 시간 초과됩니다. 이 시간 초과의 효과는 사용된 프로토콜에 따라 다릅니다. NFS 환경에서 ONTAP는 프로토콜에 따라 EJUKEBOX 또는 EDELAY 응답으로 응답합니다. 일부 오래된 운영 체제에서는 이를 오류로 해석할 수 있지만 현재 운영 체제 및 Oracle Direct NFS 클라이언트의 현재 패치 수준에서는 이를 다시 시도 가능한 오류로 처리하고 I/O가 완료될 때까지 계속 기다립니다.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">SAN 환경에 더 짧은 시간 초과가 적용됩니다. 객체 저장소 환경에서 블록이 필요하고 2분 동안 액세스할 수 없는 경우 읽기 오류가 호스트에 반환됩니다. ONTAP 볼륨과 LUN은 온라인 상태로 유지되지만 호스트 운영 체제에서 파일 시스템에 오류 상태가 플래그를 지정할 수 있습니다.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">오브젝트 스토리지 연결 문제<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 백업 데이터만 계층화되기 때문에 정책이 관심의 대상이 아닙니다. 통신 문제로 인해 데이터 복구 속도가 느려지지만 사용 중인 데이터에 영향을 주지 않습니다. 를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 및<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 정책을 통해 활성 LUN에서 콜드 데이터를 계층화할 수 있으므로 오브젝트 저장소 데이터를 검색하는 동안 오류가 데이터베이스 가용성에 영향을 미칠 수 있습니다. 이러한 정책을 통한 SAN 구축은 고가용성을 위해 설계된 엔터프라이즈급 오브젝트 스토리지 및 네트워크 연결에서만 사용해야 합니다. NetApp StorageGRID는 탁월한 옵션입니다.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">대부분의 관계형 데이터베이스는 트랜잭션 로그 보관 모드에서 작동하여 시점 복구를 제공합니다. 데이터베이스에 대한 변경 내용은 트랜잭션 로그에 변경 내용을 기록하여 커밋되며 트랜잭션 로그는 덮어쓰지 않고 유지됩니다. 따라서 대량의 아카이빙된 트랜잭션 로그를 보존해야 할 수 있습니다. 유사한 예제가 존재하며, 보존해야 하지만 액세스할 가능성은 매우 낮은 데이터를 생성합니다.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">FabricPool는 통합 계층화를 통한 단일 솔루션을 제공하여 이러한 문제를 해결합니다. 파일이 저장되어 일반적인 위치에 계속 액세스할 수 있지만 운영 스토리지의 공간을 거의 차지하지 않습니다.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">를 사용합니다<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> 며칠 정책을 적용하면 최근에 생성된 파일(단기간 내에 가장 필요할 가능성이 높은 파일)의 블록이 성능 계층에 보존됩니다. 그런 다음 이전 파일의 데이터 블록이 용량 계층으로 이동합니다.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">를 클릭합니다<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 로그가 삭제되었거나 운영 파일 시스템에 계속 존재하는지 여부에 관계없이 냉각 임계값에 도달하면 프롬프트 계층화를 적용합니다. 액티브 파일 시스템의 단일 위치에 잠재적으로 필요한 모든 로그를 저장하면 관리가 간편해집니다. 복원해야 하는 파일을 찾기 위해 스냅샷을 검색할 이유가 없습니다.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Microsoft SQL Server와 같은 일부 응용 프로그램은 백업 작업 중에 트랜잭션 로그 파일을 잘라서 로그가 더 이상 활성 파일 시스템에 없도록 합니다. 을 사용하여 용량을 절약할 수 있습니다<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> 계층화 정책만 지원하고<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> 활성 파일 시스템에 로그 데이터가 냉각되는 경우는 거의 없기 때문에 로그 데이터에는 정책이 유용하지 않습니다.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster는 3가지 구성으로 사용할 수 있습니다</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">IP 연결이 포함된 HA 쌍</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">FC 연결이 포함된 HA 쌍</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">FC 연결이 포함된 단일 컨트롤러</block>
  <block id="6fa7041982bed9488213a7bd2ecccfdf" category="paragraph">[참고] '접속'이라는 용어는 사이트 간 복제에 사용되는 클러스터 접속을 의미합니다. 호스트 프로토콜을 참조하지 않습니다. 모든 호스트측 프로토콜은 클러스터 간 통신에 사용되는 연결 유형에 관계없이 MetroCluster 구성에서 평소와 같이 지원됩니다.</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">MetroCluster IP를 선택합니다</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">HA 쌍 MetroCluster IP 구성은 사이트당 2~4개의 노드를 사용합니다. 이 구성 옵션은 2노드 옵션에 비해 복잡성과 비용을 증가시키지만, 내부 중복이라는 중요한 이점을 제공합니다. 컨트롤러 장애가 간단하더라도 WAN을 통한 데이터 액세스가 필요하지 않습니다. 데이터 액세스는 대체 로컬 컨트롤러를 통해 로컬에 유지됩니다.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">대부분의 고객은 인프라 요구 사항이 더 간단하기 때문에 IP 연결을 선택하고 있습니다. 과거에는 다크 파이버 및 FC 스위치를 사용하여 고속 사이트 간 연결을 제공하기가 일반적으로 더 쉬웠지만, 오늘날의 고속, 짧은 지연 시간 IP 회로는 보다 쉽게 사용할 수 있었습니다.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">또한 사이트 간 연결만 컨트롤러를 위한 것이므로 아키텍처가 더욱 단순합니다. FC SAN 연결 MetroCluster에서 컨트롤러는 반대쪽 사이트의 드라이브에 직접 기록하므로 SAN 연결, 스위치 및 브리지가 추가로 필요합니다. 반면, IP 구성의 컨트롤러는 컨트롤러를 통해 반대쪽 드라이브에 씁니다.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">MetroCluster IP 솔루션 아키텍처 및 설계</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">자세한 내용은 공식 ONTAP 설명서 및 를 참조하십시오<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">HA-쌍 FC SAN 연결 MetroCluster</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">HA 쌍 MetroCluster FC 구성은 사이트당 2개 또는 4개의 노드를 사용합니다. 이 구성 옵션은 2노드 옵션에 비해 복잡성과 비용을 증가시키지만, 내부 중복이라는 중요한 이점을 제공합니다. 컨트롤러 장애가 간단하더라도 WAN을 통한 데이터 액세스가 필요하지 않습니다. 데이터 액세스는 대체 로컬 컨트롤러를 통해 로컬에 유지됩니다.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">일부 멀티사이트 인프라는 액티브-액티브 운영을 위해 설계되지 않았지만 운영 사이트 및 재해 복구 사이트로 더 많이 사용됩니다. 이 상황에서 HA 쌍 MetroCluster 옵션이 일반적으로 다음과 같은 이유로 더 권장됩니다.</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">2노드 MetroCluster 클러스터는 HA 시스템이지만, 컨트롤러의 예상치 못한 장애나 계획된 유지 관리를 위해서는 반대쪽 사이트에서 데이터 서비스를 온라인으로 전환해야 합니다. 사이트 간 네트워크 연결이 필요한 대역폭을 지원할 수 없는 경우 성능이 영향을 받습니다. 유일한 옵션은 다양한 호스트 OS 및 관련 서비스를 대체 사이트로 페일오버하는 것입니다. HA Pair MetroCluster 클러스터는 동일한 사이트 내에서 단순한 페일오버가 발생하기 때문에 이 문제가 해소됩니다.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">일부 네트워크 토폴로지는 사이트 간 액세스용으로 설계되지 않은 대신 서로 다른 서브넷이나 격리된 FC SAN을 사용합니다. 이런 경우 2노드 MetroCluster 클러스터는 다른 사이트의 서버에 데이터를 제공할 수 없기 때문에 더 이상 HA 시스템으로 작동하지 않습니다. 완벽한 이중화를 제공하려면 HA Pair MetroCluster 옵션이 필요합니다.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">2개 사이트 인프라를 고가용성 단일 인프라로 간주하는 경우 2노드 MetroCluster 구성이 적합합니다. 하지만 사이트 장애 후 시스템이 오랫동안 작동해야 하는 경우에는 단일 사이트 내에서 HA를 계속 제공하기 때문에 HA 2노드가 선호됩니다.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">2노드 FC SAN 연결 MetroCluster</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">2노드 MetroCluster 구성은 사이트당 하나의 노드만 사용합니다. 이 설계는 구성과 유지 관리가 필요한 구성 요소가 적기 때문에 HA 쌍 옵션보다 단순합니다. 또한 케이블 연결 및 FC 스위칭에 대한 인프라 요구도 줄었습니다. 마지막으로 비용을 절감할 수 있습니다.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">이 설계의 분명한 영향은 단일 사이트에서 컨트롤러 장애가 발생하면 반대쪽 사이트에서 데이터를 사용할 수 있다는 것입니다. 이러한 제한이 반드시 문제가 되는 것은 아닙니다. 많은 기업은 기본적으로 단일 인프라로 작동하는 지연 시간이 짧은 확장된 고속 네트워크를 통해 멀티사이트 데이터 센터를 운영하고 있습니다. 이 경우 MetroCluster의 2노드 버전을 사용하는 것이 좋습니다. 현재 여러 서비스 공급자가 두 노드 시스템을 페타바이트 규모로 사용하고 있습니다.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">MetroCluster 복원력 기능</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">MetroCluster 솔루션에는 단일 장애 지점이 없습니다.</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">각 컨트롤러에는 로컬 사이트의 드라이브 쉘프에 대한 2개의 독립적 경로가 있습니다.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">각 컨트롤러에는 원격 사이트의 드라이브 쉘프에 대한 두 개의 독립적 경로가 있습니다.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">각 컨트롤러에는 반대쪽 사이트에 있는 컨트롤러에 대한 독립적인 경로가 2개 있습니다.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">HA 쌍 구성에서 각 컨트롤러에는 로컬 파트너에 대한 두 가지 경로가 있습니다.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">요약하면, MetroCluster의 데이터 제공 기능에 영향을 주지 않으면서 구성의 모든 구성 요소를 제거할 수 있습니다. 두 옵션 간의 복원력에서 유일한 차이점은 HA 쌍 버전이 사이트 장애 발생 후 전체 HA 스토리지 시스템이라는 점입니다.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">공간 관리</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">씬 프로비저닝은 다양한 형태로 제공되며 ONTAP이 엔터프라이즈 애플리케이션 환경에 제공하는 여러 기능 중 핵심이 됩니다. 또한 씬 프로비저닝은 효율성 기술과 밀접하게 관련되어 있습니다. 즉, 스토리지 시스템에서 기술적으로 있는 것보다 더 많은 논리적 데이터를 저장할 수 있다는 것입니다.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">거의 모든 경우 스냅샷 사용에는 씬 프로비저닝이 수반됩니다. 예를 들어, NetApp 스토리지의 일반적인 10TB 데이터베이스에는 약 30일 스냅샷이 포함되어 있습니다. 이 방식을 통해 액티브 파일 시스템에서 약 10TB의 데이터가 표시되고 스냅샷 전용으로는 300TB가 표시됩니다. 보통 총 310TB의 스토리지가 12TB~15TB의 공간에 상주합니다. 원래 데이터의 변경사항만 저장되기 때문에 액티브 데이터베이스가 10TB를 소비하며 나머지 300TB 데이터에는 2TB~5TB의 공간만 필요합니다.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">클로닝도 씬 프로비저닝의 한 예입니다. 주요 NetApp 고객은 개발에 사용하기 위해 80TB 데이터베이스의 클론 40개를 생성했습니다. 이 클론을 사용하는 40명 모두가 모든 데이터 파일의 모든 블록을 덮어쓴다면 3.2PB를 넘는 스토리지가 필요할 것입니다. 변경사항만 드라이브에 저장되기 때문 실제로 턴오버가 낮으며 총체적인 공간 요구사항은 40TB에 가깝습니다.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">데이터 변경률이 예기치 않게 증가할 수 있기 때문에 애플리케이션 환경에서 씬 프로비저닝을 수행할 때 주의를 기울여야 합니다. 예를 들어 데이터베이스 테이블을 다시 인덱싱하거나 VMware 게스트에 대규모 패치를 적용하면 스냅샷으로 인한 공간 소비가 빠르게 증가할 수 있습니다. 백업을 잘못 배치하면 매우 짧은 시간에 많은 양의 데이터를 쓸 수 있습니다. 마지막으로, 파일 시스템에 예기치 않게 사용 가능한 공간이 부족할 경우 일부 응용 프로그램을 복구하기가 어려울 수 있습니다.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">하지만 을 신중하게 구성하면 이러한 위험을 해결할 수 있습니다<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> 및<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> 정책. 그 이름이 시사하듯 이들 옵션은 사용자가 스냅샷에 의해 소비되는 공간을 자동으로 삭제하거나 추가 데이터를 수용하기 위해 볼륨을 늘리는 정책을 수립하도록 지원합니다. 다양한 옵션을 사용할 수 있으며 요구사항은 고객에 따라 다릅니다.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">논리적 스토리지 관리 설명서</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">를 참조하십시오 <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> 이러한 기능에 대한 자세한 내용은</block>
  <block id="8cf44a7a390ab582c5010ba430143d4b" category="section-title">LUN 씬 프로비저닝</block>
  <block id="ba0bdf51bc57bacdd6f3f0bd26b7674c" category="paragraph">파일 시스템 환경에서 액티브 LUN 씬 프로비저닝의 효율성은 데이터가 삭제되면 시간이 지남에 따라 손실될 수 있습니다. 삭제된 데이터를 0으로 덮어쓰거나 TRIM/UNMAP 공간 재확보와 함께 공간이 해제되지 않는 한 "지워진" 데이터는 파일 시스템에서 할당되지 않은 공백을 더 많이 차지합니다. 게다가 데이터 파일이 생성 당시의 파일 최대 크기로 초기화되기 때문에 많은 데이터베이스 환경에서는 액티브 LUN의 씬 프로비저닝의 사용이 제한적입니다.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">LVM 구성을 신중하게 계획하면 효율성이 향상되고 스토리지 프로비저닝 및 LUN 리사이징에 대한 필요성이 최소화됩니다. Veritas VxVM 또는 Oracle ASM 같은 LVM을 사용할 때 기본 LUN은 익스텐트로 분할되며 이는 필요할 때만 사용됩니다. 예를 들어, 데이터 세트가 2TB 크기에서 시작되어 차차 10TB까지 증가할 수 있는 경우, 이 데이터 세트는 LVM 디스크 그룹으로 구성되어 씬 프로비저닝된 LUN 10TB에 배치될 수 있습니다. 이는 생성 당시에 2TB의 공간만 점유하며 데이터 증가를 수용하기 위해 익스텐트가 할당됨에 따라 추가 공간을 요구할 수 있습니다. 이 프로세스는 공간이 모니터링되는 한 안전합니다.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">부분 예약</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">부분 예약은 공간 효율성과 관련하여 볼륨에서의 LUN 동작을 칭합니다. 옵션을 선택합니다<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> 100%로 설정하면 볼륨의 모든 데이터에서 볼륨의 공간이 소진되지 않으며 모든 데이터 패턴의 턴오버가 100%가 됩니다.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">예를 들어 1TB 볼륨에서 단일 250GB LUN의 데이터베이스를 가정해 보겠습니다. 스냅샷을 생성하면 어떤 이유로든 볼륨이 공간을 소진하지 않도록 보장하기 위해 즉시 볼륨에서 250GB의 공간이 추가로 예약됩니다. 데이터베이스 볼륨의 모든 바이트에 덮어쓰기를 해야 하는 경우는 거의 없기 때문에 부분 예약 사용은 일반적으로 리소스를 낭비하는 것입니다. 일어나지 않을 경우를 위해 공간을 예약할 필요는 없습니다. 그럼에도, 고객이 스토리지 시스템에서 공간 소비를 모니터링할 수 없으며 공간이 절대 소진되지 않도록 할 경우에는 스냅샷을 사용하기 위해 100% 부분 예약이 필요할 것입니다.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">압축 및 중복제거</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">압축과 중복제거는 둘 다 씬 프로비저닝의 한 형태입니다. 예를 들어, 50TB의 데이터가 30TB까지 압축될 수 있다면 20TB가 절약될 것입니다. 압축의 이점을 얻기 위해서는 이 20TB의 일부를 다른 데이터에 사용하거나 50TB보다 적은 용량의 스토리지 시스템을 구매해야 합니다. 그 결과 스토리지 시스템에서 기술적으로 지원되는 것보다 많은 데이터를 저장할 수 있게 됩니다. 데이터 관점에서 보면 드라이브에서 30TB만 점유되어 있어도 50TB의 데이터가 있는 것입니다.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">데이터 세트의 압축 가능성은 언제든 바뀔 수 있으며 이로 인해 실제 공간의 소비가 증가될 수 있습니다. 이렇게 소비가 증가하므로 모니터링과 사용 측면에서 압축을 다른 형태의 씬 프로비저닝과 마찬가지로 관리해야 합니다<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> 및<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">압축과 중복제거에 대한 자세한 내용은 efficiency.html 링크를 참조하십시오</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">압축 및 분할 예약</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">압축은 씬 프로비저닝의 한 형태입니다. 부분 예약은 압축 사용에 영향을 미치며, 스냅샷 생성 전에 공간을 예약한다는 점에 유의해야 합니다. 일반적으로 부분 예약은 스냅샷이 있는 경우에만 중요합니다. 스냅샷이 없는 경우 부분 예약은 중요하지 않습니다. 압축의 경우는 이와 다릅니다. 압축을 통해 볼륨에서 LUN이 생성되는 경우 ONTAP은 스냅샷을 수용하기 위해 공간을 보존합니다. 이 동작은 구성 단계에서 혼란을 줄 수 있지만 이는 예상할 수 있는 것입니다.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">예를 들어, 스냅샷 없이 2.5GB까지 압축된 5GB LUN을 가지고 있는 10GB 볼륨을 생각해 보겠습니다. 두 가지 시나리오를 생각할 수 있습니다.</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">부분 예약 = 100, 결과: 7.5GB 활용률</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">부분 예약 = 0, 결과: 2.5GB 활용률</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">첫 번째 시나리오는 현재 데이터의 경우 2.5GB의 공간 소비와 스냅샷 사용을 예상하여 100% 소스 턴오버를 지원하기 위한 5GB의 공간이 포함됩니다. 두 번째 시나리오는 여분의 공간을 예약하지 않습니다.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">혼란스러워 보이는 이 상황은 사실상 발생할 확률이 낮습니다. 압축은 씬 프로비저닝을 시사하며 LUN 환경에서 씬 프로비저닝을 수행하려면 부분 예약이 필요합니다. 압축할 수 없는 무언가로 인해 압축된 데이터를 항상 덮어쓸 수 있습니다. 즉, 압축을 위해서는 볼륨을 씬 프로비저닝해야 절약 효과를 거둘 수 있습니다.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">* NetApp는 * 다음과 같은 예약 구성을 권장합니다.</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">설정<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> 과 함께 기본 용량 모니터링이 있는 경우 0으로 설정합니다<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> 및<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">설정<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> 모니터링 기능이 없거나 어떤 상황에서도 공간을 소진하는 것이 불가능한 경우 100까지.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">LIF 유형</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">ONTAP 네트워크 관리 설명서</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">이 섹션은 LIF 설계의 주요 원칙에 대해 간략하게 설명합니다. 보다 포괄적인 설명서는 를 참조하십시오 <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. 데이터베이스 아키텍처의 다른 측면과 마찬가지로, 스토리지 가상 머신(SVM, CLI의 SVM) 및 논리 인터페이스(LIF) 설계를 위한 최고의 옵션은 확장 요구사항과 비즈니스 요구사항에 크게 의존합니다.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">LIF 전략을 구축할 때는 다음 주요 주제를 고려해야 합니다.</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">* 성능. * 네트워크 대역폭은 충분한가?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">* 복구. * 설계에 단일 장애 지점이 있습니까?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">* 관리 효율성. * 네트워크를 중단 없이 확장할 수 있습니까?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">이러한 주제는 호스트부터 스위치, 스토리지 시스템에 이르기까지 엔드 투 엔드 솔루션에 적용됩니다.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">LIF 유형에 대한 ONTAP 설명서</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">LIF 유형에는 여러 가지가 있습니다. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> 이 주제에 대한 전체 정보를 제공하지만 기능적 관점에서 LIF를 다음 그룹으로 나눌 수 있습니다.</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">* 클러스터 및 노드 관리 LIF. * 스토리지 클러스터 관리에 사용되는 LIF.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">* SVM 관리 LIF. * 스냅샷 생성 또는 볼륨 리사이징 같은 기능을 위해 REST API 또는 ONTAPI(ZAPI라고도 함)를 통해 SVM에 대한 액세스를 허용하는 인터페이스. SMO(SnapManager for Oracle)와 같은 제품은 SVM 관리 LIF에 대한 액세스 권한을 가지고 있어야 합니다.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">* Data LIF. * FC, iSCSI, NVMe/FC, NVMe/TCP, NFS용 인터페이스 또는 SMB/CIFS 데이터를 생성할 수 있습니다.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">NFS 트래픽에 사용되는 데이터 LIF는 의 방화벽 정책을 에서 변경하여 관리에 사용할 수도 있습니다<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> 또는 HTTP, HTTPS 또는 SSH를 허용하는 또 다른 정책입니다. 이렇게 변경할 때는 NFS 데이터 LIF와 별도의 관리 LIF 둘 다에 대한 액세스를 위해 각 호스트를 구성할 필요가 없기 때문에 네트워크 구성을 단순화할 수 있습니다. 둘 다 IP 프로토콜을 사용함에도 불구하고 iSCSI와 관리 트래픽 모두를 위한 인터페이스를 구성하는 것은 불가능하며 iSCSI 환경에는 별도의 관리 LIF가 필요합니다.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">SAN LIF 설계</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">SAN 환경에서 LIF 설계는 상대적으로 단순합니다. 바로 다중 경로를 사용할 수 있기 때문입니다. 모든 최신 SAN 구현에서는 클라이언트가 다중 독립형 네트워크 경로를 통해 데이터에 액세스하고 액세스를 위한 최상의 경로를 선택할 수 있습니다. 그 결과, SAN 클라이언트가 최상의 경로를 통과하여 자동으로 로드 밸런싱을 수행하기 때문에 LIF 설계에서 성능을 더 간단하게 해결할 수 있습니다.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">최상의 경로를 사용할 수 없게 되면 클라이언트는 자동으로 다른 경로를 선택합니다. 이러한 설계 단순성 덕분에 일반적으로 SAN LIF의 관리가 더 용이해집니다. 그렇다고 SAN 환경의 관리가 항상 더 쉬운 것은 아닙니다. SAN 스토리지의 여러 다른 측면은 NFS보다 훨씬 더 복잡하며 SAN LIF는 설계만 더 쉽습니다.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">성능</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">SAN 환경의 LIF 성능과 관련하여 가장 중요한 고려사항은 대역폭입니다. 예를 들어, 노드당 16Gb FC 포트가 2개인 2노드 ONTAP AFF 클러스터는 각 노드에서 최대 32Gb의 대역폭을 허용합니다.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">복원력</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">SAN LIF는 AFF 스토리지 시스템에서 페일오버되지 않습니다. 컨트롤러 페일오버로 SAN LIF에서 장애가 발생하면 클라이언트의 다중 경로 소프트웨어가 경로 손실을 탐지하고 I/O를 다른 LIF로 리디렉션합니다. ASA 스토리지 시스템을 사용할 경우 짧은 지연 후 LIF가 페일오버되지만, 다른 컨트롤러에 이미 활성 경로가 있으므로 IO가 중단되지 않습니다. 페일오버 프로세스는 정의된 모든 포트에서 호스트 액세스를 복구하기 위해 수행됩니다.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">관리 효율성</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">LIF 마이그레이션은 클러스터 주변의 볼륨 재배치와 관련된 경우가 많기 때문에 NFS 환경에서 일반적으로 수행됩니다. SAN 환경에서는 HA 쌍 내에 볼륨을 재배치할 때 LIF를 마이그레이션할 필요가 없습니다. 볼륨 이동이 완료된 후에 경로가 변경되면 ONTAP가 SAN에 알림을 전송하고 SAN 클라이언트가 자동으로 다시 최적화하기 때문입니다. SAN의 LIF 마이그레이션은 기본적으로 주요 물리적 하드웨어 변경과 관련되어 있습니다. 예를 들어, 컨트롤러의 무중단 업그레이드가 필요한 경우 SAN LIF는 새로운 하드웨어로 마이그레이션됩니다. FC 포트에서 오류가 발견되면 LIF를 미사용 포트로 마이그레이션할 수 있습니다.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">설계 권장 사항</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp는 다음과 같은 권장 사항을 제공합니다.</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">필요한 수보다 많은 경로를 생성하지 마십시오. 경로 수가 너무 많으면 전체적인 관리가 더 복잡해지며 일부 호스트에서 경로 페일오버 문제가 야기될 수 있습니다. 또한, 호스트에 SAN 부팅 같은 구성과 관련하여 예기치 않은 경로 한계가 있을 수도 있습니다.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">극소수의 구성에서는 LUN에 대한 경로가 4개 이상 필요합니다. LUN과 그 HA 파트너가 속한 노드에 장애가 발생하는 경우 LUN을 호스팅하는 애그리게이트에 액세스할 수 없기 때문에 LUN에 3개 이상의 노드 보급 경로를 소유했을 때의 가치는 크지 않습니다. 이 상황에서 1차 HA 쌍 외에 노드에 대한 경로를 생성하는 것은 도움이 되지 않습니다.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">FC 존에 어떤 포트를 포함할 것인지 선택하여 가시적인 LUN 경로의 수를 관리할 수 있긴 하나 일반적으로 FC 존의 모든 잠재적 타겟 지점을 포함하고 ONTAP 수준에서 LUN 가시성을 제어하는 것이 더 간편합니다.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">ONTAP 8.3 이후 버전에서 선택적 LUN 매핑(SLM: Selective LUN Mapping) 기능은 기본값입니다. SLM 기능을 통해 새로운 LUN은 기본 애그리게이트와 노드의 HA 파트너가 속한 노드에서 자동으로 보급됩니다. 이러한 방식에서는 포트 세트를 생성하거나 포트 접근성을 제한하기 위해 조닝을 구성할 필요가 없습니다. 각 LUN은 최적의 성능과 복원력을 위해 필요한 최소 개수의 노드에서 동작합니다.
* LUN을 2개의 컨트롤러 외부로 마이그레이션해야 하는 경우 를 사용하여 노드를 추가할 수 있습니다<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> 명령을 사용하여 LUN을 새 노드에서 보급합니다. 이렇게 하면 LUN 마이그레이션을 위해 LUN에 대한 추가 SAN 경로를 생성할 수 있습니다. 그러나 호스트는 새로운 경로를 사용하기 위한 검색 작업을 수행해야 합니다.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">간접 트래픽을 너무 신경 쓰지 마십시오. 매우 I/O 집약적인 환경에서는 간접 트래픽을 피하는 것이 가장 좋으며 1마이크로초의 지연 시간도 중요하지만 일반적 워크로드의 성능에 미치는 가시적 영향은 미미합니다.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">NFS LIF 설계</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">SAN 프로토콜과 대조적으로 NFS는 데이터에 대한 다중 경로를 정의하는 기능이 제한적입니다. NFSv4에 대한 병렬 NFS(pNFS) 확장이 이 한계를 해결해주긴 하나, 이더넷 속도가 100GB에 도달했기 때문에 추가 경로를 추가할 가치가 거의 없습니다.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">성능 및 복원력</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">SAN LIF 성능을 측정할 때는 기본적으로 모든 1차 경로의 총 대역폭을 계산하는 것이 관건이지만 NFS LIF 성능을 결정하기 위해서는 정확한 네트워크 구성을 면밀히 살펴야 합니다. 예를 들어, 2개의 10Gb 포트를 원시 물리적 포트로 구성하거나 링크 통합 제어 프로토콜(LACP) 인터페이스 그룹으로 구성할 수 있습니다. 이를 인터페이스 그룹으로 구성하는 경우, 트래픽이 스위칭될 때와 라우팅될 때 각각 다르게 작동하는 다중 로드 밸런싱 정책을 사용할 수 있습니다. 마지막으로, Oracle dNFS(Direct NFS)는 현재 어떤 OS NFS 클라이언트에도 존재하지 않는 로드 밸런싱 구성을 제공합니다.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">SAN 프로토콜과 달리 NFS 파일 시스템은 프로토콜 계층의 복원력이 필요합니다. 예를 들어, LUN은 항상 다중 경로가 활성화되어 구성되므로 스토리지 시스템에 다중 이중화 채널이 제공되고 각각 FC 프로토콜을 사용하게 됩니다. 반면, NFS 파일 시스템은 물리적 계층에서만 보호되는 단일 TCP/IP 채널의 가용성에 따라 달라집니다. 포트 페일오버와 LACP 포트 애그리게이션 같은 옵션은 이 방식 때문에 존재하는 것입니다.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">NFS 환경에서는 네트워크 프로토콜 계층에서 성능과 복원력 둘 다 제공되기 때문에 두 주제가 긴밀히 연관되어 있으며 함께 논의되어야 합니다.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">포트 그룹에 LIF를 바인딩합니다</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">LIF를 포트 그룹에 바인딩하려면 LIF IP 주소를 물리적 포트 그룹에 연계합니다. 물리적 포트를 함께 애그리게이팅하는 주된 방법은 LACP입니다. LACP의 내결함성 기능은 상당히 단순한데, LACP 그룹의 각 포트를 모니터링하고 오작동이 발생하면 포트 그룹에서 제거하는 것입니다. 그러나 LACP의 성능과 관련하여 다음과 같이 많은 오해가 있습니다.</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP는 엔드포인트 매칭을 위해 스위치를 구성하지 않아도 됩니다. 예를 들어, ONTAP는 IP 기반 부하 분산을 사용하여 구성할 수 있고 스위치는 MAC 기반 부하 분산을 사용할 수 있습니다.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">LACP 연결을 사용하는 각 엔드포인트는 패킷 전송 포트를 독립적으로 선택할 수 있지만 수신에 사용할 포트는 선택할 수 없습니다. 즉, ONTAP에서 특정 대상으로 가는 트래픽이 특정 포트에 연관되어 있고 반환 트래픽은 다른 인터페이스에 도착할 수 있습니다. 하지만 이로 인해 문제가 발생하지는 않습니다.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP가 트래픽을 언제나 균등하게 분산하지는 않습니다. 다수의 NFS 클라이언트가 있는 대규모 환경에서는 일반적으로 LACP 애그리게이션의 모든 포트가 균등하게 사용됩니다. 그러나 이 환경에서 모든 NFS 파일 시스템은 전체 애그리게이션이 아닌 단 1포트의 대역폭으로 제한됩니다.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">ONTAP에서 라운드 로빈 LACP 정책을 사용할 수 있지만 이들 정책은 스위치에서 호스트로의 연결을 다루지 않습니다. 예를 들어, 한 호스트에 4포트 LACP 트렁크가 있고 ONTAP에 4포트 LACP 트렁크가 있는 구성에서는 단일 포트를 사용하여 파일 시스템을 읽을 수만 있습니다. ONTAP는 4포트 모두를 통해 데이터를 전송할 수 있지만 현재 4포트 모두를 통해 스위치에서 호스트로 전송하는 데 사용할 수 있는 스위치 기술은 없으며 하나만 사용됩니다.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">여러 데이터베이스 호스트로 구성된 대규모 환경에서 가장 일반적인 접근 방식은 IP 로드 밸런싱을 사용하여 적절한 수의 10Gb(또는 더 빠른) 인터페이스 LACP 애그리게이트를 구축하는 것입니다. 이 접근 방식에서는 클라이언트 수가 충분하다면 ONTAP에서 모든 포트를 사용할 수 있습니다. 구성에 있는 클라이언트 수가 더 적을 때는 LACP 트렁킹이 로드를 동적으로 재분산하지 않으므로 로드 밸런싱이 중단됩니다.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">연결이 확립되면 특정 방향의 트래픽이 하나의 포트에만 배치됩니다. 예를 들어, 4포트 LACP 트렁크로 연결된 NFS 파일 시스템에 대해 전체 테이블 스캔을 수행하는 데이터베이스는 네트워크 인터페이스 카드(NIC)가 하나에 불과하지만 데이터를 읽습니다. 이러한 환경에 단 3개의 데이터베이스 서버가 있는 경우 3개 서버 모두 같은 포트에서 데이터를 읽을 가능성도 있으며 다른 3개의 포트는 유휴 상태입니다.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">LIF를 물리적 포트에 바인딩합니다</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">LIF를 물리적 포트에 바인딩하면 ONTAP 시스템의 특정 IP 주소가 한 번에 하나의 네트워크 포트에만 연계되기 때문에 네트워크 구성을 더 세부적으로 제어할 수 있습니다. 이렇게 하고 나면 페일오버 그룹 구성과 페일오버 정책을 통해 복원력을 실현할 수 있습니다.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">페일오버 정책 및 페일오버 그룹</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">페일오버 그룹 및 정책에 대한 ONTAP 네트워크 관리 설명서</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">네트워크가 중단되었을 때 LIF의 동작은 페일오버 정책과 페일오버 그룹에 의해 제어됩니다. 구성 옵션은 ONTAP의 다른 버전에 따라 변경되었습니다. 을 참조하십시오 <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> 구축하고 있는 ONTAP 버전에 대한 세부 정보를 참조하십시오.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">ONTAP 8.3 이상에서는 브로드캐스트 도메인 기반의 LIF 페일오버 관리를 허용합니다. 그러므로 관리자는 특정 서브넷에 대한 액세스 권한을 가진 모든 포트를 정의하여 ONTAP이 적절한 페일오버 LIF를 선택하도록 할 수 있습니다. 어떤 고객은 이 접근 방식을 사용할 수 있지만 예측 가능성이 부족하기 때문에 고속 스토리지 네트워크 환경에서는 한계가 있습니다. 예를 들어, 일반적인 파일 시스템 액세스를 위한 1Gb 포트와 데이터 파일 I/O를 위한 10Gb 포트 모두를 환경에 포함할 수 있습니다 두 유형의 포트가 같은 브로드캐스트 도메인에 존재하는 경우 LIF 페일오버는 데이터 파일 I/O를 10Gb 포트에서 1Gb 포트로 이동할 수 있습니다.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">요약하자면, 다음과 같은 방식을 사용해 보십시오.</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">사용자 정의대로 페일오버 그룹을 구성합니다.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">스토리지 페일오버 중에 LIF가 애그리게이트를 따르도록 스토리지 페일오버(SFO) 파트너 컨트롤러의 포트로 페일오버 그룹을 채웁니다. 그러면 간접 트래픽의 생성을 방지할 수 있습니다.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">성능 특성이 원래의 LIF와 일치하는 페일오버 포트를 사용합니다. 예를 들어, 하나의 물리적 10Gb 포트에 있는 LIF에는 단일 10Gb 포트의 페일오버 그룹이 포함되어야 합니다. 4포트 LACP LIF는 다른 4포트 LACP LIF로 페일오버해야 합니다. 이들 포트는 브로드캐스트 도메인에서 정의된 포트의 하위 세트가 될 것입니다.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">SFO 파트너에 관한 페일오버 정책을 수립합니다. 이렇게 하면 페일오버 중에 LIF가 애그리게이트를 따르도록 할 수 있습니다.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">자동 되돌리기</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">를 설정합니다<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> 원하는 대로 매개 변수입니다. 대부분의 고객은 이 매개 변수를 로 설정하는 것을 선호합니다<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> LIF가 홈 포트로 되돌아갑니다. 그러나 경우에 따라 LIF를 홈 포트에 반환하기 전에 예기치 않은 페일오버를 조사할 수 있다는 사실이 이를 false로 설정한 경우도 있습니다.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">LIF-볼륨 비율</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">일반적인 오해는 볼륨과 NFS LIF 사이에 1:1 관계가 있어야 한다는 것입니다. 이 구성은 인터커넥트 트래픽을 추가로 생성하지 않고 클러스터의 어느 곳으로든 볼륨을 이동하기 위해 필요하기는 하나 절대적인 요구사항은 아닙니다. 인터클러스터 트래픽을 고려해야 하지만 단순히 인터클러스터 트래픽이 존재하는 것만으로 문제가 발생하지는 않습니다. ONTAP를 위해 수립되고 발표된 대다수의 벤치마크에는 대개 간접 I/O가 포함되어 있습니다</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">예를 들어, 성능이 중요한 데이터베이스가 상대적으로 적게 포함된 데이터베이스 프로젝트에서 LIF 전략에 대한 1:1 볼륨을 보장하기 위해 총 40개의 볼륨만 필요하다면 IP 주소는 40개가 필요합니다. 어떤 볼륨이든 연계된 LIF와 함께 클러스터 내 어느 곳으로든 이동할 수 있으며 트래픽이 항상 직접적이기 때문에 마이크로초 수준에서도 지연 시간의 소스를 모두 최소화합니다.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">반대의 예를 들어 보면, 대규모 호스팅 환경은 고객과 LIF 간 1:1 관계를 더 쉽게 관리할 수 있습니다. 시간이 경과하면 볼륨을 다른 노드로 마이그레이션해야 할 수 있으며 이로 인해 간접 트래픽이 발생할 수 있습니다. 하지만 인터커넥트 스위치의 네트워크 포트가 포화 상태가 되지 않는 한 성능 영향을 감지할 수 없습니다. 우려가 된다면 새로운 LIF를 추가 노드에 설정할 수 있으며 다음 유지보수 윈도우에 호스트를 업데이트하여 구성에서 간접 트래픽을 제거할 수 있습니다.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster 및 다중 애그리게이트</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">정상적인 조건에서 특정 컨트롤러에 쓰기가 수신되면 파트너에게 동시에 미러링됩니다. NetApp MetroCluster 환경에서는 쓰기가 원격 컨트롤러에도 미러링됩니다. 쓰기가 모든 위치에서 비휘발성 미디어에 저장되기 전까지는 호스트 애플리케이션에서 인지되지 않습니다.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">쓰기 데이터가 저장된 미디어를 비휘발성 메모리 또는 NVMEM이라 합니다. 이는 NVRAM(Nonvolatile Random-Access Memory)으로도 불리며, 저널 기능을 하지만 쓰기 캐시로 간주할 수 있습니다. 정상 작동 중에는 NVMEM에서 데이터를 읽을 수 없으며 소프트웨어나 하드웨어 장애 발생 시 데이터를 보호하는 데에만 사용됩니다. 드라이브에 데이터를 쓸 때 데이터는 NVMEM이 아니라 시스템의 RAM에서 전송됩니다.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">테이크오버 작동 중에 고가용성(HA) 쌍의 노드 1개가 파트너로부터 작업을 넘겨받습니다. 스위치오버도 기본적으로는 같으나 MetroCluster 구성에 적용되며 여기서 원격 노드가 로컬 노드의 기능을 넘겨받습니다.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">정기적인 유지보수 작업 중에 스토리지 테이크오버 또는 스위치오버 작동은 네트워크 경로가 변경될 때 작동이 잠깐 정지되는 경우를 제외하고 투명해야 합니다. 그러나 네트워킹은 복잡할 수 있고 오류가 발생하기 쉽기 때문에 NetApp 스토리지 시스템을 운영 환경에 구축하기 전에 테이크오버와 스위치오버 작업을 철저하게 테스트하는 것이 좋습니다. 이것이 모든 네트워크 경로가 올바르게 구성되도록 하는 유일한 방법입니다. SAN 환경에서는 명령의 출력을 신중하게 확인하십시오<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> 필요한 모든 기본 및 보조 경로를 사용할 수 있는지 확인합니다.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">강제 적용 테이크오버나 스위치오버를 실행할 때는 주의해야 합니다. 이 옵션으로 스토리지 구성을 변경하면 드라이브가 속한 컨트롤러의 상태를 무시하고 대체 노드가 강제로 드라이브를 제어하게 됩니다. 강제 적용 테이크오버를 잘못 적용하면 데이터 손실 또는 손상을 야기할 수 있는데, 강제 적용 테이크오버 또는 스위치오버로 인해 NVMEM의 콘텐츠가 폐기될 수 있기 때문입니다. 테이크오버 또는 스위치오버가 완료된 후 데이터가 손실되면 드라이브에 저장된 데이터가 데이터베이스를 확인하는 시점보다 약간 더 과거의 상태로 되돌아갈 수 있습니다.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">일반 HA 쌍의 강제 적용 테이크오버는 거의 필요하지 않습니다. 거의 모든 장애 시나리오에서 노드가 종료되고 자동 페일오버가 수행되도록 파트너에게 알립니다. 노드 간 인터커넥트가 손실된 후 컨트롤러 하나가 손실되는 롤링 장애와 같이 극단적인 상황이 발생하는 경우에는 강제 적용 테이크오버가 필요합니다. 이런 상황에서 노드 간 미러링은 컨트롤러 장애가 발생하기 전에 손실되며, 정상적인 컨트롤러는 쓰기 작업이 진행되고 있는 복사본을 더 이상 가지고 있지 않게 됩니다. 이때 테이크오버가 강제 적용되어야 하며, 이렇게 하면 데이터가 손실될 수 있습니다.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">MetroCluster 스위치오버에도 동일한 논리가 적용됩니다. 정상 조건에서는 스위치오버가 거의 투명합니다. 그러나 재해로 인해 정상적인 사이트와 재해 사이트 간에 연결이 손실될 수 있습니다. 정상적인 사이트의 관점에서는 사이트 간 연결 중단 문제에 불과한 것으로 인식될 것이며 원래의 사이트는 여전히 데이터를 처리하고 있을 것입니다. 노드가 1차 컨트롤러의 상태를 확인할 수 없는 경우 강제 적용 스위치오버만 가능합니다.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">* NetApp는 * 다음 주의사항을 준수할 것을 권장합니다.</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">테이크오버나 스위치오버를 실수로 강제 적용하지 않도록 특별히 주의하십시오. 일반적으로 강제 적용은 필요하지 않으며 변경을 강제 적용할 시 데이터가 손실될 수 있습니다.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">강제 적용 테이크오버 또는 스위치오버가 필요한 경우 애플리케이션이 종료되고 모든 파일 시스템이 마운트 해제되며 논리적 볼륨 관리자(LVM) 볼륨 그룹이 varyoffed인지 확인합니다. ASM 디스크 그룹은 마운트 해제해야 합니다.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">강제 적용 MetroCluster 스위치오버가 수행될 때에는 정상적인 스토리지 리소스로부터 장애 노드를 분리하십시오. 자세한 내용은 관련 ONTAP 버전에 대한 MetroCluster 관리 및 재해 복구 가이드를 참조하십시오.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster는 연결이 중단되면 비동기식 모드로 전환되는 동기식 복제 기술입니다. 이는 고객이 가장 일반적으로 요청하는 사항으로, 동기식 복제가 보장되면 사이트 연결이 중단되었을 때 데이터베이스 I/O가 완전히 지연되고 데이터베이스의 작동이 멈추기 때문입니다.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">MetroCluster는 연결이 복원되면 애그리게이트를 신속하게 재동기화합니다. 다른 스토리지 기술과 달리 MetroCluster에서는 사이트 장애 후에 전체 재미러링이 전혀 필요하지 않으며 델타 변경사항만 전달되면 됩니다.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">애그리게이트가 확장되는 데이터 세트의 경우 롤링 재해 시나리오에서 추가 데이터 복구 단계가 필요할 수 있어 약간의 위험이 뒤따릅니다. 특히, (a) 사이트 간 연결이 중단되고 (b) 연결이 복원되고 (c) 애그리게이트가 일부는 동기화되고 일부는 동기화되지 않은 상태에 도달한 경우 그런 다음 (d) 기본 사이트가 손실되고, 결과적으로 애그리게이트가 서로 동기화되지 않는 정상적인 사이트가 됩니다. 이 경우 데이터 세트의 각 부분이 서로 동기화되며 복구가 수행되지 않으면 애플리케이션, 데이터베이스 또는 데이터 저장소를 가져올 수 없습니다. 데이터 세트에서 애그리게이트를 확장하는 경우 NetApp, 사용할 수 있는 여러 도구 중 하나와 함께 스냅샷 기반 백업을 활용하여 이 비정상적인 시나리오에서 빠른 복구 기능을 확인하는 것이 좋습니다.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP 및 RAID-TEC는 모두 패리티를 사용하여 드라이브 오류로 인해 데이터가 손실되지 않도록 합니다. 이들 RAID 옵션은 미러링에 비해 스토리지 사용률이 훨씬 뛰어나지만 대부분의 RAID 구현에서는 쓰기 작업이 영향을 받는다는 문제가 있습니다. 다른 RAID 구현에서 쓰기 작업을 완료하려면 다중 드라이브 읽기를 통해 패리티 데이터를 재생성해야 할 수 있으며, 이를 일반적으로 RAID 성능 저하라고 합니다.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">그러나 ONTAP에서는 이 RAID 성능 저하가 발생하지 않습니다. 이는 NetApp WAFL(Write Anywhere File Layout)과 RAID 계층의 통합 때문입니다. 쓰기 작업은 RAM에 병합되며 패리티 생성을 포함하여 전체 RAID 스트라이프로 준비됩니다. ONTAP는 쓰기를 완료하기 위해 읽기를 수행할 필요가 없으며, 이는 ONTAP 및 WAFL에서 RAID 성능 저하가 일어나지 않는다는 뜻입니다. 로깅 재실행과 같이 지연 시간이 중요한 작업의 성능은 영향을 받지 않으며, 랜덤 데이터 파일 쓰기에는 패리티를 다시 생성해야 하므로 RAID 성능 저하가 발생하지 않습니다.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">통계적 안정성을 고려하면 RAID DP도 RAID 미러링보다 우수한 보호 기능을 제공합니다. 기본적인 문제는 RAID 리빌드 중에 드라이브에서 발생하는 수요입니다. 미러링된 RAID 세트가 있으면 RAID 세트에서 파트너에 대해 리빌드를 하는 동안 드라이브 장애로 인해 데이터가 손실될 위험이 RAID DP 세트에서 삼중 드라이브 장애가 일어날 위험보다 훨씬 큽니다.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">플래시 드라이브의 시대 이전에는 스트라이핑이 회전식 드라이브의 성능 제한을 극복하는 데 사용되었습니다. 예를 들어, OS에서 1MB 읽기 작업을 수행해야 하는 경우 1MB가 느리게 전송되기 때문에 단일 드라이브에서 1MB의 데이터를 읽으려면 많은 드라이브 헤드가 필요합니다. 이 1MB의 데이터가 8개의 LUN에 스트라이핑된 경우 운영 체제에서는 8개의 128K의 읽기 작업을 병렬로 실행하고 1MB 전송을 완료하는 데 필요한 시간을 줄일 수 있습니다.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">회전식 드라이브를 사용한 스트라이핑은 I/O 패턴을 사전에 알고 있어야 하므로 더 어려웠습니다. 스트라이핑이 실제 I/O 패턴에 맞게 올바르게 조정되지 않은 경우 스트라이핑된 구성이 성능을 저하시킬 수 있습니다. Oracle 데이터베이스, 특히 All-Flash 구성을 사용하면 스트라이핑이 훨씬 쉽게 구성되고 성능이 크게 향상된다는 사실이 입증되었습니다.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">기본적으로 Oracle ASM 스트라이프와 같은 논리적 볼륨 관리자는 있지만 기본 OS LVM은 그렇지 않습니다. 이 중 일부는 여러 LUN을 연결된 장치로 연결하므로 하나의 LUN 디바이스와 하나의 LUN 디바이스에 데이터 파일이 존재합니다. 이로 인해 핫스팟이 발생합니다. 다른 LVM 구현은 기본적으로 분산 익스텐트로 설정됩니다. 이는 스트라이핑과 비슷하지만 더 거칠습니다. 볼륨 그룹의 LUN은 익스텐트라고 하는 큰 조각으로 분할되며 일반적으로 메가바이트 단위로 측정되며 논리적 볼륨은 이러한 익스텐트에 분산됩니다. 그 결과 파일에 대한 랜덤 I/O가 LUN 전체에 분산되어야 하지만 순차적 I/O 작업의 효율성이 최대한 높지는 않습니다.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">높은 성능을 필요로 하는 애플리케이션 I/O는 거의 항상 (a) 기본 블록 크기 단위 또는 (b) 1MB입니다.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">스트라이핑 구성의 기본적인 목표는 단일 파일 I/O를 단일 유닛으로 수행하고, 1MB 크기여야 하는 다중 블록 I/O를 스트라이핑 볼륨의 모든 LUN에 걸쳐 균등하게 병렬 처리할 수 있도록 지원하는 것입니다. 즉, 스트라이프 크기가 데이터베이스 블록 크기보다 작아서는 안 되며 스트라이프 크기를 LUN 수를 곱한 크기가 1MB여야 합니다.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">다음 그림에서는 스트라이프 크기 및 폭 조정에 사용할 수 있는 세 가지 옵션을 보여 줍니다. 위에서 설명한 대로 성능 요구 사항을 충족하기 위해 LUN 수를 선택하지만 모든 경우에 단일 스트라이프의 총 데이터는 1MB입니다.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">ONTAP 구성</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">여기.</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">계층화</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">ONTAP의 PostgreSQL 데이터베이스</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">네이티브 데이터 보호</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">스토리지 설계의 주요 측면 중 하나는 PostgreSQL 볼륨을 보호하는 것입니다. 고객은 덤프 방식을 사용하거나 파일 시스템 백업을 사용하여 PostgreSQL 데이터베이스를 보호할 수 있습니다. 이 섹션에서는 개별 데이터베이스 또는 전체 클러스터를 백업하는 다양한 접근 방식에 대해 설명합니다.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">PostgreSQL 데이터를 백업하는 방법에는 세 가지가 있습니다.</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">SQL Server 덤프</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">파일 시스템 레벨 백업</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">지속적인 아카이빙</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">SQL Server 덤프 방법의 기본 개념은 SQL Server 명령을 사용하여 파일을 생성하는 것입니다. 이 명령은 서버에 반환될 때 덤프 시점의 데이터베이스를 다시 만들 수 있습니다. PostgreSQL은 유틸리티 프로그램을 제공합니다<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> 및<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> 개별 및 클러스터 수준 백업을 생성하는 데 사용됩니다. 이러한 덤프는 논리적이며 Wal 재생에 사용할 수 있는 충분한 정보가 포함되어 있지 않습니다.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">다른 백업 전략은 파일 시스템 수준 백업을 사용하는 것입니다. 이 백업을 사용하면 관리자가 PostgreSQL에서 데이터베이스에 데이터를 저장하는 데 사용하는 파일을 직접 복사할 수 있습니다. 이 방법은 오프라인 모드에서 수행됩니다. 데이터베이스나 클러스터를 종료해야 합니다. 또 다른 대안은 을 사용하는 것입니다<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> PostgreSQL 데이터베이스의 핫 스트리밍 백업을 실행합니다.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">ONTAP의 PostgreSQL 데이터베이스</block>
  <block id="b5f477e959f26421a80e1eebdadbdd71" category="paragraph">PostgreSQL에는 PostgreSQL, PostgreSQL Plus 및 EDB Postgres Advanced Server(EPAS)가 포함된 변종이 함께 제공됩니다. PostgreSQL은 일반적으로 다중 계층 애플리케이션을 위한 백엔드 데이터베이스로 구축됩니다. 일반적인 미들웨어 패키지(PHP, Java, Python, Tcl/Tk, ODBC, 또한 JDBC는 오픈 소스 데이터베이스 관리 시스템에서 널리 사용되고 있습니다. NetApp ONTAP는 PostgreSQL 데이터베이스를 실행할 때 탁월한 선택으로 신뢰성, 고성능 및 효율적인 데이터 관리 기능을 제공합니다.</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">ONTAP 및 PostgreSQL 데이터베이스에 대한 이 문서는 이전에 게시된 _TR-4770:PostgreSQL 데이터베이스를 ONTAP 모범 사례에 대한 데이터베이스로 대체합니다</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">스냅샷 수</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">PostgreSQL을 사용한 스냅샷 기반 백업에는 전체 또는 시점 복구를 제공하기 위해 데이터 파일, Wal 파일 및 보관된 Wal 파일에 대한 스냅샷 구성이 필요합니다.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">PostgreSQL 데이터베이스의 경우 스냅샷을 사용하는 평균 백업 시간은 몇 초에서 몇 분 사이입니다. 이 백업 속도는 보다 60 ~ 100배 빠릅니다<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> 다양한 파일 시스템 기반 백업 방법을 알아봅니다.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">NetApp 스토리지의 스냅샷은 충돌 시에도 정합성이 보장되는 스냅샷과 애플리케이션 정합성을 유지할 수 있습니다. 장애 발생 시 정합성이 보장되는 스냅샷은 데이터베이스를 중지하지 않고 스토리지에 생성되지만 애플리케이션 정합성이 보장되는 스냅샷은 데이터베이스가 백업 모드에 있는 동안 생성됩니다. 또한 NetApp는 후속 스냅샷이 증분식 영구 백업되도록 하여 스토리지 절감 및 네트워크 효율성을 높입니다.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">스냅샷은 빠르고 시스템 성능에 영향을 미치지 않으므로 다른 스트리밍 백업 기술과 마찬가지로 일일 백업을 하나씩 생성하는 대신 매일 여러 스냅샷을 예약할 수 있습니다. 복원 및 복구 작업이 필요한 경우 시스템 가동 중지 시간은 다음과 같은 두 가지 주요 기능으로 줄어듭니다.</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">NetApp SnapRestore 데이터 복구 기술은 복원 작업이 몇 초 안에 실행된다는 것을 의미합니다.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">공격적 RPO(복구 시점 목표)는 적용해야 하는 데이터베이스 로그 수가 적고 전달 복구도 가속화된다는 것을 의미합니다.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">PostgreSQL을 백업하려면 (consistency-group) Wal 및 보관된 로그를 사용하여 데이터 볼륨을 동시에 보호해야 합니다. Snapshot 기술을 사용하여 Wal 파일을 복사하는 동안 를 실행해야 합니다<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> 보관해야 하는 모든 Wal 항목을 플러시합니다. 복구 중에 Wal 항목을 플러시하는 경우 데이터베이스를 중지하거나, 기존 데이터 디렉토리를 마운트 해제 또는 삭제하고, 스토리지에서 SnapRestore 작업만 수행하면 됩니다. 복구가 완료된 후 시스템을 마운트하여 현재 상태로 되돌릴 수 있습니다. 시점 복구의 경우 Wal 및 아카이브 로그를 복원할 수도 있습니다. 그러면 PostgreSQL이 가장 일관된 지점을 결정하고 자동으로 복구합니다.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">정합성 보장 그룹은 ONTAP의 기능이며 단일 인스턴스 또는 여러 테이블스페이스가 있는 데이터베이스에 여러 개의 볼륨이 마운트된 경우 권장됩니다. 정합성 보장 그룹 스냅샷은 모든 볼륨이 함께 그룹화되고 보호되도록 합니다. 일관성 그룹은 ONTAP System Manager에서 효율적으로 관리할 수 있으며 일관성 그룹을 클론 복제하여 테스트 또는 개발 목적으로 데이터베이스의 인스턴스 복사본을 생성할 수도 있습니다.</block>
  <block id="55ca4b30c6f7c3ef975a6d1e1fb222a2" category="inline-link-macro">NetApp 정합성 보장 그룹 개요</block>
  <block id="69dd5879aee425e37fdd5796a8e06a56" category="paragraph">일관성 그룹에 대한 자세한 내용은 를 참조하십시오 <block ref="112c5744a39904facdbc5fab385d9fe1" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">데이터 보호</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">테이블스페이스</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">데이터베이스 클러스터가 초기화될 때 두 개의 테이블스페이스가 자동으로 생성됩니다.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">를 클릭합니다<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> 테이블스페이스는 공유 시스템 카탈로그에 사용됩니다. 를 클릭합니다<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> 테이블스페이스는 Template1 및 template0 데이터베이스의 기본 테이블스페이스입니다. 클러스터가 초기화된 파티션이나 볼륨에 공간이 부족하여 확장할 수 없는 경우 다른 파티션에 테이블스페이스를 생성하여 시스템을 재구성할 때까지 사용할 수 있습니다.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">자주 사용되는 인덱스는 솔리드 스테이트 디바이스처럼 빠른 고가용성 디스크에 배치할 수 있습니다. 또한 드물게 사용되거나 성능이 중요하지 않은 아카이브 데이터를 저장하는 테이블을 SAS 또는 SATA 드라이브와 같이 더 저렴하고 느린 디스크 시스템에 저장할 수 있습니다.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">테이블스페이스는 데이터베이스 클러스터의 일부이며 데이터 파일의 자동 모음으로 취급할 수 없습니다. 기본 데이터 디렉토리에 포함된 메타데이터에 따라 달라지므로 다른 데이터베이스 클러스터에 연결하거나 개별적으로 백업할 수 없습니다. 마찬가지로 파일 삭제, 디스크 오류 등을 통해 테이블스페이스를 잃으면 데이터베이스 클러스터를 읽을 수 없거나 시작할 수 없게 됩니다. RAM 디스크와 같은 임시 파일 시스템에 테이블스페이스를 배치하면 전체 클러스터의 안정성이 저하됩니다.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">생성된 후 요청 사용자에게 충분한 권한이 있는 경우 모든 데이터베이스에서 테이블스페이스를 사용할 수 있습니다. PostgreSQL은 심볼 링크를 사용하여 테이블스페이스의 구현을 간소화합니다. PostgreSQL은 에 행을 추가합니다<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> 테이블(클러스터 전체 테이블) 및 새 OID(개체 식별자)를 해당 행에 할당합니다. 마지막으로, 서버는 OID를 사용하여 클러스터와 지정된 디렉토리 사이에 심볼 링크를 생성합니다. 디렉터리<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> 클러스터에 정의되어 있지 않은 각 테이블스페이스를 가리키는 심볼 링크를 포함합니다.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">데이터베이스 구성</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">성능을 향상시킬 수 있는 PostgreSQL 튜닝 구성에는 여러 가지가 있습니다.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">가장 일반적으로 사용되는 매개 변수는 다음과 같습니다.</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: 한 번에 가질 최대 데이터베이스 연결 수입니다. 이 매개 변수를 사용하여 디스크로의 스와핑을 제한하고 성능을 중단합니다. 응용 프로그램 요구 사항에 따라 연결 풀 설정에 대해 이 매개 변수를 조정할 수도 있습니다.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: 데이터베이스 서버의 성능을 개선하는 가장 간단한 방법입니다. 최신 하드웨어의 기본값은 LOW 입니다. 배포 중에 시스템에서 사용 가능한 RAM의 약 25%로 설정됩니다. 이 매개 변수 설정은 특정 데이터베이스 인스턴스에서 작동하는 방식에 따라 달라집니다. 시행 착오로 값을 늘리거나 줄여야 할 수도 있습니다. 그러나 높게 설정하면 성능이 저하될 수 있습니다.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: 이 값은 PostgreSQL의 최적화 프로그램에 PostgreSQL이 데이터를 캐싱하는 데 사용할 수 있는 메모리 양을 알려주고 인덱스를 사용할지 여부를 결정하는 데 도움이 됩니다. 값이 클수록 인덱스를 사용할 가능성이 높아집니다. 이 매개 변수는 에 할당된 메모리 크기로 설정해야 합니다<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> 사용 가능한 OS 캐시 양에 더합니다. 이 값은 전체 시스템 메모리의 50%를 초과하는 경우가 많습니다.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: 이 매개변수는 정렬 작업 및 해시 테이블에 사용할 메모리 양을 제어합니다. 응용 프로그램에서 무거운 정렬을 수행하는 경우 메모리 양을 늘려야 할 수 있지만 주의해야 합니다. 이는 시스템 차원 매개 변수가 아니라 작업당 매개 변수입니다. 복합 쿼리에 여러 개의 정렬 작업이 있는 경우 여러 개의 work_mem 메모리 유닛을 사용하며 여러 백 엔드에서 동시에 이 작업을 수행할 수 있습니다. 값이 너무 큰 경우 이 쿼리로 인해 데이터베이스 서버가 스왑될 수 있습니다. 이전 버전의 PostgreSQL에서는 이 옵션을 sort_mem이라고 했습니다.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: 이 매개변수는 트랜잭션이 커밋되기 전에 fsync()를 사용하여 모든 Wal 페이지를 디스크에 동기화할지 여부를 결정합니다. 이 기능을 끄면 쓰기 성능이 향상될 수 있으며 이 기능을 켜면 시스템이 충돌할 때 손상 위험으로부터 보호됩니다.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: 체크포인트 프로세스는 커밋된 데이터를 디스크로 플러시합니다. 여기에는 디스크에서 많은 양의 읽기/쓰기 작업이 사용됩니다. 이 값은 초 단위로 설정되고 값이 낮을수록 충돌 복구 시간이 줄어들고 값을 늘리면 체크포인트 호출을 줄여 시스템 리소스의 부하가 감소할 수 있습니다. 애플리케이션 중요도, 사용량, 데이터베이스 가용성에 따라 checkpoint_timeout 값을 설정합니다.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> 및<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: 이러한 옵션은 한 번에 커밋되는 여러 트랜잭션을 작성함으로써 성능을 향상시키는 데 사용됩니다. 트랜잭션이 커밋되는 즉시 여러 개의 commit_siblings 개체가 활성 상태인 경우 서버는 commit_delay microseconds가 한 번에 여러 트랜잭션을 커밋할 때까지 기다립니다.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: 프로세스에 대한 최적의 작업자 수를 구성합니다. max_parallel_workers는 사용 가능한 CPU 수에 해당합니다. 응용 프로그램 설계에 따라 병렬 작업의 경우 쿼리에 필요한 작업자의 수가 줄어들 수 있습니다. 두 매개 변수의 값을 동일하게 유지하되 테스트 후 값을 조정하는 것이 좋습니다.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: 이 값은 PostgreSQL이 비순차적 디스크 읽기를 보는 방식을 제어합니다. 값이 높을수록 PostgreSQL은 인덱스 검사 대신 순차 검사를 사용할 가능성이 높으므로 서버에 빠른 디스크가 있음을 나타냅니다. 계획 기반 최적화, 진공 청소, 쿼리 또는 스키마를 변경하는 인덱싱 등의 다른 옵션을 평가한 후 이 설정을 수정합니다.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: 이 매개변수는 PostgreSQL이 동시에 실행하려고 시도하는 동시 디스크 I/O 작업의 수를 설정합니다. 이 값을 높이면 개별 PostgreSQL 세션이 병렬로 시작하려고 하는 입출력 작업 수가 증가합니다. 허용되는 범위는 1에서 1,000까지이며, 비동기 I/O 요청 발급을 비활성화하려면 0입니다. 현재 이 설정은 비트맵 힙 스캔에만 영향을 줍니다. SSD(Solid-State Drive)와 기타 메모리 기반 스토리지(NVMe)는 동시 요청을 많이 처리할 수 있으므로 수백 개의 요청이 최고의 가치를 실현할 수 있습니다.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">PostgreSQL 구성 매개 변수의 전체 목록은 PostgreSQL 설명서를 참조하십시오.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">토스트</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST는 특대형 특성 저장 기술을 의미합니다. PostgreSQL은 고정된 페이지 크기(일반적으로 8KB)를 사용하며 튜플이 여러 페이지에 걸쳐 있을 수 없습니다. 따라서 큰 필드 값을 직접 저장할 수 없습니다. 이 크기를 초과하는 행을 저장하려고 할 때 TOAST는 큰 열의 데이터를 작은 "조각"으로 나눈 다음 TOAST 테이블에 저장합니다.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">토스트 속성의 큰 값은 결과 집합이 클라이언트로 전송될 때만(선택한 경우) 당겨집니다. TOAST(Out-of-Line Storage)가 없을 때보다 테이블 자체가 훨씬 작고 공유 버퍼 캐시에 더 많은 행을 저장할 수 있습니다.</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">진공</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">일반적인 PostgreSQL 작업에서는 업데이트로 삭제되거나 폐기된 튜플은 테이블에서 물리적으로 제거되지 않으며 진공이 실행될 때까지 그대로 유지됩니다. 따라서, 특히 자주 업데이트되는 테이블에서 정기적으로 진공을 실행해야 합니다. 그런 다음 디스크 공간 중단을 방지하기 위해 새 행에서 재사용할 수 있도록 해당 공간을 재확보해야 합니다. 그러나 운영 체제에 공간을 반환하지 않습니다.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">페이지 내의 여유 공간은 조각화되지 않습니다. Vacuum은 전체 블록을 다시 쓰므로 나머지 행을 효율적으로 압축하고 페이지에 연속된 단일 여유 공간 블록을 남깁니다.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">반면, VACUM FULL은 데드 공간 없이 완전히 새로운 버전의 테이블 파일을 작성하여 테이블을 적극적으로 압축합니다. 이렇게 하면 테이블 크기가 최소화되지만 시간이 오래 걸릴 수 있습니다. 또한 작업이 완료될 때까지 테이블의 새 복사본을 위한 추가 디스크 공간이 필요합니다. 일상적인 진공의 목적은 진공이 완전히 작동하지 않도록 하는 것입니다. 이 프로세스는 테이블을 최소 크기로 유지할 뿐만 아니라 디스크 공간의 안정적 상태 사용도 유지합니다.</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">초기화</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">를 사용하여 새 데이터베이스 클러스터를 생성합니다<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> 프로그램. AN<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> 스크립트는 클러스터를 정의하는 데이터 파일, 시스템 테이블 및 템플릿 데이터베이스(template0 및 Template1)를 생성합니다.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">템플릿 데이터베이스는 재고 데이터베이스를 나타냅니다. 시스템 테이블, 표준 보기, 함수 및 데이터 형식에 대한 정의가 포함되어 있습니다.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> 에 대한 인수 역할을 합니다<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> 데이터베이스 클러스터의 위치를 지정하는 스크립트입니다.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">PostgreSQL의 모든 데이터베이스 개체는 해당 OID에 의해 내부적으로 관리됩니다. 테이블 및 인덱스도 개별 OID에 의해 관리됩니다. 데이터베이스 개체와 해당 OID 간의 관계는 개체 유형에 따라 적절한 시스템 카탈로그 테이블에 저장됩니다. 예를 들어 데이터베이스 및 힙 테이블의 OID는 에 저장됩니다<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> 및 ``pg_class. PostgreSQL 클라이언트에서 쿼리를 실행하여 OID를 확인할 수 있습니다.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">모든 데이터베이스에는 1GB로 제한된 고유한 개별 테이블 및 인덱스 파일이 있습니다. 각 테이블에는 각각 접미사가 붙은 두 개의 관련 파일이 있습니다<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> 및<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. 이를 여유 공간 지도와 가시성 지도라고 합니다. 이러한 파일은 사용 가능한 공간 용량에 대한 정보를 저장하며 테이블 파일의 각 페이지를 볼 수 있습니다. 인덱스에는 개별 가용 공간 맵만 있으며 가시성 맵은 없습니다.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">를 클릭합니다<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> 디렉토리에는 미리 쓰기 로그가 포함됩니다. 미리 쓰기 로그는 데이터베이스의 안정성과 성능을 개선하는 데 사용됩니다. 테이블의 행을 업데이트할 때마다 PostgreSQL은 먼저 미리 쓰기 로그에 변경 내용을 쓰고 나중에 실제 데이터 페이지에 대한 수정 내용을 디스크에 씁니다. 를 클릭합니다<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> 디렉터리에는 일반적으로 여러 파일이 포함되어 있지만 initdb는 첫 번째 파일만 만듭니다. 필요에 따라 추가 파일이 추가됩니다. 각 xlog 파일의 길이는 16MB입니다.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">* NetApp는 NFSv4 기능이 필요한 경우 NFSv4.1을 사용할 것을 권장합니다. NFSv4.1에서는 NFSv4 프로토콜의 기능이 개선되어 특정 엣지 경우 복원력을 향상할 수 있습니다.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">NFS 전송 크기</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">FC SAN</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">PostgreSQL 아키텍처</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL은 클라이언트 및 서버 아키텍처를 기반으로 하는 RDBMS입니다. PostgreSQL 인스턴스는 데이터베이스 클러스터라고 하며, 이 클러스터는 서버 컬렉션이 아닌 데이터베이스의 모음입니다.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">오류: 그래픽을 찾을 수 없습니다</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">PostgreSQL 데이터베이스에는 포스트마스터, 프런트 엔드(클라이언트) 및 백 엔드의 세 가지 주요 요소가 있습니다 클라이언트는 IP 프로토콜 및 연결할 데이터베이스와 같은 정보를 사용하여 Postmaster에 요청을 보냅니다. 포스트마스터는 연결을 인증하고 추가 통신을 위해 백 엔드 프로세스에 전달합니다. 백 엔드 프로세스는 쿼리를 실행하고 결과를 프런트 엔드(클라이언트)로 직접 보냅니다.</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">PostgreSQL 인스턴스는 다중 스레드 모델 대신 다중 프로세스 모델을 기반으로 합니다. 이 프로세스는 서로 다른 작업에 대해 여러 프로세스를 생성하며 각 프로세스에는 고유한 기능이 있습니다. 주요 프로세스에는 클라이언트 프로세스, Wal 작성기 프로세스, 백그라운드 작성기 프로세스 및 체크포인트 프로세스가 포함됩니다.</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">클라이언트(포그라운드) 프로세스가 PostgreSQL 인스턴스에 읽기 또는 쓰기 요청을 보내면 디스크에 직접 데이터를 읽거나 쓰지 않습니다. 먼저 공유 버퍼와 Wal(Write-Ahead Logging) 버퍼에 데이터를 버퍼링합니다.</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Wal 작성기 프로세스는 Wal 로그에 쓸 공유 버퍼 및 Wal 버퍼의 내용을 조작합니다. WAL 로그는 일반적으로 PostgreSQL의 트랜잭션 로그이며 순차적으로 기록됩니다. 따라서 데이터베이스의 응답 시간을 향상시키기 위해 PostgreSQL은 먼저 트랜잭션 로그에 기록하고 클라이언트를 확인합니다.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">데이터베이스를 일관된 상태로 만들기 위해 백그라운드 작성기 프로세스는 공유 버퍼에 더티 페이지가 있는지 주기적으로 검사합니다. 그런 다음 데이터를 NetApp 볼륨 또는 LUN에 저장된 데이터 파일로 플러싱합니다.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">또한 체크포인터 프로세스는 백그라운드 프로세스보다 빈도가 낮아 주기적으로 실행되며 버퍼가 수정되지 않습니다. NetApp 디스크에 저장된 Wal 로그 끝에 체크포인트 레코드를 쓰고 플러시하도록 Wal 작성기 프로세스에 신호를 보냅니다. 또한 백그라운드 작성기 프로세스에 모든 더티 페이지를 기록하고 디스크에 플러시하도록 신호를 보냅니다.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">데이터 보호 소프트웨어</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Snapshot 및 NetApp FlexClone 기술과 함께 PostgreSQL 데이터베이스용 NetApp SnapCenter 플러그인을 사용하면 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">신속한 백업 및 복원:</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">공간 효율적인 클론 복제:</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">빠르고 효율적인 재해 복구 시스템을 구축할 수 있는 능력.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">다음과 같은 상황에서 Veeam Software 및 Commvault와 같은 NetApp 프리미엄 백업 파트너를 선호할 수 있습니다.</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">이기종 환경에서 워크로드 관리</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">장기간 보존을 위해 클라우드 또는 테이프에 백업 저장</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">다양한 OS 버전 및 유형 지원</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">PostgreSQL용 SnapCenter 플러그인은 커뮤니티 지원 플러그인이며 설치 및 설명서는 NetApp 자동화 스토어에서 사용할 수 있습니다. 사용자는 SnapCenter를 통해 원격으로 데이터베이스를 백업하고, 데이터를 클론 복제하고, 복원할 수 있습니다.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">SAP HANA 및 AnyDB용 솔루션</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA 및 SAP with AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">SAP 솔루션의 구성, 관리 및 자동화에 대한 Best Practice는 NetApp SAP 솔루션 페이지에서 확인할 수 있습니다.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">여기</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">을 클릭하십시오 <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> 더 보기.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">ONTAP 기반 Microsoft SQL Server</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Microsoft SQL Server 재해 복구</block>
  <block id="810304d54e0a61663cfc457b0894037b" category="paragraph">NetApp는 하드웨어, 소프트웨어 또는 사이트 장애 발생 시 데이터 가용성을 높이기 위한 다양한 접근 방식을 제공합니다.</block>
  <block id="9c1e9d82d3220658621f72dca978adb0" category="section-title">NetApp SnapMirror 를 참조하십시오</block>
  <block id="46983273062fdc8ce8561a9ce89cdc5b" category="paragraph">NetApp SnapMirror 기술은 LAN 및 WAN을 통해 데이터를 미러링 또는 복제할 수 있는 빠르고 유연한 엔터프라이즈 솔루션을 제공합니다. SnapMirror 기술은 초기 기본 전송 후에 수정된 4KB 데이터 블록만 타겟으로 전송하므로 네트워크 대역폭 요구사항을 크게 줄여줍니다. SnapMirror는 구성된 복제 업데이트 간격을 기반으로 하는 비동기 볼륨 수준 복제를 제공합니다.
다음은 SQL Server용 SnapMirror에 대한 권장사항입니다.</block>
  <block id="5f3bfe8f92842bdc2f9455d4102f2531" category="list-text">CIFS를 사용하는 경우 대상 SVM은 소스 SVM이 속한 동일한 Active Directory 도메인의 구성원이어야 NAS 파일 내에 저장된 ACL(액세스 제어 목록)이 재해로부터 복구하는 동안 손상되지 않습니다.</block>
  <block id="e0fd410ebdc68e7ca628bbca66b63ff4" category="list-text">소스 볼륨 이름과 동일한 대상 볼륨 이름을 사용할 필요는 없지만, 대상 볼륨을 대상에 마운트하는 프로세스를 더 간편하게 관리할 수 있습니다. CIFS를 사용하는 경우 소스 네임스페이스와 경로 및 디렉토리 구조의 대상 NAS 네임스페이스를 동일하게 만들어야 합니다.</block>
  <block id="14b01fb6bdbebef1f8a00c7f84926307" category="list-text">일관성을 위해 컨트롤러에서 SnapMirror 업데이트를 예약하지 마십시오. 단, 전체 또는 로그 백업이 완료된 후 SnapCenter에서 SnapMirror를 업데이트하도록 SnapMirror를 활성화합니다.</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">SQL Server 데이터가 포함된 볼륨을 클러스터의 서로 다른 노드에 분산하여 모든 클러스터 노드가 SnapMirror 복제 활동을 공유할 수 있도록 합니다. 이러한 분산은 노드 리소스 사용을 최적화합니다.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">TR-4015:ONTAP 9용 SnapMirror 구성 및 모범 사례 가이드</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">SnapMirror에 대한 자세한 내용은 를 참조하십시오 <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="3d4b417d78ff0ef4c84f0c043de24b10" category="doc">데이터베이스 보안</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">CPU 구성</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">하이퍼스레딩</block>
  <block id="fe520b79816bad6a21fbebcb205c7ca9" category="paragraph">하이퍼스레딩은 인텔의 독점 SMT(동시 멀티스레딩) 구현으로 x86 마이크로프로세서에서 수행되는 계산(멀티태스킹)의 병렬화를 개선합니다.</block>
  <block id="005f484c2235e04f39d2e69256147281" category="paragraph">하이퍼스레딩을 사용하는 하드웨어에서는 논리적 하이퍼스레드 CPU가 운영 체제에 물리적 CPU로 나타날 수 있습니다. 그러면 SQL Server는 운영 체제가 제공하는 물리적 CPU를 인식하므로 하이퍼스레드 프로세서를 사용할 수 있습니다.</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">여기서 주의해야 할 점은 각 SQL Server 버전에는 사용할 수 있는 컴퓨팅 성능에 대한 제한이 있다는 것입니다. 자세한 내용은 SQL Server Edition별 계산 용량 제한 을 참조하십시오.</block>
  <block id="932a9271c08db114962ce3791480f371" category="paragraph">SQL Server 라이선스를 취득할 때 두 가지 주요 고려 사항이 있습니다. 첫 번째는 서버 + 클라이언트 액세스 라이센스(CAL) 모델이며 두 번째는 프로세서당 코어 모델입니다. 서버 + CAL 전략을 통해 SQL Server에서 사용할 수 있는 모든 제품 기능에 액세스할 수 있지만 소켓당 20개의 CPU 코어로 하드웨어 제한이 있습니다. 소켓당 20개가 넘는 CPU 코어가 있는 서버에 대해 SQL Server Enterprise Edition + CAL을 사용하는 경우에도 응용 프로그램은 해당 인스턴스에서 이러한 모든 코어를 한 번에 사용할 수 없습니다. 그림 에서는 시작 후 코어 제한 적용을 나타내는 SQL Server 로그 메시지를 보여 줍니다.</block>
  <block id="d06fce44fdcf20791141e7585205a477" category="section-title">로그 항목은 SQL Server 시작 후 사용 중인 코어 수를 나타냅니다.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022: 최신 데이터 플랫폼</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">따라서 모든 CPU를 사용하려면 프로세서당 코어 라이센스를 사용해야 합니다. SQL Server 라이센스에 대한 자세한 내용은 을 참조하십시오 <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">CPU 선호도</block>
  <block id="884be48d06a17be095fb51de089dfc89" category="paragraph">성능 문제가 발생하지 않는 한 프로세서 선호도 기본값을 변경할 필요는 없습니다. 그러나 성능 문제가 무엇이고 어떻게 작동하는지 이해하는 것이 좋습니다.</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server는 다음 두 가지 옵션을 통해 프로세서 선호도를 지원합니다.</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">CPU 선호도 마스크</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">선호도 I/O 마스크</block>
  <block id="14ad08466dec6635067b988a82e91a8e" category="paragraph">SQL Server는 운영 체제에서 사용할 수 있는 모든 CPU를 사용합니다(프로세서당 코어 라이센스를 선택한 경우). 모든 CPU에 스케줄러를 생성하여 지정된 워크로드에 대한 리소스를 최대한 활용할 수 있습니다. 멀티태스킹 시 서버의 운영 체제 또는 다른 응용 프로그램은 프로세스 스레드를 하나의 프로세서에서 다른 프로세서로 전환할 수 있습니다. SQL Server는 리소스를 많이 사용하는 응용 프로그램이므로 이 경우 성능에 영향을 줄 수 있습니다. 영향을 최소화하기 위해 모든 SQL Server 로드가 미리 선택된 프로세서 그룹으로 전달되도록 프로세서를 구성할 수 있습니다. 이는 CPU 선호도 마스크를 사용하여 수행할 수 있습니다.</block>
  <block id="28a51b601de21080b76fe2d8b2ec8101" category="paragraph">선호도 입출력 마스크 옵션은 SQL Server 디스크 입출력을 CPU의 하위 집합에 바인딩합니다. SQL Server OLTP 환경에서는 이 확장을 통해 입출력 작업을 실행하는 SQL Server 스레드의 성능을 향상시킬 수 있습니다.</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">최대 평행 거리(MAXDOP)</block>
  <block id="f7e9f8e341a301aec4560db108b93020" category="paragraph">기본적으로 SQL Server는 쿼리 실행 중에 사용 가능한 모든 CPU를 사용합니다(프로세서당 코어 라이센스가 선택된 경우).</block>
  <block id="9bdcdbe52ea41cf96b314b7b7671bd2a" category="paragraph">대규모 쿼리에 적합하지만 성능 문제가 발생하고 동시성이 제한될 수 있습니다. 더 좋은 방법은 병렬 처리를 단일 CPU 소켓의 물리적 코어 수로 제한하는 것입니다. 예를 들어, 하이퍼스레딩에 관계없이 소켓당 12개의 코어가 있는 물리적 CPU 소켓 2개가 있는 서버에서 MAXDOP를 12로 설정해야 합니다. MAXDOP는 사용할 CPU를 제한하거나 지정할 수 없습니다. 대신 단일 배치 쿼리에서 사용할 수 있는 CPU 수를 제한합니다.</block>
  <block id="1a6b79859b80796a108bd348f98856f6" category="admonition">* NetApp는 데이터 웨어하우스와 같은 DSS에 대해 이 설정을 50 이상으로 시작하고 필요에 따라 조정 또는 축소할 것을 권장합니다. 응용 프로그램에서 중요한 쿼리를 측정하고 필요한 경우 조정합니다.</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">최대 작업자 스레드 수</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">최대 작업자 스레드 옵션을 사용하면 많은 수의 클라이언트가 SQL Server에 연결될 때 성능을 최적화할 수 있습니다.</block>
  <block id="aefc7f2ee96effbbbe49e6ece6d2f72a" category="paragraph">일반적으로 각 쿼리 요청에 대해 별도의 운영 체제 스레드가 만들어집니다. SQL Server에 수백 개의 동시 연결이 이루어지면 쿼리 요청당 하나의 스레드가 많은 양의 시스템 리소스를 소비합니다. 최대 작업자 스레드 옵션을 사용하면 SQL Server에서 작업자 스레드 풀을 만들어 더 많은 수의 쿼리 요청을 처리할 수 있으므로 성능이 향상됩니다.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">기본값은 0입니다. 이 값을 사용하면 SQL Server가 시작 시 작업자 스레드 수를 자동으로 구성할 수 있습니다. 이는 대부분의 시스템에서 작동합니다. Max worker 스레드는 고급 옵션이므로 숙련된 데이터베이스 관리자(DBA)의 도움 없이 변경할 수 없습니다.</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">최대 작업자 스레드 서버 구성 옵션을 구성합니다</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">작업자 스레드를 더 많이 사용하도록 SQL Server를 구성해야 하는 경우는 언제입니까? 각 스케줄러의 평균 작업 대기열 길이가 1을 초과하면 시스템에 더 많은 스레드를 추가할 수 있습니다. 단, 로드가 CPU에 바인딩되지 않거나 다른 과중한 대기가 발생하는 경우에만 가능합니다. 이러한 상황이 발생하는 경우 스레드를 더 추가해도 다른 시스템 병목 현상이 발생하기 때문에 도움이 되지 않습니다. 최대 작업자 스레드에 대한 자세한 내용은 을 참조하십시오 <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">SQL Server Management Studio를 사용하여 최대 작업자 스레드 구성</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="doc">Microsoft SQL Server tempdb 파일</block>
  <block id="625156cc6cef9a3c56b1b535579bd2c9" category="paragraph">NetApp에서는 디스크 조각화를 방지하기 위해 tempdb 파일을 전체 크기로 미리 확장하는 것이 좋습니다.</block>
  <block id="ca75041d415f4dafabb49b7f06b634ed" category="paragraph">페이지 경합은 SQL Server가 새 개체를 할당하기 위해 특수 시스템 페이지에 써야 하는 경우 전역 할당 맵(GAM), 공유 전역 할당 맵(SGAM) 또는 페이지 사용 가능 공간(PFS) 페이지에서 발생할 수 있습니다. 래치는 이러한 페이지를 메모리에서 보호(잠금)합니다. 사용 중인 SQL Server 인스턴스의 경우 tempdb의 시스템 페이지에 래치가 표시되는 데 시간이 오래 걸릴 수 있습니다. 이로 인해 쿼리 실행 시간이 느려지며 래치 경합이라고 합니다. tempdb 데이터 파일을 생성하는 방법은 다음 Best Practice를 참조하십시오.</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">또는 = 8코어: tempdb 데이터 파일 = 코어 수입니다</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">8코어 이상의 경우: 8tempdb 데이터 파일</block>
  <block id="b9f341e4fb0e6b384aa7ec0b5c33f964" category="paragraph">다음 예제 스크립트는 tempdb 파일 8개를 생성하고 tempdb를 마운트 지점으로 이동하여 tempdb를 수정합니다<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> SQL Server 2012 이상</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">SQL Server 2016부터 운영 체제에 표시되는 CPU 코어 수가 설치 중에 자동으로 감지되며, 이 수에 따라 SQL Server는 최적의 성능을 위해 필요한 tempdb 파일 수를 계산 및 구성합니다.</block>
  <block id="1c5b37437282a3648dde78afd914e452" category="doc">Microsoft SQL Server 개요</block>
  <block id="9aa5016539f88d8f1972a16ce9babd34" category="paragraph">SQL Server는 Microsoft의 데이터 플랫폼의 토대로서, 인메모리 기술을 통해 업무상 중요한 성능을 제공하고 온프레미스 또는 클라우드의 모든 데이터에 대한 보다 빠른 인사이트를 제공합니다.</block>
  <block id="8133a02d7327679696821fb31b105177" category="paragraph">Microsoft SQL Server는 미션 크리티컬 응용 프로그램을 위한 탁월한 성능, 가용성 및 관리 효율성을 제공하여 이전 릴리스에서 제공된 업무상 중요한 기능을 기반으로 구축되었습니다. 스토리지 시스템은 SQL Server 데이터베이스의 전체 성능에 있어 핵심 요소입니다. NetApp은 SQL Server 데이터베이스에서 엔터프라이즈급 성능을 제공하는 동시에 환경을 관리하기 위한 세계 최고의 툴을 제공하는 여러 제품을 제공합니다.</block>
  <block id="0bdfc026961d516d3d473152b4b6a87e" category="section-title">목적 및 범위</block>
  <block id="d0554e23b25bb82082a0cd9eaf810d0f" category="paragraph">이 섹션에서는 NetApp ONTAP 소프트웨어를 실행하는 NetApp 스토리지 시스템에 SQL Server를 구축하기 위한 설계 고려사항과 모범 사례를 설명하고, 효과적이고 효율적인 스토리지 배포와 엔드 투 엔드 데이터 보호 및 보존 계획을 달성한다는 목표를 제시합니다. 이 가이드의 범위는 NetApp에서 SQL Server를 구축할 때 스토리지 인프라에 권장하는 설계 원칙 및 기본 표준에 따른 기술 설계 지침으로 제한됩니다. 전체 구현이 이 보고서의 범위를 벗어납니다.</block>
  <block id="cf4cab9c6fd24025b34dfcae06e9b6fc" category="paragraph">이 가이드에 설명된 모범 사례와 권장 사항을 사용하여 SQL Server 설계자와 NetApp 스토리지 관리자는 가용성이 높고 관리하기 쉬운 SQL Server 환경을 계획하고 엄격한 SLA를 충족할 수 있습니다. NetApp는 독자가 다음에 대한 실무 지식을 보유하고 있다고 가정합니다.</block>
  <block id="9801f873fe2232da0de3cbab00483bfb" category="list-text">NetApp ONTAP 소프트웨어</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">백업 소프트웨어로 제공되는 NetApp SnapCenter에는 다음이 포함됩니다.</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Microsoft Windows용 SnapCenter 플러그인</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">SQL Server용 SnapCenter 플러그인</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Microsoft SQL Server 아키텍처 및 관리</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">NetApp 상호 운용성 매트릭스 툴(IMT)</block>
  <block id="c02eaaaf0eed9e51c3a9e1e9ae8b9147" category="paragraph">NetApp 스택 전반의 구성 호환성은 를 참조하십시오 <block ref="ea0e6fe442c1f7a042a8853ffcc2b382" category="inline-link-macro-rx"></block>.</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Microsoft SQL Server 스토리지 고려 사항</block>
  <block id="8c2a9e7195a263b5d79d397f5c6a9f68" category="paragraph">NetApp 스토리지 솔루션과 Microsoft SQL Server를 결합하여 오늘날의 가장 까다로운 애플리케이션 요구사항을 충족할 수 있는 엔터프라이즈급 데이터베이스 스토리지 설계를 작성할 수 있습니다.</block>
  <block id="8136e237a15b0f72e5d7a60392225d17" category="paragraph">두 기술을 모두 최적화하려면 SQL Server I/O 패턴과 특성을 이해해야 합니다. SQL Server 데이터베이스를 위해 잘 설계된 스토리지 레이아웃은 SQL Server의 성능과 SQL Server 인프라의 관리를 지원합니다. 또한 우수한 스토리지 레이아웃을 통해 초기 구축을 성공적으로 수행할 수 있으며 비즈니스 성장에 따라 환경이 원활하게 확장될 수 있습니다.</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">데이터 스토리지 설계</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">SnapCenter를 사용하여 백업을 수행하지 않는 SQL Server 데이터베이스의 경우 데이터와 로그 파일을 별도의 드라이브에 배치하는 것이 좋습니다. 데이터를 동시에 업데이트하고 요청하는 응용 프로그램의 경우 로그 파일은 쓰기 작업이 많고 데이터 파일(응용 프로그램에 따라 다름)은 읽기/쓰기 작업이 많이 사용됩니다. 데이터 검색을 위해 로그 파일이 필요하지 않습니다. 따라서 자체 드라이브에 있는 데이터 파일에서 데이터 요청을 처리할 수 있습니다.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">데이터 및 로그 파일을 별도의 드라이브에 저장합니다</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">새 데이터베이스를 만들 때는 데이터와 로그에 대해 별도의 드라이브를 지정하는 것이 좋습니다. 데이터베이스를 만든 후 파일을 이동하려면 데이터베이스를 오프라인으로 전환해야 합니다. Microsoft 권장 사항에 대한 자세한 내용은 을 참조하십시오 <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">애그리게이트</block>
  <block id="b8212b86fca1dcaeb0438529a03212c3" category="paragraph">애그리게이트는 NetApp 스토리지 구성을 위한 운영 스토리지 컨테이너이며 데이터 디스크와 패리티 디스크로 구성된 하나 이상의 RAID 그룹을 포함합니다. NetApp은 데이터 파일 및 트랜잭션 로그 파일이 분리된 공유 및 전용 애그리게이트를 사용하여 다양한 I/O 워크로드 특성 테스트를 수행했습니다. 이 테스트에서는 더 많은 RAID 그룹 및 스핀들이 포함된 하나의 대형 Aggregate가 스토리지 성능을 최적화 및 개선하고 다음 두 가지 이유로 관리자가 보다 쉽게 관리할 수 있음을 보여줍니다.</block>
  <block id="5f9196be7c85ebe3a38375ace1f3a345" category="list-text">하나의 대형 Aggregate는 모든 스핀들의 I/O 기능을 모든 파일에 사용할 수 있게 합니다.</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">하나의 대형 Aggregate는 디스크 공간을 가장 효율적으로 사용합니다.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">고가용성(HA)을 위해 SQL Server Always On Availability Group 보조 동기식 복제본을 애그리게이트의 별도의 SVM(스토리지 가상 머신)에 배치합니다. 재해 복구를 위해 NetApp SnapMirror 기술을 사용하여 복제된 콘텐츠와 함께 DR 사이트에서 별도의 스토리지 클러스터의 일부인 애그리게이트에 비동기식 복제를 배치하십시오. NetApp은 최적의 스토리지 성능을 위해 애그리게이트에서 최소 10% 이상의 여유 공간을 사용할 것을 권장합니다.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">볼륨</block>
  <block id="5ec65e803efce0f0779c59e4df9b2a71" category="paragraph">NetApp FlexVol 볼륨이 생성되어 애그리게이트 내에 상주합니다. 많은 볼륨을 단일 aggregate에서 만들 수 있고, 사용자 다운타임 없이 애그리게이트 간에 확장, 축소 또는 이동할 수 있습니다.</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">볼륨 설계 고려 사항</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">데이터베이스 볼륨 설계를 생성하기 전에 SQL Server 입출력 패턴과 특성이 워크로드와 백업 및 복구 요구 사항에 따라 어떻게 다른지 이해해야 합니다. 확장 가능한 볼륨에 대한 다음 NetApp 권장 사항을 참조하십시오.</block>
  <block id="570f1006846b0d45ff44b4332b9b4d14" category="list-text">유연한 볼륨을 사용하여 SQL Server 데이터베이스 파일을 저장하고 호스트 간에 볼륨을 공유하지 않도록 합니다.</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Windows의 26개 드라이브 문자 제한을 능가하려면 드라이브 문자 대신 NTFS 마운트 지점을 사용하십시오. 볼륨 마운트 지점을 사용할 때는 볼륨 레이블에 마운트 지점과 동일한 이름을 지정하는 것이 좋습니다.</block>
  <block id="d5fe4f7f1c47df1ec78c926d21498f73" category="list-text">필요한 경우 볼륨 자동 크기 조정 정책을 구성하여 공간 부족 상태를 방지하십시오. ONTAP c 2022 NetApp, Inc.의 Microsoft SQL Server에 대한 17 모범 사례 가이드 저작권 본사 소유.</block>
  <block id="fdb3a973962ea77cf56d76e12cff8c7d" category="list-text">SQL Server 데이터베이스 I/O 프로필이 의사 결정 지원 시스템 워크로드와 같이 대부분 대규모 순차 읽기로 구성된 경우 볼륨에 대한 읽기 재할당을 설정합니다. 읽기 재할당은 블록을 최적화하여 성능을 개선합니다.</block>
  <block id="3a9320cf27fb328f77ec6153273784d5" category="list-text">SMB 공유에 SQL Server를 설치하는 경우 폴더를 생성할 수 있도록 SMB/CIFS 볼륨에 유니코드가 설정되어 있는지 확인합니다.</block>
  <block id="08a6901e4e7b04d6170563bc57864093" category="list-text">운영 관점에서 쉽게 모니터링할 수 있도록 볼륨의 NetApp 스냅샷 복사본 예약 값을 0으로 설정합니다.</block>
  <block id="156ce9adf6c474183396aa3cfb8f92f1" category="list-text">스토리지 Snapshot ™ 복사 일정 및 보존 정책을 사용하지 않도록 설정합니다. 대신 SnapCenter를 사용하여 SQL Server 데이터 볼륨의 스냅샷 복사본을 조정합니다.</block>
  <block id="f2e00c12259a4bb11608f2a12fc8014a" category="list-text">SQL Server 시스템 데이터베이스를 전용 볼륨 또는 VMDK에 배치합니다.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">tempdb는 SQL Server가 임시 작업 공간으로 사용하는 시스템 데이터베이스로, 특히 I/O를 많이 사용하는 DBCC CHECKDB 작업에 사용됩니다. 따라서 이 데이터베이스를 별도의 스핀들 세트가 있는 전용 볼륨에 배치하십시오. 볼륨 수가 문제가 되는 대규모 환경에서는 신중하게 계획을 수립한 후 tempdb를 더 적은 볼륨으로 통합하고 동일한 볼륨에 저장할 수 있습니다. SQL Server를 다시 시작할 때마다 이 데이터베이스가 다시 생성되므로 tempdb에 대한 데이터 보호는 높은 우선 순위가 아닙니다.</block>
  <block id="57eda1aa66778bf3c77caa0294652ba8" category="list-text">사용자 데이터 파일(.mdf)은 랜덤 읽기/쓰기 워크로드이므로 별도의 볼륨에 배치하십시오. 일반적으로 트랜잭션 로그 백업은 데이터베이스 백업보다 더 자주 생성됩니다. 이러한 이유로 트랜잭션 로그 파일(.ldf)을 데이터 파일과 별도의 볼륨 또는 VMDK에 배치하여 각각에 대해 독립적인 백업 일정을 생성할 수 있도록 합니다. 또한 이 분리 방식은 로그 파일의 순차적 쓰기 I/O를 데이터 파일의 랜덤 읽기/쓰기 I/O에서 격리하고 SQL Server 성능을 크게 향상시킵니다.</block>
  <block id="b26e74ed6e2892c7e2bb95e414d460c6" category="section-title">LUN을 클릭합니다</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">사용자 데이터베이스 파일과 로그 백업을 저장할 로그 디렉토리가 별도의 볼륨에 있어야 보존 정책이 SnapVault 기술과 함께 사용될 때 스냅샷을 덮어쓰지 않도록 할 수 있습니다.</block>
  <block id="152bb9192ea87919eda3b4f97fd4e1bf" category="list-text">SQL Server 데이터베이스가 전체 텍스트 검색 관련 파일과 같이 데이터베이스 파일이 아닌 LUN과 분리된 LUN에 상주해야 합니다.</block>
  <block id="e2faf723544ceb1ea01ba41cef2d633a" category="list-text">데이터베이스 보조 파일(파일 그룹의 일부로)을 별도의 볼륨에 배치하면 SQL Server 데이터베이스의 성능이 향상됩니다. 이 분리는 데이터베이스의 .mdf 파일이 LUN을 다른 .mdf 파일과 공유하지 않는 경우에만 유효합니다.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">DiskManager 또는 다른 툴을 사용하여 LUN을 생성하는 경우 LUN을 포맷할 때 파티션의 할당 단위 크기가 64K로 설정되어 있는지 확인하십시오.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">최신 SAN에 대한 ONTAP 모범 사례 하의 Microsoft Windows 및 네이티브 MPIO</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">를 참조하십시오 <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Windows에서 MPIO 속성의 iSCSI 장치에 다중 경로 지원을 적용하려면 다음을 수행합니다.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">로그 디렉토리</block>
  <block id="973781a026becacffaae9fd5fd5c2b7b" category="paragraph">로그 디렉토리는 트랜잭션 로그 백업 데이터를 호스트 레벨에서 저장하기 위해 SQL Server에 지정됩니다. SnapCenter를 사용하여 로그 파일을 백업하는 경우 SnapCenter에서 사용하는 각 SQL Server 호스트에 로그 백업을 수행하도록 구성된 호스트 로그 디렉토리가 있어야 합니다. SnapCenter에는 데이터베이스 저장소가 있으므로 백업, 복원 또는 클론 복제 작업과 관련된 메타데이터가 중앙 데이터베이스 저장소에 저장됩니다.</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">호스트 로그 디렉토리의 크기는 다음과 같이 계산됩니다.
호스트 로그 디렉토리의 크기 = ((최대 DB LDF 크기 x 일일 로그 변경률 %) x (스냅샷 보존) ÷ (1 - LUN 오버헤드 공간 %)
호스트 로그 디렉토리 크기 조정 공식에서는 10%의 LUN 오버헤드 공간을 가정합니다</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">로그 디렉토리를 전용 볼륨 또는 LUN에 배치합니다. 호스트 로그 디렉토리의 데이터 양은 백업 크기 및 백업 보존 일수에 따라 달라집니다. SnapCenter는 SQL Server 호스트당 하나의 호스트 로그 디렉토리만 허용합니다. 호스트 로그 디렉토리는 SnapCenter --&gt; 호스트 -&gt; 플러그인 구성에서 구성할 수 있습니다.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">* NetApp는 호스트 로그 디렉토리에 대해 다음을 권장합니다 *.</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">호스트 로그 디렉토리가 백업 스냅샷 데이터를 손상시킬 수 있는 다른 유형의 데이터와 공유되지 않도록 하십시오.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">마운트 지점을 호스팅하는 LUN에 사용자 데이터베이스나 시스템 데이터베이스를 배치하지 마십시오.</block>
  <block id="bdfdf6f1492d7a7beac0bce2c4109f95" category="list-text">SnapCenter에서 트랜잭션 로그를 복제할 전용 FlexVol 볼륨에 호스트 로그 디렉토리를 생성합니다.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">SnapCenter 마법사를 사용하여 데이터베이스를 NetApp 스토리지로 마이그레이션하여 데이터베이스가 유효한 위치에 저장되도록 함으로써 SnapCenter 백업 및 복구 작업을 성공적으로 수행할 수 있습니다. 마이그레이션 프로세스는 중단되며 마이그레이션이 진행 중인 동안 데이터베이스가 오프라인 상태가 될 수 있습니다.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">SQL Server의 FCI(Failover Cluster Instance)에 대해 다음 조건이 충족되어야 합니다.</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">장애 조치 클러스터 인스턴스를 사용하는 경우 호스트 로그 디렉토리 LUN은 백업 중인 SQL Server 인스턴스와 동일한 클러스터 그룹에 있는 클러스터 디스크 리소스여야 SnapCenter 합니다.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">장애 조치 클러스터 인스턴스를 사용하는 경우 SQL Server 인스턴스와 연결된 클러스터 그룹에 할당된 물리적 디스크 클러스터 리소스인 공유 LUN에 사용자 데이터베이스를 배치해야 합니다.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Microsoft SQL Server 메모리 구성</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">최대 서버 메모리</block>
  <block id="81dbc262a15fc545920141998ddd1c17" category="paragraph">최대 서버 메모리 옵션은 SQL Server 인스턴스가 사용할 수 있는 최대 메모리 양을 설정합니다.</block>
  <block id="c9fa383209ffc05f20049101298fec96" category="paragraph">일반적으로 SQL Server가 실행 중인 동일한 서버에서 여러 응용 프로그램이 실행되고 있고 이러한 응용 프로그램이 제대로 작동할 수 있는 충분한 메모리를 확보하려는 경우에 사용됩니다.</block>
  <block id="1ceeb5f5f18aefbc39e34d0d3c7b7e1c" category="paragraph">일부 응용 프로그램은 시작할 때 사용 가능한 메모리만 사용하고 필요한 경우에도 더 이상 요청하지 않습니다. 최대 서버 메모리 설정이 재생되는 위치입니다.</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">SQL Server 인스턴스가 여러 개 있는 SQL Server 클러스터에서 각 인스턴스가 리소스를 놓고 경쟁할 수 있습니다. 각 SQL Server 인스턴스에 대한 메모리 제한을 설정하면 각 인스턴스에 대해 최상의 성능을 보장할 수 있습니다.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp는 성능 문제를 방지하기 위해 운영 체제에 최소 4GB~6GB의 RAM을 남겨 둘 것을 권장합니다.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">SQL Server Management Studio를 사용하여 최소 및 최대 서버 메모리 조정</block>
  <block id="2e0d4de7d927936246f5537ba48015d2" category="paragraph">SQL Server Management Studio를 사용하여 최소 또는 최대 서버 메모리를 조정하려면 SQL Server 서비스를 다시 시작해야 합니다. 다음 코드를 사용하여 Transact SQL(T-SQL)을 사용하여 서버 메모리를 조정할 수 있습니다.</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">비균일 메모리 액세스</block>
  <block id="d92030bf70ac1cf1da30ce4c9ab2bbf6" category="paragraph">NUMA(Uniform Memory Access)는 프로세서 버스의 부하를 늘리지 않고 프로세서 속도를 높이는 메모리 액세스 최적화 방법입니다.</block>
  <block id="6ef102e61df24a50b0119558432f5623" category="paragraph">NUMA가 SQL Server가 설치된 서버에 구성되어 있는 경우 SQL Server가 NUMA를 인식하며 NUMA 하드웨어에서 잘 수행되므로 추가 구성이 필요하지 않습니다.</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">인덱스가 메모리를 만듭니다</block>
  <block id="8e7c0153e4b7aa851a5a62683c378d1c" category="paragraph">색인 메모리 만들기 옵션은 일반적으로 변경하지 말아야 하는 또 다른 고급 옵션입니다.</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">인덱스 생성을 위해 처음에 할당된 최대 RAM 양을 제어합니다. 이 옵션의 기본값은 0입니다. 즉, 이 옵션은 SQL Server에서 자동으로 관리됩니다. 그러나 인덱스를 만드는 데 문제가 발생하면 이 옵션의 값을 늘리는 것이 좋습니다.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">쿼리당 최소 메모리</block>
  <block id="027d5a3eabe88aa0ab705b9c4a2fe096" category="paragraph">쿼리가 실행되면 SQL Server는 효율적으로 실행되도록 최적의 메모리 양을 할당하려고 합니다.</block>
  <block id="4c7836a7e63c3ecb3f6860ec19643561" category="paragraph">기본적으로 쿼리당 최소 메모리 설정은 실행할 각 쿼리에 대해 &gt; 또는 =를 1024KB를 할당합니다. SQL Server에서 인덱스 생성 작업에 할당된 메모리 양을 동적으로 관리할 수 있도록 이 설정을 기본값 0으로 유지하는 것이 가장 좋습니다. 그러나 SQL Server의 RAM이 효율적으로 실행하는 데 필요한 것보다 많은 경우 이 설정을 높이면 일부 쿼리의 성능이 향상될 수 있습니다. 따라서 SQL Server, 다른 응용 프로그램 또는 운영 체제에서 사용하지 않는 서버에서 메모리를 사용할 수 있는 한 이 설정을 높이면 SQL Server의 전반적인 성능이 향상될 수 있습니다. 사용 가능한 메모리가 없는 경우 이 설정을 늘리면 전체 성능이 저하될 수 있습니다.</block>
  <block id="d2a88da9a0fcc96168f8f051909d5599" category="section-title">버퍼 풀 확장</block>
  <block id="11a3fdcfeb0715eaf26e855034f6ab9a" category="paragraph">버퍼 풀 확장을 통해 NVRAM 확장을 데이터베이스 엔진 버퍼 풀과 원활하게 통합하여 I/O 처리량을 크게 향상합니다.</block>
  <block id="c722da593d2f37b2c1ffc91a10c03dad" category="paragraph">일부 SQL Server 버전에서는 버퍼 풀 확장을 사용할 수 없습니다. 64비트 SQL Server Standard, Business Intelligence 및 Enterprise 버전에서만 사용할 수 있습니다.</block>
  <block id="df07548a7c164cbe93b68c4cbebbdcf8" category="paragraph">버퍼 풀 확장 기능은 비휘발성 스토리지(일반적으로 SSD)를 통해 버퍼 풀 캐시를 확장합니다. 확장 기능을 통해 버퍼 풀이 더 큰 데이터베이스 작업 세트를 수용하여 RAM과 SSD 간의 입출력 페이징을 수행하고 소규모 랜덤 I/O를 기계 디스크에서 SSD로 효과적으로 오프로드할 수 있습니다. SSD의 지연 시간이 짧고 랜덤 I/O 성능이 뛰어남 때문에 버퍼 풀 확장을 통해 I/O 처리량을 크게 높일 수 있습니다.</block>
  <block id="54af95ef673718e2f8bf1cc873d8b3ce" category="paragraph">버퍼 풀 확장 기능은 다음과 같은 이점을 제공합니다.</block>
  <block id="2c250b49dc6705e6d219cf2bf8d50bc5" category="list-text">랜덤 I/O 처리량 향상</block>
  <block id="93dce890e8c62b3a651edb9098201e58" category="list-text">I/O 지연 시간 단축</block>
  <block id="d7e49f79c1b78c9ead1e9541d2160307" category="list-text">트랜잭션 처리량 향상</block>
  <block id="6643befb3c9dc2fbb68fe1107fe24842" category="list-text">더 큰 하이브리드 버퍼 풀로 읽기 성능 개선</block>
  <block id="6609220b8670ffd627a3663b3beef46b" category="list-text">기존 및 향후 저비용 메모리를 활용할 수 있는 캐싱 아키텍처입니다</block>
  <block id="471bda18bb94c589b421edccb0e402fe" category="paragraph">* NetApp는 * 버퍼 풀 확장을 다음과 같이 구성할 것을 권장합니다.</block>
  <block id="12810c53d2afa05bd2a75aa3c0c55592" category="list-text">SSD 지원 LUN(예: NetApp AFF)이 버퍼 풀 확장 대상 디스크로 사용될 수 있도록 SQL Server 호스트에 제공되는지 확인합니다.</block>
  <block id="824cfa1576a82f89ee0af13fb9f086dc" category="list-text">확장 파일은 버퍼 풀과 크기가 같거나 커야 합니다.</block>
  <block id="c7e0d87e723625072015431887edf349" category="paragraph">다음 예에서는 버퍼 풀 확장을 32GB로 설정하기 위한 T-SQL 명령을 보여 줍니다.</block>
  <block id="7ef20d2374bc8b734222e4ec2f0f3643" category="doc">ONTAP를 통한 Microsoft SQL Server의 스토리지 효율성</block>
  <block id="e5bc122522e9ae1409590d9944ec4421" category="paragraph">스토리지 효율성 은 전체 시스템 성능에 거의 또는 전혀 영향을 주지 않고 최소한의 스토리지 공간을 사용하는 방식으로 SQL Server 데이터를 저장하고 관리하는 기능입니다.</block>
  <block id="2d3c9d6f03cd640c224f5daf9c2352b0" category="paragraph">SQL Server에는 데이터를 압축하고 효율적으로 관리하는 기능도 있습니다. SQL Server는 현재 행 압축과 페이지 압축이라는 두 가지 유형의 데이터 압축을 지원합니다.</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">페이지 압축 구현</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">행 압축은 데이터 저장소 형식을 변경합니다. 예를 들어, 정수와 소수를 네이티브 고정 길이 형식 대신 가변 길이 형식으로 변경합니다. 또한 빈 공백을 제거하여 고정 길이 문자 문자열을 가변 길이 형식으로 변경합니다. 페이지 압축은 행 압축과 두 가지 다른 압축 전략(접두사 압축 및 사전 압축)을 구현합니다. 페이지 압축에 대한 자세한 내용은 에서 확인할 수 있습니다 <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">데이터 압축은 현재 SQL Server 2008 이상의 Enterprise, Developer 및 Evaluation 에디션에서 지원됩니다. 데이터베이스가 자체적으로 압축을 수행할 수 있긴 하지만 SQL Server 환경에서는 이런 일이 거의 발생하지 않습니다.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">다음은 SQL Server 데이터 파일의 공간을 관리하기 위한 권장 사항입니다</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">SQL Server 환경에서 씬 프로비저닝을 사용하여 공간 사용률을 개선하고 공간 보장 기능을 사용할 때 전체 스토리지 요구 사항을 줄입니다.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">스토리지 관리자는 애그리게이트의 공간 사용량만 모니터링하면 되기 때문에 가장 일반적인 구축 구성에 대해 자동 확장 기능을 사용합니다.</block>
  <block id="13a233d96ce19e7530391105360d749b" category="list-text">SQL Server 데이터 파일이 포함된 볼륨에 백업을 단일 볼륨으로 복원하는 것과 같이 동일한 데이터의 여러 복사본이 포함되어 있는 것으로 알려져 있지 않은 경우 SQL Server 데이터 파일이 포함된 볼륨에서 중복 제거를 사용하지 않는 것이 좋습니다.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">공간 재확보</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">LUN에서 사용되지 않는 공간을 복구하기 위해 공간 재확보를 주기적으로 시작할 수 있습니다. SnapCenter에서는 다음 PowerShell 명령을 사용하여 공간 재확보를 시작할 수 있습니다.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">공간 재확보를 실행해야 하는 경우 이 프로세스는 처음에 호스트의 주기를 소비하기 때문에 작업이 적은 기간 동안 실행해야 합니다.</block>
  <block id="a356c94dff23a233551ff221e74a144d" category="summary">ONTAP을 통한 Microsoft SQL Server 데이터 보호</block>
  <block id="731c00fe6475fb22aece82ffa9d74ef3" category="paragraph">데이터베이스 보호는 모든 조직에 매우 중요합니다. 데이터베이스의 데이터 크기와 수가 증가함에 따라 복구 시간 목표(RTO) 및 복구 시점 목표(RPO)를 유지하는 것이 매우 중요합니다.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="2ddb1872f6c378e74cb7269e9de4c4e5" category="paragraph">SnapCenter는 엔터프라이즈 애플리케이션을 위한 NetApp 데이터 보호 소프트웨어입니다. SQL Server 데이터베이스는 SQL Server용 플러그인 및 Microsoft Windows용 플러그인이 있는 NetApp SnapCenter 소프트웨어를 사용하여 빠르고 쉽게 보호할 수 있습니다.</block>
  <block id="bdc6c0cf646d837838203c2980eba84a" category="paragraph">이 제품을 사용하면 SQL Server 데이터베이스, 인스턴스 또는 가용성 그룹의 애플리케이션 정합성이 보장되는 백업, 자동화된 클론 생성, 복원 및 복구가 가능합니다.</block>
  <block id="2450e19674db2a865555d3c04563e647" category="admonition">* NetApp는 SnapCenter를 사용하여 스냅샷 복사본을 생성할 것을 권장합니다 *.</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">TR-4714: NetApp SnapCenter를 사용하는 SQL Server 모범 사례 가이드</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">SnapCenter용 SQL Server 플러그인에 대한 자세한 내용은 을 참조하십시오 <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">T-SQL 스냅샷을 사용하여 데이터베이스 보호</block>
  <block id="e158e137ead13fd14e064b875e45df20" category="paragraph">SQL Server 2022에서 Microsoft는 데이터베이스 관리자가 쉽게 사용할 수 없었던 기존 방법보다 기본 이점을 제공하는 T-SQL 스냅샷을 도입했습니다. ONTAP REST API를 활용하여 명령을 스냅샷 볼륨에 호출할 수 있습니다.</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">다음은 샘플 백업 워크플로우입니다.</block>
  <block id="17884d5a1cfc06145e718a49c8d6ac66" category="list-text">alter 명령으로 데이터베이스 고정 - 기본 스토리지에서 정합성 보장 스냅샷을 수행할 수 있는 기회를 제공합니다. 그런 다음 데이터베이스를 해제하고 backup 명령을 사용하여 스냅샷을 기록할 수 있습니다.</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">새 백업 그룹 및 백업 서버 명령을 사용하여 스토리지 볼륨에서 여러 데이터베이스의 스냅샷을 동시에 수행합니다.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">전체 백업 또는 copy_only 전체 백업을 수행합니다. 이러한 백업은 msdb에도 기록됩니다.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">스냅샷 전체 백업 후 일반 스트리밍 접근 방식으로 생성된 로그 백업을 사용하여 시점 복구를 수행합니다. 원하는 경우 스트리밍 차등 백업도 지원됩니다.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">T-SQL 스냅샷에 대한 Microsoft 설명서를 제공합니다</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">바로 Microsoft SQL Server 워크로드입니다</block>
  <block id="764e07fc8f1f5e2d1b9fc63f83b88cbd" category="paragraph">SQL Server 데이터베이스 플랫폼은 다양한 응용 프로그램을 지원할 수 있습니다.</block>
  <block id="25343e3363b414e89943f5a4e46f51ad" category="paragraph">SQL Server를 배포하기 전에 SQL Server 인스턴스가 지원하는 애플리케이션의 데이터베이스 워크로드 요구 사항을 이해해야 합니다. 애플리케이션마다 용량, 성능 및 가용성에 대한 요구사항이 다르므로 각 데이터베이스가 이러한 요구사항을 최적으로 지원하도록 설계되어야 합니다. 많은 조직에서 애플리케이션 요구 사항을 사용하여 SLA를 정의하여 데이터베이스를 여러 관리 계층으로 분류합니다. SQL Server 워크로드는 다음과 같이 설명할 수 있습니다.</block>
  <block id="c6a1c5843ff7b078079edf24beeea746" category="list-text">OLTP 데이터베이스는 조직에서 가장 중요한 데이터베이스인 경우가 많습니다. 이러한 데이터베이스는 일반적으로 고객용 애플리케이션을 뒷받침하며 회사의 핵심 운영에 중요한 요소로 간주됩니다. 미션 크리티컬 OLTP 데이터베이스와 해당 데이터베이스가 지원하는 애플리케이션에는 높은 수준의 성능이 필요하고 성능 저하와 가용성에 민감한 SLA가 있는 경우가 많습니다. 또한 Always On Failover Clusters 또는 Always On Availability Group의 후보일 수도 있습니다. 이러한 유형의 데이터베이스의 I/O 혼합은 일반적으로 75%~90% 랜덤 읽기와 25%~10% 쓰기로 특징 있습니다.</block>
  <block id="96d864d235bcd68e1ef22c2c49aef352" category="list-text">DSS(의사 결정 지원 시스템) 데이터베이스는 데이터 웨어하우스라고도 합니다. 이러한 데이터베이스는 비즈니스 분석을 이용하는 많은 조직에서 미션 크리티컬한 요소가 되었습니다. 이러한 데이터베이스는 쿼리를 실행할 때 CPU 사용률 및 디스크의 읽기 작업에 민감합니다. 많은 조직에서 DSS 데이터베이스는 월, 분기 및 연말에 가장 중요합니다 이 워크로드는 일반적으로 100% 읽기 I/O 혼합입니다.</block>
  <block id="da02a82356735ded82f6661108abe7ef" category="section-title">벤치마킹</block>
  <block id="b9a9b34816c2e5ebaecb45f376b52bc3" category="paragraph">TPC(Transaction Process Council)는 트랜잭션 처리 및 데이터베이스 벤치마크를 정의하고 객관적이고 검증 가능한 TPC 성능 데이터를 업계에 전파하기 위해 설립된 비영리 기업입니다. TPC 테스트는 사용자 집단이 데이터베이스에 대해 트랜잭션을 실행하는 전체 컴퓨팅 환경을 시뮬레이션합니다.</block>
  <block id="427af860f9733f0c5427a1408195bb2b" category="cell">워크로드 유형</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="cell">시나리오</block>
  <block id="b130fcf8f0704ab887b72883b1eda2fa" category="cell">읽기/쓰기 비율(백분율)</block>
  <block id="3edb9cc3b98f151feb21dbde6323e82a" category="cell">OLTP를 지원합니다</block>
  <block id="69e16af975a283d07a422bdbcc70aa33" category="cell">TPC-C입니다</block>
  <block id="b1e04731135df8a16c5318612ec8654e" category="cell">75월 25일</block>
  <block id="106ff1baff5c32dc414f262e0a710c54" category="cell">TPC-E입니다</block>
  <block id="48e219d97cf4619f212471bafd4215ec" category="cell">2010년 9월</block>
  <block id="e71f0182ed04206cb78bd7ceb2d9f4f3" category="cell">DSS를 선택합니다</block>
  <block id="5788057170990ecf5e4d921f2853c2ae" category="cell">TPC-H입니다</block>
  <block id="492d66c3da61bdb9c69261aa1aa6f5f9" category="cell">100/0 이하</block>
  <block id="0737ef89fbed16c79fadf3568aad6ba0" category="inline-link-macro">HammerDB.com</block>
  <block id="45e5ae4569fb8a91cd5513654f31b764" category="paragraph">다양한 워크로드 생성 옵션을 사용할 수 있지만 일반적으로 트랜잭션 워크로드를 처리할 때 SQL Server 데이터베이스의 성능을 측정하는 데 주력하며, Microsoft의 TPC-E 툴 또는 HammerDB(를 사용하여 TPC-H를 사용합니다<block ref="af66be8e0834614cdd62ca4f34bc61ec" category="inline-link-macro-rx"></block>있습니다. 이러한 특정 벤치마크의 사용 방법에 대한 자세한 지침은 이 문서의 범위를 벗어납니다.</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">Microsoft SQL Server 데이터베이스 파일 및 파일 그룹</block>
  <block id="381c0738613a6b6a27d1c14f223e99ba" category="paragraph">SQL Server 데이터베이스는 데이터를 저장하고 조작할 수 있는 개체의 모음입니다.</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">이론적으로 SQL Server(64비트)는 인스턴스당 32,767개의 데이터베이스와 524,272TB의 데이터베이스 크기를 지원하지만, 일반적인 설치에는 일반적으로 여러 개의 데이터베이스가 있습니다. 그러나 SQL Server에서 처리할 수 있는 데이터베이스 수는 로드 및 하드웨어에 따라 다릅니다. SQL Server 인스턴스가 수십, 수백 또는 수천 개의 소규모 데이터베이스를 호스팅하는 것은 드문 일이 아닙니다.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">각 데이터베이스는 하나 이상의 데이터 파일과 하나 이상의 트랜잭션 로그 파일로 구성됩니다. 트랜잭션 로그에는 데이터베이스 트랜잭션에 대한 정보와 각 세션에서 수행한 모든 데이터 수정에 대한 정보가 저장됩니다. 데이터가 수정될 때마다 SQL Server는 작업을 실행 취소(롤백)하거나 다시 실행(재생)할 수 있는 충분한 정보를 트랜잭션 로그에 저장합니다. SQL Server 트랜잭션 로그는 데이터 무결성과 견고성에 대한 SQL Server의 평판에 필수적인 부분입니다. 트랜잭션 로그는 SQL Server의 원자성, 일관성, 격리 및 내구성(ACID) 기능에 매우 중요합니다. SQL Server는 데이터 페이지가 변경되는 즉시 트랜잭션 로그에 기록합니다. 모든 DML(Data Manipulation Language) 문(예: SELECT, INSERT, UPDATE 또는 DELETE)은 완전한 트랜잭션이며, 트랜잭션 로그에서는 전체 집합 기반 작업이 수행되도록 하여 트랜잭션의 원자성을 확인합니다.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">각 데이터베이스에는 기본 데이터 파일이 하나 있으며 기본적으로 확장명은 .mdf입니다. 또한 각 데이터베이스에는 보조 데이터베이스 파일이 있을 수 있습니다. 이러한 파일의 확장명은 기본적으로 .ndf입니다.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">모든 데이터베이스 파일은 파일 그룹으로 그룹화됩니다. 파일 그룹은 논리적 단위로, 데이터베이스 관리를 간소화합니다. 논리 객체 배치와 물리적 데이터베이스 파일 간의 구분이 가능합니다. 데이터베이스 개체 테이블을 만들 때 기본 데이터 파일 구성에 대해 걱정하지 않고 파일 그룹을 배치할 파일 그룹을 지정합니다.</block>
  <block id="3717596742d438a1c8e77b0aeb58fcec" category="paragraph">파일 그룹 내에 여러 데이터 파일을 배치할 수 있으므로 여러 스토리지 디바이스에 로드를 분산시킬 수 있으므로 시스템의 입출력 성능을 향상시킬 수 있습니다. 반면 SQL Server는 트랜잭션 로그에 순차적으로 기록하므로 트랜잭션 로그는 여러 파일의 이점을 얻지 못합니다.</block>
  <block id="c136ffb510a6a465d338ab0affc16641" category="paragraph">파일 그룹에서 논리적 객체 배치와 물리적 데이터베이스 파일 간의 구분을 통해 데이터베이스 파일 레이아웃을 세밀하게 조정하여 스토리지 서브시스템에서 최대한 활용할 수 있습니다. 예를 들어, 서로 다른 고객에게 제품을 배포하는 ISV(Independent Software Vendor)는 기본 I/O 구성과 구축 단계에서 예상되는 데이터 양에 따라 데이터베이스 파일 수를 조정할 수 있습니다. 이러한 변경 사항은 데이터베이스 파일이 아닌 파일 그룹에 데이터베이스 개체를 배치하는 응용 프로그램 개발자에게 영향을 주지 않습니다.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">* NetApp는 * 시스템 객체를 제외한 모든 항목에 대해 기본 파일 그룹을 사용하지 않을 것을 권장합니다. 사용자 객체에 대해 별도의 파일 그룹 또는 파일 그룹 집합을 만들면 특히 대규모 데이터베이스의 경우 데이터베이스 관리 및 재해 복구가 간소화됩니다.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">데이터베이스를 만들거나 기존 데이터베이스에 새 파일을 추가할 때 초기 파일 크기 및 자동 증가 매개 변수를 지정할 수 있습니다. SQL Server는 데이터를 기록할 데이터 파일을 선택할 때 비례 채우기 알고리즘을 사용합니다. 파일에서 사용할 수 있는 여유 공간에 비례하여 데이터의 양을 기록합니다. 파일의 여유 공간이 많을수록 처리하는 쓰기 횟수가 많아집니다.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">* NetApp는 단일 파일 그룹에 있는 모든 파일의 초기 크기 및 자동 증가 매개 변수가 같고 증가 크기가 백분율이 아닌 메가바이트로 정의됨을 * 권장합니다. 이렇게 하면 비례 채우기 알고리즘이 데이터 파일 간에 쓰기 작업의 균형을 고르게 유지할 수 있습니다.</block>
  <block id="a39d73055b8dbbe112e749e7c3ededb8" category="paragraph">SQL Server는 파일을 늘릴 때마다 새로 할당된 파일 공간을 0으로 채웁니다. 이 프로세스는 해당 파일에 기록해야 하는 모든 세션을 차단하거나 트랜잭션 로그가 증가하는 경우 트랜잭션 로그 레코드를 생성합니다.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server는 항상 트랜잭션 로그를 0으로 설정하며 이 동작은 변경할 수 없습니다. 그러나 인스턴트 파일 초기화를 사용하거나 사용하지 않도록 설정하여 데이터 파일의 제로화 여부를 제어할 수 있습니다. 즉각적인 파일 초기화를 사용하면 데이터 파일 증가 속도를 높이고 데이터베이스를 만들거나 복원하는 데 필요한 시간을 줄일 수 있습니다.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">즉각적인 파일 초기화와 관련된 보안 위험이 작습니다. 이 옵션을 활성화하면 데이터 파일의 할당되지 않은 부분에 이전에 삭제된 OS 파일의 정보가 포함될 수 있습니다. 데이터베이스 관리자가 이러한 데이터를 검토할 수 있습니다.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">SQL Server 시작 계정에 "볼륨 유지 관리 작업 수행"이라고도 하는 SA_MANAGE_VOLUME_NAME 권한을 추가하여 즉각적인 파일 초기화를 활성화할 수 있습니다. 이 작업은 다음 그림과 같이 로컬 보안 정책 관리 응용 프로그램(secpol.msc)에서 수행할 수 있습니다. "볼륨 유지 관리 작업 수행" 권한에 대한 속성을 열고 SQL Server 시작 계정을 사용자 목록에 추가합니다.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">사용 권한이 설정되어 있는지 확인하려면 다음 예제의 코드를 사용합니다. 이 코드는 SQL Server가 오류 로그에 추가 정보를 쓰고, 작은 데이터베이스를 만들고, 로그 내용을 읽도록 하는 두 개의 추적 플래그를 설정합니다.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">인스턴트 파일 초기화가 사용되지 않는 경우 SQL Server 오류 로그는 다음 예와 같이 SQL Server가 MDF 데이터 파일을 제로화하는 것 외에 LDF 로그 파일을 제로화하는 것을 보여 줍니다. 인스턴트 파일 초기화가 설정된 경우 로그 파일의 제로화만 표시됩니다.</block>
  <block id="cf346325be0652c6b6e9a04b9352bda3" category="paragraph">볼륨 유지 관리 수행 작업은 SQL Server 2016에서 간소화되며 나중에 설치 프로세스 중에 옵션으로 제공됩니다. 다음 그림에서는 SQL Server 데이터베이스 엔진 서비스에 볼륨 유지 관리 작업을 수행할 수 있는 권한을 부여하는 옵션을 보여 줍니다.</block>
  <block id="638b283700120d26a838f9cb56fca59d" category="paragraph">데이터베이스 파일 크기를 제어하는 또 다른 중요한 데이터베이스 옵션은 자동 축소입니다. 이 옵션을 사용하면 SQL Server에서 정기적으로 데이터베이스 파일을 축소하고 크기를 줄이며 운영 체제에 공간을 해제합니다. 이 작업은 리소스를 많이 사용하며 새 데이터가 시스템에 유입될 때 일정 시간이 지난 후에 데이터베이스 파일이 다시 증가하기 때문에 거의 유용하지 않습니다. 데이터베이스에서 자동 축소를 사용하지 않아야 합니다.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Microsoft SQL Server 공유 인스턴스와 전용 인스턴스 비교</block>
  <block id="8b58192b54b5dc25444ace0536a34893" category="paragraph">응용 프로그램에 스키마와 저장 프로시저가 많은 경우 SQL Server 인스턴스를 공유하는 다른 응용 프로그램에 영향을 줄 수 있습니다.</block>
  <block id="0f85d9701e2ca305652e98c4181097e4" category="paragraph">인스턴스 리소스가 분할되거나 잠길 수 있으며, 이로 인해 공유 SQL Server 인스턴스에서 호스팅되는 데이터베이스가 있는 다른 앱의 성능 문제가 발생할 수 있습니다.</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">어떤 인스턴스가 근본 원인인지 파악해야 하기 때문에 성능 문제의 해결은 복잡할 수 있습니다. 이 질문은 운영 체제 라이선스와 SQL Server 라이선스 비용을 기준으로 합니다. 애플리케이션 성능이 가장 중요한 경우에는 전용 인스턴스를 사용하는 것이 좋습니다.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft는 코어당 SQL Server의 라이센스를 인스턴스가 아닌 서버 레벨에서 부여합니다. 이러한 이유로 데이터베이스 관리자는 서버에서 처리할 수 있는 SQL Server 인스턴스를 많이 설치하여 라이센스 비용을 절감하려는 경향이 있으며, 이로 인해 나중에 주요 성능 문제가 발생할 수 있습니다.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp는 최적의 성능을 얻기 위해 가능한 한 전용 SQL Server 인스턴스를 선택할 것을 권장합니다.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP 및 엔터프라이즈 애플리케이션</block>
  <block id="6e1c62c6c9ec560b6b6cf47a8a8c83f8" category="summary">Solaris를 사용하는 ONTAP 기반 Oracle</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Solaris OS에만 해당하는 구성 항목</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Solaris NFS 마운트 옵션</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">다음 표에는 단일 인스턴스의 Solaris NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">파일 형식</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">마운트 옵션</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">ADR 홈</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">제어 파일
데이터 파일
다시 실행 로그</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">의 사용<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> 스토리지 시스템의 잠금 획득 및 해제와 관련된 지연 시간이 사라져 고객 환경에서 성능이 대폭 개선된다는 사실이 입증되었습니다. 여러 서버가 같은 파일 시스템을 마운트하도록 구성된 환경에서 이 옵션을 사용할 때는 주의를 기울여야 하며, Oracle은 이러한 데이터베이스를 마운트하도록 구성되어 있습니다. 이러한 구성은 흔치 않으며 소수의 고객들만 사용하고 있습니다. Oracle은 외부 서버에 있는 잠금 파일을 감지할 수 없기 때문에 인스턴스가 우발적으로 재시작되는 경우 데이터 손상이 발생할 수 있습니다. NFS 버전 3처럼 NFS 잠금을 통한 보호 기능은 제공되지 않으며 이는 권고사항일 뿐입니다.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">왜냐하면<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> 및<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> 매개 변수는 상호 배타적이기 때문에 가 중요합니다<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> 가 에 있습니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 파일을 클릭합니다<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> 사용됩니다. 이 매개 변수가 없으면 호스트 운영 체제 버퍼 캐싱이 사용되어 성능에 악영향을 미칠 수 있습니다.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">다음 표에는 Solaris NFS RAC 마운트 옵션이 나와 있습니다.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">제어 파일
데이터 파일
다시 실행 로그</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/투표</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">전용<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">공유됨<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">단일 인스턴스와 RAC 마운트 옵션 간의 주된 차이점은 을 추가한다는 것입니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> 마운트 옵션으로 이동합니다. 이렇게 추가되면 호스트 운영 체제 캐싱이 비활성화되어 RAC 클러스터의 모든 인스턴스에서 데이터 상태에 관한 일관된 뷰를 얻게 됩니다. 를 사용하는 경우에도 마찬가지입니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 매개 변수<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> 호스트 캐싱이 비활성화되는 것과 동일한 효과가 있으며, 그것도 사용해야 합니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">그 이유는<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 은(는) 공유에 필요합니다<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> 배포는 Oracle 암호 파일과 spfile 같은 파일의 일관성을 지원하기 위한 것입니다. RAC 클러스터의 각 인스턴스에 전용 이 있는 경우<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, 이 매개 변수는 필요하지 않습니다.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Solaris UFS 마운트 옵션</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp은 Solaris 호스트가 충돌했거나 FC 연결이 중단된 경우 데이터 무결성을 보존할 수 있도록 로깅 마운트 옵션을 사용하는 것이 좋습니다. 로깅 마운트 옵션은 스냅샷 백업의 사용 편의성도 보존해줍니다.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">Solaris ZFS입니다</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS에서 최적의 성능을 얻으려면 신중하게 설치하고 구성해야 합니다.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector입니다</block>
  <block id="c54b9977f43cf2f9a1aa7cb0de8fec22" category="paragraph">Solaris 11에서는 대규모 I/O 작업을 처리하는 방식이 변경되었으며 이로 인해 SAN 스토리지 어레이에 심각한 성능 문제가 초래될 수 있습니다. 이 문제는 NetApp 버그 보고서 630173, 'Solaris 11 ZFS 성능 퇴보'에서 상세히 다루고 있습니다. "해결책은 라는 OS 매개변수를 변경하는 것입니다<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block>.</block>
  <block id="17e692fa261653b11634297d15070637" category="paragraph">다음 명령을 루트로 실행합니다.</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">이 변경으로 인해 예기치 않은 문제가 발생하는 경우 다음 명령을 루트로 실행하면 쉽게 되돌릴 수 있습니다.</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">커널</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">안정적인 ZFS 성능을 얻으려면 LUN 정렬 문제를 방지하는 패칭이 적용된 Solaris 커널이 필요합니다. 이 픽스는 Solaris 10의 패치 147440-19와 SRU 10.5 for Solaris 11에 도입되었습니다. ZFS에는 Solaris 10 이후 버전만 사용하십시오.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">LUN 구성</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">LUN을 구성하려면 다음 단계를 완료하십시오.</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">유형이 인 LUN을 생성합니다<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">에 지정된 적절한 호스트 유틸리티 키트(HUK)를 설치합니다 <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">최신 설명서</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">HUK의 지침을 그대로 따릅니다. 기본 단계는 아래에 설명되어 있지만 을 참조하십시오 <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">를 실행합니다<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> 를 업데이트하는 유틸리티입니다<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> 파일. 이렇게 하면 SCSI 드라이브가 ONTAP LUN을 정확하게 찾을 수 있습니다.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">에서 제공하는 지침을 따릅니다<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> 다중 경로 I/O(MPIO)를 활성화하는 유틸리티.</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">재부팅합니다. 이 단계는 시스템 전체에 변경사항을 적용하는 데 필요합니다.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">LUN을 파티셔닝하고 제대로 정렬되었는지 확인합니다. 정렬을 직접 테스트하고 확인하는 방법은 "부록 B: WAFL 정렬 확인"을 참조하십시오.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpool입니다</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">LUN 구성</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">의 값<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 기본값은 9이며, 이는 2(9) 또는 512바이트를 의미합니다. 최적의 성능을 위해<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 값은 12(2-12=4K)여야 합니다. 이 값은 zpool이 생성될 때 설정되며 변경할 수 없습니다. 즉, zpool 데이터의 경우 가 로 설정된다는 의미입니다<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 12가 아닌 경우 데이터를 새로 생성된 zpool으로 마이그레이션해야 합니다.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">zpool을 생성한 후 의 값을 확인합니다<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 계속 진행하기 전에 값이 12가 아니라면 LUN이 정확히 검색되지 않았다는 뜻입니다. zpool을 폐기하고 관련 호스트 유틸리티 설명서에 표시된 모든 단계가 정확히 수행되었는지 확인한 다음 zpool을 다시 생성하십시오.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">zpool 및 Solaris LDOM</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Solaris LDOM은 I/O 정렬의 정확성을 보장하기 위해 추가 요구사항을 생성합니다. LUN이 4K 장치로 제대로 검색되어도 LDOM의 가상 vdsk 장치는 I/O 도메인의 구성을 상속하지 않습니다. 이 LUN을 기반으로 하는 vdsk는 512바이트 블록으로 되돌아갑니다.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">추가 구성 파일이 필요합니다. 먼저, 추가 구성 옵션을 활성화하려면 개별 LDOM에 Oracle 버그 15824910 패치를 적용해야 합니다. 이 패치는 현재 사용되는 모든 Solaris 버전에 이식되었습니다. LDOM에 패치를 적용했다면 다음과 같이 제대로 정렬된 새로운 LUN을 구성할 준비가 된 것입니다.</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">LUN이 새 zpool에서 사용되고 있는지 확인합니다. 이 예에서는 c2d1 장치입니다.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">ZFS 풀에 사용할 장치의 vdc 인스턴스를 검색합니다.</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">편집<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">이렇게 하면 장치 인스턴스 1이 블록 크기 4096에 할당됩니다.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">다른 예로, vdsk 인스턴스 1~6을 4K 블록 크기 및 로 구성해야 한다고 가정합니다<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> 는 다음과 같습니다.</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">결승선입니다<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> 파일에는 다음이 포함되어야 합니다.</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">주의</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">vdc.conf를 구성하고 vdsk를 생성한 후에 LDOM을 재부팅해야 합니다. 이 단계는 반드시 수행해야 합니다. 블록 크기 변경은 재부팅 후에 적용됩니다. 계속해서 zpool을 구성합니다. 앞서 설명한 것처럼 shift가 12로 설정되었는지 확인합니다.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">ZFS Intent Log(ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">일반적인 상황에서는 다른 장치에 ZIL(ZFS Intent Log)을 배치할 이유가 없습니다. 이 로그는 공간을 메인 풀과 공유할 수 있습니다. 개별 ZIL은 최신 스토리지 어레이에서 쓰기 캐싱 기능이 없는 물리적 드라이브를 사용할 때 주로 활용합니다.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">로그 바이어스</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">를 설정합니다<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Oracle 데이터를 호스팅하는 ZFS 파일 시스템의 매개 변수입니다.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">이 매개 변수를 사용하면 쓰기 레벨이 전체적으로 낮아집니다. 기본값으로 설정된 경우, 작성된 데이터는 먼저 ZIL에 할당된 다음 기본 스토리지 풀에 할당됩니다. 이 접근 방식은 기본 스토리지 풀을 위한 SSD 기반 ZIL 장치와 회전식 미디어가 포함된 일반적인 드라이브 구성에 적합합니다. 이는 사용 가능한 미디어의 단일 I/O 트랜잭션에서 커밋이 발생할 수 있도록 하기 때문입니다.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">자체 캐싱 기능이 포함된 최신 스토리지 어레이를 사용할 때는 보통 이 접근 방식이 필요하지 않습니다. 매우 집약적이고 지연 시간에 민감한 랜덤 쓰기로 구성된 워크로드 등의 드문 상황에서 로그에 관한 단일 트랜잭션으로 쓰기를 커밋하는 것이 바람직할 때도 있습니다. 로깅된 데이터는 결국 기본 스토리지 풀에 작성되기 때문에 쓰기가 증폭되는 결과가 발생하며 이에 따라 쓰기 활동이 두 배로 늘어납니다.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">직접 I/O</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">Oracle 제품을 포함한 다수의 애플리케이션이 직접 I/O를 활성화하여 호스트 버퍼 캐시를 우회할 수 있으나 ZFS 파일 시스템에서는 이 전략이 예상했던 효과를 발휘하지 않습니다. 호스트 버퍼 캐시를 우회하더라도 ZFS 자체가 계속하여 데이터를 캐싱하기 때문입니다. 이 동작으로 인해 fio 또는 sio 같은 툴을 사용할 때 잘못된 결과가 발생할 수 있는데, I/O가 스토리지 시스템에 도달했는지 또는 운영 체제 내에서 로컬 I/O 캐싱이 이뤄지고 있는지를 예측하기가 어렵기 때문입니다. 또한, 이 동작은 그러한 가상 테스트를 사용하여 ZFS 성능을 다른 파일 시스템과 비교하기 힘들게 만듭니다. 현실적으로 실제 사용자 워크로드에서 파일 시스템의 성능은 거의 차이가 없습니다.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">다중 zpool</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">스냅샷 기반 백업, 복원, 클론, ZFS 기반 데이터 아카이빙은 zpool 레벨에서 수행되어야 하며 일반적으로 여러 개의 zpool이 필요합니다. zpool은 LVM 디스크 그룹과 비슷하며, 같은 규칙을 사용하여 구성해야 합니다. 예를 들어, 데이터베이스는 에 상주하는 데이터 파일과 함께 배치하는 것이 가장 좋습니다<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> 및 에 상주하는 아카이브 로그, 제어 파일 및 재실행 로그도 있습니다<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. 이 접근 방식에서는 표준 핫 백업이 허용되어 데이터베이스가 핫 백업 모드로 전환되고 그 뒤에 의 스냅샷이 생성됩니다<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. 그런 다음 핫 백업 모드에서 데이터베이스가 제거되고 로그 아카이브가 강제 적용되며 의 스냅샷이 생성됩니다<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> 이 생성됩니다. 복원 작업에서는 zfs 파일 시스템의 마운트를 해제하고 zpool 전체를 오프라인으로 만들어야 하며 그 다음으로 SnapRestore 복원 작업이 이뤄집니다. 이렇게 되면 zpool이 다시 온라인으로 전환될 수 있고 데이터베이스가 복구됩니다.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesystemio_options 를 참조하십시오</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Oracle 매개 변수<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> ZFS와 다르게 작동합니다. If(경우<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> 또는<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> 사용되는 경우 쓰기 작업이 동기식이고 운영 체제 버퍼 캐시가 우회되며 ZFS에서 읽기 작업을 버퍼링합니다. 이 동작은 I/O를 가로채서 ZFS 캐시에 의해 서비스하는 경우가 있기 때문에 성능 분석에 어려움을 야기하며, 스토리지 지연 시간과 총 I/O가 실제보다 작아지기 때문입니다.</block>
  <block id="22a7d37643562540ddbda52f511fb1fe" category="summary">HP-UX를 사용하는 ONTAP 기반 Oracle</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX를 참조하십시오</block>
  <block id="5be7e182308e16aee80978c6a5ebe02b" category="paragraph">HP-UX 운영 체제에만 해당되는 구성 항목</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">HP-UX NFS 마운트 옵션</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">다음 표에는 단일 인스턴스에 대한 HP-UX NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">제어 파일
데이터 파일
다시 실행 로그</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">다음 표에는 RAC에 대한 HP-UX NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">단일 인스턴스와 RAC 마운트 옵션 간의 주된 차이점은 을 추가한다는 것입니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> 마운트 옵션으로 이동합니다. 이렇게 추가되면 호스트 운영 체제 캐싱이 비활성화되어 RAC 클러스터의 모든 인스턴스에서 데이터 상태에 관한 일관된 뷰를 얻게 됩니다. 를 사용하는 경우에도 마찬가지입니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 매개 변수<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> 호스트 캐싱이 비활성화되는 것과 동일한 효과가 있으며, 그것도 사용해야 합니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">그 이유는<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 은(는) 공유에 필요합니다<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> 배포는 Oracle 암호 파일과 spfile 같은 파일의 일관성을 지원하기 위한 것입니다. RAC 클러스터의 각 인스턴스에 전용 이 있는 경우<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, 이 매개 변수는 필요하지 않습니다.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">HP-UX VxFS 마운트 옵션</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Oracle 바이너리를 호스팅하는 파일 시스템에 다음 마운트 옵션을 사용하십시오.</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">HP-UX 버전이 동시 I/O를 지원하지 않으며 데이터 파일, 재실행 로그, 아카이브 로그, 제어 파일이 포함된 파일 시스템에 다음 마운트 옵션을 사용하십시오.</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">동시 I/O가 지원되는 경우(VxFS 5.0.1 이상 또는 ServiceGuard 스토리지 관리 제품군) 데이터 파일, 재실행 로그, 아카이브 로그, 제어 파일이 포함된 파일 시스템에 다음 마운트 옵션을 사용하십시오.</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">매개 변수입니다<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> 특히 VxFS 환경에서 중요합니다. 달리 명시되지 않는 한 Oracle 10g R1 이상에서는 이 매개 변수를 설정 해제 상태로 유지하는 것이 좋습니다. Oracle 8KB 블록 크기의 기본값은 128입니다. 이 매개 변수의 값이 16 이하로 강제 적용되면 를 제거합니다<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> 순차적 I/O 성능이 저하될 수 있으므로 마운트 옵션을 제공합니다. 이 단계는 성능의 다른 측면을 저하시키므로 의 가치가 있는 경우에만 수행해야 합니다<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> 기본값에서 변경해야 합니다.</block>
  <block id="ca3fa25943498edb0ee62d0ea286bb7a" category="summary">Linux 및 ASMlib/ASM 필터 드라이버를 사용하는 ONTAP 기반 Oracle</block>
  <block id="d7e9c72be485a5a848f1f7cd15a9a5ba" category="doc">ASMlib 및 ASM 필터 드라이버</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">AFD 및 ASMlib를 사용하는 Linux 운영 체제에만 해당되는 구성 항목</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">ASMlib 블록 크기</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib는 ASM 관리 라이브러리 및 관련 유틸리티 옵션입니다. 이 옵션은 LUN 또는 NFS 기반 파일을 사람이 읽을 수 있는 라벨이 포함된 ASM 리소스로 스탬핑할 수 있어 유용합니다.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">ASMlib의 최신 버전은 LBPPBE(Logical Blocks Per Physical Block Exponent)라는 LUN 매개 변수를 감지합니다. 이 값은 최근까지 ONTAP SCSI 타겟에 의해 보고되지 않았습니다. 여기서 반환되는 값은 4KB 블록 크기가 낫다는 사실을 나타냅니다. 이는 블록 크기의 정의가 아니며 LBPPBE 값을 사용하여 특정 크기의 I/O를 더 효율적으로 처리할 수 있게 만드는 애플리케이션을 암시합니다. 그러나 ASMlib는 LBPPBE를 블록 크기로 해석하며 ASM 장치가 생성될 때 ASM 헤더를 지속적으로 스탬핑합니다.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">이 프로세스는 같은 ASM 디스크 그룹에서 ASMlib 장치를 여러 블록 크기와 혼합할 수 없기 때문에 업그레이드와 마이그레이션에서 다양한 문제를 일으킬 수 있습니다.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">예를 들어, 기존의 어레이는 일반적으로 LBPPBE 값을 0으로 보고하거나 값을 아예 보고하지 않았습니다. ASMlib는 이를 512바이트 블록 크기로 해석합니다. 최신 어레이의 경우에는 블록 크기가 4KB인 것으로 해석될 것입니다. 같은 ASM 디스크 그룹에서 512바이트와 4KB 장치를 혼합하는 것이 불가능하지는 않습니다. 그러나 이렇게 하면 사용자가 두 어레이의 LUN을 사용하는 ASM 디스크 그룹의 크기를 늘리거나 ASM을 마이그레이션 툴로 활용할 수 없게 됩니다. RMAN이 512바이트 블록 크기의 ASM 디스크 그룹과 4KB 블록 크기의 ASM 디스크 그룹 간 파일 복사를 허용하지 않을 수 있습니다.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">적절한 해결책은 ASMlib를 패치하는 것입니다. Oracle 버그 ID는 13999609이며 패치는 oracleasm-support-2.1.8-1 이후 버전에 있습니다. 이 패치는 사용자가 매개 변수를 설정할 수 있습니다<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> 에 있습니다<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> 구성 파일. 이렇게 하면 ASMlib가 LBPPBE 매개 변수를 사용할 수 없으며 새로운 어레이의 LUN이 512바이트 블록 장치로 인식됩니다.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">이 옵션은 ASMlib에 의해 이전에 스탬핑된 LUN의 블록 크기를 변경하지 않습니다. 예를 들어, 512바이트 블록의 ASM 디스크 그룹은 4KB 블록을 보고하는 새로운 스토리지 시스템으로 마이그레이션해야 하는 경우 옵션<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> 새로운 LUN은 ASMlib에 스탬핑되기 전에 설정해야 합니다.  장치가 이미 oracleasm에 스탬프로 찍힌 경우 새 블록 크기로 재정비되기 전에 다시 포맷해야 합니다. 먼저 로 장치의 그림을 해제합니다<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>를 누른 다음 로 장치의 첫 1GB를 지웁니다<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. 마지막으로, 이전에 디바이스를 파티션한 경우 를 사용합니다<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> 오래된 파티션을 제거하거나 운영 체제를 재부팅하는 명령입니다.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">ASMlib를 패칭할 수 없을 경우 구성에서 ASMlib를 제거할 수 있습니다. 이는 매우 큰 변경이므로 ASM 디스크의 스탬핑을 해제하고 가 확실히 변경되어야 합니다<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> 매개 변수가 올바르게 설정되었습니다. 하지만 이 변경에 따라 데이터를 마이그레이션할 필요는 없습니다.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">AFD(ASM 필터 드라이브) 블록 크기</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD는 ASMlib를 대체하는 선택적 ASM 관리 라이브러리입니다. 스토리지 관점에서는 ASMlib와 매우 유사하지만 Oracle이 아닌 I/O를 차단하여 데이터 손상을 일으킬 수 있는 사용자 또는 애플리케이션 오류를 줄일 수 있는 기능과 같은 추가 기능이 포함되어 있습니다.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">장치 블록 크기</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">ASMlib와 마찬가지로 AFD는 LUN 매개 변수 LBPPBE(Logical Blocks Per Physical Block Exponent)를 읽으며 기본적으로 논리적 블록 크기가 아닌 물리적 블록 크기를 사용합니다.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">ASM 디바이스가 이미 512바이트 블록 디바이스로 포맷된 기존 구성에 AFD가 추가되면 문제가 발생할 수 있습니다. AFD 드라이버는 LUN을 4K 디바이스로 인식하며 ASM 레이블과 물리적 디바이스 간의 불일치로 인해 액세스가 차단됩니다. 마찬가지로, 동일한 ASM 디스크 그룹에서 512바이트와 4KB 장치를 혼합하는 것이 불가능하기 때문에 마이그레이션이 영향을 받습니다. 그러나 이렇게 하면 사용자가 두 어레이의 LUN을 사용하는 ASM 디스크 그룹의 크기를 늘리거나 ASM을 마이그레이션 툴로 활용할 수 없게 됩니다. RMAN이 512바이트 블록 크기의 ASM 디스크 그룹과 4KB 블록 크기의 ASM 디스크 그룹 간 파일 복사를 허용하지 않을 수 있습니다.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">솔루션은 간단합니다. AFD에는 논리적 블록 크기인지 물리적 블록 크기를 사용할지 여부를 제어하는 매개 변수가 포함됩니다. 시스템의 모든 장치에 영향을 주는 전역 매개 변수입니다. AFD에서 논리 블록 크기를 사용하도록 강제 설정하려면 를 설정합니다<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> 에 있습니다<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">다중 경로 전송 크기</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">최근 Linux 커널 변경 사항은 다중 경로 디바이스에 전송되는 입출력 크기 제한을 적용하며 AFD는 이러한 제한을 준수하지 않습니다. 그런 다음 I/O가 거부되어 LUN 경로가 오프라인 상태가 됩니다. 그 결과 Oracle Grid를 설치하거나 ASM을 구성하거나 데이터베이스를 생성할 수 없게 됩니다.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">해결책은 ONTAP LUN에 대해 multipath.conf 파일에서 최대 전송 길이를 수동으로 지정하는 것입니다.</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">현재 문제가 없는 경우에도 향후 Linux 업그레이드로 인해 예기치 않게 문제가 발생하지 않도록 AFD를 사용하는 경우 이 매개 변수를 설정해야 합니다.</block>
  <block id="72247c591c444399f3d42dffa31b644e" category="summary">AIX를 사용하는 ONTAP 기반 Oracle</block>
  <block id="23802d94b756cf69028557bea156ab1a" category="doc">IBM AIX</block>
  <block id="5b8d4d99cdcb494ca636eb065004b165" category="paragraph">IBM AIX 운영 체제에만 해당되는 구성 항목입니다.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">동시 I/O</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">IBM AIX에서 최적의 성능을 달성하려면 동시 I/O를 사용해야 합니다 동시 I/O를 사용하지 않으면 AIX에서 직렬화된 원자 I/O가 수행되어 성능이 저하될 수 있으며 이에 따라 상당한 오버헤드가 발생하게 됩니다.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">원래 NetApp는 를 사용할 것을 권장합니다<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> 파일 시스템에 동시 I/O 사용을 강제 적용하는 마운트 옵션이지만 이 프로세스에는 결점이 있어 더 이상 필요하지 않습니다. AIX 5.2 및 Oracle 10gR1의 도입 이후로, AIX 기반 Oracle에서는 전체 파일 시스템에 동시 I/O를 강제 적용하는 것이 아니라 동시 IO를 위해 개별 파일을 열 수 있습니다.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">동시 I/O 활성화를 위한 최상의 방법은 를 설정하는 것입니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 매개 변수<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. 이렇게 설정하면 Oracle은 동시 I/O와 함께 사용할 특정 파일을 열 수 있습니다</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">사용<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> 마운트 옵션은 동시 I/O 사용을 강제 적용되며 이는 부정적인 결과를 초래할 수 있습니다. 예를 들어 동시 I/O를 적용하면 파일 시스템에서 미리 읽기를 비활성화하므로 파일 복사, 테이프 백업 수행과 같이 Oracle 데이터베이스 소프트웨어 외부에서 발생하는 I/O 성능이 손상될 수 있습니다. 또한, Oracle GoldenGate와 SAP BR * Tools 같은 제품은 을 사용하는 것과 호환되지 않습니다<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Oracle의 특정 버전에서 마운트 옵션.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">를 사용하지 마십시오<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> 파일 시스템 레벨에서 마운트 옵션입니다. 을 사용하여 동시 I/O를 활성화하십시오<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">만 사용하십시오<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> 를 설정할 수 없는 경우 마운트 옵션을 설정해야 합니다<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">AIX NFS 마운트 옵션</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">다음 표에는 Oracle 단일 인스턴스 데이터베이스에 대한 AIX NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">다음 표에는 RAC에 대한 AIX NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">단일 인스턴스와 RAC 마운트 옵션 간의 주된 차이점은 을 추가한다는 것입니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 마운트 옵션으로 이동합니다. 이렇게 추가되면 호스트 운영 체제 캐싱이 비활성화되어 RAC 클러스터의 모든 인스턴스에서 데이터 상태에 관한 일관된 뷰를 얻게 됩니다.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">를 사용하는 경우에도 마찬가지입니다<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> 마운트 옵션 및<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 매개 변수<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> 호스트 캐싱이 비활성화되는 것과 동일한 효과가 있으며, 그것도 사용해야 합니다<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 은(는) 공유에 필요합니다<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> 구축을 통해 Oracle 암호 파일 및 과 같은 파일의 일관성을 지원합니다<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> 매개 변수 파일 RAC 클러스터의 각 인스턴스에 전용 이 있는 경우<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>이 매개 변수는 필요하지 않습니다.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">AIX jfs/jfs2 마운트 옵션</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">다음 표에는 AIX jfs/jfs2 마운트 옵션이 나와 있습니다.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">기본값</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">AIX를 사용하기 전에<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> 데이터베이스를 포함하여 모든 환경에서 매개 변수를 확인합니다<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. 이 매개 변수는 호스트 버스 어댑터 큐 길이가 아니며, 개인의 SCSI 큐 길이와 관련이 있습니다<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> 성능이 뛰어나기 때문에 너무 낮을 수 있습니다. 테스트 결과 최적의 값은 64였습니다.</block>
  <block id="6e1dee25b21d0005970053df9e9384ba" category="summary">Microsoft Windows를 사용하는 ONTAP 기반 Oracle</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="44959b8c12de9e1107621ee8c0337463" category="paragraph">Microsoft Windows 운영 체제에만 해당되는 구성 항목</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle은 Microsoft Windows를 direct NFS 클라이언트와 함께 사용할 수 있도록 지원합니다. 이 기능을 통해 환경 전반의 파일을 확인하고, 볼륨 크기를 동적으로 조정하며 비용이 적게 드는 IP 프로토콜을 활용하는 것 등 NFS 관리에서 이점을 얻을 수 있습니다. DNFS를 사용하여 Microsoft Windows에 데이터베이스를 설치하고 구성하는 방법은 공식 Oracle 설명서를 참조하십시오. 특별한 모범 사례는 없습니다.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">최적의 압축 효율성을 위해 NTFS 파일 시스템이 8K 이상의 할당 유닛을 사용하는지 확인하십시오. 일반적으로 기본값인 4K 할당 유닛을 사용하면 압축 효율성에 부정적인 영향을 줄 수 있습니다.</block>
  <block id="140def8362bd2cf6a999328e25572cfd" category="summary">Linux를 사용하는 ONTAP 기반의 Oracle</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">리눅스</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Linux 운영 체제에만 해당되는 구성 항목</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">슬롯 테이블</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Linux NFS 마운트 옵션</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">다음 표에는 단일 인스턴스의 Linux NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">다음 표에는 RAC에 대한 Linux NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/투표</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">단일 인스턴스와 RAC 마운트 옵션 간의 주된 차이점은 을 추가한다는 것입니다<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 마운트 옵션으로 이동합니다. 이렇게 추가되면 호스트 운영 체제 캐싱이 비활성화되어 RAC 클러스터의 모든 인스턴스에서 데이터 상태에 관한 일관된 뷰를 얻게 됩니다. 를 사용하는 경우에도 마찬가지입니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 매개 변수<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> 호스트 캐싱이 비활성화되는 것과 동일한 효과가 있으며, 그것도 사용해야 합니다<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">그 이유는<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 은(는) 공유에 필요합니다<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> 배포는 Oracle 암호 파일과 spfile 같은 파일의 일관성을 지원하기 위한 것입니다. RAC 클러스터의 각 인스턴스에 전용 이 있는 경우<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>이 매개 변수는 필요하지 않습니다.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">특정 애플리케이션에서는 요구사항이 다를 수 있지만 일반적으로 데이터베이스가 아닌 파일은 단일 인스턴스 데이터 파일에 사용되는 것과 같은 옵션으로 마운트해야 합니다. 마운트 옵션을 사용하지 마십시오<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 이러한 옵션은 파일 시스템 레벨의 미리 읽기 및 버퍼링을 비활성화하기 때문에 가능한 경우 추출, 변환, 로딩 같은 프로세스에 심각한 성능 문제가 초래될 수 있습니다.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESS 및 GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">ACCESS 및 GETATTR 같은 극히 높은 레벨의 기타 IOPS가 워크로드를 장악할 수 있다는 사실을 깨달은 고객들이 있습니다. 극단적인 경우 그러한 읽기 및 쓰기 작업이 전체 중 10% 남짓할 수 있습니다. 이는 를 포함하는 모든 데이터베이스에서 정상적인 동작입니다<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 및/또는<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 이러한 옵션 덕분에 Linux 운영 체제가 스토리지 시스템에서 파일 메타데이터를 지속적으로 다시 로드하게 되기 때문입니다. ACCESS 및 GETATTR 같은 작업은 데이터베이스 환경에서 ONTAP 캐시로부터 서비스되며 그 영향이 크지 않습니다. 스토리지 시스템에 대한 진정한 수요를 창출하는 읽기 및 쓰기 같은 진정한 IOPS로 간주해서는 안 됩니다. 이러한 기타 IOPS는 특히 RAC 환경에서 약간의 로드를 생성합니다. 이러한 상황을 해결하려면 DNFS를 활성화하여 운영 체제 버퍼 캐시를 우회하고 이 불필요한 메타데이터 작업을 피하십시오.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">Linux 직접 NFS</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">한 가지 추가 마운트 옵션이라고 합니다<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>는 (a) DNFS가 활성화되고 (b) 소스 볼륨이 단일 서버에 두 번 이상 마운트되며 (c) 중첩된 NFS 마운트가 있는 경우에 필요합니다. 이 구성은 SAP 애플리케이션을 지원하는 환경에서 주로 볼 수 있습니다. 예를 들어, NetApp 시스템의 단일 볼륨의 경우 에 디렉토리가 있을 수 있습니다<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> 그리고 에서 두 번째에도<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. If(경우<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> 에 탑재됩니다<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> 및<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> 에 탑재됩니다<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>이 경우 같은 소스에서 NFS 마운트가 중첩됩니다.</block>
  <block id="b06ff38483faff2d17d8de1fc966848e" category="paragraph">운영 체제는 바로 그 사실을 감지할 수 있습니다<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> 및<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> 동일한 소스 파일 시스템인 동일한 볼륨에 상주합니다. 같은 장치를 사용하여 데이터에 대한 액세스를 처리합니다. 이렇게 되면 운영 체제 캐싱 사용 및 기타 특정 작업이 개선되나 DNFS에는 지장을 줍니다. DNFS가 같은 파일에 액세스해야 하는 경우<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block>, 켜짐<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>잘못된 데이터 경로를 사용하려고 잘못 시도할 수 있습니다. 그 결과 I/O 작업이 실패합니다. 이 설정에서 를 추가합니다<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> 소스 FlexVol 볼륨을 해당 호스트의 다른 NFS 파일 시스템과 공유하는 NFS 파일 시스템에 마운트 옵션 그러면 Linux 운영 체제에서 해당 파일 시스템을 처리할 독립적 장치를 할당하게 됩니다.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS 및 Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">Linux에는 노드 전체에 걸친 일관성을 위해 RAC에 필요한 직접 I/O를 강제 적용할 방법이 없기 때문에 DNFS를 사용하면 Linux 운영 체제 기반 Oracle RAC에서 특별한 성능 이점을 얻을 수 있습니다. 이를 해결하려면 Linux에서 를 사용해야 합니다<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 마운트 옵션을 사용하면 운영 체제 캐시에서 파일 데이터가 즉시 만료됩니다 그러면 이 옵션은 Linux NFS 클라이언트가 특성 데이터를 계속 다시 읽게 강제 적용합니다. 이는 지연 시간을 저하시키고 스토리지 컨트롤러의 로드를 증가시킵니다.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">DNFS를 활성화하면 호스트 NFS 클라이언트가 우회되어 이러한 저하가 일어나지 않습니다. 여러 고객의 보고에 따르면, DNFS를 활성화했을 때 RAC 클러스터에서의 성능이 상당히 개선되었고 특히 IOPS와 관련하여 ONTAP 로드가 크게 감소하였다고 합니다.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS 및 oranfstab 파일</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">다중 경로 옵션으로 Linux에서 DNFS를 사용할 때는 여러 서브넷을 사용해야 합니다. 그 외 운영 체제에서는 를 사용하여 여러 DNFS 채널을 설정할 수 있습니다<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> 및<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> 단일 서브넷에 여러 DNFS 채널을 구성하는 옵션입니다. 하지만 이 방법은 Linux에서 제대로 작동하지 않을 수 있고 예기치 않은 성능 문제가 초래될 수 있습니다. Linux에서는 DNFS 트래픽을 위해 사용되는 각 NIC가 다른 서브넷에 있어야 합니다.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">I/O 스케줄러</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Linux 커널은 블록 장치의 I/O를 스케줄링하여 낮은 레벨의 제어를 허용합니다. Linux의 다양한 배포 방식에서는 여러 가지의 기본값을 사용할 수 있습니다. 테스트에 의하면 Deadline이 보통 최상의 결과를 제공하지만 NOOP에서 성능이 더 높은 경우도 간혹 있었습니다. 성능 차이는 크지 않으나 데이터베이스 구성에서 최대한의 성능을 끌어내려면 필요 시 두 옵션을 모두 테스트하십시오. 대다수 구성은 CFQ를 기본값으로 하며, 데이터베이스 워크로드에서 심각한 성능 문제가 발생한다는 사실이 입증되었습니다.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">I/O 스케줄러 구성에 관한 관련 Linux 공급업체 설명서의 지침을 참조하십시오.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">다중 경로</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">어떤 고객은 다중 경로 데몬이 시스템에서 실행되지 않아 네트워크 중단 시 충돌이 발생하였습니다. Linux 최신 버전에서는 운영 체제 설치 프로세스와 다중 경로 데몬에 의해 운영 체제가 이 문제에 취약해질 수 있습니다. 패키지는 올바르게 설치되나 재부팅 후 자동 시동되도록 구성되지 않습니다.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">예를 들어, RHEL5.5에서 다중 경로 데몬의 기본값은 다음과 같이 나타날 수 있습니다.</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">다음과 같은 명령으로 이를 수정할 수 있습니다.</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">ASM 미러링</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">ASM 미러링은 ASM이 문제를 인식하고 대체 장애 그룹으로 전환할 수 있도록 Linux 다중 경로 설정을 변경해야 할 수 있습니다. ONTAP의 대다수 ASM 구성은 외부 이중화를 사용하는데, 이는 외부 어레이를 통해 데이터가 보호되고 ASM은 데이터를 미러링하지 않는다는 뜻입니다. 일부 사이트는 ASM에서 일반적인 수준의 이중화를 사용하며 일반적으로 여러 사이트에 걸쳐 양방향 미러링을 제공합니다.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">NetApp Host Utilities 설명서</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">에 나와 있는 Linux 설정입니다 <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> I/O의 무한 대기를 야기하는 다중 경로 매개 변수를 포함하십시오 즉, 액티브 경로가 없는 LUN 장치의 I/O가 I/O가 완료될 때까지 큐에서 대기합니다. Linux 호스트가 SAN 경로 변경이 완료될 때까지, FC 스위치가 재부팅될 때까지, 또는 스토리지 시스템의 페일오버가 완료될 때까지 대기하기 때문에 이는 일반적으로 바람직한 방식입니다.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">무제한 큐잉 동작은 ASM 미러링에 문제를 발생시키는데, 대체 LUN에서 I/O를 재시도하려면 ASM이 I/O 장애를 수신해야 하기 때문입니다.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Linux에서 다음 매개 변수를 설정합니다<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> ASM 미러링과 함께 사용되는 ASM LUN용 파일:</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">이들 설정은 ASM 장치의 시간 초과 값을 120초로 만듭니다. 시간 초과는 로 계산됩니다<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> 초 단위로 표시합니다. 정확한 값을 위해 조정이 필요할 때도 있지만 대부분의 경우에는 120초 시간 초과로 충분합니다. 특히, 장애 그룹을 오프라인 상태로 만들어버리는 I/O를 생성하지 않고 120초 동안 컨트롤러가 테이크오버 또는 반환을 수행할 수 있어야 합니다.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">더 낮아졌습니다<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> 값을 지정하면 ASM이 대체 장애 그룹으로 전환하는 데 필요한 시간을 단축할 수 있지만 이렇게 하면 컨트롤러 테이크오버 같은 유지보수 활동 중에 원치 않는 페일오버 위험이 증가합니다. 이러한 위험은 ASM 미러링 상태를 주의 깊게 모니터링하여 완화할 수 있습니다. 원치 않는 페일오버가 발생한 경우에도 재동기화가 상대적으로 빠르게 수행된다면 미러링이 신속하게 재동기화됩니다. 추가 정보는 사용 중인 Oracle 소프트웨어 버전의 ASM 빠른 미러 재동기화에 관한 Oracle 설명서를 참조하십시오.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Linux xfs, ext3 및 ext4 마운트 옵션</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">* NetApp는 기본 마운트 옵션을 사용하여 * 를 권장합니다.</block>
  <block id="17361a1d111a3ff3a45b20c3a1efa11b" category="summary">Oracle 및 TCP/IP 및 이더넷 구성</block>
  <block id="fe586387f0871fa578f77ac2e26e624a" category="doc">Oracle Database용 TCP/IP 및 이더넷 구성</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">많은 Oracle on ONTAP 고객은 이더넷, NFS, iSCSI, NVMe/TCP 및 특히 클라우드를 사용합니다.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Oracle 데이터베이스용 논리 인터페이스 설계</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">Oracle 데이터베이스는 스토리지에 액세스해야 합니다. 논리 인터페이스(LIF)는 SVM(스토리지 가상 머신)을 네트워크에 연결하고 데이터베이스에 연결하는 네트워크 사업부입니다. 각 데이터베이스 워크로드에 충분한 대역폭을 보장하기 위해 올바른 LIF 설계가 필요하며, 페일오버로 인해 스토리지 서비스가 손실되지 않습니다.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Oracle 데이터베이스를 위한 FC 네트워크 구성</block>
  <block id="ee955933387c00b282dcfda69005517f" category="doc">Oracle을 위한 FC 구성</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">Oracle 데이터베이스용 FC SAN 구성은 주로 일상적인 SAN 모범 사례를 따르는 것과 관련됩니다.</block>
  <block id="953369199e3a71ad1ad58bc7d5ad2d9f" category="summary">NetApp ONTAP는 즉각적인 백업, 복원 및 클로닝 기능, 인라인 압축, 무중단 하드웨어 업그레이드, 외부 스토리지 어레이에서 LUN 가져오기 등과 같은 효율성 기능 등 모든 기본 기능을 갖춘 강력한 데이터 관리 플랫폼입니다.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">ONTAP 기반의 Oracle 데이터베이스</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP는 Oracle 데이터베이스를 위해 설계되었습니다. 지난 수십 년 동안 ONTAP은 관계형 데이터베이스 I/O의 고유한 요구사항에 맞게 최적화되었으며, Oracle 데이터베이스의 필요에 따라 여러 ONTAP 기능이 특별히 개발되었으며, 심지어 Oracle Inc. 자체의 요청도 있었습니다.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-3633: ONTAP 기반 Oracle 데이터베이스, TR-4591: Oracle 데이터 보호: 백업, 복구, 복제, TR-4592: MetroCluster 기반 Oracle, TR-4534: NetApp 스토리지 시스템으로 Oracle 데이터베이스 마이그레이션 _ 을(를) 대체합니다</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">ONTAP이 데이터베이스 환경에 가치를 제공하는 다양한 방법 외에도 데이터베이스 규모, 성능 요구사항, 데이터 보호 요구사항 등 다양한 사용자 요구사항이 있습니다. 알려진 NetApp 스토리지 구축에는 Mware ESX에서 약 6,000개의 데이터베이스가 실행되는 가상 환경부터 현재 규모 996TB에서 계속 증가하는 단일 인스턴스 데이터 웨어하우스까지 모든 것이 포함됩니다. 따라서 NetApp 스토리지에 Oracle 데이터베이스를 구성하는 데는 명백한 몇 가지 모범 사례가 있습니다.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">NetApp 스토리지에서 Oracle 데이터베이스 작동이라는 요구사항은 두 가지 방식으로 해결됩니다. 첫째, 확실한 모범 사례가 있을 경우 이를 구체적으로 언급합니다. 상위 레벨에서는 특정 비즈니스 요구사항에 따라 Oracle 스토리지 솔루션 설계자가 다루어야 할 여러 설계 고려사항에 대해 설명할 것입니다.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Oracle 스토리지 마이그레이션 소개</block>
  <block id="6ca08c212e9ec987ce485fd9c7705eff" category="doc">NetApp 스토리지 시스템으로 Oracle 데이터베이스 마이그레이션</block>
  <block id="9e099143017b5d9ff9c117de4ac659d7" category="paragraph">새로운 스토리지 플랫폼의 기능 활용에는 한 가지 필연적인 요구사항이 있으므로 데이터를 새로운 스토리지 시스템에 배치해야 합니다.</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">이 문서는 이전에 게시된 기술 보고서 _TR-4534: Oracle 데이터베이스를 NetApp 스토리지 시스템으로 마이그레이션 _ 을(를) 대체합니다</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">새 데이터베이스 프로젝트의 경우 데이터베이스 및 애플리케이션 환경이 제대로 구축되기 때문에 이 문제가 발생하지 않습니다. 그러나 마이그레이션은 비즈니스 중단, 마이그레이션 완료에 필요한 시간, 필요한 기술 세트 및 위험 최소화와 관련하여 특별한 과제를 안고 있습니다.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">스크립트</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">샘플 스크립트는 이 설명서에 나와 있습니다. 이러한 스크립트는 사용자 오류 가능성을 줄이기 위해 마이그레이션의 다양한 측면을 자동화하는 샘플 방법을 제공합니다. 이 스크립트는 마이그레이션을 담당하는 IT 직원의 전반적인 요구사항을 줄이고 전반적인 프로세스를 가속화할 수 있습니다. 이 스크립트는 NetApp 프로페셔널 서비스 및 NetApp 파트너가 수행하는 실제 마이그레이션 프로젝트로부터 작성되었습니다. 이 설명서 전반에 걸쳐 사용 예제가 나와 있습니다.</block>
  <block id="b3978e376e381abd116a2ae7938d8a9c" category="summary">FLI 컷오버 - Oracle</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">FC 네트워크 구성을 변경해야 하기 때문에 외부 LUN 임포트 중에는 중단이 불가피합니다. 그러나 운영 중단은 데이터베이스 환경을 재시작하고 FC 조닝을 업데이트하여 호스트 FC 연결을 외부 LUN에서 ONTAP로 전환하는 데 필요한 시간보다 훨씬 오래 지속되지 않습니다.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">이 프로세스는 다음과 같이 요약할 수 있습니다.</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">외부 LUN에서 모든 LUN 작업을 중지합니다.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">호스트 FC 연결을 새 ONTAP 시스템으로 리디렉션합니다.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">가져오기 프로세스를 트리거합니다.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">LUN을 다시 검색합니다.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">데이터베이스를 다시 시작합니다.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">마이그레이션 프로세스가 완료될 때까지 기다리지 않아도 됩니다. 특정 LUN의 마이그레이션이 시작되는 즉시 ONTAP에서 사용할 수 있으며 데이터 복사 프로세스가 진행되는 동안 데이터를 제공할 수 있습니다. 모든 읽기는 외부 LUN으로 전달되고 모든 쓰기는 두 스토리지에 동기식으로 기록됩니다. 복사 작업은 매우 빠르고 FC 트래픽 리디렉션의 오버헤드가 최소화되므로 성능에 미치는 영향은 일시적이고 최소화해야 합니다. 문제가 있는 경우 마이그레이션 프로세스가 완료되고 가져오기 관계가 삭제될 때까지 환경 다시 시작을 지연시킬 수 있습니다.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">데이터베이스를 종료합니다</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">이 예에서 환경을 정지하는 첫 번째 단계는 데이터베이스를 종료하는 것입니다.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">그리드 서비스를 종료합니다</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">마이그레이션되는 SAN 기반 파일 시스템 중 하나에 Oracle ASM 서비스도 포함됩니다. 기본 LUN을 정지하려면 파일 시스템을 마운트 해제해야 합니다. 즉, 이 파일 시스템에서 열려 있는 파일이 있는 프로세스를 모두 중지해야 합니다.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">파일 시스템을 마운트 해제합니다</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">모든 프로세스가 종료되면 마운트 해제 작업이 성공합니다. 사용 권한이 거부되면 파일 시스템에 잠금이 설정된 프로세스가 있어야 합니다. 를 클릭합니다<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> 명령은 이러한 프로세스를 식별하는 데 도움이 될 수 있습니다.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">볼륨 그룹을 비활성화합니다</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">지정된 볼륨 그룹의 모든 파일 시스템이 마운트 해제된 후 볼륨 그룹을 비활성화할 수 있습니다.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">FC 네트워크 변경 사항</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">이제 FC 존을 업데이트하여 호스트에서 외부 스토리지에 대한 모든 액세스를 제거하고 ONTAP에 대한 액세스를 설정할 수 있습니다.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">가져오기 프로세스를 시작합니다</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">LUN 가져오기 프로세스를 시작하려면 를 실행합니다<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">가져오기 진행 상황을 모니터링합니다</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">를 사용하여 가져오기 작업을 모니터링할 수 있습니다<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> 명령. 아래와 같이 20개의 LUN을 모두 가져오는 작업이 진행 중입니다. 따라서 이제 데이터 복사 작업이 계속 진행되더라도 ONTAP를 통해 데이터에 액세스할 수 있습니다.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">외부 LUN 임포트 - 완료</block>
  <block id="24a74765303a8fc0e4b1e7afbb8e2205" category="paragraph">오프라인 프로세스가 필요한 경우 까지 서비스 재검색 또는 재시작을 연기합니다<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> 명령은 모든 마이그레이션이 성공적이고 완료되었음을 나타냅니다. 그런 다음 에 설명된 대로 마이그레이션 프로세스를 완료할 수 있습니다 <block ref="5b0017122426f8734e0358273adc6802" category="inline-link-macro-rx"></block>.</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">온라인 마이그레이션이 필요한 경우 새 집에서 LUN을 다시 검색하고 서비스를 시작합니다.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">SCSI 장치 변경 사항을 검색합니다</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">대부분의 경우 새 LUN을 다시 검색하는 가장 간단한 옵션은 호스트를 재시작하는 것입니다. 이렇게 하면 오래된 오래된 장치가 자동으로 제거되고 모든 새 LUN이 올바르게 검색되며 다중 경로 장치와 같은 관련 장치가 구축됩니다. 이 예제에서는 데모를 위한 완전한 온라인 프로세스를 보여 줍니다.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">주의: 호스트를 다시 시작하기 전에 의 모든 항목이 있는지 확인하십시오<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 마이그레이션된 참조 SAN 리소스가 주석 처리되었습니다. 이렇게 하지 않고 LUN 액세스에 문제가 있으면 운영 체제가 부팅되지 않을 수 있습니다. 이 상황은 데이터를 손상시키지 않습니다. 그러나 구조 모드 또는 유사한 모드로 부팅하고 를 수정하는 것은 매우 불편할 수 있습니다<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 문제 해결을 위해 운영 체제를 부팅할 수 있습니다.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">이 예에 사용된 Linux 버전의 LUN을 로 다시 검색할 수 있습니다<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> 명령. 명령이 성공하면 각 LUN 경로가 출력에 표시되어야 합니다. 출력에서 해석하기가 어려울 수 있지만, 조닝 및 igroup 구성이 올바르면 을 포함하는 많은 LUN이 표시되어야 합니다<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> 공급업체 문자열</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">다중 경로 장치를 확인합니다</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">LUN 검색 프로세스는 다중 경로 장치의 재구성을 트리거하지만 Linux 다중 경로 드라이버에는 간헐적인 문제가 있는 것으로 알려져 있습니다. 의 출력입니다<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> 출력이 예상한 대로 나타나는지 확인해야 합니다. 예를 들어, 아래 출력에는 와 연결된 다중 경로 장치가 나와 있습니다<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> 공급업체 문자열 각 디바이스에는 4개의 경로가 있으며, 우선 순위가 50이고 우선 순위가 10인 2개의 경로가 있습니다. 정확한 출력은 Linux 버전에 따라 다를 수 있지만 이 출력은 예상한 대로 표시됩니다.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">사용하는 Linux 버전에 대한 호스트 유틸리티 설명서를 참조하여 를 확인하십시오<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> 설정이 올바릅니다.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">LVM 볼륨 그룹을 다시 활성화합니다</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">LVM LUN이 제대로 검색되면 가 나타납니다<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> 명령이 성공해야 합니다. 이것은 논리적 볼륨 관리자의 값에 대한 좋은 예입니다. 볼륨 그룹 메타데이터가 LUN 자체에 기록되므로 LUN의 WWN이나 일련 번호도 변경하는 것은 중요하지 않습니다.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">OS는 LUN을 검색하여 LUN에 기록된 소량의 데이터를 발견했습니다. 이 데이터는 LUN에 속한 물리적 볼륨으로 식별됩니다<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. 그런 다음 필요한 모든 장치를 구축했습니다. 볼륨 그룹을 다시 활성화하기만 하면 됩니다.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">파일 시스템을 다시 마운트합니다</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">볼륨 그룹이 다시 활성화된 후 모든 원본 데이터가 손상되지 않은 상태로 파일 시스템을 마운트할 수 있습니다. 앞서 설명했듯이 백 그룹에서 데이터 복제가 아직 활성 상태인 경우에도 파일 시스템이 완전히 작동합니다.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">ASM 장치를 다시 검색합니다</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">SCSI 장치를 다시 검색할 때 ASMlib 장치를 다시 검색해야 합니다. ASMlib를 다시 시작한 다음 디스크를 검사하여 온라인으로 재검색을 확인할 수 있습니다.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">이 단계는 ASMlib가 사용되는 ASM 구성에만 관련이 있습니다.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">주의: ASMlib를 사용하지 않는 경우<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> 디바이스가 자동으로 다시 생성되어야 합니다. 그러나 사용 권한이 올바르지 않을 수 있습니다. ASMlib가 없는 경우 ASM에 대한 기본 장치에 특수 권한을 설정해야 합니다. 이러한 작업은 일반적으로 둘 중 하나의 특수 항목을 통해 수행됩니다<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> 또는<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> 두 규칙 집합에서 사용할 수 있습니다. 이러한 파일은 WWN 또는 일련 번호 측면에서 환경의 변경 사항을 반영하도록 업데이트하여 ASM 장치에 올바른 권한이 있는지 확인해야 할 수 있습니다.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">이 예에서는 ASMlib를 다시 시작하고 디스크 검색을 통해 원래 환경과 동일한 10개의 ASM LUN을 표시합니다.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">그리드 서비스를 다시 시작합니다</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">이제 LVM 및 ASM 장치가 온라인 상태이고 사용 가능해졌으므로 그리드 서비스를 다시 시작할 수 있습니다.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">데이터베이스를 다시 시작합니다</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">그리드 서비스가 다시 시작된 후 데이터베이스를 불러올 수 있습니다. 데이터베이스를 시작하기 전에 ASM 서비스를 완전히 사용할 수 있도록 몇 분 정도 기다려야 할 수 있습니다.</block>
  <block id="0b986cf2a434b03b097578ad444e72f0" category="summary">FLI 컷오버 완료 - Oracle</block>
  <block id="24bd7d2a01571aa270c81d8d9f8370e9" category="doc">FLI 완료 - Oracle</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">호스트 관점에서 보면 마이그레이션이 완료되지만 가져오기 관계가 삭제될 때까지 외부 스토리지에서 입출력이 계속 제공됩니다.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">관계를 삭제하기 전에 모든 LUN에 대해 마이그레이션 프로세스가 완료되었는지 확인해야 합니다.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">관계 가져오기를 삭제합니다</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">마이그레이션 프로세스가 완료되면 마이그레이션 관계를 삭제합니다. I/O를 완료한 후에는 ONTAP의 드라이브에서만 I/O를 처리합니다.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">외부 LUN 등록을 취소합니다</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">마지막으로 디스크를 수정하여 를 제거합니다<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> 지정.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">로그 전달을 통한 Oracle 마이그레이션</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Oracle 로그 전달</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">로그 전달을 사용하는 마이그레이션의 목표는 새 위치에 원본 데이터 파일의 복사본을 만든 다음 새 환경에 변경 사항을 전달하는 방법을 설정하는 것입니다.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">설정된 후에는 로그 전송 및 재생을 자동화하여 복제 데이터베이스를 소스와 대부분 동기화된 상태로 유지할 수 있습니다. 예를 들어, Cron 작업은 (a) 가장 최근의 로그를 새 위치로 복사하고 (b) 15분마다 재생하도록 예약할 수 있습니다. 이렇게 하면 아카이브 로그를 15분 이상 재생해야 하므로 전환 시 작업 중단이 최소화됩니다.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">아래에 나와 있는 절차는 기본적으로 데이터베이스 클론 작업입니다. 표시된 로직은 NetApp SnapManager for Oracle(SMO) 및 NetApp SnapCenter Oracle 플러그인 내의 엔진과 유사합니다. 일부 고객은 맞춤형 클론 복제 작업을 위해 스크립트 또는 WFA 워크플로우에 표시된 절차를 사용했습니다. 이 절차는 SMO 또는 SnapCenter를 사용하는 것보다 수동적이지만, ONTAP의 데이터 관리 API로 인해 프로세스가 더욱 간소화됩니다.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">로그 전달 - 파일 시스템을 파일 시스템으로 전송합니다</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">이 예제에서는 Waffle이라는 데이터베이스를 일반 파일 시스템에서 다른 서버에 있는 다른 일반 파일 시스템으로 마이그레이션하는 방법을 보여 줍니다. 또한 SnapMirror를 사용하여 데이터 파일의 신속한 복사본을 만드는 방법을 보여 주지만 이것이 전체 절차의 필수 요소가 아닙니다.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">데이터베이스 백업을 만듭니다</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">첫 번째 단계는 데이터베이스 백업을 만드는 것입니다. 특히 이 절차를 수행하려면 아카이브 로그 재생에 사용할 수 있는 데이터 파일 세트가 필요합니다.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">방법입니다</block>
  <block id="82f9b672d88793b2ca5716b2a5427056" category="paragraph">이 예에서 소스 데이터베이스는 ONTAP 시스템에 있습니다. 데이터베이스 백업을 생성하는 가장 간단한 방법은 스냅샷 복사본을 사용하는 것입니다. 데이터베이스는 가 있는 동안 몇 초 동안 핫 백업 모드로 전환됩니다<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> 이 작업은 데이터 파일을 호스팅하는 볼륨에서 실행됩니다.</block>
  <block id="1fd3a22cf15d1e18a6507f539346c40d" category="paragraph">그 결과 라는 디스크의 스냅샷 복사본이 생성됩니다<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> 핫 백업 모드에 있는 동안 데이터 파일의 이미지가 포함됩니다. 적절한 아카이브 로그와 결합하여 데이터 파일의 일관성을 유지할 경우, 이 스냅샷 복사본의 데이터를 복원 또는 클론의 기반으로 사용할 수 있습니다. 이 경우 새 서버에 복제됩니다.</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">새 환경으로 복원합니다</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">이제 새 환경에서 백업을 복원해야 합니다. 이는 Oracle RMAN, NetBackup 같은 백업 애플리케이션에서 복원 또는 핫 백업 모드에 있었던 데이터 파일의 간단한 복사 작업을 비롯하여 다양한 방법으로 수행할 수 있습니다.</block>
  <block id="ca7da361ad92f677545e12dd462c6e39" category="paragraph">이 예에서는 SnapMirror를 사용하여 hotbackup이라는 스냅샷 복사본을 새 위치에 복제합니다.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">스냅샷 데이터를 수신할 새 볼륨을 생성합니다. 에서 미러링을 초기화합니다<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">동기화가 완료되었음을 나타내는 SnapMirror가 상태를 설정한 후, 특히 원하는 스냅샷을 기반으로 미러를 업데이트합니다.</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">동기화를 확인하려면 을 참조하십시오<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> 미러 볼륨의 필드입니다.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">그런 다음 미러가 파손될 수 있습니다.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">새 파일 시스템을 마운트합니다. 블록 기반 파일 시스템을 사용하면 사용 중인 LVM에 따라 정확한 절차가 달라집니다. FC 조닝 또는 iSCSI 연결을 구성해야 합니다. LUN에 대한 연결이 설정된 후 Linux와 같은 명령이 표시됩니다<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> ASM이 검색할 수 있도록 올바르게 구성해야 하는 볼륨 그룹 또는 LUN을 찾는 데 필요한 수도 있습니다.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">이 예에서는 단순 NFS 파일 시스템이 사용됩니다. 이 파일 시스템은 직접 마운트할 수 있습니다.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">컨트롤 파일 만들기 템플릿을 만듭니다</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">그런 다음 컨트롤 파일 템플릿을 만들어야 합니다. 를 클릭합니다<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> 명령은 텍스트 명령을 만들어 컨트롤 파일을 다시 만듭니다. 이 기능은 경우에 따라 백업에서 데이터베이스를 복원하는 데 유용할 수 있으며 데이터베이스 클론 생성과 같은 작업을 수행하는 스크립트와 함께 사용됩니다.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">다음 명령의 출력은 마이그레이션된 데이터베이스에 대한 컨트롤 파일을 다시 생성하는 데 사용됩니다.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">컨트롤 파일을 만든 후 새 서버에 파일을 복사합니다.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">매개 변수 파일을 백업합니다</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">매개 변수 파일도 새 환경에 필요합니다. 가장 간단한 방법은 현재 spfile 또는 pfile 에서 pfile 을 만드는 것입니다. 이 예에서는 소스 데이터베이스가 spfile을 사용하고 있습니다.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">ORATAB 항목을 만듭니다</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">오라타브 항목의 생성은 오라타브 같은 유틸리티의 적절한 기능을 위해 필요합니다. ORATAB 항목을 만들려면 다음 단계를 완료합니다.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">디렉토리 구조를 준비합니다</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">필요한 디렉터리가 없는 경우 해당 디렉터리를 만들어야 합니다. 그렇지 않으면 데이터베이스 시작 절차가 실패합니다. 디렉토리 구조를 준비하려면 다음과 같은 최소 요구 사항을 완료하십시오.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">매개 변수 파일 업데이트</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">매개 변수 파일을 새 서버에 복사하려면 다음 명령을 실행합니다. 기본 위치는 입니다<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> 디렉토리. 이 경우 pfile은 어디에나 배치할 수 있습니다. 마이그레이션 프로세스의 중간 단계로만 사용되고 있습니다.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">필요에 따라 파일을 편집합니다. 예를 들어 아카이브 로그 위치가 변경된 경우 새 위치를 반영하도록 pfile을 변경해야 합니다. 이 예제에서는 제어 파일만 재배치되고 일부는 로그 및 데이터 파일 시스템 간에 배포됩니다.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">편집이 완료되면 이 pfile을 기반으로 spfile을 만듭니다.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">컨트롤 파일을 다시 만듭니다</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">이전 단계에서 의 출력입니다<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> 새 서버로 복사되었습니다. 필요한 출력의 특정 부분은 입니다<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> 명령. 이 정보는 표시된 섹션 아래의 파일에서 찾을 수 있습니다<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. 라인부터 시작합니다<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> 및 은 단어를 포함해야 합니다<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. 세미콜론(;) 문자로 끝납니다.</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">이 예제 절차에서 파일은 다음과 같이 읽힙니다.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">다양한 파일의 새 위치를 반영하기 위해 이 스크립트를 편집합니다. 예를 들어, 높은 I/O를 지원하는 것으로 알려진 특정 데이터 파일은 고성능 스토리지 계층의 파일 시스템으로 리디렉션될 수 있습니다. 다른 경우에는 지정된 PDB의 데이터 파일을 전용 볼륨에 격리하는 것과 같은 관리자의 이유만으로 변경 내용이 변경될 수 있습니다.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">이 예에서 는 입니다<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> 스탠자는 변경되지 않은 상태로 유지되지만 다시 실행 로그는 의 새 위치로 이동됩니다<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> 아카이브 로그와 공간을 공유하는 대신<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">파일이 잘못 배치되거나 매개 변수가 잘못 구성된 경우 수정해야 할 항목을 나타내는 오류가 생성됩니다. 데이터베이스가 마운트되었지만 아직 열려 있지 않으며 사용 중인 데이터 파일이 핫 백업 모드로 표시되어 있기 때문에 열 수 없습니다. 데이터베이스의 일관성을 유지하기 위해서는 먼저 아카이브 로그를 적용해야 합니다.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">초기 로그 복제</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">데이터 파일의 일관성을 유지하려면 하나 이상의 로그 응답 작업이 필요합니다. 로그를 재생하는 데 사용할 수 있는 옵션은 다양합니다. 경우에 따라 원래 서버의 원래 아카이브 로그 위치를 NFS를 통해 공유할 수 있으며 로그 회신을 직접 수행할 수 있습니다. 다른 경우에는 아카이브 로그를 복사해야 합니다.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">예를 들어, 단순 입니다<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> 작업은 소스 서버에서 마이그레이션 서버로 모든 현재 로그를 복사할 수 있습니다.</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">초기 로그 재생</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">파일이 아카이브 로그 위치에 있으면 명령을 실행하여 재생할 수 있습니다<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> 그 다음에 응답이 옵니다<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> 사용 가능한 모든 로그를 자동으로 재생합니다.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">최종 아카이브 로그 응답에서 오류를 보고하지만 이는 정상입니다. 로그는 이를 나타냅니다<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> 특정 로그 파일을 찾지만 찾지 못했습니다. 로그 파일이 아직 존재하지 않기 때문일 가능성이 높습니다.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">아카이브 로그를 복사하기 전에 소스 데이터베이스를 종료할 수 있는 경우 이 단계는 한 번만 수행해야 합니다. 아카이브 로그가 복사되고 재생된 다음 프로세스를 계속 진행하여 중요한 재실행 로그를 복제하는 컷오버 프로세스로 이동할 수 있습니다.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">증분 로그 복제 및 재생</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">대부분의 경우 마이그레이션은 즉시 수행되지 않습니다. 마이그레이션 프로세스가 완료되기까지 며칠이나 몇 주가 걸릴 수 있습니다. 즉, 로그가 계속해서 복제본 데이터베이스로 전송되고 재생되어야 합니다. 따라서 컷오버가 도착하면 최소한의 데이터를 전송하고 재생해야 합니다.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">이러한 작업은 여러 가지 방법으로 스크립팅할 수 있지만 일반적인 방법 중 하나는 일반적인 파일 복제 유틸리티인 rsync를 사용하는 것입니다. 이 유틸리티를 사용하는 가장 안전한 방법은 데몬으로 구성하는 것입니다. 예를 들면, 입니다<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> 다음 파일은 라는 리소스를 만드는 방법을 보여 줍니다<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Oracle 사용자 자격 증명으로 액세스되고 에 매핑됩니다<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. 가장 중요한 것은 리소스를 읽기 전용으로 설정하여 운영 데이터를 읽을 수는 있지만 변경할 수는 없다는 것입니다.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">다음 명령은 새 서버의 아카이브 로그 대상을 rsync 리소스와 동기화합니다<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> 원래 서버에 있습니다. 를 클릭합니다<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> 의 인수입니다<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> 타임스탬프를 기준으로 파일 목록을 비교하고 새 파일만 복사하도록 합니다. 이 프로세스는 새 서버의 증분 업데이트를 제공합니다. 이 명령은 정기적으로 실행되도록 cron으로 예약할 수도 있습니다.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">데이터베이스에서 로그를 재생합니다</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">로그를 수신한 후 재생해야 합니다. 이전 예에서는 sqlplus를 사용하여 수동으로 실행하는 방법을 보여 줍니다<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>쉽게 자동화할 수 있는 프로세스입니다. 여기에 표시된 예에서는 에 설명된 스크립트를 사용합니다 <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. 스크립트에는 재생 작업이 필요한 데이터베이스를 지정하는 인수를 사용할 수 있습니다. 이렇게 하면 다중 데이터베이스 마이그레이션 작업에 동일한 스크립트를 사용할 수 있습니다.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">컷오버</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">새 환경으로 전환할 준비가 되면 아카이브 로그와 redo 로그를 모두 포함하는 하나의 최종 동기화를 수행해야 합니다. 원래 redo 로그 위치를 아직 모르는 경우 다음과 같이 식별할 수 있습니다.</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">원본 데이터베이스를 종료합니다.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">원하는 방법으로 새 서버에서 아카이브 로그의 최종 동기화를 수행합니다.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">원본 redo 로그를 새 서버에 복사해야 합니다. 이 예에서는 redo 로그가 의 새 디렉토리로 재배치되었습니다<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">이 단계에서 새 데이터베이스 환경에는 원본과 동일한 상태로 되돌리는 데 필요한 모든 파일이 포함됩니다. 아카이브 로그는 마지막으로 한 번 재생되어야 합니다.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">완료되면 재실행 로그를 재생해야 합니다. 메시지가 표시되는 경우<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> 이 반환되고 프로세스가 성공하며 데이터베이스가 동기화되어 열 수 있습니다.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">로그 전달 - 파일 시스템에 ASM을 전달합니다</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">이 예에서는 Oracle RMAN을 사용하여 데이터베이스를 마이그레이션하는 방법을 보여 줍니다. 이는 파일 시스템 로그 전달과 파일 시스템 로그 전달의 이전 예와 매우 유사하지만 ASM의 파일은 호스트에 표시되지 않습니다. ASM 디바이스에 있는 데이터를 마이그레이션하는 유일한 옵션은 ASM LUN을 재배치하거나 Oracle RMAN을 사용하여 복제 작업을 수행하는 것입니다.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">RMAN은 Oracle ASM에서 파일을 복사하기 위한 요구 사항이지만 RMAN 사용은 ASM에 국한되지 않습니다. RMAN을 사용하여 모든 유형의 스토리지에서 다른 유형으로 마이그레이션할 수 있습니다.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">이 예에서는 팬케이크라는 데이터베이스를 ASM 스토리지에서 경로의 다른 서버에 있는 일반 파일 시스템으로 재배치하는 방법을 보여 줍니다<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> 및<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">첫 번째 단계는 대체 서버로 마이그레이션할 데이터베이스의 백업을 만드는 것입니다. 소스가 Oracle ASM을 사용하므로 RMAN을 사용해야 합니다. 간단한 RMAN 백업은 다음과 같이 수행할 수 있습니다. 이 방법은 나중에 RMAN에서 쉽게 식별할 수 있는 태그가 지정된 백업을 생성합니다.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">첫 번째 명령은 백업 대상 유형과 사용할 위치를 정의합니다. 두 번째는 데이터 파일의 백업만 시작합니다.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">백업 제어 파일</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">백업 제어 파일은 이 절차의 뒷부분에서 필요합니다<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> 작동.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">매개 변수 파일도 새 환경에 필요합니다. 가장 간단한 방법은 현재 spfile 또는 pfile 에서 pfile 을 만드는 것입니다. 이 예제에서 원본 데이터베이스는 spfile을 사용합니다.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">ASM 파일 이름 바꾸기 스크립트</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">현재 컨트롤 파일에 정의된 여러 파일 위치는 데이터베이스를 이동할 때 변경됩니다. 다음 스크립트는 프로세스를 쉽게 하기 위해 RMAN 스크립트를 생성합니다. 이 예에서는 데이터 파일 수가 매우 적은 데이터베이스를 보여 주지만 일반적으로 데이터베이스에는 수백 또는 수천 개의 데이터 파일이 포함되어 있습니다.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">ASM에서 파일 시스템으로 이름 변환</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">이 스크립트는 에서 찾을 수 있습니다 <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> 그리고 이 두 가지를 수행합니다.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">먼저 매개 변수를 만들어 라는 redo 로그 위치를 다시 정의합니다<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. 기본적으로 대체 필드의 목록입니다. 첫 번째 필드는 현재 redo 로그의 위치이고 두 번째 필드는 새 서버의 위치입니다. 그런 다음 패턴이 반복됩니다.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">두 번째 기능은 데이터 파일 이름 변경을 위한 템플릿을 제공하는 것입니다. 스크립트는 데이터 파일을 반복하고 이름 및 파일 번호 정보를 가져와서 RMAN 스크립트로 형식을 지정합니다. 그런 다음 임시 파일에서도 마찬가지입니다. 그 결과, 파일이 원하는 위치로 복구되도록 원하는 대로 편집할 수 있는 간단한 RMAN 스크립트가 생성됩니다.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">이 화면의 출력을 캡처합니다. 를 클릭합니다<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> 매개 변수는 아래 설명된 대로 pfile에 배치됩니다. 데이터 파일을 원하는 위치에 배치하려면 RMAN 데이터 파일 이름 바꾸기 및 중복 스크립트를 적절히 편집해야 합니다. 이 예제에서는 모두 에 배치됩니다<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">스크립트는 거의 실행할 준비가 되었지만 먼저 디렉토리 구조가 있어야 합니다. 필요한 디렉터리가 아직 없으면 해당 디렉터리를 만들어야 합니다. 그렇지 않으면 데이터베이스 시작 절차가 실패합니다. 아래의 예는 최소 요구 사항을 반영합니다.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">oraenv와 같은 유틸리티가 제대로 작동하려면 다음 명령이 필요합니다.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">매개 변수 업데이트</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">새 서버의 경로 변경 사항을 반영하도록 저장된 pfile을 업데이트해야 합니다. 데이터 파일 경로 변경은 RMAN 복제 스크립트에 의해 변경되며 거의 모든 데이터베이스를 변경해야 합니다<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> 및<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> 매개 변수. 또한 변경해야 하는 감사 파일 위치와 같은 매개 변수가 있을 수 있습니다<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> ASM 외부에서는 관련이 없을 수 있습니다. 숙련된 DBA는 계속하기 전에 제안된 변경 사항을 주의 깊게 검토해야 합니다.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">이 예에서 주요 변경 사항은 제어 파일 위치, 로그 아카이브 대상 및 추가입니다<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> 매개 변수.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">새 매개 변수가 확인되면 매개 변수가 적용되어야 합니다. 여러 옵션이 있지만 대부분의 고객은 pfile 텍스트를 기반으로 spfile을 만듭니다.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">시동 nomount</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">데이터베이스를 복제하기 전의 마지막 단계는 데이터베이스 프로세스를 불러오지만 파일을 마운트하지 않는 것입니다. 이 단계에서는 spfile에 문제가 발생할 수 있습니다. 를 누릅니다<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> 명령 실패 매개 변수 오류로 인해 실패합니다. pfile 템플릿을 종료하고 수정한 다음 spfile로 다시 로드한 후 다시 시도하십시오.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">데이터베이스를 복제합니다</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">이전 RMAN 백업을 새 위치로 복원하는 데 이 프로세스의 다른 단계보다 시간이 더 오래 걸립니다. 데이터베이스 ID(DBID)를 변경하거나 로그를 재설정하지 않고 데이터베이스를 복제해야 합니다. 이렇게 하면 로그를 적용할 수 없습니다. 이는 복사본을 완전히 동기화하는 데 필요한 단계입니다.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">RMAN을 aux로 데이터베이스에 연결하고 이전 단계에서 생성한 스크립트를 사용하여 중복 데이터베이스 명령을 실행합니다.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">이제 원본 데이터베이스의 변경 내용을 새 위치로 전달해야 합니다. 이렇게 하려면 여러 단계를 조합해야 할 수 있습니다. 가장 간단한 방법은 소스 데이터베이스의 RMAN이 공유 네트워크 연결에 아카이브 로그를 기록하도록 하는 것입니다. 공유 위치를 사용할 수 없는 경우 RMAN을 사용하여 로컬 파일 시스템에 쓴 다음 RCP 또는 rsync를 사용하여 파일을 복사하는 방법이 있습니다.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">이 예에서 는 입니다<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> 디렉토리는 원래 데이터베이스와 마이그레이션된 데이터베이스 모두에서 사용할 수 있는 NFS 공유입니다.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">여기서 한 가지 중요한 문제는 입니다<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> 조항. 백업의 디스크 형식은 입니다<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>즉, 데이터베이스에 대한 스레드 번호, 시퀀스 번호 및 활성화 ID 형식을 사용해야 합니다. 글자는 다르지만 이 문장은 과 일치합니다<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> pfile의 매개 변수입니다. 또한 이 매개 변수는 스레드 번호, 시퀀스 번호 및 활성화 ID 형식으로 아카이브 로그를 지정합니다. 결과적으로 소스의 로그 파일 백업이 데이터베이스에서 예상하는 명명 규칙을 사용하게 됩니다. 이렇게 하면 과 같은 작업이 수행됩니다<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> sqlplus 는 재생될 아카이브 로그의 이름을 올바르게 예측하기 때문에 훨씬 더 간단합니다.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">파일이 아카이브 로그 위치에 있으면 명령을 실행하여 재생할 수 있습니다<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> 그 다음에 응답이 옵니다<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> 사용 가능한 모든 로그를 자동으로 재생합니다. 매개 변수 파일이 현재 아카이브 로그를 로 리디렉션하고 있습니다<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>하지만 RMAN이 로그를 저장하는 데 사용된 위치와 일치하지 않습니다. 데이터베이스를 복구하기 전에 다음과 같이 위치를 일시적으로 리디렉션할 수 있습니다.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">최종 아카이브 로그 응답에서 오류를 보고하지만 이는 정상입니다. 이 오류는 sqlplus가 특정 로그 파일을 찾고 있지만 찾지 못했음을 나타냅니다. 로그 파일이 아직 존재하지 않기 때문일 수 있습니다.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">대부분의 경우 마이그레이션은 즉시 수행되지 않습니다. 마이그레이션 프로세스가 완료되기까지 며칠이나 몇 주가 걸릴 수 있습니다. 즉, 로그가 계속해서 복제본 데이터베이스로 전송되고 재생되어야 합니다. 이렇게 하면 컷오버가 도착할 때 최소한의 데이터를 전송하고 재생해야 합니다.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">이 프로세스는 쉽게 스크립팅할 수 있습니다. 예를 들어, 로그 전달에 사용되는 위치가 지속적으로 업데이트되도록 원본 데이터베이스에 다음 명령을 예약할 수 있습니다.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">대기 데이터베이스에서 로그를 재생합니다</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">로그를 수신한 후 재생해야 합니다. 이전 예제에서는 sqlplus 를 사용하여 수동으로 실행하는 방법을 보여 주었습니다<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>쉽게 자동화할 수 있습니다. 여기에 표시된 예에서는 에 설명된 스크립트를 사용합니다 <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. 스크립트에는 재생 작업이 필요한 데이터베이스를 지정하는 인수를 사용할 수 있습니다. 이 프로세스에서는 다중 데이터베이스 마이그레이션 작업에 동일한 스크립트를 사용할 수 있습니다.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">새 환경으로 컷오버할 준비가 되면 최종 동기화 하나를 수행해야 합니다. 일반 파일 시스템으로 작업할 때 원래 redo 로그가 복사되고 재생되므로 마이그레이션된 데이터베이스가 원본과 100% 동기화되도록 쉽게 할 수 있습니다. ASM과 함께 이 작업을 수행하는 좋은 방법은 없습니다. 보관 로그만 쉽게 다시 복사할 수 있습니다. 데이터가 손실되지 않도록 하려면 원본 데이터베이스의 최종 종료를 주의 깊게 수행해야 합니다.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">먼저 데이터베이스를 정지하여 변경 사항이 없는지 확인해야 합니다. 이 일시 중지에는 예약된 작업을 비활성화하거나, 수신기를 종료하거나, 응용 프로그램을 종료하는 작업이 포함될 수 있습니다.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">이 단계를 수행한 후 대부분의 DBA는 종료의 표시자 역할을 하는 더미 테이블을 생성합니다.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">로그 아카이빙을 강제 수행하여 더미 테이블 생성이 아카이브 로그 내에 기록되도록 합니다. 이렇게 하려면 다음 명령을 실행합니다.</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">마지막 아카이브 로그를 복사하려면 다음 명령을 실행합니다. 데이터베이스를 사용할 수 있어야 하지만 열려 있지 않아야 합니다.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">아카이브 로그를 복사하려면 다음 명령을 실행합니다.</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">마지막으로 새 서버에서 나머지 아카이브 로그를 재생합니다.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">이 단계에서는 모든 데이터를 복제합니다. 데이터베이스를 대기 데이터베이스에서 활성 작업 데이터베이스로 변환할 준비가 된 다음 열 수 있습니다.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">더미 테이블이 있는지 확인한 다음 삭제합니다.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">무중단 재실행 로그 마이그레이션</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">재실행 로그를 제외하고 데이터베이스가 전체적으로 올바르게 구성된 경우가 있습니다. 이러한 현상은 여러 가지 이유로 발생할 수 있으며, 그 중 가장 일반적인 원인은 스냅샷과 관련이 있습니다. Oracle용 SnapManager, SnapCenter, NetApp Snap Creator 스토리지 관리 프레임워크와 같은 제품을 사용하면 데이터 파일 볼륨의 상태를 되돌리는 경우에만 거의 즉각적으로 데이터베이스 복구가 가능합니다. 재실행 로그가 데이터 파일과 공간을 공유하는 경우 재실행 로그가 삭제되어 데이터 손실이 발생할 수 있으므로 재버전을 안전하게 수행할 수 없습니다. 따라서 redo 로그를 재배치해야 합니다.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">이 절차는 단순하며 중단 없이 수행할 수 있습니다.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">현재 redo 로그 구성</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">재실행 로그 그룹의 수와 해당 그룹 번호를 식별합니다.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">redo 로그의 크기를 입력합니다.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">새 로그를 만듭니다</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">각 REDO 로그에 대해 일치하는 크기와 구성원 수가 있는 새 그룹을 만듭니다.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">새 구성을 확인합니다.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">오래된 로그를 삭제합니다</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">이전 로그(그룹 1, 2, 3)를 삭제합니다.</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">활성 로그를 삭제할 수 없는 오류가 발생하면 다음 로그로 스위치를 강제로 전환하여 잠금을 해제하고 글로벌 체크포인트를 강제로 설정합니다. 이 프로세스의 다음 예를 참조하십시오. 이 로그 파일에 활성 데이터가 있기 때문에 이전 위치에 있던 로그 파일 그룹 2를 삭제하려는 시도가 거부되었습니다.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">로그 보관 후 체크포인트를 수행하면 로그 파일을 삭제할 수 있습니다.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">그런 다음 파일 시스템에서 로그를 삭제합니다. 이 과정은 매우 세심한 주의를 기울여 수행해야 합니다.</block>
  <block id="eb290dfcb2d35cffcb49a22fd05168b5" category="summary">Oracle 마이그레이션 계획</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">Oracle 데이터 마이그레이션은 데이터베이스, 호스트 또는 스토리지 배열의 세 가지 레벨 중 하나에서 수행할 수 있습니다.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">데이터베이스, 호스트 운영 체제 또는 스토리지 시스템 등 전체 솔루션의 어떤 구성 요소가 데이터 이동을 담당하는지에 따라 차이가 있습니다.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">아래 그림에서는 마이그레이션 수준과 데이터 흐름의 예를 보여 줍니다. 데이터베이스 레벨 마이그레이션의 경우 데이터가 원래 스토리지 시스템에서 호스트 및 데이터베이스 계층을 통해 새로운 환경으로 이동됩니다. 호스트 레벨 마이그레이션은 비슷하지만 데이터가 애플리케이션 계층을 거치지 않고 호스트 프로세스를 사용하여 새 위치에 기록됩니다. 마지막으로, 스토리지 레벨 마이그레이션을 통해 NetApp FAS 시스템과 같은 어레이가 데이터 이동을 담당합니다.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">데이터베이스 수준 마이그레이션은 일반적으로 Oracle 계층에서 마이그레이션을 완료하기 위해 대기 데이터베이스를 통한 Oracle 로그 전달을 사용하는 것을 의미합니다. 호스트 레벨 마이그레이션은 호스트 운영 체제 구성의 기본 기능을 사용하여 수행됩니다. 이 구성에는 cp, tar 및 Oracle RMAN(Recovery Manager)과 같은 명령을 사용하거나 LVM(Logical Volume Manager)을 사용하여 파일 시스템의 기본 바이트를 재배치하는 파일 복사 작업이 포함됩니다. Oracle ASM(Automatic Storage Management)은 데이터베이스 애플리케이션 수준 이하로 실행되기 때문에 호스트 수준 기능으로 분류됩니다. ASM은 호스트에서 일반적인 논리적 볼륨 관리자를 대체합니다. 마지막으로, 데이터는 스토리지 어레이 레벨에서 마이그레이션될 수 있으며, 이는 운영 체제 레벨 아래에서 마이그레이션됩니다.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">계획 고려 사항</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">마이그레이션을 위한 최상의 옵션은 마이그레이션할 환경의 규모, 다운타임을 방지해야 하는 필요성, 마이그레이션을 수행하는 데 필요한 전반적인 노력 등 여러 요소의 조합에 따라 달라집니다. 대규모 데이터베이스에는 마이그레이션을 위해 더 많은 시간과 노력이 필요하지만, 이와 같은 마이그레이션의 복잡성은 최소화됩니다. 작은 데이터베이스는 신속하게 마이그레이션할 수 있지만, 수천 개의 마이그레이션을 해야 하는 경우 그 규모가 커지면 복잡한 문제가 발생할 수 있습니다. 마지막으로, 데이터베이스가 클수록 비즈니스 크리티컬에 해당할 가능성이 커지므로 백엔드 경로를 유지하면서 다운타임을 최소화해야 합니다.</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">여기에서는 마이그레이션 전략 계획을 위한 몇 가지 고려 사항에 대해 설명합니다.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">데이터 크기입니다</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">크기가 컷오버 시간에 영향을 미칠 필요는 없지만 마이그레이션할 데이터베이스의 크기는 마이그레이션 계획에 분명히 영향을 미칩니다. 대량의 데이터를 마이그레이션해야 하는 경우 주요 고려 사항은 대역폭입니다. 복제 작업은 일반적으로 효율적인 순차적 I/O를 사용하여 수행됩니다 보수적인 추정치로, 복제 작업에 사용 가능한 네트워크 대역폭의 50%를 사용한다고 가정합니다. 예를 들어, 8GB FC 포트는 이론적으로 약 800MBps를 전송할 수 있습니다. 50%의 활용률을 가정하면 약 400Mbps의 속도로 데이터베이스를 복사할 수 있습니다. 따라서 10TB 데이터베이스를 이 속도로 약 7시간 내에 복사할 수 있습니다.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">온라인 데이터 파일 이동</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">데이터베이스 수입니다</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">많은 경우 대량의 데이터를 이동할 때 발생하는 문제는 데이터 크기가 아니라 데이터베이스를 지원하는 구성의 복잡성입니다. 단순히 50TB의 데이터베이스를 마이그레이션해야 한다는 사실을 아는 것만으로는 충분하지 않습니다. 단일 50TB 미션 크리티컬 데이터베이스, 4천 개의 기존 데이터베이스 컬렉션 또는 운영 데이터와 비운영 데이터의 조합이 될 수 있습니다. 경우에 따라 대부분의 데이터는 소스 데이터베이스의 클론으로 구성됩니다. 특히, 새 아키텍처에서 NetApp FlexClone 볼륨을 활용하도록 설계된 경우 이러한 클론을 쉽게 다시 생성할 수 있으므로 이러한 클론을 마이그레이션할 필요가 없습니다.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">마이그레이션 계획을 수립하려면 범위에 포함되는 데이터베이스의 수와 우선 순위를 어떻게 지정해야 하는지 파악해야 합니다. 데이터베이스 수가 증가함에 따라 기본 마이그레이션 옵션은 스택에서 더 낮거나 낮은 경향이 있습니다. 예를 들어, RMAN과 짧은 운영 중단으로 단일 데이터베이스를 쉽게 복사할 수 있습니다. 이것이 호스트 수준 복제입니다.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">데이터베이스가 50개인 경우 RMAN 복제본을 수신하도록 새 파일 시스템 구조를 설정하는 대신 데이터를 제자리로 이동하는 것이 더 쉬울 수 있습니다. 이 프로세스는 호스트 기반 LVM 마이그레이션을 통해 데이터를 이전 LUN에서 새 LUN으로 재배치하는 방법으로 수행할 수 있습니다. 이렇게 하면 DBA(데이터베이스 관리자) 팀에서 OS 팀으로 역할이 이전되고, 결과적으로 데이터가 데이터베이스와 관련하여 투명하게 마이그레이션됩니다. 파일 시스템 구성이 변경되지 않았습니다.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">끝으로, 서버 200대에서 500개의 데이터베이스를 마이그레이션해야 하는 경우 ONTAP FLI(Foreign LUN Import) 기능과 같은 스토리지 기반 옵션을 사용하여 LUN을 직접 마이그레이션할 수 있습니다.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">재건축 요구 사항</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">일반적으로 새 스토리지 어레이의 기능을 활용하기 위해 데이터베이스 파일 레이아웃을 변경해야 하지만 항상 그렇지는 않습니다. 예를 들어, EF-Series All-Flash 어레이의 기능은 주로 SAN 성능과 SAN 안정성을 최우선으로 합니다. 대부분의 경우 데이터 레이아웃과 관련하여 특별한 고려 사항 없이 데이터베이스를 EF-Series 어레이로 마이그레이션할 수 있습니다. 높은 IOPS, 짧은 지연 시간 및 강력한 안정성만 필요합니다. RAID 구성 또는 Dynamic Disk Pool과 같은 요소와 관련된 모범 사례가 있지만 EF-Series 프로젝트에서 이러한 기능을 활용하기 위해 전체 스토리지 아키텍처를 크게 변경할 필요는 없습니다.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">반면, ONTAP로 마이그레이션하려면 일반적으로 최종 구성이 최대한의 가치를 제공할 수 있도록 데이터베이스 레이아웃을 좀 더 고려해야 합니다. ONTAP는 그 자체로 특별한 아키텍처 노력 없이 데이터베이스 환경에 많은 기능을 제공합니다. 가장 중요한 것은 현재 하드웨어의 수명이 다할 때 새 하드웨어로 중단 없이 마이그레이션할 수 있는 기능을 제공한다는 것입니다. 일반적으로 ONTAP로의 마이그레이션은 수행해야 하는 마지막 마이그레이션입니다. 후속 하드웨어가 업그레이드되고 데이터가 중단 없이 새로운 미디어로 마이그레이션됩니다.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">어떤 계획을 세우면 훨씬 더 많은 혜택을 누릴 수 있습니다. 가장 중요한 고려 사항은 스냅샷 사용과 관련됩니다. 스냅샷은 거의 즉각적인 백업, 복원 및 클론 복제 작업을 수행하기 위한 기반입니다. 스냅샷 성능의 예로, 알려진 가장 큰 용도는 6개의 컨트롤러에서 약 250개의 LUN에서 실행되는 996TB의 단일 데이터베이스를 사용하는 것입니다. 이 데이터베이스는 2분 내에 백업되고 2분 내에 복원되며 15분 내에 복제될 수 있습니다. 추가 이점으로는 워크로드의 변화에 대응하여 클러스터 주변으로 데이터를 이동하는 기능과 QoS(서비스 품질) 제어 애플리케이션을 통해 다중 데이터베이스 환경에서 양호하고 일관된 성능을 제공하는 기능이 있습니다.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Oracle 마이그레이션 절차 개요</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">QoS 제어, 데이터 재배치, 스냅샷, 클론 복제 등의 기술은 거의 모든 구성에서 작동합니다. 그러나 일반적으로 이점을 극대화하기 위해서는 몇 가지 생각이 필요합니다. 새로운 스토리지 어레이에 대한 투자를 최대화하기 위해 데이터베이스 스토리지 레이아웃을 변경해야 하는 경우도 있습니다. 호스트 기반 또는 스토리지 기반 마이그레이션은 원본 데이터 레이아웃을 복제하므로 이러한 설계 변경은 마이그레이션 전략에 영향을 미칠 수 있습니다. 마이그레이션을 완료하고 ONTAP에 최적화된 데이터 레이아웃을 제공하기 위해 추가 단계가 필요할 수 있습니다. 에 나와 있는 절차 <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> 그리고 나중에 데이터베이스를 마이그레이션하는 것뿐만 아니라 최소한의 노력으로 최적의 최종 레이아웃으로 마이그레이션하는 몇 가지 방법을 보여 줍니다.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">컷오버 시간</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">컷오버 중에 허용되는 최대 서비스 중단 시간을 결정해야 합니다. 전체 마이그레이션 프로세스로 인해 운영이 중단된다고 생각하는 일반적인 실수입니다. 서비스 중단이 시작되기 전에 다양한 작업을 완료할 수 있으며, 다양한 옵션을 통해 운영 중단 또는 운영 중단 없이 마이그레이션을 완료할 수 있습니다. 불가피한 운영 중단이 불가피한 경우에도 컷오버 시간의 기간이 절차마다 다르므로 허용되는 최대 서비스 중단 시간을 정의해야 합니다.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">뒤로 이동 경로</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">마이그레이션 시 위험을 완전히 없앨 수는 없습니다. 기술이 완벽하게 작동하더라도 사용자 오류가 발생할 가능성이 항상 있습니다. 선택한 마이그레이션 경로와 관련된 위험은 실패한 마이그레이션의 결과와 함께 고려해야 합니다. 예를 들어, Oracle ASM의 투명한 온라인 스토리지 마이그레이션 기능은 주요 기능 중 하나이며 이 방법은 가장 신뢰할 수 있는 기능 중 하나입니다. 그러나 이 메서드를 사용하여 데이터를 복구할 수 없는 방식으로 복사하고 있습니다. 드문 경우지만 ASM에서 문제가 발생하는 경우에는 쉬운 백아웃 경로가 없습니다. 유일한 옵션은 원래 환경을 복원하거나 ASM을 사용하여 마이그레이션을 원래 LUN으로 되돌리는 것입니다. 시스템에서 이러한 작업을 수행할 수 있다고 가정하면 원래 스토리지 시스템에서 스냅샷 유형 백업을 수행하면 위험이 최소화될 수 있지만 제거되지는 않습니다.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">예행 연습</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">일부 마이그레이션 절차는 실행 전에 완전히 검증되어야 합니다. 마이그레이션 및 전환 프로세스의 예행 연습은 마이그레이션을 성공적으로 수행하고 다운타임을 최소화해야 하는 미션 크리티컬 데이터베이스에 대한 일반적인 요청입니다. 또한 사용자 수용 테스트는 마이그레이션 후 작업의 일부로 포함되는 경우가 많으며 이러한 테스트가 완료된 후에만 전체 시스템을 운영 환경으로 되돌릴 수 있습니다.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">예행 연습이 필요한 경우 몇 가지 ONTAP 기능을 통해 프로세스를 훨씬 쉽게 수행할 수 있습니다. 특히 스냅샷은 테스트 환경을 재설정하고 데이터베이스 환경의 공간 효율적인 여러 복제본을 신속하게 생성할 수 있습니다.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">개별 Oracle 데이터 파일 마이그레이션</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">데이터 파일 이동</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">단일 명령으로 개별 Oracle 데이터 파일을 이동할 수 있습니다.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">예를 들어, 다음 명령은 파일 시스템에서 데이터 파일 IOPST.dbf를 이동합니다<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> 파일 시스템으로<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">이 방법으로 데이터 파일을 이동하는 것은 느릴 수 있지만 일반적으로는 일상적인 데이터베이스 워크로드에 지장을 줄 만큼 I/O가 충분히 생성하지 않아야 합니다. 반면 ASM 재조정을 통한 마이그레이션은 훨씬 빠르게 실행할 수 있지만 데이터가 이동되는 동안 전체 데이터베이스의 속도가 느려질 수 있습니다.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">데이터 파일을 이동한 시간은 테스트 데이터 파일을 만든 다음 이동하는 방법으로 손쉽게 측정할 수 있습니다. 작업에 대해 경과된 시간은 v$ 세션 데이터에 기록됩니다.</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">이 예에서는 데이터 파일 8로 이동했습니다. 데이터 파일 8은 21GB이며 마이그레이션하는 데 6분 정도 걸렸습니다. 필요한 시간은 스토리지 시스템의 기능, 스토리지 네트워크 및 마이그레이션 시 발생하는 전체 데이터베이스 활동에 따라 달라집니다.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">호스트 측 스토리지 스택을 사용한 Oracle 마이그레이션</block>
  <block id="174f3246d5f9cdf330404cb6158e67e2" category="doc">Oracle 호스트 데이터 복사본</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">데이터베이스 레벨 마이그레이션과 마찬가지로 호스트 계층에서 마이그레이션하면 스토리지 공급업체에 종속되지 않는 접근 방식이 제공됩니다.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">다시 말해, 언젠가는 "그냥 파일 복사"가 가장 좋은 옵션입니다.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">이러한 낮은 수준의 기술 접근 방식은 매우 기본적이라고 생각될 수 있지만, 특별한 소프트웨어가 필요하지 않고 원본 데이터가 프로세스 중에 안전하게 유지되기 때문에 상당한 이점을 제공합니다. 주된 제한 사항은 파일 복사 데이터 마이그레이션은 복사 작업을 시작하기 전에 데이터베이스를 종료해야 하기 때문에 중단 프로세스라는 점입니다. 파일 내의 변경 내용을 동기화하는 좋은 방법은 없으므로 복사하기 전에 파일을 완전히 정지해야 합니다.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">복사 작업에 필요한 종료가 바람직하지 않은 경우 다음으로 가장 좋은 호스트 기반 옵션은 논리 볼륨 관리자(LVM)를 활용하는 것입니다. Oracle ASM을 비롯한 많은 LVM 옵션이 존재하며 모든 기능이 비슷하지만 몇 가지 제한도 고려해야 합니다. 대부분의 경우 다운타임 및 운영 중단 없이 마이그레이션을 수행할 수 있습니다.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">파일 시스템 대 파일 시스템 복제</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">단순 복사 작업의 유용성을 과소 평가해서는 안 됩니다. 이 작업은 복사 프로세스 중에 다운타임이 발생하지만 매우 안정적인 프로세스이며 운영 체제, 데이터베이스 또는 스토리지 시스템에 대한 특별한 전문 지식이 필요하지 않습니다. 또한 원본 데이터에 영향을 주지 않기 때문에 매우 안전합니다. 일반적으로 시스템 관리자는 소스 파일 시스템을 읽기 전용으로 마운트하도록 변경한 다음 서버를 재부팅하여 현재 데이터가 손상되지 않도록 합니다. 복제 프로세스는 사용자 오류의 위험 없이 가능한 한 빨리 실행되도록 스크립트될 수 있습니다. I/O 유형은 데이터의 단순한 순차 전송이므로 대역폭 효율성이 매우 높습니다.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">다음 예에서는 안전하고 신속한 마이그레이션을 위한 한 가지 옵션을 보여 줍니다.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">마이그레이션할 환경은 다음과 같습니다.</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">현재 파일 시스템</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">새 파일 시스템</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">개요</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">데이터베이스를 종료하고 파일을 복사하기만 하면 DBA가 데이터베이스를 마이그레이션할 수 있지만, 많은 데이터베이스를 마이그레이션해야 하거나 가동 중지 시간을 최소화하는 것이 중요한 경우 프로세스가 쉽게 스크립팅됩니다. 또한 스크립트를 사용하면 사용자의 실수 가능성이 줄어듭니다.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">표시된 예제 스크립트는 다음 작업을 자동화합니다.</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">데이터베이스를 종료합니다</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">기존 파일 시스템을 읽기 전용 상태로 변환합니다</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">소스의 모든 데이터를 타겟 파일 시스템으로 복제하여 모든 파일 사용 권한을 유지합니다</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">이전 파일 시스템과 새 파일 시스템의 마운트를 해제합니다</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">이전 파일 시스템과 동일한 경로에 새 파일 시스템을 다시 마운트합니다</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">절차를 참조하십시오</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">데이터베이스를 종료합니다.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">파일 시스템을 읽기 전용으로 변환합니다</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">파일 시스템을 읽기 전용으로 변환합니다. 에서와 같이 스크립트를 사용하여 보다 빠르게 수행할 수 있습니다 <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">이제 파일 시스템이 읽기 전용인지 확인합니다.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">와 파일 시스템 컨텐츠를 동기화합니다<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">파일 시스템을 교체합니다</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">이전 파일 시스템을 마운트 해제하고 복제된 데이터를 재배치합니다. 에서와 같이 스크립트를 사용하여 보다 빠르게 수행할 수 있습니다 <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">새 파일 시스템이 올바른 위치에 있는지 확인합니다.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">데이터베이스를 시작합니다.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">완전 자동화된 컷오버</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">이 샘플 스크립트에서는 데이터베이스 SID의 인수 다음에 파일 시스템의 공용 구분 쌍이 오는 인수를 사용할 수 있습니다. 위의 예에서 명령은 다음과 같이 실행됩니다.</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">예제 스크립트가 실행되면 다음 순서를 수행하려고 시도합니다. 어떤 단계에서든 오류가 발생하면 종료됩니다.</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">현재 파일 시스템을 읽기 전용 상태로 변환합니다.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">쉼표로 구분된 각 파일 시스템 인수 쌍을 사용하고 첫 번째 파일 시스템을 두 번째 파일 시스템과 동기화합니다.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">이전 파일 시스템을 분리합니다.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">를 업데이트합니다<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 다음과 같은 파일:</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">에서 백업을 생성합니다<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">이전 및 새 파일 시스템에 대한 이전 항목을 주석 처리합니다.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">이전 마운트 지점을 사용하는 새 파일 시스템에 대한 새 항목을 생성합니다.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">파일 시스템을 마운트합니다.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">다음 텍스트는 이 스크립트에 대한 실행 예제를 제공합니다.</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Oracle ASM spfile 및 passwd 마이그레이션</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">ASM과 관련된 마이그레이션을 완료하는 데 있어 한 가지 어려움은 ASM 관련 spfile과 암호 파일입니다. 기본적으로 이러한 중요 메타데이터 파일은 정의된 첫 번째 ASM 디스크 그룹에 생성됩니다. 특정 ASM 디스크 그룹을 비우고 제거해야 하는 경우 해당 ASM 인스턴스를 제어하는 spfile 및 암호 파일을 재배치해야 합니다.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">이러한 파일을 재배치해야 하는 또 다른 활용 사례는 SnapManager for Oracle 또는 SnapCenter Oracle 플러그인과 같은 데이터베이스 관리 소프트웨어를 구축하는 경우입니다. 이러한 제품의 기능 중 하나는 데이터 파일을 호스팅하는 ASM LUN의 상태를 되돌려 신속하게 데이터베이스를 복원하는 것입니다. 이렇게 하려면 복원을 수행하기 전에 ASM 디스크 그룹을 오프라인으로 전환해야 합니다. 특정 데이터베이스의 데이터 파일이 전용 ASM 디스크 그룹에서 격리되어 있는 한 이 문제는 문제가 되지 않습니다.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">해당 디스크 그룹에 ASM spfile/passwd 파일도 포함되어 있는 경우 디스크 그룹을 오프라인으로 전환할 수 있는 유일한 방법은 전체 ASM 인스턴스를 종료하는 것입니다. 이는 중단 프로세스이므로 spfile/passwd 파일을 재배치해야 합니다.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">데이터베이스 SID = 토스트</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">의 현재 데이터 파일<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">의 현재 로그 파일 및 제어 파일<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">로 설정된 새 ASM 디스크 그룹<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> 및<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">ASM spfile/passwd 파일 위치</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">이러한 파일 재배치는 중단 없이 수행할 수 있습니다. 그러나 안전을 위해 NetApp에서는 파일이 재배치되고 구성이 올바르게 업데이트되었는지 확인할 수 있도록 데이터베이스 환경을 종료하는 것이 좋습니다. 서버에 여러 ASM 인스턴스가 있는 경우 이 절차를 반복해야 합니다.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">ASM 인스턴스 식별</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">에 기록된 데이터를 기반으로 ASM 인스턴스를 식별합니다<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> 파일. ASM 인스턴스는 + 기호로 표시됩니다.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">이 서버에는 +asm 이라는 ASM 인스턴스가 하나 있습니다.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">모든 데이터베이스가 종료되었는지 확인합니다</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">사용 중인 ASM 인스턴스에 대한 smon 프로세스만 볼 수 있습니다. 다른 스몬 프로세스가 있으면 데이터베이스가 여전히 실행 중임을 나타냅니다.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">유일한 smon 프로세스는 ASM 인스턴스 자체입니다. 즉, 다른 데이터베이스는 실행 중이지 않으므로 데이터베이스 작업을 중단하지 않고 계속 진행하는 것이 안전합니다.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">파일을 찾습니다</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">를 사용하여 ASM spfile 및 암호 파일의 현재 위치를 식별합니다<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> 및<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">두 파일은 모두 의 하단에 있습니다<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> 디스크 그룹입니다.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">파일을 복사합니다</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">를 사용하여 파일을 새 ASM 디스크 그룹에 복사합니다<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> 및<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> 명령. 새 디스크 그룹이 최근에 생성되어 현재 비어 있는 경우 먼저 마운트해야 할 수 있습니다.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">이제 파일이 에서 복사되었습니다<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">ASM 인스턴스를 업데이트합니다</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">이제 ASM 인스턴스를 업데이트하여 위치 변경을 반영해야 합니다. 를 클릭합니다<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> 및<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> 명령은 ASM 디스크 그룹을 시작하는 데 필요한 ASM 메타데이터를 업데이트합니다.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">업데이트된 파일을 사용하여 ASM을 활성화합니다</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">이때 ASM 인스턴스는 이러한 파일의 이전 위치를 계속 사용합니다. 새 위치에서 파일을 다시 읽고 이전 파일의 잠금을 해제하려면 인스턴스를 다시 시작해야 합니다.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">이전 spfile 및 암호 파일을 제거합니다</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">절차가 성공적으로 수행되면 이전 파일이 더 이상 잠기지 않고 제거할 수 있습니다.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Oracle ASM에서 ASM으로의 복사</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM은 기본적으로 경량의 복합 볼륨 관리자와 파일 시스템입니다. 파일 시스템이 바로 보이지 않으므로 RMAN을 사용하여 복사 작업을 수행해야 합니다. 복사 기반의 마이그레이션 프로세스는 안전하고 간단하지만 약간의 운영 중단이 발생합니다. 운영 중단을 최소화할 수 있지만 완전히 제거되지는 않습니다.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">ASM 기반 데이터베이스의 무중단 마이그레이션을 원하는 경우 ASM의 기능을 활용하여 이전 LUN을 삭제하는 동시에 ASM 익스텐트를 새 LUN으로 재조정하는 것이 가장 좋습니다. 일반적으로 안전하면서 운영 중단이 일어나지 않지만 백 아웃 경로는 제공되지 않습니다. 기능 또는 성능 문제가 발생할 경우 데이터를 소스로 다시 마이그레이션하는 방법만 사용할 수 있습니다.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">데이터를 이동하지 않고 데이터베이스를 새 위치로 복사하여 원본 데이터를 그대로 유지하면 이러한 위험을 방지할 수 있습니다. 이 데이터베이스는 새 위치에서 완전히 테스트된 후 가동할 수 있으며, 문제가 발견될 경우 원래 데이터베이스를 폴백 옵션으로 사용할 수 있습니다.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">이 절차는 RMAN과 관련된 여러 옵션 중 하나입니다. 초기 백업이 생성된 후 나중에 로그 재생을 통해 동기화되는 2단계 프로세스를 허용하도록 설계되었습니다. 이 프로세스는 초기 베이스라인 복사 중에 데이터베이스가 운영 상태를 유지하고 데이터를 제공할 수 있기 때문에 다운타임을 최소화하는 것이 좋습니다.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">데이터베이스를 복사합니다</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN은 현재 ASM 디스크 그룹에 있는 소스 데이터베이스의 레벨 0(전체) 복제본을 생성합니다<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> 의 새 위치로 이동합니다<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">아카이브 로그 스위치를 강제 적용합니다</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">아카이브 로그에 복사의 일관성을 완전히 유지하는 데 필요한 모든 데이터가 포함되도록 하려면 아카이브 로그 스위치를 강제로 사용해야 합니다. 이 명령을 사용하지 않으면 주요 데이터가 재실행 로그에 계속 존재할 수 있습니다.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">원본 데이터베이스를 종료합니다</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">데이터베이스가 종료되고 제한된 읽기 전용 모드로 전환되기 때문에 이 단계에서 중단이 시작됩니다. 소스 데이터베이스를 종료하려면 다음 명령을 실행합니다.</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">제어 파일 백업</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">마이그레이션을 중단하고 원래 스토리지 위치로 되돌려야 하는 경우 controlfile을 백업해야 합니다. 백업 제어 파일 사본이 100% 필요한 것은 아니지만 데이터베이스 파일 위치를 원래 위치로 다시 설정하는 프로세스가 더 쉬워집니다.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">현재 spfile에는 이전 ASM 디스크 그룹 내의 현재 위치에 있는 컨트롤 파일에 대한 참조가 포함되어 있습니다. 중간 pfile 버전을 편집하여 쉽게 편집할 수 있도록 편집해야 합니다.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">pfile을 업데이트합니다</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">새 ASM 디스크 그룹 이름을 반영하도록 이전 ASM 디스크 그룹을 참조하는 모든 매개 변수를 업데이트합니다. 그런 다음 업데이트된 pfile을 저장합니다. 를 확인합니다<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> 매개 변수가 있습니다.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">아래 예에서는 에 대한 참조를 나타냅니다<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> 이(가) 로 변경되었습니다<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> 노란색으로 강조 표시됩니다. 두 가지 주요 매개 변수는 입니다<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> 올바른 위치에 새 파일을 만드는 매개 변수입니다.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">init.ora 파일을 업데이트합니다</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">대부분의 ASM 기반 데이터베이스는 를 사용합니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 에 있는 파일<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> 디렉토리로, ASM 디스크 그룹의 spfile을 가리킵니다. 이 파일은 새 ASM 디스크 그룹의 위치로 리디렉션되어야 합니다.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">이 파일을 다음과 같이 변경합니다.</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">매개 변수 파일 재생성</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">이제 편집된 pfile의 데이터로 spfile을 채울 준비가 되었습니다.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">데이터베이스를 시작하여 새 spfile 사용을 시작합니다</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">데이터베이스를 시작하여 새로 생성된 spfile을 사용하고 시스템 매개변수에 대한 추가 변경 사항이 올바르게 기록되었는지 확인합니다.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">제어파일을 복원합니다</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">RMAN에서 생성된 백업 제어 파일은 RMAN에서 새 spfile에 지정된 위치로 직접 복구할 수도 있습니다.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">데이터베이스를 마운트하고 새 컨트롤 파일의 사용을 확인합니다.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">로그 재생</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">데이터베이스는 현재 이전 위치에 있는 데이터 파일을 사용합니다. 복사본을 사용하려면 먼저 복사본을 동기화해야 합니다. 초기 복제 프로세스 중에 시간이 경과했으며 변경 사항이 주로 아카이브 로그에 기록되었습니다. 이러한 변경 사항은 다음과 같이 복제됩니다.</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">아카이브 로그가 포함된 RMAN 증분 백업을 수행합니다.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">로그를 재생합니다.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">활성화</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">복원된 컨트롤 파일은 원래 위치에 있는 데이터 파일을 참조하며 복사된 데이터 파일의 경로 정보도 포함합니다.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">활성 데이터 파일을 변경하려면 를 실행합니다<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">활성 데이터 파일은 이제 복사된 데이터 파일이지만 최종 redo 로그에 변경 내용이 포함될 수 있습니다.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">나머지 로그를 모두 재생하려면 를 실행합니다<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> 명령. 메시지가 표시되는 경우<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> 프로세스가 성공했다는 메시지가 나타납니다.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">이 프로세스는 일반 데이터 파일의 위치만 변경했습니다. 임시 데이터 파일은 이름을 바꿔야 하지만 임시 파일이므로 복사할 필요가 없습니다. 데이터베이스가 현재 다운되어 임시 데이터 파일에 활성 데이터가 없습니다.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">임시 데이터 파일을 재배치하려면 먼저 해당 위치를 확인합니다.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">각 데이터 파일의 새 이름을 설정하는 RMAN 명령을 사용하여 임시 데이터 파일을 재배치합니다. OMF(Oracle Managed Files)에서는 전체 이름이 필요하지 않으며 ASM 디스크 그룹이면 충분합니다. 데이터베이스가 열리면 OMF는 ASM 디스크 그룹의 적절한 위치에 연결됩니다. 파일을 재배치하려면 다음 명령을 실행합니다.</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">로그 마이그레이션을 다시 실행합니다</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">마이그레이션 프로세스는 거의 완료되었지만 재실행 로그는 여전히 원본 ASM 디스크 그룹에 있습니다. REDO 로그는 직접 재배치할 수 없습니다. 대신 새 redo 로그 세트가 생성되어 구성에 추가된 다음 이전 로그가 삭제됩니다.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">각 redo 로그에 대해 일치하는 구성을 가진 새 그룹을 생성합니다. OMF를 사용하지 않는 경우 전체 경로를 지정해야 합니다. 이는 를 사용하는 예이기도 합니다<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> 매개 변수. 앞에서 설명한 것처럼 이 매개 변수는 +NEWLOGS 로 설정되었습니다. 이 구성을 사용하면 파일 위치나 특정 ASM 디스크 그룹을 지정할 필요 없이 다음 명령을 사용하여 새로운 온라인 로그를 생성할 수 있습니다.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">데이터베이스를 엽니다.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">이전 로그를 삭제합니다.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">활성 로그를 삭제할 수 없는 오류가 발생하면 다음 로그로 스위치를 강제로 전환하여 잠금을 해제하고 글로벌 체크포인트를 강제로 설정합니다. 예를 들면 다음과 같습니다. 이 로그 파일에 활성 데이터가 있기 때문에 이전 위치에 있던 로그 파일 그룹 3을 삭제하려는 시도가 거부되었습니다. 체크포인트 다음에 로그 아카이빙을 수행하면 로그 파일을 삭제할 수 있습니다.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">환경을 검토하여 모든 위치 기반 매개 변수가 업데이트되었는지 확인합니다.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">다음 스크립트는 이 프로세스를 단순화하는 방법을 보여 줍니다.</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">ASM 디스크 그룹이 완전히 비워진 경우 에서 디스크 그룹을 마운트 해제할 수 있습니다<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. 그러나 대부분의 경우 다른 데이터베이스 또는 ASM spfile/passwd 파일에 속하는 파일이 여전히 존재할 수 있습니다.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Oracle ASM에서 파일 시스템 복사입니다</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">Oracle ASM-파일 시스템 복사 절차는 ASM과 ASM/ASM 복제 절차와 매우 유사하며, 이점과 제한 사항이 유사합니다. 기본적인 차이점은 ASM 디스크 그룹과 달리 가시적인 파일 시스템을 사용할 때 다양한 명령 및 구성 매개 변수의 구문입니다.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN은 현재 ASM 디스크 그룹에 위치한 소스 데이터베이스의 레벨 0(전체) 복제본을 생성하는 데 사용됩니다<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> 의 새 위치로 이동합니다<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">아카이브 로그 스위치를 강제로 사용하면 아카이브 로그에 복제본의 일관성을 완전히 유지하는 데 필요한 모든 데이터가 포함되도록 할 수 있습니다. 이 명령을 사용하지 않으면 주요 데이터가 재실행 로그에 계속 존재할 수 있습니다. 아카이브 로그 스위치를 강제로 전환하려면 다음 명령을 실행합니다.</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">데이터베이스가 종료되고 제한된 액세스 읽기 전용 모드로 전환되기 때문에 이 단계에서 중단이 시작됩니다. 소스 데이터베이스를 종료하려면 다음 명령을 실행합니다.</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">마이그레이션을 중단하고 원래 스토리지 위치로 되돌려야 하는 경우 제어 파일을 백업합니다. 백업 제어 파일 사본이 100% 필요한 것은 아니지만 데이터베이스 파일 위치를 원래 위치로 다시 설정하는 프로세스가 더 쉬워집니다.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">이전 ASM 디스크 그룹을 참조하는 모든 매개 변수는 업데이트되어야 하며, 경우에 따라 더 이상 관련이 없을 때 삭제해야 합니다. 새 파일 시스템 경로를 반영하도록 이 경로를 업데이트하고 업데이트된 pfile을 저장합니다. 전체 대상 경로가 나열되어 있는지 확인합니다. 이러한 매개 변수를 업데이트하려면 다음 명령을 실행합니다.</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">원본 init.ora 파일을 비활성화합니다</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">이 파일은 에 있습니다<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> 디렉토리이며 일반적으로 ASM 디스크 그룹의 spfile에 대한 포인터로 사용되는 pfile에 있습니다. 원본 spfile이 더 이상 사용되지 않도록 하려면 이름을 바꿉니다. 그러나 마이그레이션을 중단해야 하는 경우 이 파일이 필요하므로 삭제하지 마십시오.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">이 단계는 spfile 재배치의 마지막 단계입니다. 원본 spfile은 더 이상 사용되지 않으며 현재 중간 파일을 사용하여 데이터베이스가 시작(마운트되지는 않음)됩니다. 이 파일의 내용은 다음과 같이 새 spfile 위치에 쓸 수 있습니다.</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">중간 파일의 잠금을 해제하고 새 spfile 파일만 사용하여 데이터베이스를 시작하려면 데이터베이스를 시작해야 합니다. 데이터베이스를 시작하면 새 spfile 위치가 올바르고 데이터가 유효하다는 것도 증명됩니다.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">경로에 백업 제어 파일이 생성되었습니다<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> 절차의 앞부분에 있습니다. 새 spfile은 제어 파일 위치를 로 정의합니다 <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> 및<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. 그러나 해당 파일은 아직 존재하지 않습니다.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">이 명령은 컨트롤 파일 데이터를 spfile에 정의된 경로로 복원합니다.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">mount 명령을 실행하여 제어 파일이 올바르게 검색되고 유효한 데이터가 포함되도록 합니다.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">를 확인합니다<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> 매개 변수에서 다음 명령을 실행합니다.</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">데이터베이스가 현재 이전 위치의 데이터 파일을 사용하고 있습니다. 복사본을 사용하려면 먼저 데이터 파일을 동기화해야 합니다. 초기 복제 프로세스 중에 시간이 경과했으며 변경 사항은 주로 아카이브 로그에 기록되었습니다. 이러한 변경 사항은 다음 두 단계에 복제됩니다.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">로그를 재생합니다.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">활성 데이터 파일을 변경하려면 를 실행합니다<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> 명령:</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">데이터 파일은 완전히 일관되어야 하지만 온라인 재실행 로그에 기록된 나머지 변경 내용을 재생하려면 마지막 단계가 필요합니다. 를 사용합니다<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> 명령을 사용하여 이러한 변경 사항을 재생하고 복사본을 원본과 100% 동일하게 만듭니다. 하지만 복사본이 아직 열려 있지 않습니다.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">임시 데이터 파일 재배치</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">원본 디스크 그룹에서 여전히 사용 중인 임시 데이터 파일의 위치를 식별합니다.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">데이터 파일을 재배치하려면 다음 명령을 실행합니다. tempfiles가 많은 경우 텍스트 편집기를 사용하여 RMAN 명령을 생성한 다음 잘라내어 붙여 넣습니다.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">마이그레이션 프로세스는 거의 완료되었지만 재실행 로그는 여전히 원본 ASM 디스크 그룹에 있습니다. REDO 로그는 직접 재배치할 수 없습니다. 대신 새 redo 로그 세트가 생성되고 구성에 추가되며, 그 다음에 이전 로그가 삭제됩니다.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">각 redo 로그에 대해 새 파일 시스템 위치를 사용하여 현재 redo 로그 그룹과 동일한 크기를 사용하여 새 그룹을 생성합니다.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">이전 스토리지에 있는 이전 로그 파일 그룹을 제거합니다.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">활성 로그를 삭제하는 블록에 오류가 발생하는 경우 다음 로그로 스위치를 강제 전환하여 잠금을 해제하고 글로벌 체크포인트를 강제 적용합니다. 예를 들면 다음과 같습니다. 이 로그 파일에 활성 데이터가 있기 때문에 이전 위치에 있던 로그 파일 그룹 3을 삭제하려는 시도가 거부되었습니다. 로그 아카이빙과 체크포인트가 지나면 로그 파일을 삭제할 수 있습니다.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">다음 스크립트는 이 프로세스를 보다 쉽게 만드는 방법을 보여 줍니다.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">ASM 디스크 그룹이 완전히 비워진 경우 에서 디스크 그룹을 마운트 해제할 수 있습니다<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. 대부분의 경우 다른 데이터베이스 또는 ASM spfile/passwd 파일에 속하는 파일이 계속 존재할 수 있습니다.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">데이터 파일 정리 절차</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">ASM 마이그레이션 정리</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">마이그레이션 프로세스로 인해 Oracle RMAN의 사용 방식에 따라 긴 구문 또는 암호화된 데이터 파일이 생성될 수 있습니다. 여기에 표시된 예에서는 의 파일 형식으로 백업이 수행되었습니다<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> RMAN이 각 데이터 파일에 대해 기본 고유 이름을 생성해야 함을 나타냅니다. 결과는 다음 텍스트에 표시된 것과 유사합니다. 데이터 파일의 기존 이름은 이름 안에 포함됩니다. 이 작업은 에 나와 있는 스크립트된 접근 방식을 사용하여 정리할 수 있습니다 <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Oracle ASM 재조정</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">앞서 설명한 대로 재조정 프로세스를 사용하여 Oracle ASM 디스크 그룹을 새 스토리지 시스템으로 투명하게 마이그레이션할 수 있습니다. 요약하면 재조정 프로세스에서는 크기가 동일한 LUN을 기존 LUN 그룹에 추가한 다음 이전 LUN의 삭제 작업을 수행해야 합니다. Oracle ASM은 기본 데이터를 최적의 레이아웃으로 새 스토리지로 자동으로 재이동한 다음 완료되면 이전 LUN을 해제합니다.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">마이그레이션 프로세스는 효율적인 순차적 I/O를 사용하며 일반적으로 성능 중단을 일으키지 않지만 필요할 때 마이그레이션 속도를 조절할 수 있습니다.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">마이그레이션할 데이터를 식별합니다</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">새 LUN을 생성합니다</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">동일한 크기의 새 LUN을 생성하고 필요에 따라 사용자 및 그룹 멤버쉽을 설정합니다. LUN은 로 표시되어야 합니다<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> 디스크.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">새 LUN을 추가합니다</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">추가 및 삭제 작업은 함께 수행할 수 있지만 일반적으로 두 단계로 새 LUN을 추가하는 것이 더 쉽습니다. 먼저 새 LUN을 디스크 그룹에 추가합니다. 이 단계를 수행하면 익스텐트의 절반이 현재 ASM LUN에서 새 LUN으로 마이그레이션됩니다.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">재조정 성능은 데이터가 전송되는 속도를 나타냅니다. 숫자가 클수록 데이터 전송의 병렬 처리 수가 높아집니다. 마이그레이션은 성능 문제를 일으킬 소지가 없는 효율적인 순차적 I/O 작업을 통해 수행됩니다. 그러나 필요한 경우 진행 중인 마이그레이션의 균형 조정 성능을 로 조정할 수 있습니다<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> 명령. 일반적인 마이그레이션은 5의 값을 사용합니다.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">작동을 모니터링합니다</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">재조정 작업을 여러 방법으로 모니터링하고 관리할 수 있습니다. 이 예에서는 다음 명령을 사용했습니다.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">마이그레이션이 완료되면 재조정 작업이 보고되지 않습니다.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">기존 LUN을 삭제합니다</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">이제 마이그레이션이 절반 정도 완료되었습니다. 몇 가지 기본 성능 테스트를 수행하여 환경이 양호한지 확인하는 것이 좋습니다. 확인 후 이전 LUN을 삭제하여 나머지 데이터를 재배치할 수 있습니다. 그러나 LUN이 즉시 해제되지는 않습니다. 삭제 작업은 Oracle ASM에 먼저 익스텐트를 재배치한 다음 LUN을 해제하라는 신호를 보냅니다.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">재조정 작업은 여러 가지 방법으로 모니터링 및 관리할 수 있습니다. 이 예에서는 다음 명령을 사용했습니다.</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">이전 LUN을 제거합니다</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">디스크 그룹에서 기존 LUN을 제거하기 전에 헤더 상태에 대한 최종 확인 작업을 수행해야 합니다. ASM에서 LUN을 릴리즈하면 더 이상 이름이 나열되지 않고 헤더 상태가 로 표시됩니다<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. 이는 이러한 LUN을 시스템에서 안전하게 제거할 수 있음을 나타냅니다.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">LVM 마이그레이션</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">여기에 제시된 절차는 라는 볼륨 그룹의 LVM 기반 마이그레이션 원칙을 보여줍니다<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. 그 예가 Linux LVM에서 도출되었지만 원칙은 AIX, HP-UX 및 VxVM에도 동일하게 적용됩니다. 정확한 명령은 다를 수 있습니다.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">현재 에 있는 LUN을 식별합니다<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> 볼륨 그룹:</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">물리적 크기가 같거나 약간 더 큰 새 LUN을 생성하고 물리적 볼륨으로 정의합니다.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">새 볼륨을 볼륨 그룹에 추가합니다.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">를 발행합니다<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> 명령을 사용하여 각 현재 LUN의 익스텐트를 새 LUN으로 재배치합니다. 를 클릭합니다<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> argument 는 작업의 진행률을 모니터링합니다.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">이 프로세스가 완료되면 를 사용하여 볼륨 그룹에서 이전 LUN을 삭제합니다<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> 명령. 성공하면 이제 시스템에서 LUN을 안전하게 제거할 수 있습니다.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Oracle 마이그레이션 절차</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">Oracle 마이그레이션 데이터베이스에 다양한 절차를 사용할 수 있습니다. 올바른 운영 체제는 비즈니스 요구 사항에 달려 있습니다.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">대부분의 경우 시스템 관리자와 DBA는 물리적 볼륨 데이터를 재배치하거나, 미러링 및 방해 요소를 제거하거나, Oracle RMAN을 활용하여 데이터를 복제하는 방법을 선호하고 있습니다.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">이러한 절차는 사용 가능한 옵션 중 일부에 익숙하지 않은 IT 직원을 위한 지침으로 주로 제공됩니다. 또한 절차를 통해 각 마이그레이션 방법에 대한 작업, 시간 요구사항 및 기술 집합 요구를 파악할 수 있습니다. 이를 통해 NetApp 및 파트너 프로페셔널 서비스 또는 IT 관리 부서와 같은 타사는 각 절차의 요구사항을 보다 완벽하게 이해할 수 있습니다.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">마이그레이션 전략을 만드는 단일 모범 사례는 없습니다. 계획을 작성하려면 먼저 가용성 옵션을 파악한 다음 비즈니스 요구에 가장 적합한 방법을 선택해야 합니다. 아래 그림은 기본적인 고려 사항과 고객이 내린 일반적인 결론을 보여 주지만 모든 상황에 보편적으로 적용되는 것은 아닙니다.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">예를 들어 한 단계만 거치면 전체 데이터베이스 크기에 대한 문제가 발생합니다. 다음 단계는 데이터베이스가 1TB 이하인지 여부에 따라 달라집니다. 권장 단계는 일반적인 고객 사례를 기반으로 한 권장 사항입니다. 대부분의 고객은 DataGuard를 사용하여 작은 데이터베이스를 복사하지 않을 수도 있지만 일부 고객은 그렇지 않을 수도 있습니다. 대부분의 고객은 시간이 필요하기 때문에 50TB 데이터베이스를 복사하지 않으려고 하지만 어떤 고객은 이 작업을 허용할 만큼 충분한 유지 관리 기간이 있을 수 있습니다.</block>
  <block id="82f59f5f005a6ea06f0466a4ffc18b6c" category="paragraph">가장 적합한 마이그레이션 경로에 대한 고려 사항 유형의 순서도를 찾을 수 있습니다 <block ref="d197151b12289ca0258c12e9b0e8fb1c" category="inline-link-macro-rx"></block>.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 이상에는 데이터베이스가 온라인 상태일 때 데이터 파일을 이동하는 기능이 포함되어 있습니다. 또한 서로 다른 파일 시스템 유형 간에 작동합니다. 예를 들어 데이터 파일을 xfs 파일 시스템에서 ASM으로 재배치할 수 있습니다. 이 방법은 필요할 수 있는 개별 데이터 파일 이동 작업의 수로 인해 일반적으로 대규모로 사용되지 않지만 데이터 파일이 적은 작은 데이터베이스에서는 고려할 만한 옵션입니다.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">또한 데이터 파일을 단순히 이동하는 것이 기존 데이터베이스의 부분을 마이그레이션하는 좋은 방법입니다. 예를 들어, 유휴 블록을 오브젝트 저장소에 저장할 수 있는 FabricPool 볼륨과 같이 사용량이 적은 데이터 파일을 더 비용 효율적인 스토리지로 재배치할 수 있습니다.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">데이터베이스 레벨 마이그레이션</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">데이터베이스 수준에서 마이그레이션하면 데이터베이스가 데이터를 재배치할 수 있습니다. 특히 로그 전송을 의미합니다. RMAN 및 ASM 같은 기술은 Oracle 제품이지만, 마이그레이션을 위해 파일을 복제하고 볼륨을 관리하는 호스트 레벨에서 작동합니다.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">로그 전달</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">데이터베이스 수준 마이그레이션의 기반은 Oracle 아카이브 로그이며, 여기에는 데이터베이스의 변경 사항 로그가 포함됩니다. 대부분의 경우 아카이브 로그는 백업 및 복구 전략의 일부입니다. 복구 프로세스는 데이터베이스 복원으로 시작한 다음 하나 이상의 아카이브 로그를 재생하여 데이터베이스를 원하는 상태로 만듭니다. 이와 동일한 기본 기술을 사용하여 운영 중단이 거의 또는 전혀 없는 마이그레이션을 수행할 수 있습니다. 더욱 중요한 점은 이 기술을 통해 원래 데이터베이스를 그대로 유지하면서 마이그레이션을 수행할 수 있으므로 백업 경로가 유지됩니다.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">마이그레이션 프로세스는 데이터베이스 백업을 보조 서버로 복원하는 것부터 시작됩니다. 다양한 방법으로 그렇게 할 수 있지만 대부분의 고객은 일반 백업 애플리케이션을 사용하여 데이터 파일을 복원합니다. 데이터 파일이 복원되면 사용자가 로그 전달 방법을 설정합니다. 기본 데이터베이스에서 생성된 아카이브 로그의 지속적인 피드를 만들고 복원된 데이터베이스에서 다시 재생하여 두 로그 모두 동일한 상태에 가깝게 유지하는 것이 목표입니다. 전환 시간이 되면 소스 데이터베이스가 완전히 종료되고 최종 아카이브 로그가 복사되고 경우에 따라 재실행 로그가 재생됩니다. 리두 로그에는 커밋된 최종 트랜잭션이 포함될 수 있으므로 리두 로그도 고려해야 합니다.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">이러한 로그를 전송하고 재생한 후에는 두 데이터베이스가 서로 일관됩니다. 이 시점에서 대부분의 고객은 몇 가지 기본 테스트를 수행합니다. 마이그레이션 프로세스 중에 오류가 발생하면 로그 재생에서 오류를 보고하고 실패합니다. 알려진 쿼리 또는 응용 프로그램 기반 작업을 기반으로 몇 가지 빠른 테스트를 수행하여 구성이 최적화되었는지 확인하는 것이 좋습니다. 또한 원래 데이터베이스를 종료하기 전에 최종 테스트 테이블을 하나 만들어 마이그레이션된 데이터베이스에 있는지 확인하는 것이 일반적입니다. 이 단계를 수행하면 최종 로그 동기화 중에 오류가 발생하지 않습니다.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">단순한 로그 전달 마이그레이션은 원본 데이터베이스와 관련하여 대역 외 방식으로 구성할 수 있으므로 업무상 중요한 데이터베이스에 특히 유용합니다. 소스 데이터베이스에 대한 구성 변경이 필요하지 않으며 마이그레이션 환경의 복원 및 초기 구성은 운영 작업에 영향을 미치지 않습니다. 로그 전달이 구성된 후 운영 서버에 일부 입출력 요구 사항이 배치됩니다. 그러나 로그 전달은 아카이브 로그의 단순 순차 읽기로 구성되므로 운영 데이터베이스 성능에 영향을 미칠 가능성은 낮습니다.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">로그 전달은 장거리, 높은 변경률 마이그레이션 프로젝트에 특히 유용한 것으로 입증되었습니다. 한 예로, 하나의 220TB 데이터베이스가 약 500마일 떨어진 새로운 위치로 마이그레이션되었습니다. 변경률이 매우 높았고 보안 제한으로 인해 네트워크 연결이 사용되지 않았습니다. 로그 배송은 테이프 및 택배사를 사용하여 수행되었습니다. 소스 데이터베이스의 복제본은 아래에 설명된 절차를 사용하여 초기에 복원되었습니다. 그런 다음 최종 테이프 세트가 제공되고 로그가 복제 데이터베이스에 적용된 전환 시간까지 택배사에 의해 로그가 매주 배송되었습니다.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">경우에 따라 전체 DataGuard 환경이 보장됩니다. DataGuard라는 용어를 사용하여 로그 전달 또는 대기 데이터베이스 구성을 참조하는 것은 올바르지 않습니다. Oracle DataGuard는 데이터베이스 복제 관리를 위한 포괄적인 프레임워크이지만 복제 기술은 아닙니다. 마이그레이션 과정에서 완전한 DataGuard 환경의 주된 이점은 한 데이터베이스에서 다른 데이터베이스로 투명하게 전환하는 것입니다. 또한 새로운 환경의 성능 또는 네트워크 연결 문제와 같은 문제가 발견될 경우 Dataguard는 원래 데이터베이스로 투명하게 전환할 수 있습니다. 완전히 구성된 DataGuard 환경에서는 애플리케이션이 기본 데이터베이스 위치의 변경을 감지할 수 있도록 데이터베이스 계층뿐만 아니라 응용 프로그램도 구성해야 합니다. 일반적으로 DataGuard를 사용하여 마이그레이션을 완료할 필요는 없지만 일부 고객은 내부에서 광범위한 DataGuard 전문 지식을 보유하고 있으며 마이그레이션 작업에 이미 의존하고 있습니다.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">재건축</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">앞서 설명한 것처럼 스토리지 어레이의 고급 기능을 활용하려면 데이터베이스 레이아웃을 변경해야 하는 경우가 있습니다. 또한 ASM에서 NFS 파일 시스템으로 이동하는 것과 같은 스토리지 프로토콜이 변경될 경우 파일 시스템 레이아웃이 변경될 수도 있습니다.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">DataGuard를 비롯한 로그 전달 방법의 주요 이점 중 하나는 복제 대상이 소스와 일치하지 않아도 된다는 것입니다. 로그 전달 방식을 사용하여 ASM에서 일반 파일 시스템으로 마이그레이션하거나 그 반대로 마이그레이션하는 데 문제가 없습니다. 대상 위치에서 데이터 파일의 정확한 레이아웃을 변경하여 플러그형 데이터베이스(PDB) 기술의 사용을 최적화하거나 특정 파일에 대해 선택적으로 QoS 제어를 설정할 수 있습니다. 즉, 로그 전달을 기반으로 하는 마이그레이션 프로세스를 통해 데이터베이스 스토리지 레이아웃을 쉽고 안전하게 최적화할 수 있습니다.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">서버 리소스</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">데이터베이스 수준 마이그레이션의 한 가지 제한 사항은 보조 서버의 필요성입니다. 이 두 번째 서버를 사용하는 방법에는 두 가지가 있습니다.</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">두 번째 서버를 데이터베이스의 영구적인 새 홈으로 사용할 수 있습니다.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">두 번째 서버를 임시 스테이징 서버로 사용할 수 있습니다. 새 스토리지로의 데이터 마이그레이션이 완료되고 테스트된 후 LUN 또는 NFS 파일 시스템이 스테이징 서버에서 분리되어 원래 서버에 다시 연결됩니다.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">첫 번째 옵션은 가장 쉽지만 매우 강력한 서버가 필요한 대규모 환경에서는 이 옵션을 사용하는 것이 불가능할 수 있습니다. 두 번째 옵션은 파일 시스템을 원래 위치로 다시 재배치하기 위해 추가 작업이 필요합니다. 이는 파일 시스템을 스테이징 서버에서 마운트 해제하고 원래 서버에 다시 마운트할 수 있기 때문에 NFS를 스토리지 프로토콜로 사용하는 간단한 작업입니다.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">블록 기반 파일 시스템은 FC 조닝 또는 iSCSI 이니시에이터를 업데이트하기 위해 추가 작업이 필요합니다. 대부분의 논리적 볼륨 관리자(ASM 포함)에서는 원래 서버에서 LUN을 사용할 수 있게 되면 LUN이 자동으로 감지되어 온라인 상태로 전환됩니다. 그러나 일부 파일 시스템 및 LVM 구현에서는 데이터를 내보내고 가져오는 데 더 많은 작업이 필요할 수 있습니다. 정확한 절차는 다양할 수 있지만 일반적으로 마이그레이션을 완료하고 원래 서버에서 데이터를 다시 저장하는 간단하고 반복 가능한 절차를 설정하는 것이 쉽습니다.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">단일 서버 환경 내에서 로그 전달을 설정하고 데이터베이스를 복제할 수 있지만 새 인스턴스에는 로그를 재생하기 위한 다른 프로세스 SID가 있어야 합니다. SID가 다른 프로세스 ID의 다른 집합에서 데이터베이스를 임시로 가져온 후 나중에 변경할 수 있습니다. 하지만 이렇게 하면 복잡한 관리 작업이 많이 발생할 수 있으며 데이터베이스 환경에 사용자 오류가 발생할 위험이 있습니다.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">호스트 레벨 마이그레이션</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">호스트 레벨에서 데이터를 마이그레이션한다는 것은 호스트 운영 체제와 관련 유틸리티를 사용하여 마이그레이션을 완료하는 것을 의미합니다. 이 프로세스에는 Oracle RMAN 및 Oracle ASM을 비롯하여 데이터를 복사하는 모든 유틸리티가 포함됩니다.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">데이터 복사</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">단순 복사 작업의 값은 과소 평가되지 않아야 합니다. 오늘날의 네트워크 인프라는 초당 기가바이트 단위의 속도로 데이터를 이동할 수 있으며 파일 복사 작업은 효율적인 순차적 읽기 및 쓰기 I/O를 기반으로 합니다 로그 전달과 비교할 때 호스트 복제 작업에서 더 많은 중단이 불가피하지만 마이그레이션은 단순한 데이터 이동 그 이상입니다. 여기에는 일반적으로 네트워킹, 데이터베이스 재시작 시간 및 마이그레이션 후 테스트 변경 사항이 포함됩니다.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">데이터를 복사하는 데 필요한 실제 시간은 중요하지 않을 수 있습니다. 또한 원본 데이터를 그대로 유지하므로 복제 작업은 보장된 백아웃 경로를 유지합니다. 마이그레이션 프로세스 중에 문제가 발생하면 원본 데이터가 있는 원본 파일 시스템을 다시 활성화할 수 있습니다.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">플랫폼 변경</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">플랫폼 변경이란 CPU 유형의 변경을 의미합니다. 데이터베이스를 기존 Solaris, AIX 또는 HP-UX 플랫폼에서 x86 Linux로 마이그레이션할 경우 CPU 아키텍처의 변경으로 인해 데이터를 다시 포맷해야 합니다. SPARC, IA64 및 전원 CPU는 빅 엔디안 프로세서라고 하는 반면 x86 및 x86_64 아키텍처는 리틀 엔디안라고 합니다. 따라서 Oracle 데이터 파일 내의 일부 데이터는 사용 중인 프로세서에 따라 순서가 다르게 지정됩니다.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">기존에는 DataPump를 사용하여 플랫폼 간에 데이터를 복제해 왔습니다. 데이터 덤프는 대상 데이터베이스에서 보다 빠르게 가져올 수 있는 특수한 유형의 논리적 데이터 내보내기를 만드는 유틸리티입니다. DataPump 는 데이터의 논리적 복사본을 만들기 때문에 프로세서 엔디언의 종속성을 남깁니다. 데이터덤프는 여전히 일부 고객이 플랫폼 재구축을 위해 사용하고 있지만 Oracle 11g에서는 더욱 빠른 옵션인 교차 플랫폼 전송 테이블스페이스를 사용할 수 있게 되었습니다. 이렇게 하면 테이블스페이스를 다른 엔디안 형식으로 변환할 수 있습니다. 이것은 물리적 바이트를 논리적 데이터로 변환한 다음 다시 물리적 바이트로 변환해야 하는 DataPump 내보내기보다 더 나은 성능을 제공하는 물리적 변환입니다.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">DataPump 및 이식 가능한 테이블스페이스에 대한 자세한 내용은 NetApp 설명서를 참조하십시오. 하지만 NetApp는 새로운 CPU 아키텍처를 사용하여 새 스토리지 시스템 로그로 마이그레이션할 때 고객을 지원하는 경험을 바탕으로 몇 가지 권장 사항을 제시합니다.</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">DataPump를 사용 중인 경우 마이그레이션을 완료하는 데 필요한 시간을 테스트 환경에서 측정해야 합니다. 고객은 마이그레이션을 완료하는 데 필요한 시간에 놀라기도 합니다. 이와 같이 예기치 않은 추가 다운타임은 운영 중단을 일으킬 수 있습니다.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">많은 고객들이 교차 플랫폼 전송 가능 테이블스페이스는 데이터 변환이 필요하지 않다고 잘못 생각합니다. 엔디안이 다른 CPU를 사용하는 경우 RMAN이 사용됩니다<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> 데이터 파일에 대한 작업은 미리 수행해야 합니다. 이것은 즉각적인 작업이 아닙니다. 경우에 따라 서로 다른 데이터 파일에서 여러 스레드가 작동하므로 변환 프로세스가 빨라질 수 있지만 변환 프로세스를 피할 수는 없습니다.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">논리적 볼륨 관리자 기반 마이그레이션</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">LVM은 하나 이상의 LUN 그룹을 만들어 일반적으로 익스텐트라고 하는 작은 단위로 분할하는 방식으로 작동합니다. 그런 다음 익스텐트 풀이 기본적으로 가상화된 논리적 볼륨을 생성하기 위한 소스로 사용됩니다. 이 가상화 계층은 다음과 같은 다양한 방식으로 가치를 제공합니다.</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">논리적 볼륨은 여러 LUN에서 그린 익스텐트를 사용할 수 있습니다. 논리적 볼륨에 파일 시스템을 생성할 때 모든 LUN의 전체 성능을 사용할 수 있습니다. 또한 볼륨 그룹에 모든 LUN의 로드가 짝수일 뿐이므로 성능이 더욱 예측 가능합니다.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">논리적 볼륨의 크기는 익스텐트를 추가하거나 경우에 따라 제거할 수 있습니다. 논리적 볼륨에서 파일 시스템의 크기를 조정하는 작업은 일반적으로 중단되지 않습니다.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">기본 익스텐트를 이동하여 논리적 볼륨을 운영 중단 없이 마이그레이션할 수 있습니다.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">LVM을 사용한 마이그레이션은 익스텐트 이동 또는 익스텐트 미러링/디머러링의 두 가지 방법 중 하나로 작동합니다. LVM 마이그레이션은 효율적인 대규모 블록 순차적 I/O를 사용하며 성능 문제는 거의 발생하지 않습니다. 이 문제가 발생할 경우 일반적으로 I/O 속도를 제한하는 옵션이 있습니다. 이렇게 하면 마이그레이션을 완료하는 데 필요한 시간이 길어지고 호스트 및 스토리지 시스템의 I/O 부담이 줄어듭니다.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">미러 및 미러</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">AIX LVM과 같은 일부 볼륨 관리자는 사용자가 각 익스텐트의 복제본 수를 지정하고 각 복제본을 호스팅하는 디바이스를 제어할 수 있도록 합니다. 마이그레이션은 기존의 논리적 볼륨을 만들고 기본 익스텐트를 새 볼륨에 미러링하고 복사본이 동기화될 때까지 기다린 다음 이전 복사본을 삭제하여 수행됩니다. 백업 경로가 필요한 경우 미러 복사본이 삭제되기 전에 원본 데이터의 스냅샷을 생성할 수 있습니다. 또는 포함된 미러 복제본을 강제로 삭제하기 전에 서버를 잠시 종료하여 원래 LUN을 마스킹할 수 있습니다. 이렇게 하면 복구 가능한 데이터 복사본이 원래 위치에 보존됩니다.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">익스텐트 마이그레이션</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">거의 모든 볼륨 관리자는 익스텐트의 마이그레이션을 허용하며 경우에 따라서는 여러 옵션이 존재하기도 합니다. 예를 들어 일부 볼륨 관리자에서는 관리자가 특정 논리적 볼륨의 개별 익스텐트를 이전 스토리지에서 새 스토리지로 재배치할 수 있습니다. Linux LVM2와 같은 볼륨 관리자는 를 제공합니다<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> 지정된 LUN 디바이스의 모든 익스텐트를 새 LUN으로 재배치하는 명령입니다. 이전 LUN을 이동한 후 제거할 수 있습니다.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">운영 시 가장 큰 위험은 구성에서 사용되지 않은 오래된 LUN을 제거하는 것입니다. FC 조닝을 변경하고 오래된 LUN 디바이스를 제거할 때는 특히 주의해야 합니다.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Oracle 자동 스토리지 관리</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM은 논리 볼륨 관리자와 파일 시스템이 결합된 시스템입니다. 상위 수준에서 Oracle ASM은 LUN 모음을 가져와 작은 할당 단위로 분할하고 ASM 디스크 그룹이라고 하는 단일 볼륨으로 제공합니다. ASM에는 이중화 수준을 설정하여 디스크 그룹을 미러링하는 기능도 포함되어 있습니다. 볼륨은 미러링되지 않은(외부 중복), 미러링(일반 중복) 또는 3웨이 미러링(높은 중복)일 수 있습니다. 이중화 수준은 생성 후 변경할 수 없기 때문에 설정 시 주의해야 한다.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM은 파일 시스템 기능도 제공합니다. 파일 시스템이 호스트에서 직접 표시되지 않지만 Oracle 데이터베이스는 ASM 디스크 그룹에서 파일과 디렉토리를 생성, 이동 및 삭제할 수 있습니다. 또한 asmcmd 유틸리티를 사용하여 구조를 탐색할 수도 있습니다.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">다른 LVM 구현과 마찬가지로 Oracle ASM은 사용 가능한 모든 LUN에서 각 파일의 I/O를 스트라이핑 및 로드 밸런싱을 통해 I/O 성능을 최적화합니다. 둘째, 기본 익스텐트를 재배치하여 ASM 디스크 그룹의 크기 조정과 마이그레이션을 모두 수행할 수 있습니다. Oracle ASM은 재조정 작업을 통해 프로세스를 자동화합니다. 새로운 LUN이 ASM 디스크 그룹에 추가되고 기존 LUN이 삭제되어 익스텐트 재배치와 디스크 그룹에서 제거된 LUN의 후속 드롭이 트리거됩니다. 이 프로세스는 가장 검증된 마이그레이션 방법 중 하나이며, 투명한 마이그레이션을 제공하는 ASM의 신뢰성이 가장 중요한 기능일 수 있습니다.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Oracle ASM의 미러링 수준은 고정되어 있으므로 미러 및 미러 마이그레이션 방법과 함께 사용할 수 없습니다.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">스토리지 레벨 마이그레이션</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">스토리지 수준 마이그레이션은 애플리케이션 및 운영 체제 수준 모두에서 마이그레이션을 수행하는 것을 의미합니다. 과거에는 네트워크 수준에서 LUN을 복제할 특수 장치를 사용하기도 했지만 이제는 ONTAP에서 기본적으로 제공하는 이러한 기능을 사용할 수 있습니다.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror를 참조하십시오</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">NetApp 시스템 간 데이터베이스 마이그레이션은 NetApp SnapMirror 데이터 복제 소프트웨어를 통해 거의 보편적으로 수행됩니다. 이 프로세스에는 마이그레이션할 볼륨의 미러 관계를 설정하고 볼륨이 동기화될 수 있도록 한 다음 컷오버 기간을 기다리는 작업이 포함됩니다. 소스 데이터베이스가 도착하면 소스 데이터베이스가 종료되고 최종 미러 업데이트가 한 번 수행되며 미러가 중단됩니다. 그러면 포함된 NFS 파일 시스템 디렉토리를 마운트하거나 포함된 LUN을 검색하고 데이터베이스를 시작하여 복제본 볼륨을 사용할 수 있습니다.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">단일 ONTAP 클러스터 내에서 볼륨을 재배치하는 것은 마이그레이션으로 간주되는 것이 아니라 일상적인 마이그레이션으로 간주됩니다<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> 작동. SnapMirror는 클러스터 내의 데이터 복제 엔진으로 사용됩니다. 이 프로세스는 완전히 자동화되어 있습니다. LUN 매핑이나 NFS 엑스포트 권한과 같은 볼륨 특성을 볼륨 자체와 함께 이동할 때 수행해야 할 추가 마이그레이션 단계는 없습니다. 재할당은 호스트 작업의 중단 없이 수행됩니다. 경우에 따라 새로 재배치된 데이터에 가장 효율적인 방식으로 액세스할 수 있도록 네트워크 액세스를 업데이트해야 하지만, 이러한 작업은 중단되지 않습니다.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">FLI(Foreign LUN Import)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">FLI는 8.3 이상을 실행하는 Data ONTAP 시스템에서 다른 스토리지 어레이의 기존 LUN을 마이그레이션할 수 있는 기능입니다. 절차는 간단합니다. ONTAP 시스템은 다른 SAN 호스트처럼 기존 스토리지 시스템에 조닝됩니다. 그런 다음 Data ONTAP는 원하는 레거시 LUN을 제어하고 기본 데이터를 마이그레이션합니다. 또한 가져오기 프로세스에서는 데이터가 마이그레이션될 때 새 볼륨의 효율성 설정을 사용합니다. 즉, 마이그레이션 프로세스 중에 데이터를 인라인으로 압축 및 중복제거할 수 있습니다.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">Data ONTAP 8.3에서 FLI를 처음 구현하면 오프라인 마이그레이션만 허용되었습니다. 이는 매우 빠른 전송이었지만 마이그레이션이 완료될 때까지 LUN 데이터를 사용할 수 없다는 것을 의미합니다. 온라인 마이그레이션은 Data ONTAP 8.3.1에서 도입되었습니다. 이러한 종류의 마이그레이션은 전송 프로세스 중에 ONTAP에서 LUN 데이터를 제공할 수 있으므로 작업 중단이 최소화됩니다. ONTAP를 통해 LUN을 사용하도록 호스트를 다시 조닝하는 동안 중단이 짧게 발생합니다. 그러나 이러한 변경이 이루어지면 데이터에 다시 액세스할 수 있고 마이그레이션 프로세스 내내 계속 액세스할 수 있습니다.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">읽기 입출력은 복제 작업이 완료될 때까지 ONTAP를 통해 프록시되고 쓰기 입출력은 외부 및 ONTAP LUN 모두에 동기식으로 기록됩니다. 관리자가 전체 컷오버를 실행하여 외부 LUN을 해제하고 더 이상 쓰기를 복제하지 않는 한 두 LUN 복사본이 이 방식으로 동기화된 상태로 유지됩니다.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI는 FC와 함께 사용하도록 설계되었지만 iSCSI로 변경하려는 경우 마이그레이션이 완료된 후 마이그레이션된 LUN을 iSCSI LUN으로 쉽게 다시 매핑할 수 있습니다.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">FLI의 기능 중 하나는 자동 정렬 감지 및 조정입니다. 여기서 정렬이란 LUN 장치의 파티션을 의미합니다. 최적의 성능을 얻으려면 I/O를 4K 블록에 맞춰 정렬해야 합니다. 파티션이 4K의 배수가 아닌 오프셋에 배치되면 성능이 저하됩니다.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">정렬의 두 번째 측면은 파티션 오프셋을 조정하여 수정할 수 없는 파일 시스템 블록 크기입니다. 예를 들어, ZFS 파일 시스템의 기본 내부 블록 크기는 512바이트입니다. AIX를 사용하는 다른 고객은 512 또는 1, 024바이트 블록 크기의 JFS2 파일 시스템을 생성하는 경우가 있습니다. 파일 시스템이 4K 경계에 맞춰 정렬될 수 있지만 해당 파일 시스템 내에서 생성된 파일은 그렇지 않고 성능이 저하됩니다.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI는 이러한 상황에서 사용해서는 안 됩니다. 마이그레이션 후에 데이터에 액세스할 수 있지만 이로 인해 파일 시스템의 성능이 심각하게 제한됩니다. 일반적으로 ONTAP에서 랜덤 덮어쓰기 워크로드를 지원하는 모든 파일 시스템은 4K 블록 크기를 사용해야 합니다. 이 워크로드는 데이터베이스 데이터 파일 및 VDI 구축과 같은 워크로드에 주로 적용됩니다. 블록 크기는 관련 호스트 운영 체제 명령을 사용하여 확인할 수 있습니다.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">예를 들어, AIX에서는 블록 크기를 로 볼 수 있습니다<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Linux를 사용하면<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> 및<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> 에 사용할 수 있습니다<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> 및<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>있습니다. 와 함께<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>명령은 입니다<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">블록 크기를 제어하는 매개 변수는 입니다<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 일반적으로 기본값은 9이며, 이는 2의 9 또는 512바이트를 의미합니다. 최적의 성능을 위해<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 값은 12(2-12=4K)여야 합니다. 이 값은 zpool이 생성될 때 설정되며 변경할 수 없습니다. 즉, 가 포함된 데이터 zpool이 됩니다<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> 12가 아닌 경우 데이터를 새로 생성된 zpool으로 마이그레이션해야 합니다.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM은 기본 블록 크기를 가지고 있지 않습니다. 유일한 요구 사항은 ASM 디스크가 구축된 파티션이 올바르게 정렬되어야 한다는 것입니다.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">7-Mode 전환 툴</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">7MTT(7-Mode 전환 툴)는 대규모 7-Mode 구성을 ONTAP로 마이그레이션하는 데 사용되는 자동화 유틸리티입니다. 대부분의 데이터베이스 고객은 전체 스토리지 공간을 재배치하지 않고 데이터베이스를 기준으로 환경을 마이그레이션하므로 다른 방법을 더욱 쉽게 찾을 수 있습니다. 또한 데이터베이스는 대규모 스토리지 환경에 포함되는 경우가 많습니다. 따라서 데이터베이스는 종종 개별적으로 마이그레이션되며, 7MTT를 사용하여 나머지 환경을 이동할 수 있습니다.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">복잡한 데이터베이스 환경을 위한 스토리지 시스템을 보유한 고객 수는 소규모지만 상당수가 있습니다. 이러한 환경에는 많은 볼륨, 스냅샷 및 내보내기 권한, LUN 이니시에이터 그룹, 사용자 권한 및 Lightweight Directory Access Protocol 구성과 같은 수많은 구성 세부 정보가 포함될 수 있습니다. 이런 경우에는 7MTT의 자동화 기능을 사용하여 마이그레이션을 단순화할 수 있습니다.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT는 다음 2가지 모드 중 하나로 작동할 수 있습니다.</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">* CBT(Copy-Based Transition). * CBT를 사용하는 7MTT는 새로운 환경의 기존 7-Mode 시스템에서 SnapMirror 볼륨을 설정합니다. 데이터가 동기화되면 7MTT가 컷오버 프로세스를 오케스트레이션합니다.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">* CFT(Copy-Free Transition) * CFT를 지원하는 7MTT는 기존 7-Mode 디스크 쉘프의 데이터 이동 없이 변환을 기반으로 합니다. 데이터는 복사되지 않으며 기존 디스크 쉘프를 재사용할 수 있습니다. 기존 데이터 보호 및 스토리지 효율성 구성이 그대로 유지됩니다.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">이 두 옵션 간의 주된 차이점은 복사가 필요 없는 전환은 원래의 7-Mode HA 쌍에 연결된 모든 디스크 쉘프를 새로운 환경으로 재배치해야 하는 큰 방식이라는 것입니다. 쉘프의 하위 집합을 이동할 수 있는 옵션은 없습니다. 복사 기반 접근 방식에서는 선택한 볼륨을 이동할 수 있습니다. 또한 디스크 쉘프를 재구성하고 메타데이터를 변환하는 데 연결된 연결이 필요하므로 무복사 전환으로 컷오버 기간도 길어질 수 있습니다. 현장 경험에 비추어 볼 때, NetApp는 디스크 셸프를 재배치하고 재설정하는 데 1시간, 메타데이터 변환에 15분에서 2시간 동안 사용할 것을 권장합니다.</block>
  <block id="c8365c28332d425fd91f2de2e2c22dfb" category="summary">FLI 마이그레이션을 위한 ONTAP 준비</block>
  <block id="25c18537e56595b3e7f3ce78905917ba" category="doc">FLI 계획 - Oracle</block>
  <block id="f1033948d9d2d14612d27f1808720f12" category="inline-link">TR-4380: 외부 LUN 가져오기를 사용한 SAN 마이그레이션</block>
  <block id="58fc59a248fefa86003ac1867e5bd279" category="paragraph">FLI를 사용하여 SAN 리소스를 마이그레이션하는 절차는 NetApp에 설명되어 있습니다<block ref="5abd855dd5d8332b78fa966ac34c0f22" category="inline-link-rx"></block>.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">데이터베이스 및 호스트 관점에서 볼 때 특별한 단계가 필요하지 않습니다. FC 존이 업데이트되고 LUN을 ONTAP에서 사용할 수 있게 되면 LVM이 LUN에서 LVM 메타데이터를 읽을 수 있어야 합니다. 또한 볼륨 그룹을 추가 구성 단계 없이 사용할 수 있습니다. 드문 경우지만 환경에 이전 스토리지 어레이를 참조하는 하드 코딩된 구성 파일이 포함될 수 있습니다. 예를 들어, 을 포함하는 Linux 시스템이 해당됩니다<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> 주어진 디바이스의 WWN을 참조하는 규칙은 FLI에 의해 도입된 변경 사항을 반영하도록 업데이트되어야 합니다.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">지원되는 구성에 대한 자세한 내용은 NetApp 호환성 매트릭스를 참조하십시오. 사용 환경이 포함되지 않은 경우 NetApp 담당자에게 문의하십시오.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">이 예제는 Linux 서버에서 호스팅되는 ASM 및 LVM LUN의 마이그레이션을 보여줍니다. FLI는 다른 운영 체제에서 지원되며 호스트측 명령이 다를 수 있지만 원칙이 동일하고 ONTAP 절차는 동일합니다.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">LVM LUN을 식별합니다</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">준비의 첫 번째 단계는 마이그레이션할 LUN을 식별하는 것입니다. 여기에 나와 있는 예에서는 SAN 기반 파일 시스템 두 개가 에 마운트되어 있습니다<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> 및<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">볼륨 그룹의 이름은 (볼륨 그룹 이름) - (논리적 볼륨 이름) 형식을 사용하는 디바이스 이름에서 추출할 수 있습니다. 이 경우 볼륨 그룹이 호출됩니다<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">를 클릭합니다<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> 명령을 사용하여 다음 명령을 사용하여 이 볼륨 그룹을 지원하는 LUN을 식별할 수 있습니다. 이 경우 를 구성하는 LUN이 10개 있습니다<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> 볼륨 그룹:</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">ASM LUN 식별</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">ASM LUN도 마이그레이션해야 합니다. sysasm 사용자로 sqlplus에서 LUN 및 LUN 경로 수를 가져오려면 다음 명령을 실행합니다.</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">현재 환경에는 마이그레이션할 LUN 20개가 포함되어 있습니다. ONTAP가 현재 LUN에 액세스할 수 있도록 현재 SAN을 업데이트합니다. 데이터가 아직 마이그레이션되지 않았지만 ONTAP는 현재 LUN에서 구성 정보를 읽어 해당 데이터의 새 홈을 생성해야 합니다.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">AFF/FAS 시스템에서 하나 이상의 HBA 포트를 이니시에이터 포트로 구성해야 합니다. 또한 ONTAP이 외부 스토리지 어레이의 LUN에 액세스할 수 있도록 FC 존을 업데이트해야 합니다. 일부 스토리지에는 LUN 마스킹이 구성되어 있으며, 이 경우 특정 LUN을 액세스할 수 있는 WWN이 제한됩니다. 이 경우 LUN 마스킹도 업데이트하여 ONTAP WWN에 대한 액세스 권한을 부여해야 합니다.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">이 단계가 완료된 후 ONTAP는 를 사용하여 외부 스토리지 어레이를 볼 수 있어야 합니다<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> 명령. 반환되는 키 필드는 시스템에서 외부 LUN을 식별하는 데 사용되는 접두사입니다. 아래 예에서는 외부 스토리지의 LUN을 보여 줍니다<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> 의 접두사를 사용하여 ONTAP 내에 나타납니다<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">외부 어레이를 식별합니다</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">외부 LUN 식별</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">LUN은 를 전달하여 나열할 수 있습니다<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> 를 누릅니다<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> 명령. 반환되는 데이터는 마이그레이션 절차 중에 여러 번 참조됩니다.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">외부 스토리지 LUN을 가져오기 후보로 등록합니다</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">외부 LUN은 처음에 특정 LUN 유형으로 분류됩니다. 데이터를 가져오려면 먼저 LUN에 외부 태그가 지정되어야 하므로 가져오기 프로세스의 대상이 되어야 합니다. 이 단계는 에 일련 번호를 전달하여 완료합니다<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> 명령을 사용합니다. 이 프로세스에서는 ONTAP 내의 LUN에만 Foreign으로 태그를 지정합니다. 외부 LUN 자체에 데이터가 기록되지 않습니다.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">마이그레이션된 LUN을 호스팅할 볼륨을 생성합니다</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">마이그레이션된 LUN을 호스팅하려면 볼륨이 필요합니다. 정확한 볼륨 구성은 ONTAP 기능을 활용하는 전체 계획에 따라 다릅니다. 이 예에서는 ASM LUN이 한 볼륨에 배치되고 LVM LUN은 두 번째 볼륨에 배치됩니다. 따라서 계층화, 스냅샷 생성 또는 QoS 제어 설정과 같은 목적으로 LUN을 독립 그룹으로 관리할 수 있습니다.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">를 설정합니다<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. 마이그레이션 프로세스에는 많은 데이터 회전율이 포함될 수 있습니다. 따라서 원하지 않는 데이터가 스냅샷에 캡처되기 때문에 실수로 스냅샷을 생성하는 경우 공간 소비가 크게 증가할 수 있습니다.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">ONTAP LUN을 생성합니다</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">볼륨을 생성한 후에는 새 LUN을 생성해야 합니다. 일반적으로 LUN을 생성할 때 사용자가 LUN 크기와 같은 정보를 지정해야 하지만 이 경우에는 외부 디스크 인수가 명령에 전달됩니다. 따라서 ONTAP는 지정된 일련 번호에서 현재 LUN 구성 데이터를 복제합니다. 또한 LUN 형태 및 파티션 테이블 데이터를 사용하여 LUN 정렬을 조정하고 최적의 성능을 설정합니다.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">이 단계에서는 올바른 외부 LUN이 올바른 새 LUN과 일치하는지 확인하기 위해 외부 스토리지와 일련 번호를 상호 참조해야 합니다.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">가져오기 관계를 만듭니다</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">이제 LUN이 생성되었지만 복제 대상으로 구성되지 않았습니다. 이 단계를 수행하려면 먼저 LUN을 오프라인 상태로 전환해야 합니다. 이 추가 단계는 사용자 오류로부터 데이터를 보호하도록 설계되었습니다. ONTAP에서 온라인 LUN에 대해 마이그레이션을 수행할 수 있었다면 인쇄 오류로 인해 활성 데이터를 덮어쓸 위험이 발생할 수 있습니다. 사용자가 먼저 LUN을 오프라인으로 전환하도록 하는 추가 단계는 올바른 타겟 LUN이 마이그레이션 대상으로 사용되는지 확인하는 데 도움이 됩니다.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">LUN이 오프라인 상태가 된 후 외부 LUN 일련 번호를 에 전달하여 임포트 관계를 설정할 수 있습니다<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">모든 임포트 관계가 설정되면 LUN을 다시 온라인 상태로 전환할 수 있습니다.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">이니시에이터 그룹을 생성합니다</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">프로토콜 변환</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">이 예에서는 호스트의 HBA에서 사용 가능한 두 포트에 해당하는 두 개의 WWN이 포함된 igroup을 생성합니다.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">호스트에 새 LUN 매핑</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">igroup 작성 후에 LUN이 정의된 igroup에 매핑됩니다. 이 LUN은 이 igroup에 포함된 WWN에만 사용할 수 있습니다. NetApp는 마이그레이션 프로세스에서 이 단계에서 호스트가 ONTAP에 조닝되지 않은 것으로 가정합니다. 이는 호스트가 외부 스토리지와 새 ONTAP 시스템에 동시에 조닝되는 경우 동일한 일련 번호를 가진 LUN이 각 어레이에서 검색될 위험이 있기 때문에 중요합니다. 이 상황은 다중 경로 오작동이나 데이터 손상으로 이어질 수 있습니다.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Oracle 마이그레이션 작업 자동화를 위한 샘플 스크립트</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">샘플 스크립트</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">제공되는 스크립트는 다양한 OS 및 데이터베이스 작업을 스크립팅하는 방법의 예로 제공됩니다. 그들은 있는 그대로 제공됩니다. 특정 절차에 대한 지원이 필요한 경우 NetApp 또는 NetApp 리셀러에게 문의하십시오.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">데이터베이스 종료</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">다음 Perl 스크립트는 Oracle SID의 단일 인수를 사용하고 데이터베이스를 종료합니다. Oracle 사용자 또는 루트로 실행할 수 있습니다.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">데이터베이스 시작</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">파일 시스템을 읽기 전용으로 변환합니다</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">다음 스크립트는 파일 시스템 인수를 사용하여 읽기 전용으로 마운트 해제 및 다시 마운트하려고 시도합니다. 이렇게 하면 데이터를 복제하기 위해 파일 시스템을 사용할 수 있어야 하지만 우발적인 손상으로부터 보호해야 하는 마이그레이션 프로세스 중에 유용합니다.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">파일 시스템을 교체합니다</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">다음 스크립트 예제는 파일 시스템 하나를 다른 파일 시스템으로 바꾸는 데 사용됩니다. '/etc/fstab' 파일을 편집하므로 루트로 실행해야 합니다. 이전 파일 시스템과 새 파일 시스템의 쉼표로 구분된 단일 인수를 사용할 수 있습니다.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">파일 시스템을 교체하려면 다음 스크립트를 실행합니다.</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">이 스크립트 사용의 예로, 의 데이터를 가정합니다<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> 로 마이그레이션됩니다<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> 및<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> 로 마이그레이션됩니다<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. 이 작업을 수행하는 가장 간단한 방법 중 하나는 간단한 파일 복제 작업을 사용하여 새 디바이스를 원래 마운트 지점으로 재배치하는 것입니다.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">에 이전 파일 시스템과 새 파일 시스템이 있다고 가정합니다<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 다음과 같은 파일:</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">이 스크립트를 실행하면 현재 파일 시스템을 마운트 해제하고 새 파일 시스템으로 대체합니다.</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">스크립트도 를 업데이트합니다<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 그에 따라 보관합니다. 여기에 표시된 예에서는 다음과 같은 변경 사항이 포함되어 있습니다.</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">자동화된 데이터베이스 마이그레이션</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">이 예제에서는 마이그레이션을 완전히 자동화하기 위해 종료, 시작 및 파일 시스템 교체 스크립트를 사용하는 방법을 보여 줍니다.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">파일 위치를 표시합니다</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">이 스크립트는 많은 중요한 데이터베이스 매개 변수를 수집하여 읽기 쉬운 형식으로 인쇄합니다. 이 스크립트는 데이터 레이아웃을 검토할 때 유용할 수 있습니다. 또한 스크립트를 다른 용도로 수정할 수도 있습니다.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">ASM 마이그레이션 정리</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">ASM에서 파일 시스템 이름으로 변환</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">데이터베이스에서 로그를 재생합니다</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">이 스크립트는 마운트 모드에 있는 데이터베이스에 대해 Oracle SID의 단일 인수를 허용하고 현재 사용 가능한 모든 아카이브 로그를 재생하려고 시도합니다.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">대기 데이터베이스에서 로그를 재생합니다</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">이 스크립트는 대기 데이터베이스용으로 설계되었다는 점을 제외하고 위의 스크립트와 동일합니다.</block>
  <block id="109be8945d38cda6c034a22373bdbd3b" category="summary">FLI 마이그레이션 후 SAN 프로토콜 변경</block>
  <block id="b5e65fbdff41aa940dad918d9f7c0b9e" category="doc">FLI 프로토콜 변환 - Oracle</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">LUN에 액세스하는 데 사용되는 프로토콜을 변경하는 것은 일반적인 요구사항입니다.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">데이터를 클라우드로 마이그레이션하는 전체 전략의 일부이기도 한 경우도 있습니다. TCP/IP는 클라우드의 프로토콜이며 FC에서 iSCSI로 변경하면 다양한 클라우드 환경으로 쉽게 마이그레이션할 수 있습니다. 그렇지 않으면 iSCSI가 IP SAN의 감소된 비용을 활용하는 것이 바람직할 수도 있습니다. 경우에 따라 마이그레이션이 임시 조치로 다른 프로토콜을 사용할 수 있습니다. 예를 들어, 외부 스토리지 시스템과 ONTAP 기반 LUN이 동일한 HBA에 공존할 수 없는 경우 기존 스토리지의 데이터를 복제할 수 있을 정도로 긴 iSCSI LUN을 사용할 수 있습니다. 그런 다음 이전 LUN을 시스템에서 제거한 후 FC로 다시 변환할 수 있습니다.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">다음 절차는 FC에서 iSCSI로 변환하는 방법을 보여 주지만 전반적인 원칙은 역방향 iSCSI에서 FC로 변환하는 방법에 적용됩니다.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">iSCSI 이니시에이터를 설치합니다</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">대부분의 운영 체제에는 기본적으로 소프트웨어 iSCSI 초기자가 포함되어 있지만 포함되어 있지 않은 경우 쉽게 설치할 수 있습니다.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">iSCSI 이니시에이터 이름을 식별합니다</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">설치 프로세스 중에 고유한 iSCSI 이니시에이터 이름이 생성됩니다. Linux에서는 에 있습니다<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> 파일. 이 이름은 IP SAN에서 호스트를 식별하는 데 사용됩니다.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">새 이니시에이터 그룹을 생성합니다</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">igroup(이니시에이터 그룹)은 ONTAP LUN 마스킹 아키텍처의 일부입니다. 호스트에 처음으로 액세스 권한이 부여되지 않으면 새로 생성된 LUN에 액세스할 수 없습니다. 이 단계는 액세스가 필요한 FC WWN 또는 iSCSI 이니시에이터 이름을 나열하는 igroup을 생성하여 수행합니다.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">이 예에서는 Linux 호스트의 iSCSI 이니시에이터가 포함된 igroup이 생성됩니다.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">환경을 종료합니다</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">LUN 프로토콜을 변경하기 전에 LUN을 완전히 정지해야 합니다. 변환 중인 LUN 중 하나의 데이터베이스를 종료하고 파일 시스템을 마운트 해제해야 하며 볼륨 그룹을 비활성화해야 합니다. ASM이 사용되는 경우 ASM 디스크 그룹이 분리되고 모든 그리드 서비스가 종료되는지 확인합니다.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">FC 네트워크에서 LUN 매핑을 해제합니다</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">LUN이 완전히 정지된 후 원본 FC igroup에서 매핑을 제거합니다.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">LUN을 IP 네트워크에 다시 매핑합니다</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">새 iSCSI 기반 이니시에이터 그룹에 각 LUN에 대한 액세스 권한을 부여합니다.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">iSCSI 대상을 검색합니다</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">iSCSI 검색에는 두 단계가 있습니다. 첫 번째는 LUN 검색과 다른 타겟을 검색하는 것입니다. 를 클릭합니다<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> 아래 표시된 명령은 에서 지정한 포털 그룹을 검색합니다<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> 및 는 iSCSI 서비스를 제공하는 모든 IP 주소 및 포트의 목록을 저장합니다. 이 경우 기본 포트 3260에 iSCSI 서비스가 있는 네 개의 IP 주소가 있습니다.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">대상 IP 주소에 연결할 수 없는 경우 이 명령을 완료하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">iSCSI LUN을 검색합니다</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">iSCSI 대상이 검색된 후 iSCSI 서비스를 다시 시작하여 사용 가능한 iSCSI LUN을 검색하고 다중 경로 또는 ASMlib 디바이스와 같은 관련 디바이스를 구축합니다.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">환경을 다시 시작합니다</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">볼륨 그룹을 다시 활성화하고, 파일 시스템을 다시 마운트하고, RAC 서비스를 다시 시작하는 등의 방법으로 환경을 다시 시작합니다. 예방 조치로, NetApp 변환 프로세스가 완료된 후 서버를 재부팅하여 모든 구성 파일이 올바르고 오래된 모든 디바이스가 제거되도록 하는 것이 좋습니다.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">주의: 호스트를 다시 시작하기 전에 의 모든 항목이 있는지 확인하십시오<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 마이그레이션된 참조 SAN 리소스가 주석 처리되었습니다. 이 단계를 수행하지 않고 LUN 액세스에 문제가 있는 경우 운영 체제가 부팅되지 않을 수 있습니다. 이 문제는 데이터를 손상시키지 않습니다. 그러나 구조 모드 또는 유사한 모드로 부팅하고 수정하는 것은 매우 불편할 수 있습니다<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> 문제 해결 노력을 시작할 수 있도록 운영 체제를 부팅할 수 있습니다.</block>
  <block id="7e712b6bec5dd0821f1822121da9f0c6" category="summary">QoS를 사용한 Oracle 성능 관리</block>
  <block id="ff8b87ff7571fb54e71c9589f1b886a3" category="doc">Oracle 데이터베이스의 서비스 품질</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">여러 Oracle 데이터베이스를 안전하고 효율적으로 관리하려면 효과적인 QoS 전략이 필요합니다. 그 이유는 최신 스토리지 시스템의 성능 용량이 계속 늘어나고 있기 때문입니다.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Oracle 데이터베이스 및 스토리지 효율성</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Oracle 데이터베이스 및 ONTAP 효율성 기능</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">ONTAP 공간 효율성 기능은 Oracle 데이터베이스에 최적화되어 있습니다. 거의 모든 경우에 최상의 접근 방식은 모든 효율성 기능을 활성화한 상태에서 기본값을 그대로 유지하는 것입니다.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID 및 Oracle 데이터베이스</block>
  <block id="ead1ce56c368cc12c4f8932e01c92f65" category="doc">Oracle RAID 요구 사항</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID는 드라이브 손실로부터 데이터를 보호하기 위해 이중화를 사용하는 것을 말합니다.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Oracle 데이터베이스 및 기타 엔터프라이즈 애플리케이션에 사용되는 NetApp 스토리지를 구성할 때 RAID 레벨에 관한 질문이 가끔 제기됩니다. 스토리지 어레이 구성과 관련된 기존의 여러 Oracle 모범 사례에는 RAID 미러링 사용 및/또는 특정 유형의 RAID 회피에 대한 주의사항이 포함되어 있습니다. 그러나 이러한 소스는 유효한 점을 제시하지만 ONTAP에 사용되는 NetApp RAID DP 및 RAID-TEC 기술과 RAID 4에는 적용되지 않습니다.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Oracle 및 ONTAP 씬 프로비저닝</block>
  <block id="e04c5c8668870edf8392b07169f96644" category="doc">Oracle을 사용한 씬 프로비저닝</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Oracle 데이터베이스에 대한 씬 프로비저닝은 결국 실제로 사용할 수 있는 공간보다 더 많은 공간을 스토리지 시스템에 구성하게 되므로 신중한 계획이 필요합니다. 올바르게 수행하면 상당한 비용 절감 및 관리 효율성 향상을 얻을 수 있기 때문에 이러한 노력을 기울일 가치가 있습니다.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Oracle 데이터베이스용 SVM 프로비저닝</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Oracle 데이터베이스 및 스토리지 가상 머신</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">Oracle 데이터베이스 스토리지 관리가 SVM(Storage Virtual Machine)에서 중앙 집중화됨</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">테이크오버와 스위치오버 작업이 Oracle 데이터베이스 작업에 방해가 되지 않도록 하려면 스토리지 테이크오버와 스위치오버 기능을 이해해야 합니다. 또한 테이크오버 및 스위치오버 작업에서 사용되는 인수를 잘못 사용할 경우 데이터 무결성에 영향을 미칠 수 있습니다.</block>
  <block id="75f921b4326183319e82bc907e80cc42" category="doc">Oracle 및 ONTAP 컨트롤러 페일오버/스위치오버</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">데이터베이스 및 ONTAP 스토리지 용량과 여유 공간</block>
  <block id="3736e7d9912dca1541f3d86788010d1d" category="doc">Oracle 및 스토리지 용량 관리</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">예측 가능하고 관리가 용이한 고성능 엔터프라이즈 스토리지로 데이터베이스나 기타 엔터프라이즈 애플리케이션을 관리하려면 데이터 및 메타데이터 관리를 위해 드라이브에 여유 공간이 필요합니다. 필요한 여유 공간의 양은 사용하는 드라이브의 유형과 비즈니스 프로세스에 따라 다릅니다.</block>
  <block id="655dc175973dc3d055e6e798ce1399a6" category="summary">Oracle 다중 블록 읽기 매개 변수</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multiblock_read_count입니다</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">를 클릭합니다<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> 매개 변수는 Oracle이 순차적 I/O 중에 단일 작업으로 읽는 Oracle 데이터베이스 블록의 최대 수를 제어합니다</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">하지만 이 매개 변수는 모든 읽기 작업 중에 Oracle이 읽는 블록의 수나 랜덤 I/O에 영향을 미치지 않으며 순차적 I/O의 블록 크기에만 영향을 미칩니다.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle은 이 매개 변수를 설정 해제 상태로 둘 것을 권장합니다. 이렇게 하면 데이터베이스 소프트웨어가 최적의 값을 자동으로 설정할 수 있습니다. 이는 일반적으로 이 매개 변수가 1MB의 I/O 크기를 생성하는 값으로 설정된다는 뜻입니다. 예를 들어, 8KB 블록의 1MB 읽기에서는 읽을 블록이 128개 필요하며 이에 따라 이 매개 변수의 기본값은 128이 됩니다.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">NetApp이 고객 사이트에서 관찰한 데이터베이스 성능 문제는 대부분 이 매개 변수의 잘못된 설정과 관련이 있습니다. Oracle 버전 8 및 9에서 이 값을 변경할 타당한 이유가 있었습니다. 그 결과, 매개 변수가 모르게 에 있을 수 있습니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 데이터베이스가 Oracle 10 이상으로 업그레이드되었기 때문입니다. 128이라는 기본값에 비해 8 또는 16의 기존 설정은 순차적 I/O 성능을 크게 저하합니다.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">* NetApp는 * 를 설정할 것을 권장합니다<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> 매개 변수는 에 있어서는 안 됩니다<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> 파일. NetApp이 관찰한 결과 이 매개 변수를 변경하여 성능이 개선된 경우는 없었으나 순차적 I/O 처리량 저하가 사라진 사례는 많이 있습니다.</block>
  <block id="669ebbf33c0b19005e2ccaf02ba69e5f" category="summary">네트워크 스토리지가 있는 Oracle RAC 설정</block>
  <block id="5c87e825763ec1e41a459f6baa4b2a44" category="doc">Oracle RAC(Real Application Clusters)</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC는 클러스터 상태를 모니터링하는 여러 유형의 내부 하트비트 프로세스를 갖춘 클러스터웨어 제품입니다.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">잘못 장착되었습니다</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">의 정보 <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> 섹션에는 네트워크 스토리지를 사용하는 Oracle RAC 환경에 대한 중요 정보가 포함되어 있으며, 대부분의 경우 RAC 클러스터가 네트워크 경로 변경 및 스토리지 페일오버/스위치오버 작업을 지속할 수 있도록 기본 Oracle RAC 설정을 변경해야 합니다.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">디스크 시간 초과</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">은 운영 스토리지와 관련된 주요 RAC 매개 변수입니다<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. 이 매개 변수는 voting 파일 I/O가 완료되어야 하는 임계값을 제어합니다. 를 누릅니다<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> 매개 변수가 초과되면 클러스터에서 RAC 노드가 제거됩니다. 이 매개 변수의 기본값은 200이며 이 값은 표준 스토리지 테이크오버 및 반환 절차를 진행하는 데 충분합니다.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">많은 요소가 테이크오버나 반환에 영향을 미치기 때문에 RAC 구성을 운영 환경에 배치하기 전에 철저히 테스트하는 것이 좋습니다 NetApp. 스토리지 페일오버가 완료되는 데 필요한 시간 외에 링크 통합 제어 프로토콜(LACP) 변경사항을 전달하기 위한 추가 시간도 필요합니다. 또한 SAN 다중 경로 소프트웨어는 I/O 시간 초과를 감지하고 대체 경로를 다시 시도해야 합니다. 데이터베이스가 매우 활성화된 경우 보팅 디스크 I/O가 처리되기 전에 많은 양의 I/O를 대기열에 넣고 다시 시도해야 합니다.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">실제 스토리지 테이크오버 또는 반환을 수행할 수 없을 경우 데이터베이스 서버에서 케이블을 빼는 테스트를 통해 그 영향을 시뮬레이션할 수 있습니다.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">를 종료합니다<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> 기본값 200의 매개 변수입니다.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">항상 RAC 구성을 철저히 테스트하십시오.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">를 클릭합니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 매개 변수는 일반적으로 RAC 노드 간 네트워크 하트비트에만 영향을 미치며 기본값은 30초입니다. 그리드 바이너리가 스토리지 어레이에 있거나 운영 체제 부트 드라이브가 로컬에 있지 않은 경우 이 매개 변수의 중요성이 커집니다. 부트 드라이브가 FC SAN에 있는 호스트, NFS 부팅 운영 체제 그리고 VMDK 파일처럼 부트 드라이브가 가상화 데이터 저장소에 있는 호스트가 여기에 포함됩니다.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">스토리지 테이크오버 또는 반환에 의해 부트 드라이브에 대한 액세스가 중단되면 그리드 바이너리 위치 또는 전체 운영 체제가 일시적으로 멈출 수 있습니다. ONTAP에서 스토리지 작업이 완료되고 운영 체제에서 경로가 변경되고 I/O가 재개되는 데 필요한 시간이 을 초과할 수 있습니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 임계값. 노드는 부트 LUN 또는 그리드 바이너리에 대한 연결이 복원되는 즉시 제거됩니다. 대부분의 경우 재부팅 이유를 나타내는 로깅 메시지 없이 제거 및 후속 재부팅 동작이 수행합니다. 모든 구성이 영향을 받는 것은 아니므로 부트 드라이브에 대한 통신이 중단되는 경우 RAC가 안정된 상태를 유지하도록 RAC 환경에서 SAN 부팅, NFS 부팅 또는 데이터 저장소 기반 호스트를 테스트하십시오.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">비로컬 부팅 드라이브 또는 비로컬 파일 시스템 호스팅의 경우<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> 바이너리<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 일치시키려면 변경해야 합니다<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. 이 매개 변수가 변경되면 추가 테스트를 수행하여 노드 페일오버 시간 등 RAC 동작에 미치는 영향도 파악하십시오.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">를 그대로 둡니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 다음 조건 중 하나가 적용되지 않는 한 매개 변수 기본값은 30입니다.</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> 바이너리는 NFS, iSCSI, FC 및 데이터 저장소 기반 드라이브를 포함하여 네트워크 연결 드라이브에 있습니다.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">운영 체제가 SAN 환경에서 부팅됩니다.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">이러한 경우 OS 또는 에 대한 액세스에 영향을 미치는 네트워크 중단의 영향을 평가합니다<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> 파일 시스템 경우에 따라 이러한 중단으로 인해 Oracle RAC 데몬에 지연이 발생하며 이로 인해 로 이어질 수 있습니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>시간 초과 및 제거 기반. 시간 초과 기본값은 27초이며 이 값은 입니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 빼기<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. 이 경우 을 증가시킵니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 200을 선택하십시오<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="6cde0106c3eb71034259ac34de5e6a2c" category="summary">Oracle filesystemio_options 를 참조하십시오</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Oracle 초기화 매개 변수<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> 비동기식 및 직접 입출력의 사용을 제어합니다</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">일반적인 인식과 달리 비동기식 및 직접I/O는 상호 배타적이지 않습니다. NetApp은 이 매개 변수가 고객 환경에서 종종 잘못 구성되며 이 잘못된 구성이 여러 성능 문제의 직접적인 원인이 된다는 것을 목격했습니다.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">비동기식 I/O에서는 Oracle I/O 작업을 병렬화할 수 있습니다. 다양한 운영 체제에서 비동기식 I/O를 사용할 수 있게 되기 전에 사용자는 수많은 dbwriter 프로세스를 구성했고 서버 프로세스 구성을 변경했습니다. 비동기식 I/O를 통해 운영 체제는 매우 효율적인 병렬 방식으로 데이터베이스 소프트웨어 대신 I/O를 수행합니다. 이 프로세스는 데이터를 위험에 처하게 하지 않으며 Oracle 로깅 재실행 같은 중요한 작업은 여전히 동기식으로 수행됩니다.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">직접 I/O는 운영 체제 버퍼 캐시를 우회합니다. UNIX 시스템의 I/O는 일반적으로 운영 체제 버퍼 캐시를 통해 흐릅니다. 이는 내부 캐시에서 유지되지 않는 애플리케이션에 유용하지만 Oracle은 SGA 내부에 자체 버퍼 캐시가 있습니다. 거의 모든 경우 운영 체제 버퍼 캐시를 사용하는 것보다 직접 I/O를 활성화하고 서버 RAM을 SGA에 할당하는 것이 더 낫습니다. Oracle SGA는 메모리를 더 효율적으로 사용하며 I/O가 운영 체제 버퍼를 통해 흐를 때 지연 시간을 증가시키는 추가 처리가 적용됩니다. 증가한 지연 시간은 짧은 지연 시간이 중요한 요구사항일 때 쓰기 집약적 I/O에서 특히 뚜렷하게 나타납니다.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">의 옵션<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> 다음과 같습니다.</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">* 비동기 * Oracle은 처리를 위해 I/O 요청을 OS에 제출합니다. 이 프로세스는 Oracle I/O가 완료되기를 기다리면서 I/O 병렬화를 증가시키는 것이 아니라 Oracle이 다른 작업을 수행할 수 있도록 합니다.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">* directio. * Oracle은 호스트 OS 캐시를 통해 I/O를 라우팅하지 않고 물리적 파일에 직접 I/O를 수행합니다.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">* 없음. * Oracle은 동기 및 버퍼링된 I/O를 사용합니다 이 구성에서는 공유 서버와 전용 서버 프로세스 중 무엇을 선택할지 그리고 dbwriter의 개수가 어떻게 되는지가 더 중요합니다.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">* SetAll. * Oracle은 비동기 I/O와 직접 I/O를 모두 사용합니다 거의 모든 경우에 를 사용합니다<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> 최적의 상태.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">를 클릭합니다<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> 매개 변수는 DNFS 및 ASM 환경에 어떤 영향도 미치지 않습니다. DNFS 또는 ASM가 자동으로 사용되면 비동기식 및 직접 I/O 둘 다 사용됩니다</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">과거에는 특히 Red Hat Enterprise Linux 4(RHEL4) 릴리즈에서 비동기식 I/O 문제에 직면하는 고객이 있었습니다. 일부 오래된 인터넷 조언은 오래된 정보로 인해 비동기 IO를 피하는 것을 제안합니다. 비동기식 I/O는 현재의 모든 운영 체제에서 안정적입니다. OS에 알려진 버그가 없고 비활성화할 이유가 없습니다.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">데이터베이스가 버퍼링된 I/O를 사용해온 경우 직접 I/O로 전환하면 SGA 크기 변경도 보장됩니다. 버퍼링된 I/O를 비활성화하면 호스트 운영 체제 캐시가 데이터베이스에 제공하는 성능 이점이 없어집니다. RAM을 SGA에 다시 추가하면 이 문제가 해결되며 결과적으로 I/O 성능이 개선될 것입니다.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">거의 모든 경우에 Oracle SGA에 운영 체제 버퍼 캐싱보다 RAM을 사용하는 것이 더 낫지만 최고의 가치를 결정하는 것은 불가능할 수 있습니다. 예를 들어, 간헐적인 액티브 Oracle 인스턴스가 있는 데이터베이스 서버에는 아주 작은 SGA 크기의 버퍼링된 I/O를 사용하는 것이 더 나을 것입니다. 이렇게 하면 실행 중인 모든 데이터베이스 인스턴스를 통해 운영 체제의 나머지 가용 RAM을 유연하게 사용할 수 있습니다. 이는 매우 드문 상황이지만 일부 고객 사이트에서 관찰된 바 있습니다.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">* NetApp는 * 설정을 권장합니다<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>는 어떤 상황에서는 호스트 버퍼 캐시의 손실로 인해 Oracle SGA를 늘려야 할 수 있음을 유념하십시오.</block>
  <block id="caa6d47f2f011d5d1b5fb830e85a37f0" category="summary">Oracle 블록 크기입니다</block>
  <block id="6db776dab2989df63d245511a4dccf08" category="doc">Oracle 블록 크기</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP에서는 내부적으로 가변 블록 크기를 사용하므로 원하는 블록 크기로 Oracle 데이터베이스를 구성할 수 있습니다. 그러나 파일 시스템 블록 크기가 성능에 영향을 미칠 수 있으며 경우에 따라 재실행 블록 크기가 클수록 성능이 향상될 수 있습니다.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">데이터 파일 블록 크기</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">일부 운영 체제에서는 파일 시스템 블록 크기를 선택할 수 있습니다. Oracle 데이터 파일을 지원하는 파일 시스템의 경우 압축을 사용했을 때 블록 크기는 8KB가 됩니다. 압축이 필요하지 않은 경우 8KB 또는 4KB의 블록 크기를 사용할 수 있습니다.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">데이터 파일이 512바이트 블록의 파일 시스템에 배치되면 파일 정렬 불량이 발생할 수 있습니다. LUN과 파일 시스템은 NetApp 권장 사항에 따라 적절히 정렬되겠으나 파일 I/O는 정렬 불량이 될 것입니다. 이러한 정렬 불량은 심각한 성능 문제를 초래합니다.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">재실행 로그를 지원하는 파일 시스템은 재실행 블록 크기의 배수인 블록 크기를 사용해야 합니다. 일반적으로 재실행 로그 파일 시스템과 재실행 로그 자체는 512바이트의 블록 크기를 사용해야 합니다.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">블럭 크기 재실행</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">재실행 속도가 빠르면 더 간소화되고 효율적인 작업으로 I/O를 수행할 수 있기 때문에 매우 빠른 재실행 속도에서 4KB 블록 크기의 성능이 향상될 수 있습니다. 재실행 속도가 50MBps보다 빠른 경우 4KB 블록 크기를 테스트하는 것을 고려해 보십시오.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">고객 사례에서 4KB 블록 크기와 매우 작은 트랜잭션이 많이 수행되는 파일 시스템에서 512바이트 블록 크기의 재실행 로그를 사용하는 데이터베이스가 몇 가지 문제를 발생시키는 것으로 나타났습니다. 단일 4KB 파일 시스템 블록에 여러 512바이트 변경사항을 적용할 때 발생하는 오버헤드는 성능 문제를 야기했으며 이 문제는 512바이트의 블록 크기를 사용하도록 파일 시스템을 변경하여 해결되었습니다.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">* NetApp은 관련 고객 지원 팀 또는 프로페셔널 서비스 조직에서 변경하라고 조언했거나 공식 제품 설명서에 따른 것이 아닌 한 재실행 블록 크기를 변경하지 않을 것을 권장합니다.</block>
  <block id="00783c075f877e6e69c64079296967ed" category="summary">ONTAP을 사용한 Oracle 재해 복구</block>
  <block id="6a87f84ba62b57e5643d5bfa5967c7a8" category="doc">ONTAP을 사용한 재해 복구</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">재해 복구는 스토리지 시스템 또는 전체 사이트를 파괴하는 화재와 같이 심각한 사고가 발생한 후 데이터 서비스를 복원하는 것을 의미합니다.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4591: Oracle Data Protection_and_TR-4592: MetroCluster 기반 Oracle._ 을(를) 대체합니다</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">재해 복구는 물론 많은 고객이 미러링된 복제본을 매시간마다 업데이트하는 방식으로 SnapMirror를 사용하여 데이터를 간단히 복제하여 수행할 수 있습니다.</block>
  <block id="0f1b72a875a2bcb3d0e844ca2dcee233" category="paragraph">대부분의 고객이 DR에는 데이터의 원격 복사본을 소유하는 것 이상의 것이 필요하며, 해당 데이터를 빠르게 사용할 수 있는 기능이 필요합니다. NetApp은 이러한 요구사항을 해결하는 두 가지 기술, 즉 MetroCluster와 SnapMirror Business Continuity(SM-BC)를 제공합니다.</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster는 낮은 수준의 동기식 미러링 스토리지와 수많은 추가 기능을 포함하는 하드웨어 구성에서 ONTAP를 가리킵니다. MetroCluster와 같은 통합 솔루션은 오늘날의 복잡한 스케일아웃 데이터베이스, 애플리케이션 및 가상화 인프라를 단순화합니다. 여러 외부 데이터 보호 제품 및 전략을 하나의 단순한 중앙 스토리지 시스템으로 대체합니다. 또한 단일 클러스터 스토리지 시스템 내에서 통합 백업, 복구, 재해 복구 및 고가용성(HA)을 제공합니다.</block>
  <block id="05be1e741eba1ac3f0b7c924f261403b" category="paragraph">SnapMirror Business Continuity(SM-BC)는 SnapMirror Synchronous를 기반으로 합니다. MetroCluster를 사용할 경우 각 ONTAP 컨트롤러는 드라이브 데이터를 원격 위치로 복제하는 작업을 담당합니다. SM-BC에서는 기본적으로 LUN 데이터의 독립적인 복사본을 유지 관리하지만 해당 LUN의 단일 인스턴스를 제공하기 위해 두 개의 서로 다른 ONTAP 시스템이 있습니다. 호스트 관점에서 보면 단일 LUN 엔티티입니다.</block>
  <block id="70f47db03a0843fec433c8cc41a54635" category="paragraph">SM-BC와 MetroCluster는 내부적으로 매우 다르게 작동하지만 호스트에 대한 결과는 매우 유사합니다. 주요 차이점은 세분성입니다. 동기식 복제할 워크로드만 선택하는 경우 SM-BC가 더 나은 옵션입니다. 전체 환경이나 데이터 센터를 복제해야 하는 경우 MetroCluster가 더 나은 옵션입니다. 또한 SM-BC는 현재 SAN에만 해당되며 MetroCluster은 SAN, NFS, SMB를 포함한 멀티 프로토콜을 지원합니다.</block>
  <block id="7389dc8e47495ffdde7fd2e0fc19df20" category="summary">SM-BC를 사용한 Oracle 페일오버</block>
  <block id="0a54809bbd5dc721967217b79aa04429" category="paragraph">SM-BC에 Oracle 데이터베이스를 호스팅하는 주된 이유는 계획된 스토리지 이벤트 및 계획되지 않은 스토리지 이벤트 중에 투명한 페일오버를 제공하기 위해서입니다.</block>
  <block id="cfb8f86af03363ef2c73933e34108390" category="summary">SM-BC를 사용하는 ONTAP의 Oracle 단일 인스턴스</block>
  <block id="f25228759326d365adf4dca6b7b2cb8b" category="doc">SM-BC를 사용하는 단일 인스턴스 Oracle</block>
  <block id="a38cb04f35bd24313f90398cdc07e149" category="paragraph">아래 다이어그램은 Oracle 데이터베이스의 기본 및 원격 스토리지 클러스터 모두에서 스토리지 디바이스를 조닝 또는 연결하는 간단한 구축 모델을 보여 줍니다.</block>
  <block id="ac38db4f14e512b48d088eedb84cd611" category="paragraph">Oracle은 운영 환경에만 구성되어 있습니다. 이 모델은 스토리지 측 재해 발생 시 애플리케이션 다운타임 없이 데이터 손실 없이 원활한 스토리지 페일오버를 해결합니다. 그러나 이 모델은 사이트 장애 시 데이터베이스 환경의 고가용성을 제공하지 않습니다. 이 유형의 아키텍처는 스토리지 서비스의 고가용성을 갖춘 데이터 손실 없는 솔루션을 찾고 있지만 데이터베이스 클러스터의 전체 손실에는 수동 작업이 필요하다는 점을 수용하려는 고객에게 유용합니다.</block>
  <block id="ccc53ca027c7d8fb1e0d647249fd67cd" category="paragraph"><block ref="ccc53ca027c7d8fb1e0d647249fd67cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e072ef2eba1c46e59475046cd4fb880" category="paragraph">또한 이 방법을 사용하면 Oracle 라이센스 비용을 절감할 수 있습니다. 원격 사이트에서 Oracle 데이터베이스 노드를 미리 구성하려면 대부분의 Oracle 라이센스 계약에 따라 모든 코어에 라이센스를 부여해야 합니다. Oracle 데이터베이스 서버를 설치하고 나머지 데이터 복사본을 마운트하는 데 소요되는 시간으로 인한 지연이 허용되는 경우 이 설계는 비용 효율성이 매우 높습니다.</block>
  <block id="5e2dd7c2fa063e6d7af964efc0e488a0" category="summary">SM-BC를 사용하는 ONTAP 기반 Oracle RAC</block>
  <block id="f7d366254f13816be07d3c8dff4ef00c" category="doc">SM-BC를 사용하는 Oracle RAC</block>
  <block id="67bbc9e19672ee6c9c548cae8a472396" category="paragraph">SM-BC는 로드 밸런싱 또는 개별 애플리케이션 페일오버 등의 목적으로 데이터 세트 복제를 세부적으로 제어할 수 있습니다. 전체 아키텍처는 확장된 RAC 클러스터처럼 보이지만 일부 데이터베이스는 특정 사이트 전용이며 전체 부하가 분산됩니다.</block>
  <block id="9331b3ad2bcf259818157930e1c82ad3" category="paragraph">예를 들어 6개의 개별 데이터베이스를 호스팅하는 Oracle RAC 클러스터를 구축할 수 있습니다. 세 데이터베이스의 스토리지는 주로 사이트 A에서 호스팅되고, 다른 세 데이터베이스의 스토리지는 사이트 B에서 호스팅됩니다 이 구성은 사이트 간 트래픽을 최소화하여 최상의 성능을 보장합니다. 또한 활성 경로를 사용하여 스토리지 시스템에 로컬인 데이터베이스 인스턴스를 사용하도록 애플리케이션을 구성합니다. 이렇게 하면 RAC 상호 연결 트래픽이 최소화됩니다. 마지막으로, 이 전반적인 설계를 통해 모든 컴퓨팅 리소스가 균일하게 사용되도록 합니다. 워크로드가 변경되면 사이트 간에 데이터베이스를 선택적으로 장애 조치하여 로딩이 고르게 이루어질 수 있습니다.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">MetroCluster 기반 Oracle RAC</block>
  <block id="1c6753ccdcc6629af3e1febabbf271b5" category="paragraph">세분화 수준을 제외하고 SM-BC를 사용하는 Oracle RAC의 기본 원칙 및 옵션은 과 동일합니다 <block ref="f7453402f1e4779ea0ec67d873358932" category="inline-link-macro-rx"></block></block>
  <block id="7e544b57620f5cdeb71865606eab0549" category="summary">SM-BC(SnapMirror Business Continuity)를 사용한 Oracle</block>
  <block id="33aa8b7a84723347d228956fab2a4de8" category="doc">Oracle 및 SnapMirror 비즈니스 연속성</block>
  <block id="41eec95e0dbb542c5cd25248ec5759d5" category="paragraph">SM-BC는 개별 Oracle 데이터베이스 및 애플리케이션 환경에 대해 선택적 RPO=0 동기식 미러링을 지원합니다.</block>
  <block id="563d0bf19fd5d623a031d90c30128dc1" category="summary">Oracle SM-BC 장애 시나리오</block>
  <block id="3c1ea312a3c6648fc3f94a1ccd12bebc" category="doc">Oracle SM-BC 장애 시나리오</block>
  <block id="87777c84375810d8b6fd65f604dd2561" category="paragraph">SnapMirror SM-BC(Business Continuity) 장애 시나리오마다 결과가 다를 수 있습니다.</block>
  <block id="8eea62084ca7e541d918e823422bd82e" category="cell">결과</block>
  <block id="ee70ac41df7240931fee4110b599c39f" category="cell">복제 링크 오류입니다</block>
  <block id="e79e76eca171f3e596eb56ba4bb24743" category="cell">중재자는 이 브레인 분할 시나리오를 인식하고 마스터 복제본이 있는 노드에서 입출력을 재개합니다. 사이트 간 연결이 다시 온라인 상태가 되면 대체 사이트가 자동 재동기화를 수행합니다.</block>
  <block id="98a638ba6cee257a8f751bcf8d30e1f2" category="cell">1차 사이트 스토리지 장애</block>
  <block id="b92af6cefecfe68535bbd851b797379f" category="cell">자동 비계획 페일오버는 중재자에 의해 시작됩니다.

I/O 중단 없음.</block>
  <block id="ce9a584219636ca5b159a27f2dd8c445" category="cell">원격 사이트 스토리지 장애</block>
  <block id="68a293bd16c4e2589057d43506a5afbd" category="cell">I/O 중단은 없습니다. 네트워크가 동기화 복제를 중단하도록 하고 마스터가 입출력을 계속 제공할 수 있는 올바른 소유자임을 설정하여 일시 정지가 발생합니다. 따라서 입출력이 몇 초 동안 일시 중지되면 입출력이 재개됩니다.

사이트가 온라인 상태일 때 자동으로 다시 동기화됩니다.</block>
  <block id="64f4e3573d0b569ef7b5a08476fb9f7d" category="cell">중재자와 스토리지 어레이 간의 중재자 또는 링크 상실</block>
  <block id="7e7abe23ef8e465ee1b6879b35e6bab3" category="cell">입출력이 계속되고 원격 클러스터와 동기화된 상태로 유지되지만 중재자가 없는 경우 예상치 못한 자동 페일오버 및 페일백은 불가능합니다.</block>
  <block id="96b352ebd03c8c5b7589a527b18f1a2d" category="cell">HA 클러스터의 스토리지 컨트롤러 중 하나가 손실되었습니다</block>
  <block id="426c4468c3cc76191842240593fcfec3" category="cell">HA 클러스터의 파트너 노드가 테이크오버(NDO)를 시도합니다. 테이크오버가 실패하면 중재자는 스토리지의 두 노드가 모두 다운되었음을 알리고 원격 클러스터에 대한 비계획 페일오버를 자동으로 수행합니다.</block>
  <block id="0e578c93ab393c3d449d484e9fa4b84e" category="cell">디스크 손실</block>
  <block id="3d5fea5d89ec844fc92c08a585050e4e" category="cell">입출력은 최대 3개의 연속 디스크 장애에 대해 계속됩니다. RAID-TEC의 일부입니다.</block>
  <block id="bd300f92769c0ee071832cadaff91f04" category="cell">일반적인 구축 환경에서 전체 사이트 손실</block>
  <block id="9cfa40a514d333ea10de6fc8a75ac663" category="cell">오류가 발생한 사이트의 서버는 더 이상 사용할 수 없습니다. 클러스터링을 지원하는 응용 프로그램은 두 사이트에서 모두 실행되고 대체 사이트에서 계속 작동하도록 구성할 수 있습니다. 하지만 대부분의 응용 프로그램에는 SM-BC가 중재자를 요구하는 것과 유사한 3차 사이트 Tiebreaker가 필요합니다.

애플리케이션 레벨 클러스터가 없으면 정상 사이트에서 애플리케이션을 시작해야 합니다. 이 경우 가용성에 영향을 미치지만 RPO=0은 유지됩니다. 데이터는 손실되지 않습니다.</block>
  <block id="f2762385d394491398659925e75d5d01" category="summary">MetroCluster 물리적 아키텍처 - Oracle</block>
  <block id="5be41b602a41d06df45e8986ec09a8dc" category="doc">MetroCluster 물리적 아키텍처 - Oracle</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">MetroCluster 환경에서 Oracle 데이터베이스가 작동하는 방식을 이해하려면 MetroCluster 시스템의 물리적 설계에 대해 몇 가지 설명이 필요합니다.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4592: MetroCluster 기반 Oracle._ 을(를) 대체합니다</block>
  <block id="bdec122112fe3ad35d588380dc643e48" category="summary">MetroCluster 논리적 아키텍처 - 오라클</block>
  <block id="141402e8d9fa946970f252a09a01a462" category="doc">MetroCluster 논리적 아키텍처 - Oracle</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">MetroCluster 환경에서 Oracle 데이터베이스가 작동하는 방식을 이해하려면 MetroCluster 시스템의 논리적 기능에 대한 몇 가지 설명이 필요합니다.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL(* NVFAIL</block>
  <block id="6ddd3d6bc3ad92b983699970b1596e0f" category="summary">MetroCluster을 사용하는 Oracle</block>
  <block id="c1fac7a72cd91bcd345e567f6d6d93a3" category="doc">MetroCluster을 통한 Oracle 페일오버</block>
  <block id="7a60cb119af7ddcdfe38fc872d2027a1" category="paragraph">MetroCluster를 사용할 경우 엔터프라이즈 애플리케이션 및 데이터베이스 운영에 대한 모범 사례가 반드시 추가하거나 변경되지는 않습니다.</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">일반적인 모범 사례가 여전히 적용되므로 필요한 경우 RPO = 0 데이터 보호만 있으면 MetroCluster를 통해 이 요구사항을 충족할 수 있습니다. 하지만 대부분의 고객은 RPO=0 데이터 보호를 위해뿐만 아니라 재해 시나리오 중에 RTO를 개선하고 사이트 유지 관리 작업의 일부로 투명한 페일오버를 제공하기 위해 MetroCluster을 사용합니다.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">사전 구성된 OS로 페일오버</block>
  <block id="9bd9ad7f296a0e8ac3df804b3c6a392f" category="paragraph">SyncMirror은 재해 복구 사이트에서 데이터의 동기식 복사본을 제공하지만, 데이터를 사용하려면 운영 체제와 관련 애플리케이션이 필요합니다. 기본 자동화를 통해 전체 환경의 장애 조치 시간을 크게 개선할 수 있습니다. Oracle RAC, VCS(Veritas Cluster Server) 또는 VMware HA 같은 Clusterware 제품은 사이트 전체에 클러스터를 생성하는 데 자주 사용되며, 대부분의 경우 간단한 스크립트로 페일오버 프로세스를 구동할 수 있습니다.</block>
  <block id="c5a2f3b867d990c681a218d29a55fcfa" category="paragraph">운영 노드가 손실되면 대체 사이트에서 애플리케이션을 온라인으로 전환하도록 클러스터웨어(또는 스크립트)가 구성됩니다. 한 가지 옵션은 애플리케이션을 구성하는 NFS 또는 SAN 리소스에 대해 사전 구성된 대기 서버를 생성하는 것입니다. 운영 사이트에 장애가 발생하면 클러스터웨어 또는 스크립트된 대체 시스템이 다음과 유사한 일련의 작업을 수행합니다.</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">MetroCluster 강제 전환</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">FC LUN 검색 수행(SAN만 해당)</block>
  <block id="6f3fd86521759fc98ed93853eaf8a03a" category="list-text">파일 시스템을 마운트하는 중입니다</block>
  <block id="9d9ea7a9c532a3cec63305130018a45b" category="list-text">응용 프로그램을 시작하는 중입니다</block>
  <block id="b8eca7b573624230962095fcadb03ddf" category="paragraph">이 방법의 주요 요구 사항은 원격 사이트에서 실행 중인 OS입니다. 애플리케이션 바이너리로 사전 구성되어야 합니다. 즉, 패치와 같은 작업은 운영 및 대기 사이트에서 수행되어야 합니다. 또는 재해가 선언된 경우 애플리케이션 바이너리를 원격 사이트로 미러링하고 마운트할 수 있습니다.</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">실제 활성화 절차는 간단합니다. LUN 검색과 같은 명령은 FC 포트당 몇 개의 명령만 사용하면 됩니다. 파일 시스템 마운팅은 에 불과합니다<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> CLI에서 단일 명령으로 명령 및 데이터베이스와 ASM을 모두 시작하고 중지할 수 있습니다. 볼륨 및 파일 시스템이 전환 전 재해 복구 사이트에서 사용되지 않는 경우에는 설정할 필요가 없습니다<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> On 볼륨.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">가상화된 OS로 페일오버</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">데이터베이스 환경의 페일오버는 운영 체제 자체를 포함하도록 확장할 수 있습니다. 이론적으로 이 페일오버는 부팅 LUN에서 수행할 수 있지만 대부분의 경우 가상화된 OS에서 수행됩니다. 절차는 다음 단계와 유사합니다.</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">데이터베이스 서버 가상 머신을 호스팅하는 데이터 저장소를 마운트합니다</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">가상 머신 시작</block>
  <block id="ba2f22f63087151f0a0694be5f35fcf2" category="list-text">데이터베이스를 수동으로 시작하거나 가상 시스템이 데이터베이스를 자동으로 시작하도록 구성합니다</block>
  <block id="810078f3b19b93e24de8638d68f727b5" category="paragraph">예를 들어, ESX 클러스터가 사이트에 걸쳐 있을 수 있습니다. 재해 발생 시 전환 후 재해 복구 사이트에서 가상 시스템을 온라인으로 전환할 수 있습니다. 재해 발생 시 가상 데이터베이스 서버를 호스팅하는 데이터 저장소를 사용하지 않는 한 설정할 필요가 없습니다<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> 연결된 볼륨에서.</block>
  <block id="681afe3bdc351138642f233429d64762" category="summary">Oracle 및 SyncMirror</block>
  <block id="bc8a6c6eac662831d2ddce97adbd4324" category="doc">SyncMirror - 오라클</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">MetroCluster 시스템을 통한 Oracle 데이터 보호의 기반은 최대 성능 스케일아웃 동기식 미러링 기술인 SyncMirror입니다.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">MetroCluster를 사용한 Oracle RAC 확장</block>
  <block id="dbcedb2fd86e6012347a3c9ad111f3a8" category="doc">MetroCluster에서 Oracle RAC 확장</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">많은 고객이 사이트 간에 Oracle RAC 클러스터를 확장하여 완벽한 Active-Active 구성을 실현함으로써 RTO를 최적화합니다. Oracle RAC의 쿼럼 관리를 포함해야 하기 때문에 전체 설계가 더 복잡해집니다. 또한, 두 사이트에서 데이터에 액세스할 수 있으므로 강제 전환으로 인해 최신 데이터 복사본이 사용될 수 있습니다.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">두 사이트 모두에 데이터 복사본이 있지만 현재 애그리게이트를 소유하고 있는 컨트롤러만 데이터를 제공할 수 있습니다. 따라서 확장된 RAC 클러스터의 경우 원격 노드가 사이트 간 연결에서 I/O를 수행해야 합니다. 결과적으로 I/O 지연 시간이 추가되지만 이 지연 시간은 일반적으로 문제가 되지 않습니다. RAC 상호 연결 네트워크도 사이트 간에 확장해야 하므로 지연 시간이 짧은 고속 네트워크가 필요합니다. 추가된 지연 시간으로 인해 문제가 발생할 경우 클러스터를 액티브-패시브 방식으로 작동할 수 있습니다. 그런 다음 I/O 집약적인 작업을 애그리게이트가 속한 컨트롤러에 로컬인 RAC 노드로 보내야 함. 그런 다음 원격 노드가 가벼운 I/O 작업을 수행하거나 온전한 대기 서버로만 사용됩니다.</block>
  <block id="375c3caa97162bd0c2c07869d9c5b026" category="paragraph">액티브-액티브 확장 RAC가 필요한 경우 MetroCluster 대신 ASM 미러링을 고려해야 합니다. ASM 미러링을 사용하면 데이터의 특정 복제본을 선호할 수 있습니다. 따라서 모든 읽기가 로컬에서 실행되는 확장 RAC 클러스터를 구축할 수 있습니다. 읽기 I/O가 사이트를 통과하지 않으므로 지연 시간이 가장 짧습니다. 모든 쓰기 작업은 사이트 간 연결을 전송해야 하지만 동기식 미러링 솔루션에서 이러한 트래픽은 피할 수 없습니다.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">ONTAP 지원 Oracle RAC</block>
  <block id="59d934fc4614a6275fef2828bfab30cf" category="admonition">가상화된 부팅 디스크를 비롯한 부팅 LUN을 Oracle RAC와 함께 사용하는 경우, 이 명령을 사용합니다<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> 매개 변수를 변경해야 할 수 있습니다. RAC 시간 초과 매개변수에 대한 자세한 내용은 을 참조하십시오 <block ref="75080d28a1748f78cf8a666ababf51af" category="inline-link-macro-rx"></block>.</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">2개 사이트 구성</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">2개 사이트의 확장 RAC 구성은 운영 중단 없이 많은 재해 시나리오에서도 가동 중단 없이 지속되는 액티브-액티브 데이터베이스 서비스를 제공할 수 있습니다.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">RAC 보팅 파일</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">MetroCluster에서 확장 RAC를 구축할 때 가장 먼저 고려해야 할 사항은 쿼럼 관리입니다. Oracle RAC에는 디스크 하트비트와 네트워크 하트비트를 관리하는 두 가지 메커니즘이 있습니다. 디스크 하트비트는 보팅 파일을 사용하여 스토리지 액세스를 모니터링합니다. 단일 사이트 RAC 구성의 경우 기본 스토리지 시스템이 HA 기능을 제공하는 한 단일 보팅 리소스로 충분합니다.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">이전 버전의 Oracle에서는 보팅 파일이 물리적 스토리지 장치에 배치되었지만 현재 버전의 Oracle에서는 보팅 파일이 ASM 디스크 그룹에 저장됩니다.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC는 NFS에서 지원됩니다. 그리드 설치 프로세스 중에 그리드 파일에 사용되는 NFS 위치를 ASM 디스크 그룹으로 제공하기 위한 일련의 ASM 프로세스가 생성됩니다. 이 프로세스는 최종 사용자에게 거의 투명하며 설치가 완료된 후 지속적인 ASM 관리가 필요하지 않습니다.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">2개 사이트 구성의 첫 번째 요구 사항은 무중단 재해 복구 프로세스를 보장하는 방식으로 각 사이트에서 투표 파일의 절반 이상을 항상 액세스할 수 있도록 하는 것입니다. 이 작업은 투표 파일이 ASM 디스크 그룹에 저장되기 전에는 간단했지만, 오늘날 관리자는 ASM 중복의 기본 원칙을 이해해야 합니다.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">ASM 디스크 그룹에는 이중화를 위한 세 가지 옵션이 있습니다<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, 및<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. 즉, 미러링되지 않은, 미러링된, 3웨이 미러링이 있습니다. 라는 새로운 옵션입니다<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> 사용 가능하지만 거의 사용되지 않습니다. 이중화 수준 및 중복 장치의 배치가 장애 시나리오에서 수행되는 작업을 제어합니다. 예를 들면 다음과 같습니다.</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">에 투표 파일 배치<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> 와 함께<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> 이중화 리소스는 사이트 간 연결이 끊긴 경우 하나의 사이트를 제거할 수 있도록 보장합니다.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">에 투표 파일 배치<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> 와 함께<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> 사이트당 하나의 ASM 디스크만 있는 중복으로 인해 두 사이트 간 연결이 끊어지면 두 사이트 모두에서 노드 제거가 보장됩니다.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">에 투표 파일 배치<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> 와 함께<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> 한 사이트에 두 개의 디스크가 있고 다른 사이트에 한 개의 디스크가 있는 중복성을 통해 두 사이트가 모두 작동 중이고 상호 연결할 수 있는 경우 활성-활성 작업이 가능합니다. 그러나 단일 디스크 사이트가 네트워크에서 분리되어 있으면 해당 사이트가 제거됩니다.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">RAC 네트워크 하트비트</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">Oracle RAC 네트워크 하트비트는 클러스터 상호 연결에서 노드 가용성을 모니터링합니다. 클러스터에 남아 있으려면 노드가 다른 노드의 절반 이상에 연결할 수 있어야 합니다. 2개 사이트 아키텍처에서는 이 요구 사항으로 인해 RAC 노드 수를 다음과 같이 선택할 수 있습니다.</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">사이트당 동일한 수의 노드를 배치하면 네트워크 연결이 끊어질 경우 한 사이트에서 제거됩니다.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">한 사이트에 N 노드를 배치하고 반대쪽 사이트에 N+1 노드를 배치하면 사이트 간 연결이 끊어지면 사이트가 네트워크 쿼럼에 더 많은 노드를 남기고 사이트를 더 적은 수의 노드로 제거할 수 있습니다.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Oracle 12cR2 이전에는 사이트 손실 중에 퇴거가 발생하는 측을 제어할 수 없었습니다. 각 사이트에 동일한 수의 노드가 있는 경우 일반적으로 부팅되는 첫 번째 RAC 노드가 마스터 노드에 의해 제거됩니다.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2에는 노드 가중치 기능이 도입되었습니다. 이 기능을 통해 관리자는 Oracle이 브레인 분할 조건을 해결하는 방법을 보다 효과적으로 제어할 수 있습니다. 간단한 예로, 다음 명령을 실행하면 RAC의 특정 노드에 대한 기본 설정이 설정됩니다.</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Oracle High-Availability Services를 다시 시작한 후 구성은 다음과 같습니다.</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">노드<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> 이(가) 중요 서버로 지정되었습니다. 2개의 RAC 노드가 격리된 경우<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> 존속, 그리고<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> 퇴거시키다.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">자세한 내용은 Oracle 백서 "Oracle Clusterware 12c Release 2 기술 개요"를 참조하십시오. ”</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">12cR2 이전 버전의 Oracle RAC의 경우 다음과 같이 CRS 로그를 확인하여 마스터 노드를 식별할 수 있습니다.</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">이 로그는 마스터 노드가 임을 나타냅니다<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> 및 노드입니다<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> 의 ID가 있습니다<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. 이는 실제로 그 점을 의미합니다<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> 은(는) 마스터 노드가 아닙니다. 마스터 노드의 ID는 명령을 사용하여 확인할 수 있습니다<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">ID가 인 노드입니다<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> 있습니다<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, 마스터 노드입니다. 각 사이트의 노드 수가 동일한 구성에서 사이트는 을(를) 사용합니다<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> 어떤 이유로든 두 세트의 네트워크 연결이 끊길 경우 존속되는 사이트입니다.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">마스터 노드를 식별하는 로그 항목이 시스템에서 제외될 수 있습니다. 이 경우 OCR(Oracle Cluster Registry) 백업의 타임스탬프를 사용할 수 있습니다.</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">이 예는 마스터 노드가 임을 보여 줍니다<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. 또한 에서 마스터 노드가 변경되었음을 나타냅니다<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> 를 선택합니다<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> 5월 4일 2시 5분에서 21시 39분 사이. 이 마스터 노드를 식별하는 방법은 이전 OCR 백업 이후 마스터 노드가 변경될 수 있기 때문에 CRS 로그도 확인한 경우에만 사용하는 것이 안전합니다. 이 변경 사항이 발생한 경우 OCR 로그에 표시됩니다.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">대부분의 고객은 전체 환경과 각 사이트에서 동일한 수의 RAC 노드를 서비스하는 단일 보팅 디스크 그룹을 선택합니다. 디스크 그룹은 데이터베이스가 포함된 사이트에 배치해야 합니다. 그 결과, 연결이 끊어지면 원격 사이트에서 제거됩니다. 원격 사이트에는 더 이상 쿼럼이 없고 데이터베이스 파일에 액세스할 수 없지만 로컬 사이트는 평소와 같이 계속 실행됩니다. 연결이 복원되면 원격 인스턴스를 다시 온라인 상태로 만들 수 있습니다.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">재해가 발생할 경우 데이터베이스 파일과 보팅 디스크 그룹을 정상 사이트에서 온라인으로 전환하기 위해 전환을 수행해야 합니다. AUSO가 재해에 의해 전환을 트리거할 경우 클러스터가 동기화하고 스토리지 리소스가 정상적으로 온라인 상태가 되기 때문에 NVFAIL이 트리거되지 않습니다. AUSO는 매우 빠른 작동이며, 이전에 완료되어야 합니다<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> 기간이 만료됩니다.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">사이트는 두 곳밖에 없기 때문에 자동화된 외부 티브레이킹 소프트웨어를 사용할 수 없으며, 이는 강제 전환이 수동 작업이어야 한다는 것을 의미합니다.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">3개 사이트 구성</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">확장된 RAC 클러스터는 3개의 사이트로 훨씬 더 쉽게 설계할 수 있습니다. MetroCluster 시스템의 절반을 호스팅하는 두 사이트도 데이터베이스 워크로드를 지원하고, 세 번째 사이트는 데이터베이스와 MetroCluster 시스템을 위한 Tiebreaker 역할을 합니다. Oracle Tiebreaker 구성은 세 번째 사이트에 투표하는 데 사용되는 ASM 디스크 그룹의 구성원을 배치하는 것만큼 간단할 수 있으며, RAC 클러스터에 홀수 노드 수가 있는지 확인하기 위해 세 번째 사이트에 운영 인스턴스를 포함할 수도 있습니다.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">확장 RAC 구성에서 NFS를 사용하는 방법에 대한 중요한 정보는 "쿼럼 장애 그룹"에 관한 Oracle 설명서를 참조하십시오. 요약하면, 쿼럼 리소스를 호스팅하는 세 번째 사이트에 대한 연결이 끊겨 기본 Oracle 서버 또는 Oracle RAC 프로세스가 중단되지 않도록 소프트 옵션을 포함하도록 NFS 마운트 옵션을 수정해야 할 수 있습니다.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster 및 NVFAIL과 같은 모든 스토리지 시스템을 사용할 수 있습니다</block>
  <block id="ee6c613c07239c0923d940dfd448493f" category="paragraph">NVFAIL은 ONTAP의 일반적인 데이터 무결성 기능으로, 데이터베이스 워크로드에서 특히 중요합니다.</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">MetroCluster에 있는 Oracle 단일 인스턴스</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">앞서 설명한 것처럼 MetroCluster 시스템이 있다고 해서 데이터베이스 운영에 대한 모범 사례가 반드시 추가되지 않거나 변경되는 것은 아닙니다. 고객 MetroCluster 시스템에서 현재 실행 중인 데이터베이스의 대부분은 단일 인스턴스이며 Oracle on ONTAP 설명서의 권장 사항을 따릅니다.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror은 재해 복구 사이트에서 데이터의 동기식 복사본을 제공하지만, 데이터를 사용하려면 운영 체제와 관련 애플리케이션이 필요합니다. 기본 자동화를 통해 전체 환경의 장애 조치 시간을 크게 개선할 수 있습니다. VCS(Veritas Cluster Server)와 같은 클러스터웨어 제품은 사이트 전체에 클러스터를 생성하는 데 자주 사용되며, 대부분의 경우 간단한 스크립트로 페일오버 프로세스를 구동할 수 있습니다.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">운영 노드가 손실되면 대체 사이트에서 데이터베이스를 온라인으로 전환하도록 클러스터웨어(또는 스크립트)가 구성됩니다. 한 가지 옵션은 데이터베이스를 구성하는 NFS 또는 SAN 리소스에 대해 사전 구성된 대기 서버를 생성하는 것입니다. 운영 사이트에 장애가 발생하면 클러스터웨어 또는 스크립트된 대체 시스템이 다음과 유사한 일련의 작업을 수행합니다.</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">파일 시스템 마운트 및/또는 ASM 디스크 그룹 마운트</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">데이터베이스를 시작하는 중입니다</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">이 방법의 주요 요구 사항은 원격 사이트에서 실행 중인 OS입니다. Oracle 바이너리로 사전 구성되어야 합니다. 즉, Oracle 패치 적용과 같은 작업이 운영 및 대기 사이트에서 수행되어야 합니다. 또는 재해가 선언된 경우 Oracle 바이너리를 원격 사이트로 미러링하고 마운트할 수 있습니다.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">데이터베이스를 수동으로 시작하거나 데이터베이스를 자동으로 시작하도록 가상 시스템을 구성하면 ESX 클러스터가 사이트에 걸쳐 있을 수 있습니다. 재해 발생 시 전환 후 재해 복구 사이트에서 가상 시스템을 온라인으로 전환할 수 있습니다. 재해 발생 시 가상 데이터베이스 서버를 호스팅하는 데이터 저장소를 사용하지 않는 한 설정할 필요가 없습니다<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> 연결된 볼륨에서.</block>
  <block id="6c2e01aca4f10a83d34e3f3046435e82" category="summary">SnapMirror 및 SyncMirror</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">거의 모든 애플리케이션에 데이터 복제가 필요합니다.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">가장 기본적인 수준에서 복제는 오프사이트에 저장된 테이프의 복제본 또는 대기 위치에 대한 애플리케이션 수준의 복제를 의미할 수 있습니다. 재해 복구란 서비스 손실이 발생할 경우 이러한 복제본을 사용하여 서비스를 온라인으로 전환하는 것을 말합니다.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP은 스토리지 어레이 내의 다양한 요구사항을 기본적으로 해결하여 다양한 요구사항을 충족할 수 있는 다양한 복제 옵션을 제공합니다. 이러한 옵션에는 원격 사이트에 대한 백업을 단순 복제할 수 있으며, 완전히 자동화된 동기식 솔루션까지 동일한 플랫폼에서 재해 복구와 고가용성을 제공하는 것이 포함됩니다.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">애플리케이션에 적용할 수 있는 기본 ONTAP 복제 기술은 NetApp SnapMirror 및 NetApp SyncMirror 기술입니다. 이러한 제품은 애드온 제품이 아니라 ONTAP에 완전히 통합되며 라이센스 키를 간단하게 추가하여 활성화할 수 있습니다. 스토리지 레벨 복제가 유일한 옵션은 아닙니다. Oracle DataGuard와 같은 애플리케이션 레벨 복제를 ONTAP 기반의 데이터 보호 전략에 통합할 수도 있습니다.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">적절한 선택은 특정 복제, 복구 및 보존 요구 사항에 따라 달라집니다.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">ONTAP SnapMirror를 참조하십시오</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror는 NetApp 비동기식 복제 솔루션으로, 데이터베이스와 관련 애플리케이션과 같이 복잡하고 동적인 대규모 데이터 세트를 보호하는 데 이상적입니다. 주요 값은 다음과 같습니다.</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">* 관리 기능. * SnapMirror는 스토리지 소프트웨어의 기본 구성 요소이므로 쉽게 구성하고 관리할 수 있습니다. 추가 제품이 필요하지 않습니다. 복제 관계는 몇 분 내에 설정할 수 있으며 스토리지 시스템에서 직접 관리할 수 있습니다.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">* 단순성 * 복제는 FlexVol 볼륨을 기반으로 하며, LUN 또는 파일 컨테이너인 LUN은 하나의 정합성 보장 그룹으로 복제됩니다.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">* 효율성. * 초기 복제 관계가 설정된 후에는 변경 사항만 복제됩니다. 또한 중복제거 및 압축과 같은 효율성 기능이 유지되므로 원격 사이트로 전송해야 하는 데이터의 양이 추가로 줄어듭니다.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">* 유연성. * 미러를 일시적으로 분리하여 재해 복구 절차를 테스트할 수 있으며, 완전한 재미러링 없이 미러링을 쉽게 재구축할 수 있습니다. 미러를 다시 동기화하려면 변경된 데이터만 적용해야 합니다. 또한 미러링은 재해가 끝나고 원래 사이트가 다시 가동된 후에 신속하게 재동기화를 수행할 수 있도록 되돌릴 수 있습니다. 마지막으로, 복제된 데이터의 읽기-쓰기 클론을 테스트 및 개발에 사용할 수 있습니다.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP는 여러 가지 복제 기술을 제공하지만 볼륨 간 비동기 미러링 옵션인 SnapMirror가 가장 유연합니다.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">앞에서 설명한 것처럼 FlexVol 볼륨은 스냅샷 기반 백업 및 SnapRestore 기반 복구를 위한 기본 관리 단위입니다. FlexVol 볼륨은 SnapMirror 기반 복제의 기본 단위이기도 합니다. 첫 번째 단계는 소스 볼륨의 기본 미러를 타겟 볼륨에 설정하는 것입니다. 이 미러 관계가 초기화되면 이후의 모든 작업은 변경된 데이터의 복제만을 기반으로 합니다.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">복구 관점에서 SnapMirror의 주요 가치는 다음과 같습니다.</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">SnapMirror 작업은 이해하기 쉽고 손쉽게 자동화할 수 있습니다.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">SnapMirror 복제본을 간단히 업데이트하려면 델타 변경사항만 복제되어야 하므로 대역폭 요구사항이 감소하고 업데이트를 더 자주 수행할 수 있습니다.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror는 매우 세분화됩니다. 단순한 볼륨 간 관계를 기반으로 개별적으로 관리되는 수백 개의 복제본과 복제 간격을 생성할 수 있습니다. 모든 경우에 한 가지 복제 방식을 적용할 필요는 없습니다.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">대칭 복사 방향은 변경 내용만 기반으로 관계를 업데이트하는 기능을 유지하면서 쉽게 되돌릴 수 있습니다. 따라서 전원 장애와 같은 재해 발생 후 운영 사이트가 서비스 상태로 복원된 후 신속한 장애 복구 기능을 사용할 수 있습니다. 변경 내용만 원본과 다시 동기화해야 합니다.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">거울은 쉽게 깨질 수 있고 효율적으로 재동기화하여 재해 복구 절차의 예행 연습을 수행할 수 있습니다.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">전체 블록 레벨 복제 모드에서 작동하는 SnapMirror는 볼륨의 데이터뿐만 아니라 스냅샷도 복제합니다. 이 기능은 재해 복구 사이트의 데이터 복사본과 전체 백업 세트를 모두 제공합니다.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">버전에 상관없이 유연한 모드에서 작동하는 SnapMirror를 사용하면 특정 스냅샷을 복제할 수 있으므로 운영 사이트와 2차 사이트에서 보존 시간이 다를 수 있습니다.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror Synchronous</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror Synchronous(SM-S)는 RPO=0 동기식 복제를 제공하는 SnapMirror의 향상된 기능입니다. 전체 데이터의 서브셋에만 동기식 미러링이 필요한 스토리지 아키텍처에서 가장 자주 사용됩니다.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S는 Sync 및 StrictSync의 두 가지 약간 다른 모드로 작동할 수 있습니다.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">동기화 모드에서는 변경 내용이 확인되기 전에 복제됩니다. 따라서 복제가 진행되는 한 RPO가 0이 보장됩니다. 변경 내용을 복제할 수 없는 경우 SM-S는 동기 모드를 종료하고 작업을 계속할 수 있습니다. 따라서 정상적인 상황에서는 RPO=0이 허용되지만 복제 대상을 사용할 수 없는 경우 데이터 프로세스가 완전히 중지되지 않습니다.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync는 RPO=0을 보장합니다. 변경 사항을 복제하지 못하면 I/O 오류가 발생하여 일반적으로 애플리케이션이 종료됩니다.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733 을 참조하십시오</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">SM-S에 대한 자세한 설명은 을 참조하십시오<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> ONTAP 공식 문서를 참조하십시오. 새로운 버전의 ONTAP에서 기능이 지속적으로 추가됩니다.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">정합성 보장 그룹</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP를 사용하면 일관성 그룹 스냅샷을 생성할 수 있습니다. 9.13.1부터 ONTAP은 볼륨 그룹을(ONTAP 용어의 볼륨은 LUN이 아니라 하나 이상의 파일 또는 LUN으로 구성된 관리 컨테이너라는 점을 유념하십시오.) 일관성 있는 그룹으로 복제할 수 있습니다.</block>
  <block id="80c6d3e933105ad9a2c104ec78444b8c" category="paragraph">SnapMirror 복제 및 분리 CG SnapMirror 관계는 볼륨 전체의 일관성을 유지하고, SnapMirror Synchronous 및 SnapMirror Business Continuity는 구성 볼륨 전체에서 일관성을 유지합니다.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">그 결과 다중 볼륨 데이터 세트를 복제하고 모든 볼륨이 상호 정합성이 보장되도록 할 수 있습니다. 무엇보다도, 이를 통해 추가 애플리케이션 또는 데이터베이스 복구 단계가 필요하지 않고 "미러링 중단"된 DR 작업을 수행할 수 있습니다.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster and SyncMirror 를 참조하십시오</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster는 또한 대규모 미션 크리티컬 워크로드를 대상으로 하는 동기식 복제 솔루션입니다. 복제는 SyncMirror를 기반으로 합니다. 가장 단순한 계층에서 SyncMirror는 두 개의 서로 다른 위치에 두 개의 완전한 RAID 보호 데이터 세트를 생성합니다. 데이터 센터 내의 인접한 방에 있거나 수 킬로미터 떨어진 곳에 있을 수 있습니다.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror는 ONTAP와 완벽하게 통합되며 RAID 레벨 이상으로 작동합니다. 따라서 Snapshot 복사본, SnapRestore 및 NetApp FlexClone과 같은 ONTAP의 모든 일반 기능이 원활하게 작동합니다. 여전히 ONTAP이며 동기 데이터 미러링 계층이 추가로 포함되어 있습니다.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">SyncMirror 데이터를 관리하는 ONTAP 컨트롤러 모음을 NetApp MetroCluster 구성이라고 합니다. MetroCluster의 주된 목적은 다양한 일반 및 재해 복구 장애 시나리오에서 동기식으로 미러링된 데이터에 대한 고가용성 액세스를 제공하는 것입니다.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">MetroCluster 및 SyncMirror를 통한 데이터 보호의 주요 가치는 다음과 같습니다.</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">정상적인 작업에서 SyncMirror는 여러 위치에 보장된 동기식 미러링을 제공합니다. 쓰기 작업은 두 사이트의 비휘발성 미디어에 있기 때문에 승인되지 않습니다.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">사이트 간 연결에 장애가 발생할 경우 SyncMirror는 자동으로 비동기식 모드로 전환되어 연결이 복원될 때까지 데이터를 제공하는 운영 사이트를 유지합니다. 복구되면 운영 사이트에 누적된 변경 사항을 효율적으로 업데이트하여 신속하게 재동기화할 수 있습니다. 전체 재초기화가 필요하지 않습니다.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror는 SyncMirror 기반 시스템과도 완벽하게 호환됩니다. 예를 들어, 기본 데이터베이스는 두 개의 지리적 사이트에 분산된 MetroCluster 클러스터에서 실행될 수 있습니다. 이 데이터베이스는 DevOps 환경에서 백업을 장기 아카이브나 클론 생성을 위해 세 번째 사이트에 복제할 수도 있습니다.</block>
  <block id="0660b44d1a6d7e0d905c3fe28eef63ab" category="summary">on ONTAP DR 절차 및 로그 전달</block>
  <block id="54bae719e8fa53582d5b2781b4952c6b" category="doc">로그 재생을 사용한 재해 복구</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Oracle 데이터베이스의 복제 절차는 기본적으로 백업 절차와 동일합니다. 기본적인 요구 사항은 복구 가능한 백업을 구성하는 스냅샷을 원격 스토리지 시스템에 복제해야 한다는 것입니다.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">앞서 로컬 데이터 보호에 대한 설명에서 설명한 것처럼 핫 백업 프로세스를 사용하거나 스냅샷 최적화 백업을 활용하여 복구 가능한 백업을 만들 수 있습니다.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">데이터 레이아웃</block>
  <block id="30394da99a39ca8264b8f7c0e6f679e0" category="paragraph">가장 중요한 요구사항은 데이터 파일을 하나 이상의 전용 볼륨으로 분리하는 것입니다. 다른 파일 형식으로 오염되지 않아야 합니다. 그 이유는 데이터 파일 복제가 아카이브 로그 같은 다른 데이터 유형의 복제와 완전히 독립적인지 확인하기 위해서입니다. 파일 레이아웃에 대한 추가 정보 및 스토리지 레이아웃을 스냅샷과 쉽게 사용할 수 있도록 보장하는 방법에 대한 자세한 내용은 을 참조하십시오  <block ref="5a4fdf6a1fc411e544cf6d70d47a8289" category="inline-link-macro-rx"></block>.</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">데이터 파일이 전용 볼륨으로 캡슐화된다고 가정할 때 다음 질문은 재실행 로그, 아카이브 로그, 제어 파일을 관리하는 방법입니다. 가장 간단한 접근 방식은 이러한 모든 데이터 유형을 단일 볼륨에 배치하는 것입니다. 이 경우 복제된 redo 로그, 아카이브 로그 및 제어 파일이 완벽하게 동기화된다는 이점이 있습니다. 불완전한 복구나 백업 제어 파일을 사용할 필요는 없지만 다른 잠재적인 복구 시나리오를 위해 백업 제어 파일을 스크립트 작성하는 것이 바람직할 수 있습니다.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">2볼륨 레이아웃</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">가장 간단한 레이아웃은 다음 그림에 나와 있습니다.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">이것이 가장 일반적인 접근 방식입니다. DBA 관점에서 볼 때 재실행 로그와 아카이브 로그의 모든 복사본을 동일한 볼륨에 생성하는 것은 드문 것처럼 보일 수 있습니다. 그러나 파일 및 LUN이 모두 동일한 기본 드라이브 세트에 있는 경우 분리 기능을 통해 보호 기능이 크게 향상되지는 않습니다.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">3볼륨 레이아웃</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">데이터 보호 또는 재실행 로그 I/O를 컨트롤러 간에 분산해야 하기 때문에 재실행 로그를 분리해야 하는 경우가 있습니다. 이 경우 아래 그림에 나와 있는 3개 볼륨 레이아웃을 복제에 사용할 수 있지만 불완전한 복구를 수행하거나 백업 제어 파일을 사용할 필요가 없습니다.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">따라서 소스의 독립 스핀들 및 컨트롤러 세트에 대해 redo 로그 및 제어 파일을 스트라이핑할 수 있습니다. 그러나 아카이브 로그와 하나의 제어 파일 및 redo 로그 세트는 아카이브 로그와 동기화된 상태로 복제할 수 있습니다.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">이 모델에서는 Redo Log B 볼륨이 복제되지 않습니다.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">재해 복구 절차 - 핫 백업</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">핫 백업을 사용하여 재해 복구를 수행하려면 다음 기본 절차를 사용하십시오.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">필수 구성 요소</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">Oracle 바이너리는 재해 복구 서버에 설치됩니다.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">데이터베이스 인스턴스는 에 나열됩니다<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">를 클릭합니다<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> 및<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> 또는<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> 이 인스턴스는 에 있어야 합니다<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> 디렉토리. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">재해 복구</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">데이터 파일과 공통 로그 볼륨의 미러를 제거합니다.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">데이터 파일 볼륨을 데이터 파일의 최신 핫 백업 스냅샷으로 복원합니다.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">SAN을 사용하는 경우 볼륨 그룹을 활성화하고 파일 시스템을 마운트합니다.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">원하는 지점으로 아카이브 로그를 재생합니다.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">전체 복구가 필요한 경우 현재 redo 로그를 재생합니다.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">NFS를 사용하면 데이터 파일 및 로그 파일용 NFS 파일 시스템을 재해 복구 서버에 언제든지 마운트할 수 있으므로 이러한 절차가 크게 간소화됩니다. 미러가 손상되면 읽기/쓰기가 됩니다.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">재해 복구 절차 - 스냅샷에 최적화된 백업</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">스냅샷 최적화 백업에서 복구하는 작업은 다음과 같은 변경 사항이 있는 핫 백업 복구 절차와 거의 동일합니다.</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">데이터 파일 볼륨을 현재 로그 볼륨 복제본 이전에 생성된 스냅샷으로 복구합니다.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">이러한 차이는 데이터베이스가 핫 백업 모드에 있는 동안 소스에서 스냅샷이 제대로 생성되었는지 확인할 필요가 없기 때문에 전체 복구 절차가 간소화됩니다. 재해 복구 절차는 재해 복구 사이트에 있는 스냅샷의 타임스탬프를 기반으로 합니다. 스냅샷이 생성된 시점의 데이터베이스 상태는 중요하지 않습니다.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">핫 백업 스냅샷을 사용한 재해 복구</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">핫 백업 스냅샷 복제를 기반으로 하는 재해 복구 전략의 한 예입니다. 또한 단순하고 확장 가능한 로컬 백업 전략의 한 예입니다.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">예제 데이터베이스는 기본적인 두 볼륨 아키텍처에 있습니다.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> 에는 데이터 파일 및 이 포함되어 있습니다<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> 는 결합된 redo 로그, 아카이브 로그 및 제어 파일에 사용됩니다.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">야간 데이터 파일 백업용 스케줄 하나와 로그 파일 백업용 스케줄 두 개가 필요합니다. 이를 각각 자정과 15분이라고 합니다.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">그런 다음 이러한 스케줄이 스냅샷 정책 내에서 사용됩니다<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> 및<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, 아래 그림과 같이:</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">마지막으로 이러한 스냅샷 정책이 볼륨에 적용됩니다.</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">볼륨의 백업 일정을 정의합니다. 데이터 파일 스냅샷은 자정에 생성되며 60일 동안 유지됩니다. 로그 볼륨에는 15분 간격으로 생성된 72개의 스냅샷이 포함되어 최대 18시간 동안 사용 가능합니다.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">그런 다음 데이터 파일 스냅샷이 생성될 때 데이터베이스가 핫 백업 모드인지 확인합니다. 이 작업은 지정된 SID에서 백업 모드를 시작하고 중지하는 몇 가지 기본 인수를 허용하는 작은 스크립트를 사용하여 수행됩니다.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">이 단계를 수행하면 자정 스냅샷을 둘러싸고 4분 동안 데이터베이스가 핫 백업 모드에 있게 됩니다.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">재해 복구 사이트로의 복제는 다음과 같이 구성됩니다.</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">로그 볼륨 대상은 15분마다 업데이트됩니다. 이 경우 RPO는 약 15분입니다. 정확한 업데이트 간격은 업데이트 중에 전송해야 하는 총 데이터 볼륨에 따라 약간 달라집니다.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">데이터 파일 볼륨 대상은 6시간 간격으로 업데이트됩니다. RPO 또는 RTO에는 영향을 미치지 않습니다. 재해 복구가 필요한 경우 첫 번째 단계 중 하나는 데이터 파일 볼륨을 핫 백업 스냅샷으로 다시 복원하는 것입니다. 보다 빈번한 업데이트 간격의 목적은 이 볼륨의 전송 속도를 부드럽게 하는 것입니다. 업데이트가 하루에 한 번 예약된 경우 해당 날짜에 누적된 모든 변경 사항을 한 번에 전송해야 합니다. 업데이트가 자주 이루어지므로 하루 종일 변경 내용이 점차 복제됩니다.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">재해가 발생할 경우 첫 번째 단계는 두 볼륨의 미러를 분리하는 것입니다.</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">이제 복제본이 읽기-쓰기입니다. 다음 단계는 로그 볼륨의 타임스탬프를 확인하는 것입니다.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">로그 볼륨의 가장 최근 사본은 3월 14일 13:30:00입니다.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">그런 다음 로그 볼륨의 상태 바로 전에 생성된 핫 백업 스냅샷을 식별합니다. 로그 재생 프로세스에는 핫 백업 모드 중에 생성된 모든 아카이브 로그가 필요하므로 이 작업이 필요합니다. 따라서 로그 볼륨 복제본은 핫 백업 이미지보다 오래된 것이어야 합니다. 그렇지 않으면 필요한 로그가 포함되지 않습니다.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">가장 최근에 생성된 스냅샷은 입니다<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. 이 이미지는 데이터 파일의 최신 핫 백업 이미지이며 다음과 같이 복원됩니다.</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">이 단계에서는 이제 데이터베이스를 복구할 수 있습니다. SAN 환경인 경우 다음 단계에는 볼륨 그룹을 활성화하고 파일 시스템을 마운트하는 작업이 포함되며, 이는 쉽게 자동화할 수 있습니다. 이 예에서는 NFS를 사용하기 때문에 파일 시스템이 이미 마운트되어 읽기/쓰기로 전환되어 미러가 손상되는 즉시 마운트하거나 활성화할 필요가 없습니다.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">이제 데이터베이스를 원하는 시점으로 복구하거나 복제된 재실행 로그 사본과 관련하여 완전히 복구할 수 있습니다. 이 예에서는 결합된 아카이브 로그, 제어 파일 및 재실행 로그 볼륨의 값을 보여 줍니다. 백업 제어 파일에 의존하거나 로그 파일을 재설정할 필요가 없기 때문에 복구 프로세스가 매우 간단합니다.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">스냅샷 최적화 백업을 통한 재해 복구</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">스냅샷 최적화 백업을 사용하는 재해 복구 절차는 핫 백업 재해 복구 절차와 거의 동일합니다. 핫 백업 스냅샷 절차와 마찬가지로 기본적으로 재해 복구에서 사용할 수 있도록 백업을 복제하는 로컬 백업 아키텍처의 확장이기도 합니다. 다음 예에서는 자세한 구성 및 복구 절차를 보여 줍니다. 이 예에서는 핫 백업과 스냅샷 최적화 백업의 주요 차이점을 설명합니다.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">예제 데이터베이스는 기본적인 두 볼륨 아키텍처에 있습니다.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> 에는 데이터 파일, 가 포함되어 있습니다<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> 는 결합된 redo 로그, 아카이브 로그 및 제어 파일에 사용됩니다.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">야간 데이터 파일 백업용 스케줄 하나와 로그 파일 백업용 스케줄 두 개가 필요합니다. 이를 각각 자정과 15분이라고 합니다.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">이렇게 하면 볼륨의 최종 백업 일정이 제어됩니다. 스냅샷은 자정에 생성되며 60일 동안 유지됩니다. 로그 볼륨에는 15분 간격으로 생성된 72개의 스냅샷이 포함되어 최대 18시간 동안 사용 가능합니다.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">로그 볼륨 대상은 15분마다 업데이트됩니다. 이 경우 RPO는 약 15분이며, 업데이트 중에 전송해야 하는 총 데이터 볼륨에 따라 정확한 업데이트 간격이 약간 달라집니다.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">데이터 파일 볼륨 대상은 6시간마다 업데이트됩니다. RPO 또는 RTO에는 영향을 미치지 않습니다. 재해 복구가 필요한 경우 먼저 데이터 파일 볼륨을 핫 백업 스냅샷으로 복원해야 합니다. 보다 빈번한 업데이트 간격의 목적은 이 볼륨의 전송 속도를 부드럽게 하는 것입니다. 업데이트가 하루에 한 번 예약된 경우 해당 날짜에 누적된 모든 변경 사항을 한 번에 전송해야 합니다. 업데이트가 자주 이루어지므로 하루 종일 변경 내용이 점차 복제됩니다.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">재해가 발생할 경우 첫 번째 단계는 모든 볼륨의 미러를 분리하는 것입니다.</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">로그 볼륨의 가장 최근 사본은 3월 14일 13:30입니다. 그런 다음 로그 볼륨의 상태 바로 전에 생성된 데이터 파일 스냅샷을 식별합니다. 로그 재생 프로세스에는 스냅샷 바로 전부터 원하는 복구 지점까지 모든 아카이브 로그가 필요하므로 이 작업이 필요합니다.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">가장 최근에 생성된 스냅샷은 입니다<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. 이 스냅샷을 복원합니다.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">이제 데이터베이스를 복구할 준비가 되었습니다. SAN 환경에서는 볼륨 그룹을 활성화하고 파일 시스템을 마운트하여 쉽게 자동화할 수 있습니다. 그러나 이 예에서는 NFS를 사용하고 있으므로 미러가 손상된 순간 추가 마운트나 활성화가 필요 없이 파일 시스템이 이미 마운트되어 읽기/쓰기로 전환되었습니다.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">이제 데이터베이스를 원하는 시점으로 복구하거나 복제된 재실행 로그 사본과 관련하여 완전히 복구할 수 있습니다. 이 예에서는 결합된 아카이브 로그, 제어 파일 및 재실행 로그 볼륨의 값을 보여 줍니다. 백업 제어 파일에 의존하거나 로그 파일을 재설정할 필요가 없기 때문에 복구 프로세스가 매우 간단합니다.</block>
  <block id="d6597945276340ba33115e737eb4b489" category="summary">Oracle 데이터베이스에 대한 정합성 보장 그룹 복제</block>
  <block id="fc506ae4ea109f50758acc176bcb5341" category="doc">일관성 그룹 재해 복구</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">일관성 그룹 복제는 SnapMirror를 통해 단일 볼륨의 복제를 예약하는 것만큼 간단하게 수행할 수 있습니다. 여기에는 데이터 파일, 제어 파일, 아카이브 로그 및 재실행 로그가 포함됩니다. 모든 SnapMirror를 업데이트할 때마다 대상 사이트에 데이터베이스의 새 복사본이 생성됩니다. 이 복사본은 미러를 깨뜨려 활성화할 수 있도록 일관되며 즉시 수행됩니다.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">데이터베이스가 여러 볼륨으로 확장되어야 하는 경우에는 일관성 그룹 스냅샷(CG-스냅샷)이 필요합니다.</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">블록 레벨 복제 모드에서 SnapMirror와 함께 사용할 경우 이 전략의 또 다른 이점은 소스 스토리지 시스템에서 모든 스냅샷을 완벽하게 복제한다는 것입니다. 재해 복구 복제본과 함께 전체 백업 보완이 복제됩니다.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Oracle 아카이브 로그 계층화</block>
  <block id="113d9dffdeb8fa14877fc8cf8ca7c9d5" category="doc">Oracle 로그 계층화</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">FabricPool의 가장 중요한 용도는 데이터베이스 트랜잭션 로그와 같은 알려진 콜드 데이터의 효율성을 개선하는 것입니다.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Oracle 백업 계층화</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">기존 애플리케이션 백업에는 원래 데이터베이스의 위치 외부에서 파일 기반 백업을 생성하는 Oracle Recovery Manager 같은 제품이 포함됩니다.</block>
  <block id="6cddb309df5eb8791dc990f72ef2deb2" category="summary">Oracle 계층화 정책</block>
  <block id="7ba3322dbc0b3c33a66f1963e80b7a2a" category="doc">Oracle 데이터베이스 계층화 정책</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">ONTAP에서는 성능 계층의 Oracle 데이터가 용량 계층으로 재배치되는 방식을 제어하는 4가지 정책을 사용할 수 있습니다.</block>
  <block id="47f6817eca23122cc683f7c2759e6ecb" category="summary">Oracle 전체 타일 계층화</block>
  <block id="1def0ac22a738b54cce584e969065918" category="doc">Oracle 전체 파일 계층화</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">FabricPool 계층화는 블록 레벨에서 작동하지만 파일 레벨 계층화를 제공하는 데 사용될 수도 있습니다.</block>
  <block id="468853d9ed2134af17ede5fd165a8dff" category="summary">FabricPool를 통한 부분 파일 계층화</block>
  <block id="5638b2f30ee966b3ff84bac350092971" category="doc">Oracle 부분 파일 계층화</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">FabricPool가 블록 레벨에서 작동하므로 변경이 필요한 파일은 부분적으로 오브젝트 스토리지로 계층화할 수 있고 성능 계층에 부분적으로 유지할 수도 있습니다.</block>
  <block id="dd22ff2cf158f98efbd92f4522b3064b" category="summary">오브젝트 저장소의 액세스가 중단되는 동안 데이터베이스 액세스가 가능합니다</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">오브젝트 저장소 액세스가 중단됩니다</block>
  <block id="bbb21240a2cc48eb7a229ec824e70cdf" category="summary">Oracle with FabricPool 계층화 개요</block>
  <block id="ec2ffb259f21d115e5481eb0f215aa0d" category="doc">Oracle 계층화 개요</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">FabricPool 계층화가 Oracle 및 다른 데이터베이스에 미치는 영향을 이해하려면 낮은 수준의 FabricPool 아키텍처에 대한 이해가 필요합니다.</block>
  <block id="cd6b77e4d343896571bc445479f24588" category="summary">Pracle 계층화 검색 정책</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">검색 정책</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">계층화 정책은 성능 계층에서 용량 계층으로 계층화하는 Oracle 데이터베이스 블록을 제어합니다. 검색 정책은 계층화된 블록을 읽을 때 수행되는 작업을 제어합니다.</block>
  <block id="95ab96ac5aaeae15f7b499d0fa0313cf" category="summary">Oracle 스냅샷 계층화</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Oracle 데이터베이스 LUN 사이징 및 LUN 수 지침</block>
  <block id="b9e88e2eb3d5eef807fc42db706d866a" category="doc">Oracle LUN 사이징 및 LUN 수</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">최적의 LUN 크기와 사용할 LUN 수를 선택하는 것은 Oracle 데이터베이스의 성능 및 관리 효율성을 최적화하는 데 매우 중요합니다.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">Oracle 데이터베이스 및 NFS 임대 및 잠금</block>
  <block id="472f36eb81330c2c27f02245ce8a911e" category="doc">NFS 임대 및 잠금 - Oracle</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3은 상태를 저장하지 않습니다. 이는 사실상 NFS 서버(ONTAP)가 어떤 파일 시스템이 마운트되었는지, 누가 어떤 잠금이 설정되어 있는지 추적하지 않는다는 것을 의미합니다.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP에는 마운트 시도를 기록하는 몇 가지 기능이 있으므로 어떤 클라이언트가 데이터에 액세스할 수 있는지 알 수 있고, 권고 잠금이 있을 수 있지만 이 정보가 100% 완전하지는 않을 수 있습니다. NFS 클라이언트 상태 추적은 NFSv3 표준의 일부가 아니므로 완료할 수 없습니다.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">NFSv4 상태</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">이와 반대로 NFSv4는 상태 저장 방식입니다. NFSv4 서버는 어떤 클라이언트가 어떤 파일 시스템을 사용하고 있는지, 어떤 파일이 있는지, 어떤 파일 및/또는 파일 영역이 잠겨 있는지 등을 추적합니다 즉, 상태 데이터를 최신 상태로 유지하려면 NFSv4 서버 간에 정기적인 통신이 필요합니다.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">NFS 서버에서 관리하는 가장 중요한 상태는 NFSv4 잠금 및 NFSv4 리스 상태이며, 서로 매우 밀접하게 연관되어 있습니다. 당신은 각각의 작동 방식 및 서로 어떻게 관련되는지 이해해야 합니다.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">NFSv4 잠금</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">NFSv3에서는 잠금은 권장됩니다. NFS 클라이언트는 "잠긴" 파일을 계속 수정하거나 삭제할 수 있습니다. NFSv3 잠금은 단독으로 만료되지 않고 제거되어야 합니다. 이로 인해 문제가 발생합니다. 예를 들어, NFSv3 잠금을 생성하는 클러스터 애플리케이션이 있는데 노드 중 하나에 장애가 발생하면 어떻게 해야 합니까? 나머지 노드에서 애플리케이션을 코딩하여 잠금을 제거할 수 있지만 안전한지 어떻게 알 수 있습니까? "장애가 발생한" 노드가 작동 중이지만 나머지 클러스터와 통신하지 않는 것 같습니까?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">NFSv4에서는 잠금 기간이 제한됩니다. 잠금을 보유한 클라이언트가 NFSv4 서버에 계속 체크인하는 한 다른 클라이언트는 이러한 잠금을 가져올 수 없습니다. 클라이언트가 NFSv4를 통해 체크인하지 못하면 서버에서 잠금이 취소되고 다른 클라이언트가 잠금을 요청하고 받을 수 있습니다.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">NFSv4 임대</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">NFSv4 잠금은 NFSv4 임대와 연결됩니다. NFSv4 클라이언트가 NFSv4 서버와 연결을 설정하면 임대됩니다. 클라이언트가 잠금을 얻는 경우(여러 유형의 잠금이 있음) 잠금이 임대와 연결됩니다.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">이 임대에 정의된 시간 초과가 있습니다. 기본적으로 ONTAP는 시간 초과 값을 30초로 설정합니다.</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">즉, NFSv4 클라이언트는 30초마다 NFSv4 서버에 체크인해야 리스를 갱신할 수 있습니다.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">리스는 모든 활동에 의해 자동으로 갱신되므로 클라이언트가 작업을 수행하는 경우 추가 작업을 수행할 필요가 없습니다. 응용 프로그램이 조용해지고 실제 작업을 수행하지 않는 경우 대신 연결 유지 작업(시퀀스라고 함)을 수행해야 합니다. "아직 여기 있어요. 리스를 새로 고치세요."라고 말하는 것입니다.</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3은 상태를 저장하지 않습니다. 클라이언트로부터 통신을 기대하지 않습니다. NFSv4는 상태 저장이며 임대 기간이 경과하면 임대가 만료되고 잠금이 해제되고 잠긴 파일을 다른 클라이언트에서 사용할 수 있게 됩니다.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">NFSv3을 사용하면 네트워크 케이블을 이동할 수 있고, 네트워크 스위치를 재부팅하고, 구성을 변경하며, 나쁜 부분이 전혀 발생하지 않도록 매우 확신할 수 있습니다. 일반적으로 응용 프로그램은 네트워크 연결이 다시 작동할 때까지 인내심을 가지고 기다립니다.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">NFSv4를 사용하면 30초 안에 작업을 완료할 수 있습니다(ONTAP 내에서 이 매개 변수의 값을 늘리지 않는 한). 이 값을 초과하면 리스가 시간 초과됩니다. 일반적으로 이 경우 응용 프로그램이 충돌합니다.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">예를 들어, Oracle 데이터베이스가 있는데 네트워크 연결 손실("네트워크 파티션"이라고도 함)이 임대 시간 초과를 초과하면 데이터베이스가 충돌합니다.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">이 경우 Oracle 경고 로그에서 발생하는 작업의 예는 다음과 같습니다.</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">syslogs를 보면 다음과 같은 몇 가지 오류가 표시됩니다.</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">로그 메시지는 일반적으로 응용 프로그램 정지 이외의 문제의 첫 번째 징후입니다. 일반적으로 프로세스와 운영 체제 자체가 NFS 파일 시스템에 대한 액세스 시도를 차단하기 때문에 네트워크가 중단되는 동안에는 아무 것도 표시되지 않습니다.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">네트워크가 다시 작동하면 오류가 나타납니다. 위의 예에서 연결이 다시 설정되면 OS가 잠금을 다시 가져오려고 시도했지만 너무 늦었습니다. 임대가 만료되었고 잠금이 제거되었습니다. 이로 인해 오류가 Oracle 계층까지 전파되고 경고 로그에 메시지가 표시됩니다. 데이터베이스의 버전 및 구성에 따라 이러한 패턴의 변형이 표시될 수 있습니다.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">요약하면 NFSv3은 네트워크 중단은 허용하지만 NFSv4는 더 민감하며 정의된 임대 기간을 사용합니다.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">30초 시간 초과가 허용되지 않는 경우에는 어떻게 해야 합니까? 스위치가 재부팅되거나 케이블이 재배치되어 간헐적인 네트워크 중단이 발생하는 동적으로 변화하는 네트워크를 관리하는 경우 어떻게 해야 합니까? 임대 기간을 연장하도록 선택할 수 있지만, 이 작업을 수행하려면 NFSv4 유예 기간에 대한 설명이 필요합니다.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">NFSv4 유예 기간</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">NFSv3 서버를 재부팅하면 거의 즉시 IO를 처리할 수 있습니다. 그것은 고객에 대한 어떤 종류의 상태를 유지하지 않았다. 그 결과 ONTAP 테이크오버 작업이 거의 즉각적으로 발생하는 것으로 보이는 경우가 많습니다. 컨트롤러가 데이터 제공을 시작할 준비가 되면 토폴로지 변경을 알리는 ARP를 네트워크에 보냅니다. 일반적으로 클라이언트는 이를 거의 즉각적으로 감지하여 데이터가 다시 흐릅니다.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">하지만 NFSv4는 잠시 일시 중지됩니다. NFSv4의 작동 방식 중 일부에 불과합니다.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">NFSv4 서버는 임대, 잠금 및 누가 어떤 데이터를 사용하는지 추적해야 합니다. NFS 서버가 패닉 및 재부팅되거나 잠시 전원이 꺼지거나 유지 보수 작업 중에 다시 시작되면 임대/잠금이 발생하고 다른 클라이언트 정보가 손실됩니다. 서버에서 작업을 재개하기 전에 어떤 클라이언트가 어떤 데이터를 사용 중인지 파악해야 합니다. 유예 기간이 시작되는 곳입니다.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">NFSv4 서버의 전원을 갑자기 껐다 켜는 경우 다시 백업되면 입출력을 재개하려는 클라이언트는 기본적으로 "리스/잠금 정보가 손실되었습니다. 잠금 장치를 다시 등록하시겠습니까?" 이것이 유예 기간의 시작입니다. ONTAP에서는 기본적으로 45초로 설정됩니다.</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">그 결과, 재시작 후 모든 클라이언트가 임대를 재확보하고 잠금을 재설정하는 동안 컨트롤러는 IO를 일시 중지합니다. 유예 기간이 종료되면 서버가 입출력 작업을 재개합니다.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">리스 시간 초과 대 유예 기간</block>
  <block id="563494d7f0f6ebcb6698cac7f9705aaa" category="paragraph">유예 기간 및 임대 기간이 연결되었습니다. 위에서 언급한 것처럼 기본 임대 시간 초과는 30초입니다. 즉, NFSv4 클라이언트는 30초마다 서버에 체크인해야 합니다. 그렇지 않으면 리스와 잠금이 손실됩니다. NFS 서버가 임대/잠금 데이터를 재구축할 수 있는 유예 기간이 있으며 기본값은 45초입니다. ONTAP의 유예 기간은 임대 기간보다 15초 더 길어야 합니다. 이를 통해 최소 30초마다 리스를 갱신하도록 설계된 NFS 클라이언트 환경에서는 재시작 후 서버를 통해 체크인할 수 있습니다. 45초의 유예 기간은 최소 30초마다 리스를 갱신할 모든 고객이 확실히 그렇게 할 기회를 갖도록 합니다.</block>
  <block id="5e6b60906bbbb9a41b140c0749591489" category="paragraph">30초의 시간 초과가 허용되지 않는 경우 임대 기간을 연장할 수 있습니다. 60초의 네트워크 중단을 견디기 위해 리스 시간 제한을 60초로 늘리려면 유예 기간을 최소 75초로 늘려야 합니다. ONTAP에서는 임대 기간보다 15초 더 높게 설정해야 합니다. 이는 컨트롤러 페일오버 중 IO 일시 중단이 더 길다는 것을 의미합니다.</block>
  <block id="4611c7c931fc15a6feba513fe72e22de" category="paragraph">이것은 일반적으로 문제가 되지 않습니다. 일반 사용자는 연간 1~2회 ONTAP 컨트롤러를 업데이트하며, 하드웨어 장애로 인한 계획되지 않은 페일오버는 매우 드물게 발생합니다. 또한 60초 네트워크 중단이 발생할 가능성이 있는 네트워크가 있고 임대 시간 초과가 60초로 필요한 경우 드물게 발생하는 스토리지 시스템 장애 조치를 거부하여 75초 동안 일시 중지되지 않을 수 있습니다. 이미 60초 이상 일시 중지된 네트워크가 있음을 확인했습니다.</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">Oracle Direct NFS</block>
  <block id="f58bdad9659176e411f064fdb414233f" category="doc">Oracle directNFS를 참조하십시오</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">Oracle 데이터베이스는 두 가지 방법으로 NFS를 사용할 수 있습니다.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">먼저 운영 체제의 일부인 네이티브 NFS 클라이언트를 사용하여 마운트된 파일 시스템을 사용할 수 있습니다. 이를 커널 NFS 또는 kNFS라고도 합니다. NFS 파일 시스템은 다른 애플리케이션이 NFS 파일 시스템을 사용하는 것과 정확히 동일한 방식으로 Oracle 데이터베이스에 의해 마운트되고 사용됩니다.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">두 번째 방법은 Oracle Direct NFS(dNFS)입니다. Oracle 데이터베이스 소프트웨어 내에서 NFS 표준을 구현한 것입니다. Oracle 데이터베이스가 DBA에 의해 구성되거나 관리되는 방식은 변경되지 않습니다. 스토리지 시스템 자체에 올바른 설정이 있는 한 dNFS의 사용은 DBA 팀과 최종 사용자에게 투명해야 합니다.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">dNFS 기능이 활성화된 데이터베이스에는 여전히 일반적인 NFS 파일 시스템이 마운트되어 있습니다. 데이터베이스가 열리면 Oracle 데이터베이스가 일련의 TCP/IP 세션을 열고 NFS 작업을 직접 수행합니다.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">직접 NFS</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">Oracle Direct NFS의 기본 가치는 호스트 NFS 클라이언트를 우회하고 NFS 파일 작업을 NFS 서버에서 직접 수행하는 것입니다. 이를 활성화하려면 ODM(Oracle Disk Manager) 라이브러리를 변경하기만 하면 됩니다. 이 프로세스 관련 지침은 Oracle 설명서에 제공되어 있습니다.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">dNFS를 사용하면 입출력이 가능한 가장 효율적인 방식으로 수행되기 때문에 입출력 성능이 크게 향상되고 호스트와 스토리지 시스템의 부하가 감소합니다.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">또한 Oracle dNFS에는 네트워크 인터페이스 다중 경로 및 내결함성을 위한 * 옵션 * 이 포함되어 있습니다. 예를 들어, 2개의 10Gb 인터페이스를 서로 바인딩하여 20Gb 대역폭을 제공할 수 있습니다. 한 인터페이스에 장애가 발생하면 다른 인터페이스에서 I/O가 재시도됩니다. 전반적인 작동 방식은 FC 다중 경로와 매우 비슷합니다. 다중 경로는 1Gb 이더넷이 가장 일반적인 표준이었던 수년 전에 일반적이었습니다. 대부분의 Oracle 워크로드에는 10Gb NIC로 충분하지만 더 많은 작업이 필요한 경우 10Gb NIC를 연결할 수 있습니다.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">dNFS를 사용할 때는 Oracle Doc 1495104.1에 설명된 모든 패치를 설치하는 것이 중요합니다. 패치를 설치할 수 없는 경우 환경을 평가하여 문서에 설명된 버그가 문제를 유발하지 않는지 확인해야 합니다. 필요한 패치를 설치할 수 없어 dNFS를 사용할 수 없는 경우도 있습니다.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">DNS, DDNS, NIS 또는 기타 방법을 포함하여 어떤 유형의 라운드 로빈 이름 확인과도 dNFS를 함께 사용하지 마십시오. ONTAP에서 사용할 수 있는 DNS 로드 밸런싱 기능도 여기에 포함됩니다. dNFS를 사용하는 Oracle 데이터베이스가 호스트 이름을 IP 주소로 확인하면 이후 조회에서 호스트 이름을 변경해서는 안 됩니다. 변경할 경우 Oracle 데이터베이스 충돌과 잠재적 데이터 손상을 야기할 수 있습니다.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Direct NFS 및 호스트 파일 시스템 액세스</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">dNFS를 사용하면 호스트에 마운트된 가시적인 파일 시스템을 사용하는 애플리케이션이나 사용자 작업에 문제가 발생할 수 있습니다. dNFS 클라이언트가 호스트 OS에서 대역 외 파일 시스템에 액세스하기 때문입니다. dNFS 클라이언트는 운영 체제에 대한 지식 없이도 파일을 생성, 삭제 및 수정할 수 있습니다.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">단일 인스턴스 데이터베이스의 마운트 옵션을 사용할 때 이들 옵션은 파일과 디렉토리 특성의 캐싱을 활성화할 수 있으며 이에 따라 디렉토리의 콘텐츠가 캐싱됩니다. 따라서 dNFS는 파일을 생성할 수 있으며 OS가 디렉토리 콘텐츠를 다시 읽고 파일이 사용자에게 표시되기 전에 짧은 지연이 발생합니다. 일반적으로는 이것이 문제가 되지 않지만 드물게 SAP BR * Tools 같은 유틸리티에 문제가 발생할 수 있습니다. 이런 일이 발생하면 Oracle RAC 관련 권장사항을 사용하기 위한 마운트 옵션을 변경하여 문제를 해결하십시오. 이렇게 변경하면 모든 호스트 캐싱이 비활성화됩니다.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">(a) dNFS가 사용되고 (b) 파일 가시성의 지연으로 인해 문제가 발생하는 경우에만 마운트 옵션을 변경하십시오. dNFS를 사용하지 않는 경우 단일 인스턴스 데이터베이스에서 Oracle RAC 마운트 옵션을 사용하면 성능이 저하됩니다.</block>
  <block id="b1ced01e4bbcd95ec43a2756131f8f9d" category="admonition">에 대한 참고 사항을 참조하십시오<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> 인치 <block ref="657185beb26ec14433f7e083717fa98b" category="inline-link-macro-rx"></block> 비정상적인 결과를 초래할 수 있는 Linux 관련 dNFS 문제의 경우</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Oracle 데이터베이스에 대한 NFS 구성</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp은 30년 이상 엔터프라이즈급 NFS 스토리지를 제공하고 있으며 단순성 덕분에 클라우드 기반 인프라로의 전환과 함께 사용 사례가 증가하고 있습니다.</block>
  <block id="95e0ac965f4d3a739263ba13584b6411" category="inline-link-macro">NetApp ONTAP 모범 사례 기반 TR-4067 NFS</block>
  <block id="c46e4d65876bc5d9253e8e293f59b613" category="paragraph">NFS 프로토콜에는 다양한 요구사항이 있는 여러 버전이 포함되어 있습니다. ONTAP를 사용한 NFS 구성에 대한 자세한 내용은 을 참조하십시오 <block ref="e3fa0577f1d5ea8870d93a30eb76667f" category="inline-link-macro-rx"></block>. 다음 섹션에서는 보다 중요한 요구 사항 및 일반적인 사용자 오류에 대해 설명합니다.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">NFS 버전</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">운영 체제 NFS 클라이언트는 NetApp에서 지원되어야 합니다.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3은 NFSv3 표준 OS에서 지원됩니다.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3은 Oracle dNFS 클라이언트에서 지원됩니다.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4는 NFSv4 표준을 따르는 모든 OS에서 지원됩니다.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">NFSv4.1 및 NFSv4.2에는 특정 OS 지원이 필요합니다. 을 참조하십시오 <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> 지원되는 운영 체제.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">NFSv4.1에 대해 Oracle dNFS를 지원하려면 Oracle 12.2.0.2 이상이 필요합니다.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">NetApp 지원 매트릭스</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">를 클릭합니다 <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> NFSv3 및 NFSv4의 경우 특정 운영 체제가 포함되지 않습니다. RFC를 준수하는 모든 OS는 일반적으로 지원됩니다. IMT에서 NFSv3 또는 NFSv4 지원을 찾을 때 일치하는 항목이 표시되지 않으므로 특정 OS를 선택하지 마십시오. 모든 OS는 일반 정책에 의해 암시적으로 지원됩니다.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Linux NFSv3 TCP 슬롯 테이블</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">TCP 슬롯 테이블은 호스트 버스 어댑터(HBA) 큐 길이(queue depth)와 동등한 NFSv3의 기능입니다. 이들 테이블은 한 번에 수행될 수 있는 최대 NFS 작업의 수를 제어합니다. 기본값은 보통 16이며 최적의 성능을 발휘하기에 너무 낮습니다. 최신 Linux 커널에서는 반대의 문제가 발생하는데, 요청을 통해 NFS 서버를 포화시키는 수준까지 TCP 슬롯 테이블의 한계를 자동으로 높일 수 있습니다.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">최적의 성능을 얻으면서 성능 문제를 방지하려면 TCP 슬롯 테이블을 제어하는 커널 매개 변수를 조정하십시오.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">를 실행합니다<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> 명령을 실행하고 다음 매개 변수를 관찰합니다.</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">모든 Linux 시스템에는 가 포함되어 있습니다<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>그러나 일부에만 가 포함됩니다<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. 둘 다 128로 설정해야 합니다.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">이러한 매개 변수를 설정하지 않으면 성능에 상당한 영향을 미칠 수 있습니다. 경우에 따라 Linux 운영 체제가 충분한 I/O를 실행하지 않기 때문에 성능이 제한됩니다 또는 Linux 운영 체제가 처리할 수 있는 것보다 더 많은 I/O를 발급하려고 하면 I/O 지연 시간이 늘어납니다.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR과 NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">에서 데이터와 관련하여 과도한 양의 I/O가 초래하는 성능 문제를 보고하는 고객이 있습니다<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> 위치. 일반적으로, 성능 데이터가 대량으로 누적되기 전에는 이 문제가 발생하지 않습니다. 과도한 I/O의 이유는 알려지지 않았지만 이 문제는 Oracle 프로세스가 변경을 위해 타겟 디렉토리를 반복하여 스캐닝했기 때문인 것으로 추측됩니다.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">의 제거<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 및/또는<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 마운트 옵션을 사용하면 호스트 운영 체제 캐싱이 수행되고 스토리지 I/O 레벨이 낮아집니다.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">* NetApp는 배치하지 않을 것을 권장합니다<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> 을 사용하는 파일 시스템 데이터<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> 또는<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> 성능 문제를 일으킬 수 있기 때문입니다. 분리<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> 필요한 경우 데이터를 다른 마운트 지점으로 이동합니다.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">NFS - rootonly 및 mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP에는 이라는 NFS 옵션이 포함되어 있습니다<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> 서버가 높은 포트의 NFS 트래픽 연결을 허용할지 여부를 제어합니다. 보안 조치로서 루트 사용자만 1024 미만의 소스 포트를 사용하여 TCP/IP 연결을 열 수 있습니다. 이러한 포트는 일반적으로 사용자 프로세스가 아닌 OS 사용을 위해 예약되기 때문입니다. 이러한 제한을 통해 NFS 트래픽이 NFS 클라이언트를 에뮬레이트하는 악의적인 프로세스가 아닌 실제 운영 체제 NFS 클라이언트에서 발생하도록 할 수 있습니다. Oracle dNFS 클라이언트는 사용자 공간 드라이버이지만 프로세스는 루트로 실행되므로 일반적으로 의 값을 변경할 필요가 없습니다<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. 이 연결은 로우 포트로 이루어집니다.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">를 클릭합니다<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> 옵션은 NFSv3에만 적용됩니다. 1024 이상의 포트에서 RPC 마운트 호출을 수락할지 여부를 제어합니다. dNFS를 사용하면 클라이언트가 루트로 다시 실행되므로 1024 미만의 포트를 열 수 있습니다. 이 매개 변수는 효과가 없습니다.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">프로세스 NFS 버전 4.0 이상을 통해 dNFS 연결을 열면 루트로 실행되지 않으므로 1024를 초과하는 포트가 필요합니다. 를 클릭합니다<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> dNFS가 연결을 완료하려면 매개 변수를 disabled로 설정해야 합니다.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">If(경우<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> 이 활성화되면 dNFS 접속을 여는 마운트 단계 동안 작동이 중단됩니다. sqlplus 출력은 다음과 유사합니다.</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">파라미터는 다음과 같이 변경할 수 있다.</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">드문 경우지만 nfs-rootonly와 mount-rootonly를 모두 disabled로 변경해야 할 수도 있습니다. 서버가 매우 많은 수의 TCP 연결을 관리하는 경우 1024 미만의 포트를 사용할 수 없으며 OS가 더 높은 포트를 사용하도록 강제됩니다. 연결을 완료하려면 이 두 ONTAP 매개 변수를 변경해야 합니다.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">NFS 내보내기 정책: superuser 및 setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Oracle 바이너리가 NFS 공유에 있는 경우 내보내기 정책에 수퍼유저 및 setuid 권한이 포함되어야 합니다.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">사용자 홈 디렉토리와 같은 일반 파일 서비스에 사용되는 공유 NFS 내보내기는 일반적으로 루트 사용자를 스쿼시 처리합니다. 즉, 파일 시스템을 마운트한 호스트에서 루트 사용자의 요청이 더 낮은 권한을 가진 다른 사용자로 다시 매핑됩니다. 이렇게 하면 특정 서버의 루트 사용자가 공유 서버의 데이터에 액세스하지 못하도록 하여 데이터를 보호할 수 있습니다. setuid 비트는 공유 환경에서 보안 위험이 될 수도 있습니다. setuid 비트를 사용하면 명령을 호출하는 사용자와 다른 사용자로 프로세스를 실행할 수 있습니다. 예를 들어, setuid 비트가 있는 루트가 소유한 쉘 스크립트는 루트로 실행됩니다. 다른 사용자가 쉘 스크립트를 변경할 수 있는 경우, 루트가 아닌 사용자는 스크립트를 업데이트하여 명령을 루트로 실행할 수 있습니다.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">Oracle 바이너리는 루트가 소유한 파일을 포함하며 setuid 비트를 사용합니다. Oracle 바이너리가 NFS 공유에 설치된 경우 내보내기 정책에 적절한 수퍼 사용자 및 setuid 권한이 포함되어야 합니다. 아래 예제에서는 규칙에 두 가지가 모두 포함되어 있습니다<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> 있습니다<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> 시스템 인증을 사용하여 NFS 클라이언트에 대한 (루트) 액세스.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">NFSv4/4.1 구성</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">대부분의 애플리케이션에서 NFSv3과 NFSv4 사이에는 아주 작은 차이가 있습니다. 애플리케이션 입출력은 대개 매우 간단한 입출력이며 NFSv4에서 제공되는 일부 고급 기능의 이점은 크게 활용되지 않습니다. 더 높은 버전의 NFS는 데이터베이스 스토리지의 관점에서 "업그레이드"로 간주해서는 안 되며, 추가 기능이 포함된 NFS 버전으로 간주해야 합니다. 예를 들어 Kerberos 개인 정보 보호 모드(krb5p)의 엔드 투 엔드 보안이 필요한 경우 NFSv4가 필요합니다.</block>
  <block id="5cee42a6ee353ec8d6538898f8e63d2d" category="inline-link">NetApp ONTAP 모범 사례 기반 TR-4067 NFS</block>
  <block id="1ca271e9db310f8a7fb925b114fd6811" category="paragraph">NFSv4로 전환하는 것은 마운트 옵션을 단순히 vers=3에서 vers=4.1로 변경하는 것보다 더 복잡합니다. 운영 체제 구성에 대한 지침을 포함하여 ONTAP를 사용한 NFSv4 구성에 대한 자세한 설명은 을 참조하십시오<block ref="2d2395ce3ab8a9852abebca9822b9553" category="inline-link-rx"></block>. 이 TR의 다음 섹션에서는 NFSv4 사용을 위한 몇 가지 기본 요구 사항에 대해 설명합니다.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">NFSv4 도메인입니다</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">NFSv4/4.1 구성에 대한 자세한 설명은 이 문서의 범위를 벗어나지만 도메인 매핑이 일치하지 않는 문제가 흔히 발생합니다. sysadmin 관점에서 NFS 파일 시스템은 정상적으로 작동하는 것처럼 보이지만 애플리케이션이 특정 파일에 대한 권한 및/또는 setuid에 대한 오류를 보고합니다. 경우에 따라 관리자는 응용 프로그램 바이너리의 사용 권한이 손상되었다는 잘못된 결론을 내리고 실제 문제가 도메인 이름일 때 chown 또는 chmod 명령을 실행했습니다.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">NFSv4 도메인 이름은 ONTAP SVM에 설정됩니다.</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">호스트의 NFSv4 도메인 이름은 에 설정되어 있습니다<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">도메인 이름이 일치해야 합니다. 그렇지 않은 경우 에 다음과 유사한 매핑 오류가 나타납니다<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">Oracle 데이터베이스 바이너리와 같은 애플리케이션 바이너리에는 setuid 비트가 있는 루트가 소유한 파일이 포함됩니다. 즉, NFSv4 도메인 이름이 일치하지 않으면 Oracle 시작 시 오류가 발생하고 라는 파일의 소유권이나 사용 권한에 대한 경고가 발생합니다<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>에 있습니다<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> 디렉토리. 다음과 같이 나타납니다.</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">이 파일의 소유권이 아무도 없는 경우 NFSv4 도메인 매핑 문제가 있을 수 있습니다.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">이 문제를 해결하려면 을 선택합니다<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> ONTAP에서 v4-id-domain 설정을 기준으로 한 파일로, 일관성이 있는지 확인합니다. 그렇지 않은 경우 필요한 변경 작업을 수행하고 를 실행합니다<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>를 클릭하고 변경 사항이 전파될 때까지 잠시 기다립니다. 그런 다음 파일 소유권이 루트로 올바르게 인식되어야 합니다. 사용자가 실행을 시도한 경우<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> NFS 도메인 구성이 수정되기 전에 이 파일에서 를 실행해야 할 수도 있습니다<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> 다시?</block>
  <block id="51fb8677d45bb006235a9f8cbe477f6f" category="summary">NFS 속성 데이터베이스 캐싱</block>
  <block id="4da0a3b9c2e8fc0df8844a41ac133401" category="doc">데이터베이스를 통한 NFS 캐싱</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">다음과 같은 마운트 옵션이 있으면 호스트 캐싱이 비활성화됩니다.</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">이러한 설정은 소프트웨어 설치, 패치 적용 및 백업/복원 작업 속도에 심각한 악영향을 미칠 수 있습니다. 경우에 따라, 특히 클러스터형 애플리케이션의 경우 클러스터의 모든 노드에 캐시 정합성을 보장해야 하기 때문에 이러한 옵션이 불가피하게 필요하게 되었습니다. 고객이 이러한 매개 변수를 잘못 사용하면 불필요한 성능 저하가 발생하게 됩니다.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">많은 고객들이 애플리케이션 바이너리의 설치 또는 패칭 중에 이러한 마운트 옵션을 임시로 제거합니다. 설치 또는 패칭 프로세스 중에 타겟 디렉토리를 적극적으로 사용하는 여타 프로세스가 없음이 확인되면 제거를 안전하게 수행할 수 있습니다.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Oracle 데이터베이스에 대한 LVM 스트라이프 구성</block>
  <block id="7844f2cc495a938f3039da5801958506" category="doc">Oracle 데이터베이스를 사용한 LVM 스트라이핑</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">LVM 스트라이핑은 여러 LUN에 데이터를 배포하는 것을 의미합니다. 그 결과 많은 데이터베이스의 성능이 크게 향상되었습니다.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Oracle 데이터베이스와의 LUN 정렬</block>
  <block id="c4cb2c6af5d7b6c38cd7e588d846e8b4" category="doc">Oracle 입출력에 대한 LUN 정렬</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">LUN 정렬은 기본 파일 시스템 레이아웃과 관련하여 I/O를 최적화하는 것을 칭합니다.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">효율성</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">정렬 불량 경고</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">ONTAP SAN 호스트 구성</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">Solaris 환경에서는 정렬이 더 복잡합니다. 을 참조하십시오<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Solaris x86 환경에서는 대부분의 구성에 여러 개의 파티션 계층이 있기 때문에 정렬이 제대로 되는지 더 주의를 기울여야 합니다. Solaris x86 파티션 조각은 일반적으로 표준 마스터 부트 레코드 파티션 테이블의 상단에 존재합니다.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Oracle의 NFS 전송 크기</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Oracle 데이터베이스의 NFS 전송 크기</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">기본적으로 ONTAP에서는 NFS I/O 크기를 64K로 제한합니다.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">대부분의 애플리케이션 및 데이터베이스에서 랜덤 I/O는 최대 64K 미만으로 훨씬 작은 블록 크기를 사용합니다. 대규모 블록 I/O는 일반적으로 병렬화되므로 최대 64K 역시 최대 대역폭을 확보하는 데 제한이 없습니다.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">일부 워크로드는 최대 64K로 인해 제한이 발생합니다. 특히, 데이터베이스가 적은 수의 입출력을 수행할 수 있는 경우 백업 또는 복구 작업 또는 데이터베이스 전체 테이블 스캔과 같은 단일 스레드 작업이 보다 빠르고 효율적으로 실행됩니다. ONTAP의 최적의 I/O 처리 크기는 256K입니다.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">특정 ONTAP SVM의 최대 전송 크기를 다음과 같이 변경할 수 있습니다.</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">ONTAP에서 허용되는 최대 전송 크기를 현재 마운트된 NFS 파일 시스템의 rsize/wsize 값보다 작게 줄이지 마십시오. 이로 인해 일부 운영 체제에서 중단되거나 심지어 데이터 손상이 발생할 수 있습니다. 예를 들어, NFS 클라이언트가 현재 rsize/wsize 65536으로 설정되어 있는 경우 클라이언트 자체가 제한되기 때문에 ONTAP 최대 전송 크기를 65536에서 1048576 사이에서 아무 영향 없이 조정할 수 있습니다. 최대 전송 크기를 65536 미만으로 줄이면 가용성 또는 데이터가 손상될 수 있습니다.</block>
  <block id="a5c97d9c3645b9a26e3febeb4bc95e24" category="summary">ONTAP를 사용하는 ASM 재생 유틸리티</block>
  <block id="861a5ecc95a8478c750be41bf2ddd6f5" category="doc">ASM 재생 유틸리티 및 제로 블록 감지</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP은 인라인 압축이 활성화되었을 때 파일 또는 LUN에 기록되는 제로 블록을 효율적으로 제거합니다. Oracle ASRU(ASM Reclamation Utility)와 같은 유틸리티는 사용되지 않는 ASM 익스텐트에 0을 쓰는 방식으로 작동합니다.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">데이터베이스 관점에서 보면 ASM 디스크 그룹은 0을 포함하고 LUN의 해당 영역을 읽으면 스트림이 0이 되지만 ONTAP는 드라이브에 0을 저장하지 않습니다. 그 대신, 내부적으로 LUN의 제로화된 영역을 모든 데이터가 비어 있는 상태로 표시하는 간단한 메타데이터 변경이 이루어집니다.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">마찬가지로 0의 블록이 실제로 스토리지 시스템 내에서 쓰기로 처리되지 않기 때문에 제로화된 데이터를 포함하는 성능 테스트는 유효하지 않습니다.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">ASRU를 사용하는 경우 모든 Oracle 권장 패치가 설치되어 있는지 확인합니다.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">Oracle 데이터베이스를 사용한 LUN 및 LVM 크기 조정</block>
  <block id="e0327f97ac271a738dd1ac6b182a4369" category="doc">LUN 리사이징과 LVM 기반 리사이징</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">SAN 기반 파일 시스템이 용량 제한에 도달하면 사용 가능한 공간을 늘리기 위한 두 가지 옵션이 있습니다.</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Oracle 데이터베이스를 보호하기 위한 NVFAIL 구성</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle 및 NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL은 대규모 페일오버 시나리오 중에 무결성을 보장하는 ONTAP의 기능입니다.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">데이터베이스는 대규모 내부 캐시를 유지하기 때문에 스토리지 페일오버 중에 손상에 취약합니다. 재앙적인 이벤트에서 ONTAP 페일오버를 강제 적용하거나 MetroCluster 스위치오버를 강제 적용해야 하는 경우, 전체 구성 상태와 관계없이 이전에 승인된 변경 사항을 효과적으로 삭제할 수 있기 때문입니다. 스토리지 어레이의 콘텐츠가 시간 뒤로 이동하며, 데이터베이스 캐시의 상태는 디스크에 있는 데이터의 상태를 더 이상 반영하지 않습니다. 이러한 불일치로 인해 데이터가 손상됩니다.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">캐싱은 애플리케이션이나 서버 계층에서 발생할 수 있습니다. 예를 들어, 운영 사이트와 원격 사이트 모두에서 서버가 활성 상태인 Oracle RAC(Real Application Cluster) 구성은 Oracle SGA 내의 데이터를 캐시합니다. 강제 전환 작업으로 인해 데이터가 손실되면 SGA에 저장된 블록이 디스크의 블록과 일치하지 않을 수도 있기 때문에 데이터베이스가 손상될 위험에 처하게 됩니다.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">운영 체제 파일 시스템 계층에서의 캐싱 사용은 이보다 덜 명확합니다. 마운트된 NFS 파일 시스템의 블록이 운영 체제에 캐싱될 수 있습니다. 또는 운영 사이트에 있는 LUN 기반의 클러스터된 파일 시스템을 원격 사이트의 서버에 마운트하여 데이터를 다시 캐시할 수 있습니다. 이러한 상황에서 NVRAM 장애 또는 강제 적용 테이크오버 또는 강제 적용 스위치오버로 인해 파일 시스템이 손상될 수 있습니다.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP는 NVFAIL 및 관련 설정을 통해 이 시나리오로부터 데이터베이스와 운영 체제를 보호합니다.</block>
  <block id="45293b650c7dacd88d269bebf219b8ef" category="summary">NetApp SnapRestore 기술을 통해 ONTAP에서 스냅샷 복사본으로 신속하게 Oracle 데이터베이스 복구 수행</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">ONTAP의 빠른 스냅샷 데이터 복원은 NetApp SnapRestore 기술을 통해 수행됩니다.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">중요 데이터 세트를 사용할 수 없으면 중요한 비즈니스 운영이 중단됩니다. 테이프는 작동 중지될 수 있으며 디스크 기반 백업에서 복원하는 경우 네트워크를 통해 전송되는 속도가 느려질 수 있습니다. SnapRestore은 데이터 세트를 거의 즉각적으로 복원하여 이러한 문제를 방지합니다. 페타바이트급 데이터베이스도 단 몇 분만에 완벽하게 복원할 수 있습니다.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">SnapRestore 파일/LUN 기반과 볼륨 기반에는 두 가지 형식이 있습니다.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">개별 파일 또는 LUN은 2TB LUN인지 4KB 파일인지에 관계없이 몇 초 이내에 복원할 수 있습니다.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">파일 또는 LUN의 컨테이너는 10GB 또는 100TB의 데이터이든 몇 초 만에 복원할 수 있습니다.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">"파일 또는 LUN 컨테이너"는 일반적으로 FlexVol 볼륨을 의미합니다. 예를 들어, 단일 볼륨에 LVM 디스크 그룹을 구성하는 10개의 LUN이 있거나 볼륨에 1000명의 사용자가 있는 NFS 홈 디렉토리를 저장할 수 있습니다. 각 개별 파일 또는 LUN에 대해 복구 작업을 실행하는 대신 전체 볼륨을 단일 작업으로 복구할 수 있습니다. 이 프로세스는 FlexGroup 또는 ONTAP 일관성 그룹과 같은 여러 볼륨이 포함된 스케일아웃 컨테이너에도 작동합니다.</block>
  <block id="a8d6a4d1b7fc6e1f60bb0ab716b4e72f" category="paragraph">SnapRestore이 빠르고 효율적으로 작동하는 이유는 기본적으로 특정 시점에 볼륨 콘텐츠에 대한 병렬 읽기 전용 보기인 스냅샷 복사본의 특성 때문입니다. 활성 블록은 변경할 수 있는 실제 블록이지만 스냅샷은 스냅샷이 생성된 시점의 파일 및 LUN을 구성하는 블록 상태에 대한 읽기 전용 뷰입니다.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP에서는 스냅샷 데이터에 대한 읽기 전용 액세스만 허용하지만, SnapRestore를 사용하여 데이터를 다시 활성화할 수 있습니다. 스냅샷은 데이터의 읽기/쓰기 뷰로 다시 설정되며 데이터를 이전 상태로 되돌립니다. SnapRestore는 볼륨 또는 파일 레벨에서 작동할 수 있습니다. 이 기술은 본질적으로 같으며 몇 가지 사소한 행동 차이가 있습니다.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">Volume SnapRestore를 참조하십시오</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">볼륨 기반 SnapRestore는 전체 데이터 볼륨을 이전 상태로 되돌립니다. 이 작업은 데이터를 이동할 필요가 없습니다. 즉, API 또는 CLI 작업을 처리하는 데 몇 초가 걸릴 수 있지만 복원 프로세스가 기본적으로 즉각적입니다. 1GB의 데이터를 복원하는 것은 1PB의 데이터를 복원하는 것보다 더 복잡하거나 시간이 많이 소요됩니다. 이 기능 은 많은 엔터프라이즈 고객이 ONTAP 스토리지 시스템으로 마이그레이션하는 주된 이유입니다. 또한 가장 큰 데이터 세트에 대해 몇 초 단위의 RTO를 제공합니다.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">볼륨 기반 SnapRestore의 한 가지 단점은 볼륨 내의 변경 사항이 시간 경과에 따라 누적된다는 사실에 의해 발생합니다. 따라서 각 스냅샷 및 활성 파일 데이터는 해당 시점까지 이어지는 변경 사항에 따라 달라집니다. 볼륨을 이전 상태로 되돌리면 데이터에 적용된 이후의 모든 변경 내용이 취소됩니다. 그러나 이는 이후에 생성된 스냅샷을 포함한다는 점은 그만큼 분명하지 않습니다. 이것이 항상 바람직한 것은 아닙니다.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">예를 들어, 데이터 보존 SLA는 30일 야간 백업을 지정할 수 있습니다. 볼륨 SnapRestore를 사용하여 5일 전에 생성된 스냅샷으로 데이터 세트를 복구하면 지난 5일 동안 생성된 모든 스냅샷이 삭제되어 SLA를 위반하게 됩니다.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">이 제한 사항을 해결하는 데 사용할 수 있는 여러 가지 옵션이 있습니다.</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">전체 볼륨의 SnapRestore를 수행하는 것이 아니라 이전 스냅샷에서 데이터를 복사할 수 있습니다. 이 방법은 보다 작은 데이터 집합에 가장 적합합니다.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">스냅샷은 복구하지 않고 클론을 생성할 수 있습니다. 이 접근 방식의 제한 사항은 소스 스냅샷이 클론에 종속된다는 것입니다. 따라서 클론이 삭제되거나 독립 볼륨으로 분할되지 않는 한 삭제할 수 없습니다.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">파일 기반 SnapRestore 사용:</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">파일 SnapRestore</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">파일 기반 SnapRestore는 보다 세부적인 스냅샷 기반 복원 프로세스입니다. 전체 볼륨의 상태를 되돌리는 대신 개별 파일 또는 LUN의 상태를 되돌립니다. 스냅샷을 삭제할 필요가 없으며, 이 작업으로 이전 스냅샷에 대한 종속성이 생성되지 않습니다. 파일 또는 LUN을 활성 볼륨에서 즉시 사용할 수 있습니다.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">파일 또는 LUN의 SnapRestore 복원 중에 데이터를 이동할 필요가 없습니다. 그러나 파일 또는 LUN의 기본 블록이 이제 스냅샷과 활성 볼륨 모두에 존재한다는 사실을 반영하려면 일부 내부 메타데이터를 업데이트해야 합니다. 성능에는 영향을 미치지 않겠지만 이 프로세스는 완료될 때까지 스냅샷 생성을 차단합니다. 처리 속도는 복원된 파일의 총 크기에 따라 약 5GBps(시간당 18TB)입니다.</block>
  <block id="a68b31b502bf7555cda2514354e553c2" category="summary">ONTAP 데이터 보호 전략</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">데이터 보호 계획</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">적절한 엔터프라이즈 데이터 보호 아키텍처는 다양한 이벤트 중에 데이터 보존, 복구 기능 및 운영 중단에 대한 허용성과 관련된 비즈니스 요구 사항에 따라 달라집니다.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">예를 들어, 적용 범위의 애플리케이션, 데이터베이스 및 중요 데이터 세트의 수를 예로 들어 보겠습니다. 관리할 객체가 많지 않기 때문에 단일 데이터 세트에 대해 일반적인 SLA를 준수하는 백업 전략을 구축하는 것은 매우 간단합니다. 데이터 세트의 수가 늘어나면 모니터링이 더 복잡해지고 관리자는 백업 장애를 해결하는 데 더 많은 시간을 소비해야 할 수도 있습니다. 환경이 클라우드에 도달하고 서비스 공급자가 확장됨에 따라 완전히 다른 접근 방식이 필요합니다.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">데이터 세트 크기도 전략에 영향을 줍니다. 예를 들어, 데이터 세트가 매우 작기 때문에 100GB 데이터베이스를 사용한 백업 및 복구에 사용할 수 있는 옵션이 많이 있습니다. 기존 툴을 사용하여 백업 미디어에서 데이터를 복제하는 것만으로도 복구에 충분한 RTO를 얻을 수 있습니다. 일반적으로 100TB 데이터베이스에는 다일의 운영 중단이 허용되지 않는 한 100TB 데이터베이스에는 일반적으로 완전히 다른 전략이 필요합니다. 이 경우 기존의 복사본 기반 백업 및 복구 절차가 허용되는 경우가 아니라면 말입니다.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">마지막으로, 백업 및 복구 프로세스 자체 이외의 요소가 있습니다. 예를 들어, 중요한 운영 작업을 지원하는 데이터베이스가 있어 숙련된 DBA만 수행하는 드문 이벤트로 간주됩니까? 아니면 데이터베이스가 대규모 개발 환경에 있어서 복구가 자주 발생하고 일반 IT 팀이 관리하는 환경입니까?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">스냅샷이 백업입니까?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">스냅샷을 데이터 보호 전략으로 사용하는 것에 대해 일반적으로 제기되는 반대 의견 중 하나는 "실제" 데이터와 스냅샷 데이터가 동일한 드라이브에 있다는 것입니다. 이러한 드라이브가 손실되면 기본 데이터와 백업이 모두 손실됩니다.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">이는 유효한 문제입니다. 로컬 스냅샷은 일상적인 백업 및 복구 요구에 사용되며 이러한 측면에서 스냅샷은 백업입니다. NetApp 환경의 모든 복구 시나리오 중 거의 99%가 가장 공격적인 RTO 요구 사항까지도 충족하기 위해 스냅샷에 의존합니다.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">하지만 로컬 스냅샷만 사용할 수 있는 백업 전략이 되어서는 안 됩니다. 그렇기 때문에 NetApp에서는 스냅샷을 독립 드라이브에 빠르고 효율적으로 복제할 수 있는 SnapMirror 복제 같은 기술을 제공합니다. 스냅샷과 스냅샷 복제를 갖춘 제대로 설계된 솔루션을 사용하면 분기별 아카이브로 테이프 사용을 최소화하거나 완전히 제거할 수 있습니다.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">정합성 보장 그룹 백업</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">정합성 보장 그룹 백업에는 단일 원자 시점에서 데이터 세트(또는 여러 데이터 세트) 상태를 캡처하는 작업이 포함됩니다. 데이터베이스의 예를 들어, 여기에는 데이터 파일, 로그 파일 같은 모든 데이터베이스 구성 요소와 데이터베이스와 직접 연결된 기타 파일이 포함됩니다. Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL 및 MariaDB. 정합성 보장 그룹 백업을 사용하여 VMware 구성을 보호하는 것은 유사한 방식으로 모든 데이터 저장소와 ESX 부팅 LUN을 단일 원자적 시점에 캡처하는 것입니다.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">이러한 일관성 그룹 스냅샷의 생성은 기본적으로 충돌을 시뮬레이션하기 때문에 이러한 백업을 자주 충돌 시에도 정합성 보장 백업이라고 합니다. 복구 시나리오에 대한 지원과 관련된 문제가 있을 수 있지만 일반적으로 복구 절차가 필요하지 않다는 것을 이해하는 것이 중요합니다. 정합성 보장 그룹 백업을 복원한 후 애플리케이션이 시작되면 일반적인 로그 복구 프로세스, 파일 시스템 저널 재생 및 기타 작업을 수행하여 백업 시점에 전송 중인 모든 입출력을 재생합니다. 그러면 응용 프로그램이 평소와 같이 시작됩니다.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">기본적으로, 데이터 손상 없이 전원 장애 또는 서버 충돌을 견딜 수 있는 모든 응용 프로그램은 이러한 방식으로 보호할 수 있습니다. 이러한 작동 방식은 다양한 공급업체의 동기식 및 비동기식 미러링 제품으로 보호되는 엄청난 수의 애플리케이션을 통해 입증될 수도 있습니다. 재해가 갑자기 기본 사이트에 발생하면 복제 사이트에 재해가 발생한 시점의 원래 환경에 대한 일관된 이미지가 포함됩니다. 다시 한 번 특별한 복구 절차가 필요하지 않습니다.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">이 접근 방식의 RPO는 일반적으로 백업 지점으로 제한됩니다. 일반적으로 단일 볼륨 스냅샷의 최소 RPO는 1시간입니다. 예를 들어, 48개의 시간별 스냅샷과 30일간의 야간 스냅샷을 사용하는 것이 적절하므로 과도한 수의 스냅샷을 보존할 필요가 없습니다. 1시간 미만의 RPO를 달성하는 것은 어려우므로 먼저 NetApp 프로페셔널 서비스와 상의하여 환경, 확장 및 데이터 보호 요구사항을 파악한 후에는 권장하지 않습니다.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">RTO는 일반적으로 몇 초 단위로 측정할 수 있습니다. 응용 프로그램이 종료되고 볼륨이 복구되며 응용 프로그램이 다시 시작됩니다.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">가장 간단한 방법은 모든 파일 또는 LUN을 단일 볼륨 정합성 보장 그룹에 배치하는 것입니다. 이렇게 하면 ONTAP에서 직접 스냅샷 생성을 예약할 수 있습니다. 데이터 세트가 여러 볼륨으로 확장되는 경우에는 일관성 그룹 스냅샷(CG-snapshot)이 필요합니다. 이는 System Manager 또는 RESTful API 호출을 사용하여 구성할 수 있으며 SnapCenter은 정의된 볼륨 목록에서 단순한 일관성 그룹 스냅샷을 생성할 수 있습니다.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">복제 및 재해 복구 아키텍처</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="7b8111b0a2fc76252bbacbbc9de542a4" category="inline-link-macro">SnapMirror 비즈니스 연속성</block>
  <block id="96a7c86d5bc52a478876c48dc6dcc9f0" category="paragraph">이 섹션에서는 안전한 오프사이트 스토리지 및 재해 복구를 위해 데이터를 원격 사이트로 복제하는 원격 데이터 보호에 대해 설명합니다. 이 표는 동기 미러링 데이터 보호를 다루지 않습니다. 이 요구 사항은 를 포함한 NetApp MetroCluster 설명서를 참조하십시오 <block ref="5c964f26ec7fbbad5ac67aaa5dcf9269" category="inline-link-macro-rx"></block> 및 <block ref="30831ec866621e18e7521d6c2750acaa" category="inline-link-macro-rx"></block></block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">DR RPO는 사용 가능한 네트워크 대역폭 및 보호되는 데이터의 총 크기에 따라 제한됩니다. 초기 베이스라인 전송이 생성된 후 업데이트는 변경된 데이터만 기반으로 하며, 이는 일반적으로 예외가 존재하지만 전체 데이터 공간 중 낮은 비율입니다.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">예를 들어, 주간 변경률이 10%인 10TB 데이터베이스의 경우 시간당 평균 약 6GB의 총 변경 사항이 발생합니다. 10GB의 연결을 통해 이 데이터베이스를 전송하는 데 약 6분이 소요됩니다. 변경률은 데이터베이스 변경률의 변동에 따라 다르지만 전체적으로 업데이트 간격이 15분이므로 RPO는 15분 이내여야 합니다. 100개의 데이터베이스가 있는 경우 데이터를 전송하는 데 600분이 필요합니다. 따라서 1시간의 RPO는 불가능합니다. 마찬가지로, 주간 변경률이 10%인 단일 데이터베이스 100TB의 복제본은 1시간 내에 안정적으로 업데이트할 수 없습니다.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">복제 오버헤드 및 동시 복제 작업 수 제한 등 추가적인 요인이 복제에 영향을 미칠 수 있습니다. 그러나 사용 가능한 대역폭을 기준으로 단일 볼륨 복제 전략을 전반적으로 계획할 수 있으며 복제 RPO는 일반적으로 1시간으로 달성할 수 있습니다. 1시간 미만의 RPO는 달성하는 것이 더 어려우며 NetApp 프로페셔널 서비스를 상담한 후에만 수행해야 합니다. 사이트 간 네트워크 연결이 매우 양호하여 15분이 걸리는 경우도 있습니다. 그러나 전반적으로 1시간 미만의 RPO가 필요한 경우 다중 볼륨 로그 재생 아키텍처를 통해 더 나은 결과를 얻을 수 있습니다.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">재해 복구 시나리오에서 정합성 보장 그룹 복제를 사용하는 RTO는 우수하며 일반적으로 스토리지 관점에서 몇 초 이내에 측정됩니다. 가장 간단한 방법은 단순히 미러를 중단하는 것이며 데이터베이스를 시작할 준비가 된 것입니다. 데이터베이스 시작 시간은 일반적으로 약 10초이지만 트랜잭션이 많이 기록되는 대용량 데이터베이스에는 몇 분이 걸릴 수 있습니다.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">RTO를 결정하는 데 있어 가장 중요한 요소는 스토리지 시스템이 아니라 해당 시스템이 실행되는 애플리케이션과 호스트 운영 체제입니다. 예를 들어, 복제된 데이터를 1-2초 내에 사용할 수 있지만 이는 데이터만 나타냅니다. 또한 데이터를 사용하는 데 사용할 수 있는 응용 프로그램 바이너리가 있는 올바르게 구성된 운영 체제도 있어야 합니다.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">경우에 따라 고객이 운영 체제에서 미리 발견된 스토리지를 사용하여 재해 복구 인스턴스를 사전에 준비해 둔 경우도 있습니다. 이러한 경우 재해 복구 시나리오를 활성화하려면 미러를 해제하고 애플리케이션을 시작하는 것만으로도 충분합니다. 운영 체제와 관련 애플리케이션이 데이터베이스와 함께 ESX 가상 시스템 디스크(VMDK)로 미러링될 수도 있습니다. 이 경우 애플리케이션을 시작할 수 있도록 VMDK를 신속하게 부팅하기 위해 자동화에 투자한 고객 수에 따라 RPO가 결정됩니다.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">보존 시간은 부분적으로 스냅샷 제한에 의해 제어됩니다. 예를 들어, ONTAP의 볼륨은 1,024개의 스냅샷을 포함할 수 있습니다. 경우에 따라 고객은 멀티플렉싱된 복제를 사용하여 제한을 늘렸습니다. 예를 들어 2000일 분량의 백업이 필요한 경우 대체 날짜에 업데이트가 수행되는 두 개의 볼륨에 소스를 복제할 수 있습니다. 이 경우 필요한 초기 공간을 늘려야 하지만 여러 개의 전체 백업이 필요한 기존 백업 시스템보다 훨씬 효율적인 접근 방식을 제공합니다.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">단일 볼륨 일관성 그룹</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">가장 간단한 접근 방식은 모든 파일 또는 LUN을 단일 볼륨 일관성 그룹에 배치하는 것입니다. 이렇게 하면 SnapMirror 및 SnapVault 업데이트를 스토리지 시스템에서 직접 예약할 수 있습니다. 외부 소프트웨어가 필요하지 않습니다.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">다중 볼륨 일관성 그룹</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">데이터베이스가 여러 볼륨으로 확장되는 경우에는 일관성 그룹 스냅샷(CG-스냅샷)이 필요합니다. 위에서 언급한 것처럼 System Manager 또는 RESTful API 호출을 사용하여 구성할 수 있으며 SnapCenter는 정의된 볼륨 목록에서 단순한 일관성 그룹 스냅샷을 생성할 수 있습니다.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">또한 재해 복구를 위해 정합성 보장 다중 볼륨 스냅샷을 사용하는 방법에 대해서도 한 가지 추가 고려 사항이 있습니다. 여러 볼륨의 업데이트를 수행할 때 전송이 진행 중인 동안 재해가 발생할 수 있습니다. 그 결과 서로 일치하지 않는 볼륨 세트가 생성됩니다. 이 경우 충돌 시에도 정합성이 보장되는 데이터베이스 이미지를 제공하고 사용할 수 있도록 일부 볼륨을 이전 스냅샷 상태로 복원해야 합니다.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">재해 복구: 활성화</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">재해 복구 복제본을 활성화하는 프로세스는 스토리지 유형에 따라 다릅니다. NFS를 사용하면 파일 시스템을 재해 복구 서버에 미리 마운트할 수 있습니다. 읽기 전용 상태이며 미러가 손상되면 읽기/쓰기가 됩니다. 따라서 RPO가 매우 낮고 관리해야 할 부품이 적기 때문에 전체 재해 복구 프로세스의 신뢰성이 높아집니다.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">재해 복구 시 SAN 구성을 활성화하는 작업이 더 복잡해집니다. 가장 간단한 옵션은 일반적으로 미러를 일시적으로 깨고 LVM 구성 검색(Oracle Automatic Storage Management[ASM]과 같은 애플리케이션별 기능 포함) 및 /etc/fstab에 항목 추가 등의 단계를 포함하여 SAN 리소스를 마운트하는 것입니다.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">그 결과 LUN 디바이스 경로, 볼륨 그룹 이름 및 기타 디바이스 경로가 타겟 서버에 인식됩니다. 그런 다음 이러한 리소스를 종료하고 나중에 미러를 복구할 수 있습니다. 그 결과, 애플리케이션을 신속하게 온라인으로 전환할 수 있는 서버 상태가 됩니다. 볼륨 그룹을 활성화하고, 파일 시스템을 마운트하거나, 데이터베이스와 애플리케이션을 시작하는 단계는 쉽게 자동화됩니다.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">재해 복구 환경이 최신 상태인지 확인할 수 있도록 주의를 기울여야 합니다. 예를 들어 소스 서버에 새 LUN을 추가할 수 있습니다. 즉, 재해 복구 계획이 예상대로 작동하는지 확인하려면 대상에서 새 LUN을 미리 검색해야 합니다.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Oracle 재해 복구</block>
  <block id="7fe779a487e8f113f1ffdff0fb80353f" category="summary">ONTAP에서 Oracle에 대한 정합성 보장 그룹 백업</block>
  <block id="773f9afa3df0cf82ed853c988183c73f" category="doc">Oracle 정합성 보장 그룹 백업</block>
  <block id="5afd3dc3f8d489d47587e10e6663c512" category="paragraph">가장 간단한 백업을 위해서는 전체 Oracle 데이터베이스를 단일 볼륨에 배치하기만 하면 됩니다.</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">단일 스냅샷을 사용하여 데이터 파일, 아카이브 로그, redo 로그 및 제어 파일을 보호하는 것은 유효한 백업, 복원 및 복제 방법입니다.  그러나 RPO는 백업 자체의 지점으로 제한됩니다. 1시간 이상의 RPO에 적합합니다. 데이터베이스가 여러 볼륨으로 확장되는 경우 앞에서 설명한 툴 중 하나를 사용하여 CG 스냅샷이 필요합니다.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">예를 들어, 전체 데이터베이스는 다음과 같은 스냅샷 스케줄로 단일 볼륨에 있을 수 있습니다.</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">시간별 스냅샷 72개</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30개의 야간 스냅샷</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12개의 월별 스냅샷</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">따라서 이전 72시간의 롤링 기간 동안 RPO가 1시간이며 야간 및 월별 백업이 추가로 제공됩니다. 여러 데이터베이스 또는 애플리케이션 파일을 단일 볼륨 또는 CG 스냅샷 세트에 포함하여 대규모 환경에서 일관된 백업을 제공할 수도 있습니다.</block>
  <block id="5eb532bcede5a8d57b8fb4429d5cc7ec" category="summary">ONTAP 기반의 Oracle을 통해 가용성 극대화</block>
  <block id="b4343a8438e1b9cc9e9486f85831f2a1" category="doc">ONTAP을 사용한 Oracle 데이터 가용성</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP는 최대한의 Oracle 데이터베이스 가용성을 제공하도록 설계되었습니다. ONTAP 고가용성 기능에 대한 전체 설명은 본 문서의 범위를 벗어나며 그러나 데이터 보호와 마찬가지로 데이터베이스 인프라를 설계할 때는 이 기능에 대한 기본적인 이해가 중요합니다.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">HA 쌍</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">고가용성의 기본 단위는 HA 쌍입니다. 각 쌍에는 NVRAM에 데이터 복제를 지원하는 중복 링크가 포함되어 있습니다. NVRAM은 쓰기 캐시가 아닙니다. 컨트롤러 내의 RAM은 쓰기 캐시 역할을 합니다. NVRAM의 목적은 예기치 않은 시스템 장애를 방지하기 위해 일시적으로 데이터를 저널링하는 것입니다. 이 점에서 데이터베이스 재실행 로그와 유사합니다.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">NVRAM과 데이터베이스 재실행 로그를 모두 사용하여 데이터를 빠르게 저장하므로 데이터의 변경사항을 최대한 빠르게 커밋할 수 있습니다. 드라이브(또는 데이터 파일)의 영구 데이터에 대한 업데이트는 ONTAP 플랫폼과 대부분의 데이터베이스 플랫폼 모두에서 체크포인트라는 프로세스 도중 늦게 수행되지 않습니다. 정상 작업 중에는 NVRAM 데이터나 데이터베이스 재실행 로그를 읽지 않습니다.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">컨트롤러가 갑자기 실패할 경우 드라이브에 아직 기록되지 않은 NVRAM에 저장된 변경 사항이 보류 중일 수 있습니다. 파트너 컨트롤러는 장애를 감지하고 드라이브를 제어하며 NVRAM에 저장된 필수 변경 사항을 적용합니다.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">테이크오버 및 반환</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Takeover 및 Giveback은 HA 2노드의 노드 간에 스토리지 리소스에 대한 책임을 지는 프로세스를 의미합니다. Takeover와 반환에는 두 가지 측면이 있습니다.</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">드라이브에 액세스할 수 있는 네트워크 연결 관리</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">드라이브 자체 관리</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">CIFS 및 NFS 트래픽을 지원하는 네트워크 인터페이스는 홈 위치와 페일오버 위치 모두를 사용하여 구성됩니다. 테이크오버는 원래 위치와 동일한 서브넷에 있는 물리적 인터페이스에서 네트워크 인터페이스를 임시 홈으로 이동하는 것을 포함합니다. 반환에는 네트워크 인터페이스를 원래 위치로 이동하는 것도 포함됩니다. 정확한 동작은 필요에 따라 조정할 수 있습니다.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">iSCSI 및 FC와 같은 SAN 블록 프로토콜을 지원하는 네트워크 인터페이스는 테이크오버 및 반환 중에 재배치되지 않습니다. 전체 HA 쌍이 포함된 경로를 사용하여 LUN을 프로비저닝해야 하므로 1차 경로와 2차 경로가 됩니다.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">추가 컨트롤러를 위한 추가 경로를 대규모 클러스터에서 노드 간 데이터 재배치를 지원하도록 구성할 수도 있지만 이는 HA 프로세스에 포함되지 않습니다.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Takeover와 Giveback의 두 번째 측면은 디스크 소유권을 이전하는 것입니다. 정확한 프로세스는 Takeover/Giveback 이유 및 실행된 명령줄 옵션을 비롯한 여러 요인에 따라 달라집니다. 목표는 최대한 효율적으로 작업을 수행하는 것입니다. 전체 프로세스에는 몇 분이 필요한 것처럼 보이지만 드라이브 소유권이 노드에서 노드로 전환되는 실제 순간은 일반적으로 초 단위로 측정할 수 있습니다.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">인수 시간</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">테이크오버 및 반환 작업 중에 호스트 I/O가 잠깐 정지되지만 올바르게 구성된 환경에서는 애플리케이션이 중단되어서는 안 됩니다. I/O가 지연되는 실제 전환 프로세스는 일반적으로 몇 초 내로 측정되지만, 호스트에서 데이터 경로의 변경을 인식하고 I/O 작업을 다시 제출하기 위해 추가 시간이 필요할 수 있습니다.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">중단 특성은 프로토콜에 따라 다릅니다.</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">NFS 및 CIFS 트래픽을 지원하는 네트워크 인터페이스는 새 물리적 위치로 전환한 후 네트워크에 ARP(Address Resolution Protocol) 요청을 발급합니다. 이로 인해 네트워크 스위치가 MAC(Media Access Control) 주소 테이블을 업데이트하고 I/O 처리를 재개합니다 계획된 테이크오버와 반환의 경우 운영 중단은 일반적으로 몇 초 단위로 측정되며, 대부분의 경우 감지할 수 없는 경우가 많습니다. 일부 네트워크는 네트워크 경로의 변화를 완전히 인식하기 위해 더 느려질 수 있으며 일부 운영 체제는 재시도해야 하는 매우 짧은 시간 내에 많은 I/O를 대기시킬 수 있습니다. 이렇게 하면 입출력을 재개하는 데 필요한 시간이 길어질 수 있습니다</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">SAN 프로토콜을 지원하는 네트워크 인터페이스는 새 위치로 전환되지 않습니다. 호스트 운영 체제에서 사용 중인 경로를 변경해야 합니다. 호스트에서 관찰되는 입출력 일시 중지는 여러 요인에 따라 달라집니다. 스토리지 시스템 관점에서 볼 때 입출력을 처리할 수 없는 기간은 불과 몇 초입니다. 그러나 다른 호스트 운영 체제마다 재시도하기 전에 I/O가 시간 초과되도록 하려면 추가 시간이 필요할 수 있습니다. 최신 운영 체제는 경로 변경을 훨씬 더 빠르게 인식할 수 있지만, 기존 운영 체제에서는 일반적으로 변경 사항을 인식하는 데 최대 30초가 걸립니다.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">아래 표에는 스토리지 시스템에서 애플리케이션 환경에 데이터를 제공할 수 없는 테이크오버가 예상되고 있습니다. 애플리케이션 환경에서 오류가 발생하지 않도록 하려면 테이크오버 대신 IO 처리 중에 잠깐 정지된 상태로 표시되어야 합니다.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">계획된 테이크오버</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15초</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10초</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3초</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">계획되지 않은 테이크오버</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30초</block>
  <block id="a4985782267828ce03a3d13f37392de1" category="summary">체크섬 및 Oracle 데이터 보호</block>
  <block id="407941abab873f61b271b481e105eb33" category="doc">체크섬 및 Oracle 데이터 무결성</block>
  <block id="b93232347a11497969d0ea20d34cd16e" category="paragraph">NetApp가 자주 받는 질문 중 하나는 Oracle 데이터베이스의 데이터 무결성을 어떻게 보호할지입니다.</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">ONTAP 내의 논리적 데이터 보호는 다음과 같은 세 가지 주요 요구 사항으로 구성됩니다.</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">데이터가 손상되지 않도록 보호해야 합니다.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">드라이브 장애로부터 데이터를 보호해야 합니다.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">데이터 변경사항을 손실로부터 보호해야 합니다.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">이 세 가지 요구 사항은 다음 섹션에서 설명합니다.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">네트워크 손상: 체크섬</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">가장 기본적인 데이터 보호 수준은 데이터와 함께 저장되는 특별한 오류 감지 코드인 체크섬입니다. 네트워크 전송 중 데이터 손상은 체크섬을 사용하여 감지되며 경우에 따라 여러 체크섬을 사용할 수 있습니다.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">예를 들어, FC 프레임에는 전송 중에 페이로드가 손상되지 않도록 CRC(Cyclic Redundancy Check)라는 체크섬 유형이 포함되어 있습니다. 송신기는 데이터와 데이터의 CRC를 모두 전송합니다. FC 프레임의 수신기는 수신된 데이터의 CRC를 다시 계산하여 전송된 CRC와 일치하는지 확인합니다. 새로 계산된 CRC가 프레임에 연결된 CRC와 일치하지 않으면 데이터가 손상되고 FC 프레임이 삭제되거나 거부됩니다. iSCSI I/O 작업에는 TCP/IP 및 이더넷 계층에 체크섬이 포함되며, 추가적인 보호를 위해 SCSI 계층에 선택 사항인 CRC 보호 기능이 포함될 수도 있습니다. 와이어의 모든 비트 손상은 TCP 계층 또는 IP 계층에서 감지되어 패킷의 재전송을 초래합니다. FC와 마찬가지로 SCSI CRC의 오류로 인해 작업이 삭제되거나 거부됩니다.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">드라이브 손상: 체크섬</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">또한 체크섬을 사용하여 드라이브에 저장된 데이터의 무결성을 검증합니다. 드라이브에 기록된 데이터 블록은 원래 데이터와 연결된 예측 불가능한 수를 생성하는 체크섬 기능과 함께 저장됩니다. 드라이브에서 데이터를 읽으면 체크섬이 다시 계산되어 저장된 체크섬과 비교됩니다. 일치하지 않으면 데이터가 손상되어 RAID 계층에 의해 복구되어야 합니다.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">데이터 손상: 쓰기 손실</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">감지하기 가장 어려운 유형의 손상 중 하나는 손실되거나 잘못 배치된 쓰기입니다. 쓰기가 확인되면 올바른 위치에 있는 미디어에 기록해야 합니다. 데이터 이동 없는 데이터 손상은 데이터와 함께 저장된 간단한 체크섬을 사용하여 비교적 쉽게 감지할 수 있습니다. 그러나 쓰기가 단순히 손실되는 경우 이전 버전의 데이터가 여전히 존재하고 체크섬이 정확할 수 있습니다. 쓰기가 잘못된 물리적 위치에 배치되면 쓰기가 다른 데이터를 제거했더라도 연결된 체크섬이 저장된 데이터에 대해 다시 한 번 유효합니다.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">이 문제에 대한 해결책은 다음과 같습니다.</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">쓰기 작업에는 쓰기를 찾을 위치를 나타내는 메타데이터가 포함되어야 합니다.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">쓰기 작업에는 버전 식별자가 일부 포함되어 있어야 합니다.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">ONTAP에서 블록을 쓰면 해당 블록이 속한 위치에 대한 데이터가 포함됩니다. 후속 읽기에서 블록을 식별하지만 메타데이터에서 위치 456에서 찾은 위치 123에 해당 블록이 속해 있음을 나타내는 경우 쓰기가 잘못 배치된 것입니다.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">완전히 손실된 쓰기를 감지하기가 더 어렵습니다. 이 설명은 매우 복잡하지만 기본적으로 ONTAP은 쓰기 작업으로 인해 드라이브의 서로 다른 두 위치에 업데이트가 이루어지도록 메타데이터를 저장하고 있습니다. 쓰기가 손실되면 후속 데이터 읽기와 관련 메타데이터를 읽으면 서로 다른 두 버전 ID가 표시됩니다. 이는 드라이브에서 쓰기가 완료되지 않았음을 나타냅니다.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">손실되거나 잘못 배치된 쓰기 손상은 매우 드물지만 드라이브가 계속 증가하고 데이터 세트가 엑사바이트 규모로 증가함에 따라 위험이 증가합니다. 손실된 쓰기 감지 기능은 데이터베이스 워크로드를 지원하는 모든 스토리지 시스템에 포함되어야 합니다.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">드라이브 장애: RAID, RAID DP 및 RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">드라이브의 데이터 블록이 손상되었거나 전체 드라이브에 장애가 발생하여 완전히 사용할 수 없는 경우 데이터를 다시 구성해야 합니다. 이 작업은 ONTAP에서 패리티 드라이브를 사용하여 수행됩니다. 데이터가 여러 데이터 드라이브에 스트라이핑된 다음 패리티 데이터가 생성됩니다. 원본 데이터와 별도로 저장됩니다.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP에서는 원래 데이터 드라이브 그룹마다 단일 패리티 드라이브를 사용하는 RAID 4를 사용했습니다. 그 결과, 그룹의 드라이브 중 하나에 장애가 발생하여 데이터가 손실되지 않을 수 있었습니다. 패리티 드라이브에 장애가 발생하면 데이터가 손상되지 않았으며 새 패리티 드라이브를 구성할 수 있습니다. 단일 데이터 드라이브에 장애가 발생하면 나머지 드라이브를 패리티 드라이브와 함께 사용하여 누락된 데이터를 재생성할 수 있습니다.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">드라이브 용량이 작을 경우 두 개의 드라이브가 동시에 실패할 가능성이 매우 낮았습니다. 드라이브 용량이 증가함에 따라 드라이브 장애 후 데이터를 재구성하는 데 많은 시간이 필요하게 되었습니다. 이로 인해 두 번째 드라이브 오류로 인해 데이터가 손실되는 기간이 늘어났습니다. 또한 리빌드 프로세스는 나머지 드라이브에서 많은 I/O를 추가로 생성합니다. 드라이브가 노후화되면 추가 로드로 인해 두 번째 드라이브 장애가 발생할 위험도 증가합니다. 마지막으로 RAID 4를 계속 사용하면 데이터 손실 위험이 증가하지 않더라도 데이터 손실의 결과는 더욱 심각해집니다. RAID 그룹 장애 시 손실될 데이터가 많을수록 데이터 복구에 시간이 더 오래 걸리기 때문에 비즈니스 운영이 중단됩니다.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">이러한 문제로 인해 NetApp는 RAID 6의 변종인 NetApp RAID DP 기술을 개발하게 되었습니다. 이 솔루션에는 패리티 드라이브가 2개 포함되어 있으므로 RAID 그룹에 있는 두 드라이브가 데이터 손실없이 실패할 수 있습니다. 드라이브의 크기가 계속 커짐에 따라 NetApp는 NetApp RAID-TEC 기술을 개발하여 세 번째 패리티 드라이브를 도입했습니다.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">일부 내역 데이터베이스 모범 사례에서는 스트라이프 미러링이라고도 하는 RAID-10을 사용할 것을 권장합니다. 여러 개의 2-디스크 장애 시나리오가 있기 때문에 RAID DP보다 데이터 보호 기능이 떨어지는 반면 RAID DP는 없습니다.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">또한 성능 문제로 인해 RAID-10이 RAID-4/5/6 옵션보다 선호됨을 나타내는 몇 가지 과거 데이터베이스 모범 사례가 있습니다. 이러한 권장 사항은 종종 RAID 성능 저하와 관련이 있습니다. 이러한 권장 사항은 일반적으로 정확하지만 ONTAP 내에서 RAID를 구현하는 경우에는 적용되지 않습니다. 성능 문제는 패리티 재생과 관련이 있습니다. 기존 RAID 구현에서 데이터베이스에서 수행하는 일상적인 랜덤 쓰기를 처리하려면 패리티 데이터를 재생성하고 쓰기를 완료하기 위해 여러 디스크 읽기를 수행해야 합니다. 페널티는 쓰기 작업을 수행하는 데 필요한 추가 읽기 IOPS로 정의됩니다.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">쓰기 작업은 패리티가 생성된 메모리에서 스테이징된 다음 단일 RAID 스트라이프로 디스크에 기록되므로 ONTAP에서 RAID 패널티가 발생하지 않습니다. 쓰기 작업을 완료하는 데 읽기 작업이 필요하지 않습니다.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">요약하면 RAID DP 및 RAID-TEC는 RAID 10과 비교하여 훨씬 더 많은 가용 용량을 제공하고, 드라이브 장애를 방지하며, 성능에 영향을 주지 않습니다.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">하드웨어 장애 방지: NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">데이터베이스 워크로드를 처리하는 스토리지 어레이는 쓰기 작업을 최대한 빨리 처리해야 합니다. 또한 쓰기 작업은 전원 장애와 같은 예기치 않은 이벤트로 인한 손실로부터 보호해야 합니다. 즉, 쓰기 작업은 적어도 두 위치에 안전하게 저장해야 합니다.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">AFF 및 FAS 시스템은 이러한 요구사항을 충족하기 위해 NVRAM을 사용합니다. 쓰기 프로세스는 다음과 같이 작동합니다.</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">인바운드 쓰기 데이터는 RAM에 저장됩니다.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">디스크의 데이터에 필요한 변경 사항은 로컬 및 파트너 노드 모두의 NVRAM으로 저널링됩니다. NVRAM은 쓰기 캐시가 아니라 데이터베이스 재실행 로그와 유사한 저널입니다. 정상적인 상태에서는 읽지 않습니다. I/O 처리 중 전원 장애 발생 후와 같은 복구에만 사용됩니다.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">그러면 쓰기가 호스트에 인식됩니다.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">이 단계의 쓰기 프로세스는 응용 프로그램 관점에서 완료되며 데이터는 서로 다른 두 위치에 저장되므로 손실로부터 보호됩니다. 최종적으로 변경 사항이 디스크에 기록되지만 이 프로세스는 쓰기 확인 후에 발생하므로 지연 시간에 영향을 주지 않기 때문에 애플리케이션 관점에서 대역 외로 처리됩니다. 이 프로세스는 데이터베이스 로깅과 다시 유사합니다. 데이터베이스 변경 사항은 가능한 한 빨리 재실행 로그에 기록되고 변경 사항은 커밋된 것으로 확인됩니다. 데이터 파일에 대한 업데이트는 훨씬 나중에 수행되며 처리 속도에 직접적인 영향을 주지 않습니다.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">컨트롤러 장애가 발생할 경우 파트너 컨트롤러가 필요한 디스크의 소유권을 가져오고 NVRAM에 기록된 데이터를 재생하여 장애가 발생했을 때 전송 중이었던 I/O 작업을 복구합니다.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">하드웨어 장애 보호: NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">앞서 설명한 것처럼, 쓰기는 하나 이상의 다른 컨트롤러에서 로컬 NVRAM 및 NVRAM에 로그인되기 전까지는 승인되지 않습니다. 이렇게 하면 하드웨어 장애나 정전이 발생해도 전송 중인 I/O가 손실되지 않습니다 로컬 NVRAM에 장애가 발생하거나 HA 파트너에 대한 연결이 실패하면 전송 중인 이 데이터는 더 이상 미러링되지 않습니다.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">로컬 NVRAM에 오류가 보고되면 노드가 종료됩니다. 이 종료를 통해 HA 파트너 컨트롤러로 페일오버됩니다. 오류가 발생한 컨트롤러가 쓰기 작업을 인식하지 못했기 때문에 데이터가 손실되지 않습니다.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">페일오버가 강제 적용되지 않는 한 ONTAP는 데이터가 동기화되지 않을 때 페일오버를 허용하지 않습니다. 이러한 방식으로 조건을 강제로 변경하면 데이터가 원래 컨트롤러에 남겨질 수 있으며 데이터 손실이 허용되는 수준임을 알 수 있습니다.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">데이터베이스는 디스크에 대규모 내부 데이터 캐시를 유지하기 때문에 페일오버가 강제 적용되는 경우 손상에 특히 취약합니다. 강제 적용 페일오버가 발생하면 이전에 승인되었던 변경사항이 효과적으로 폐기됩니다. 스토리지 어레이의 콘텐츠가 사실상 이전 시간으로 이동하며, 데이터베이스 캐시의 상태는 디스크에 있는 데이터의 상태를 더 이상 반영하지 않습니다.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">이 상황에서 데이터를 보호하기 위해 ONTAP에서는 NVRAM 장애에 대비하여 특별한 보호를 제공하도록 볼륨을 구성할 수 있습니다. 이 보호 메커니즘이 트리거되면 볼륨이 NVFAIL이라는 상태로 전환됩니다. 이 상태에서는 I/O 오류가 발생하여 오래된 데이터를 사용하지 않도록 애플리케이션이 종료됩니다. 확인된 쓰기가 스토리지 배열에 있어야 하므로 데이터가 손실되지 않아야 합니다.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">특정 사이트의 각 드라이브 세트는 미러링 사용과 관계없이 하나 이상의 완전히 이중화된 RAID-DP 또는 RAID-TEC 그룹으로 자동으로 구성됩니다. 따라서 사이트 손실 후에도 데이터를 지속적으로 보호할 수 있습니다.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">위 그림은 SyncMirror 구성의 예를 보여 줍니다. 24-드라이브 애그리게이트가 사이트 A에 할당된 쉘프의 드라이브 12개와 사이트 B에 할당된 쉘프의 드라이브 12개로 컨트롤러에서 생성되었습니다 드라이브는 두 개의 미러링된 RAID 그룹으로 그룹화되었습니다. RAID Group 0에는 사이트 B의 6개 드라이브 플렉스에 미러링된 사이트 A의 6개 드라이브 플렉스가 포함되어 있습니다 마찬가지로, RAID 그룹 1에는 사이트 B의 6개 드라이브 플렉스에 미러링되는 사이트 A의 6개 드라이브 플렉스가 포함되어 있습니다</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">SyncMirror는 일반적으로 각 사이트에 하나의 데이터 복사본으로 MetroCluster 시스템에 원격 미러링을 제공하는 데 사용됩니다. 경우에 따라 단일 시스템에서 추가 수준의 이중화를 제공하기 위해 사용되었습니다. 특히, 쉘프 레벨 이중화를 제공합니다. 드라이브 쉘프에는 이미 이중 전원 공급 장치와 컨트롤러가 포함되어 있으며 전반적으로 판금보다 조금 더 크지만, 경우에 따라 추가 보호가 필요할 수 있습니다. 예를 들어, 한 NetApp 고객은 자동차 테스트에 사용되는 모바일 실시간 분석 플랫폼용 SyncMirror를 구축했습니다. 시스템은 독립적인 UPS 시스템의 독립적인 전원 공급으로 공급되는 두 개의 물리적 랙으로 분리되었습니다.</block>
  <block id="95a3cc99b05998d49d8e035b994815bc" category="paragraph">== 체크섬</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">체크섬에 대한 주제는 Oracle RMAN 스트리밍 백업을 사용하는 데 익숙한 DBA가 스냅샷 기반 백업으로 마이그레이션하는 데 특히 유용합니다. RMAN은 백업 운영 중에 무결성 점검을 수행하는 기능을 가지고 있습니다. 이것이 유용하기는 하지만 이 기능의 주요 이점은 최신 스토리지 어레이에 사용되지 않는 데이터베이스를 위한 것입니다. Oracle 데이터베이스에 물리적 드라이브를 사용할 때 드라이브가 노후하면 결국 손상이 발생할 확률이 매우 높아지는데, 이 문제는 진정한 스토리지 어레이에서 어레이 기반 체크섬을 통해 해결됩니다.</block>
  <block id="58d7088c13cf2013ef373d85e3c27de7" category="paragraph">진정한 스토리지 어레이는 여러 레벨에서 체크섬을 사용하여 데이터 무결성을 보호합니다. IP 기반 네트워크에서 데이터가 손상된 경우 TCP(Transmission Control Protocol) 계층은 패킷 데이터를 거부하고 재전송을 요청합니다. FC 프로토콜은 캡슐화된 SCSI 데이터처럼 체크섬을 포함하고 있습니다. 이것이 어레이에 배치되면 ONTAP에서 RAID 및 체크섬 보호 기능을 수행할 수 있습니다. 대부분의 엔터프라이즈 어레이에서 그렇듯 손상이 발생할 수도 있지만 감지하여 수정할 수 있습니다. 일반적으로 전체 드라이브에 장애가 발생하면 RAID 리빌드가 신속하게 이뤄지며 데이터베이스 무결성은 영향을 받지 않습니다. ONTAP가 드라이브의 데이터가 손상되었음을 의미하는 체크섬 오류를 감지하는 경우가 간혹 있습니다. 그러면 드라이브 작동이 중단되고 RAID 리빌드가 시작됩니다. 여기서도 데이터 무결성은 영향을 받지 않습니다.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">또한, Oracle 데이터 파일 및 재실행 로그 아키텍처는 극단적인 환경에서도 최고 수준의 데이터 무결성을 제공하도록 설계되었습니다. 가장 기본적인 레벨에서 Oracle 블록은 거의 모든 I/O에 관한 체크섬과 기본 논리 점검을 포함합니다 Oracle이 충돌하거나 테이블스페이스를 오프라인으로 전환하지 않았다면 데이터는 온전한 상태입니다. 데이터 무결성 점검의 수준은 조정할 수 있으며 쓰기를 확인하도록 Oracle을 구성할 수도 있습니다. 결과적으로 거의 모든 충돌 및 장애 시나리오가 복구될 수 있으며, 극도로 드물긴 하나 복구가 불가능한 상황에서는 손상이 즉시 감지됩니다.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">Oracle 데이터베이스를 사용하는 대부분의 NetApp 고객은 스냅샷 기반 백업으로 마이그레이션한 후에 RMAN 및 기타 백업 제품의 사용을 중단합니다. SnapCenter를 통한 블록 레벨 복구를 수행하기 위해 RMAN을 사용할 수 있는 옵션이 여전히 있습니다. 하지만, 일별 기준으로 보면 RMAN, NetBackup 및 기타 제품은 월별 또는 분기별 아카이빙 복사본을 생성하기 위해 가끔씩만 사용됩니다.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">어떤 고객은 실행을 선택합니다<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> 정기적으로 기존 데이터베이스에 대한 무결성 검사를 수행합니다. 하지만 NetApp에서는 불필요한 I/O 로드가 생성되기 때문에 이 방식은 권장되지 않습니다. 위에서 설명한 바와 같이 데이터베이스에 이전에 문제가 발생하지 않았다면 의 가능성이 높습니다<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> 문제를 감지하는 것은 거의 0에 가까우며, 이 유틸리티는 네트워크 및 스토리지 시스템에 매우 높은 순차 I/O 로드를 생성합니다. 알려진 Oracle 버그에 관한 노출 같은 손상이 존재한다고 판단할 근거가 있지 않는 한 를 실행할 이유는 없습니다<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="db97518eeb3e040b5a78c451efd4b252" category="summary">스냅샷 최적화 백업</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Oracle Storage Snapshot Optimized Backups의 약어입니다</block>
  <block id="52fb042c0d82d8e7bdf9ae239c387729" category="paragraph">데이터베이스를 핫 백업 모드로 설정할 필요가 없기 때문에 Oracle 12c를 사용하면 스냅샷 기반 백업 및 복구가 훨씬 간편해집니다. 그 결과 스토리지 시스템에서 직접 스냅샷 기반 백업을 예약하고 전체 또는 시점 복구를 수행하는 기능을 유지할 수 있습니다.</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">핫 백업 복구 절차는 DBA에게 더 익숙하지만 데이터베이스가 핫 백업 모드인 동안 생성되지 않은 스냅샷을 사용할 수 있는 것은 오래되었습니다. Oracle 10g 및 11g를 복구하는 동안 데이터베이스의 일관성을 유지하기 위해 추가 수동 단계가 필요했습니다. Oracle 12c를 사용하면<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> 및<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> 핫 백업 모드에 있지 않은 데이터 파일 백업에서 아카이브 로그를 재생하는 추가 로직을 포함합니다.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">앞에서 설명한 것처럼 스냅샷 기반 핫 백업을 복구하려면 두 가지 데이터 세트가 필요합니다.</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">백업 모드에서 생성된 데이터 파일의 스냅샷입니다</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">데이터 파일이 핫 백업 모드일 때 생성되는 아카이브 로그</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">복구 중에 데이터베이스는 데이터 파일에서 메타데이터를 읽어 복구에 필요한 아카이브 로그를 선택합니다.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">스토리지 스냅샷으로 최적화된 복구에서는 동일한 결과를 얻기 위해 약간 다른 데이터 세트가 필요합니다.</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">데이터 파일의 스냅샷과 스냅샷이 생성된 시간을 식별하는 방법입니다</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">최신 데이터 파일 체크포인트 시점부터 스냅샷의 정확한 시간까지 로그를 아카이빙합니다</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">복구 중에 데이터베이스는 데이터 파일에서 메타데이터를 읽어 필요한 초기 아카이브 로그를 식별합니다. 전체 또는 특정 시점 복구를 수행할 수 있습니다. 시점 복구를 수행할 때는 데이터 파일의 스냅샷 시간을 알아야 합니다. 지정된 복구 지점은 스냅샷 생성 시간 이후여야 합니다. NetApp에서는 클럭 변동을 고려하여 스냅샷 시간에 최소 몇 분을 추가하는 것이 좋습니다.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">자세한 내용은 Oracle 12c 설명서의 다양한 릴리스에서 제공되는 "Recovery using Storage Snapshot Optimization(스토리지 스냅샷 최적화를 사용한 복구)" 항목에 대한 Oracle 설명서를 참조하십시오. 또한 Oracle 타사 스냅샷 지원에 대해서는 Oracle Document ID Doc ID 604683.1을 참조하십시오.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">데이터 레이아웃</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">가장 간단한 레이아웃은 데이터 파일을 하나 이상의 전용 볼륨으로 분리하는 것입니다. 다른 파일 형식으로 오염되지 않아야 합니다. 이는 중요한 redo 로그, 제어 파일 또는 아카이브 로그를 삭제하지 않고 SnapRestore 작업을 통해 데이터 파일 볼륨을 신속하게 복원할 수 있도록 하기 위한 것입니다.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">SAN은 전용 볼륨 내의 데이터 파일 격리에 대해서도 유사한 요구사항을 가지고 있습니다. Microsoft Windows 같은 운영 체제에서 단일 볼륨에는 각각 NTFS 파일 시스템이 포함된 여러 데이터 파일 LUN이 포함될 수 있습니다. 다른 운영 체제에서는 일반적으로 논리적 볼륨 관리자도 있습니다. 예를 들어, Oracle ASM을 사용할 경우 가장 간단한 옵션은 디스크 그룹을 하나의 볼륨으로 백업 및 복원할 수 있는 단일 볼륨으로 제한하는 것입니다. 성능 또는 용량 관리를 위해 추가 볼륨이 필요한 경우 새 볼륨에 추가 디스크 그룹을 생성하면 관리가 더 쉬워집니다.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">이러한 지침을 따를 경우 정합성 보장 그룹 스냅샷을 수행할 필요 없이 ONTAP에서 스냅샷을 직접 예약할 수 있습니다. 이유는 스냅샷 최적화 백업에는 데이터 파일을 동시에 백업할 필요가 없기 때문입니다.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">여러 볼륨에 분산된 ASM 디스크 그룹과 같은 상황에서는 문제가 발생합니다. 이 경우 ASM 메타데이터가 모든 구성 볼륨에서 일관되도록 CG-스냅샷을 수행해야 합니다.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[참고] ASM spfile 및 passwd 파일이 데이터 파일을 호스팅하는 디스크 그룹에 없는지 확인합니다. 이로 인해 데이터 파일과 데이터 파일만 선택적으로 복원할 수 없습니다.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">로컬 복구 절차 - NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">이 절차는 수동으로 또는 SnapCenter와 같은 응용 프로그램을 통해 실행할 수 있습니다. 기본 절차는 다음과 같습니다.</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">원하는 복원 지점 바로 전에 데이터 파일 볼륨을 스냅샷으로 복구합니다.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">이 절차에서는 활성 파일 시스템에 원하는 아카이브 로그가 여전히 존재한다고 가정합니다. 그렇지 않은 경우, 또는 아카이브 로그를 복원해야 합니다<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> 또는<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> 의 데이터로 이동할 수 있습니다<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> 디렉토리.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">또한 데이터베이스의 규모가 작은 경우 최종 사용자가 에서 직접 데이터 파일을 복구할 수 있습니다<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> 디렉토리에는 자동화 툴 또는 스토리지 관리자의 도움 없이 SnapRestore 명령을 실행할 수 있습니다.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">로컬 복구 절차 - SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">데이터 파일을 호스팅하는 디스크 그룹을 중지합니다. 절차는 선택한 논리적 볼륨 관리자에 따라 다릅니다. ASM을 사용할 경우 이 프로세스에서는 디스크 그룹을 마운트 해제해야 합니다. Linux에서는 파일 시스템을 마운트 해제해야 하며 논리적 볼륨 및 볼륨 그룹이 비활성화됩니다. 목표는 복구할 타겟 볼륨 그룹의 모든 업데이트를 중지하는 것입니다.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">원하는 복원 지점 바로 전에 데이터 파일 디스크 그룹을 스냅샷으로 복원합니다.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">새로 복구된 디스크 그룹을 다시 활성화합니다.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">이 절차에서는 활성 파일 시스템에 원하는 아카이브 로그가 여전히 존재한다고 가정합니다. 그렇지 않은 경우 아카이브 로그 LUN을 오프라인으로 전환하고 복원을 수행하여 아카이브 로그를 복원해야 합니다. 아카이브 로그를 전용 볼륨으로 분할하는 것이 유용한 예이기도 합니다. 아카이브 로그가 재실행 로그와 볼륨 그룹을 공유하는 경우, 최종 기록된 트랜잭션이 손실되지 않도록 전체 LUN 세트를 복원하기 전에 재실행 로그를 다른 곳에 복사해야 합니다.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">전체 복구 예</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">데이터 파일이 손상되었거나 제거되었으며 전체 복구가 필요한 것으로 가정합니다. 이렇게 하는 절차는 다음과 같습니다.</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">특정 시점 복구 예</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">전체 복구 절차는 단일 명령입니다.<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">시점 복구가 필요한 경우 스냅샷의 타임스탬프를 알고 있어야 하며 다음과 같이 식별할 수 있습니다.</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">스냅샷 생성 시간은 3월 9일 및 10:10:06으로 표시됩니다. 안전을 위해 스냅샷 시간에 1분이 추가됩니다.</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">이제 복구가 시작됩니다. 또한 스냅샷 시간을 10:11:00, 기록된 시간 1분 후 가능한 클럭 편차를 계산하고 목표 복구 시간을 10:44로 지정했습니다. 그런 다음 sqlplus는 원하는 복구 시간인 10:44에 도달하는 데 필요한 아카이브 로그를 요청합니다.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">를 사용하여 스냅샷을 사용하여 데이터베이스 복구를 완료합니다<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> 명령에는 특정 라이센스가 필요하지 않지만 를 사용하여 시점 복구가 필요합니다<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Oracle Advanced Compression 라이센스가 필요합니다.</block>
  <block id="87161b635cff9308859c719a20929913" category="summary">Oracle 및 NetApp 백업 툴</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter 및 기타 도구</block>
  <block id="400937771ac8b3d4e7be82bf39033db5" category="paragraph">애플리케이션 환경에서 ONTAP의 기본적인 가치는 즉각적인 스냅샷 복사본, 단순한 SnapMirror 복제, 효율적인 FlexClone 볼륨 생성 등의 핵심 ONTAP 기술에서 비롯됩니다.</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">이러한 핵심 기능을 ONTAP에서 직접 간단히 구성하여 요구사항을 충족하는 경우도 있지만, 더 복잡한 요구사항에는 오케스트레이션 계층이 필요합니다.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter은 NetApp의 대표적인 데이터 보호 제품입니다. 매우 낮은 수준에서 SnapManager 제품은 데이터베이스 백업을 수행하는 방법이라는 측면에서 볼 때 NetApp 제품과 비슷하지만, 처음부터 NetApp 스토리지 시스템의 데이터 보호 관리에 대한 단일 창 방식을 제공하도록 제작되었습니다.</block>
  <block id="e538db970e1ed1ffe018725fdf223f9e" category="paragraph">SnapCenter에는 스냅샷 복사본 기반 백업 및 복원, SnapMirror 및 SnapVault 복제 등의 기본 기능과 더불어 대기업에서 규모에 따라 운영하는 데 필요한 기타 기능이 포함되어 있습니다. 이러한 고급 기능에는 확장된 역할 기반 액세스 제어(RBAC) 기능, 타사 오케스트레이션 제품과 통합하기 위한 RESTful API, 데이터베이스 호스트에서 SnapCenter 플러그인의 무중단 중앙 관리, 클라우드급 환경에 맞게 설계된 사용자 인터페이스가 포함됩니다.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">휴식</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP에는 풍부한 RESTful API 세트도 포함되어 있습니다. 따라서 타사 공급업체에서는 ONTAP과 긴밀히 통합되는 데이터 보호 및 기타 관리 애플리케이션을 구축할 수 있습니다. 또한 RESTful API는 자체 자동화 워크플로우와 유틸리티를 생성하려는 고객이 손쉽게 사용할 수 있습니다.</block>
  <block id="e4cea644160fe9fa4ccd92ab3f079363" category="summary">Oracle 스냅샷 기반 백업 및 복구</block>
  <block id="9adc36f162691b8ed14a886b6068f368" category="doc">Oracle 온라인 백업</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">백업 모드에서 Oracle 데이터베이스를 보호하고 복구하려면 두 세트의 데이터가 필요합니다. 이것이 유일한 Oracle 백업 옵션은 아니지만 가장 일반적입니다.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">백업 모드의 데이터 파일 스냅샷</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">데이터 파일이 백업 모드일 때 생성된 아카이브 로그입니다</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">커밋된 모든 트랜잭션을 포함하여 완전한 복구가 필요한 경우 세 번째 항목이 필요합니다.</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">현재 redo 로그 집합입니다</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">온라인 백업의 복구를 유도하는 방법에는 여러 가지가 있습니다. 많은 고객은 ONTAP CLI를 사용한 다음 Oracle RMAN 또는 sqlplus를 사용하여 복구를 완료함으로써 스냅샷을 복구합니다. 이러한 현상은 데이터베이스 복구 가능성과 빈도가 매우 낮고 숙련된 DBA가 복구 절차를 처리하는 대규모 운영 환경에서 특히 흔합니다. NetApp SnapCenter와 같은 솔루션에는 완벽한 자동화를 위해 명령줄 및 그래픽 인터페이스 모두를 지원하는 Oracle 플러그인이 포함되어 있습니다.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">일부 대규모 고객은 예약된 스냅샷을 준비하는 과정에서 특정 시간에 데이터베이스를 백업 모드로 전환하도록 호스트에 기본 스크립트를 구성하여 보다 간단한 접근 방식을 취했습니다. 예를 들어, 명령을 예약합니다<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> 23:58에<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> 00:02에 스냅샷을 예약한 다음 자정에 스토리지 시스템에서 직접 스냅샷을 예약합니다. 그 결과 외부 소프트웨어 또는 라이센스가 필요 없는 간단하고 확장성이 뛰어난 백업 전략을 구축할 수 있습니다.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">가장 간단한 레이아웃은 데이터 파일을 하나 이상의 전용 볼륨으로 분리하는 것입니다. 다른 파일 형식으로 오염되지 않아야 합니다. 이는 중요한 재실행 로그, 제어 파일 또는 아카이브 로그를 삭제하지 않고 SnapRestore 작업을 통해 데이터 파일 볼륨을 신속하게 복원할 수 있도록 보장하기 위한 것입니다.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">SAN은 전용 볼륨 내의 데이터 파일 격리에 대해서도 유사한 요구사항을 가지고 있습니다. Microsoft Windows 같은 운영 체제에서 단일 볼륨에는 각각 NTFS 파일 시스템이 포함된 여러 데이터 파일 LUN이 포함될 수 있습니다. 다른 운영 체제에는 일반적으로 논리적 볼륨 관리자가 있습니다. 예를 들어, Oracle ASM을 사용할 경우 가장 간단한 옵션은 ASM 디스크 그룹의 LUN을 하나의 볼륨으로 백업 및 복원할 수 있는 단일 볼륨으로 제한하는 것입니다. 성능 또는 용량 관리를 위해 추가 볼륨이 필요한 경우 새 볼륨에 추가 디스크 그룹을 생성하면 관리가 더 간단해집니다.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">이러한 지침을 따를 경우 정합성 보장 그룹 스냅샷을 수행할 필요 없이 스토리지 시스템에서 스냅샷을 직접 예약할 수 있습니다. Oracle 백업에는 데이터 파일을 동시에 백업할 필요가 없기 때문입니다. 온라인 백업 절차는 몇 시간 내에 테이프로 천천히 스트리밍될 때 데이터 파일을 계속해서 업데이트할 수 있도록 설계되었습니다.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">여러 볼륨에 분산된 ASM 디스크 그룹을 사용하는 것과 같은 상황에서는 문제가 발생합니다. 이 경우 ASM 메타데이터가 모든 구성 볼륨에서 일관되도록 CG-스냅샷을 수행해야 합니다.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">* 주의: * ASM을 확인합니다<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> 및<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> 파일이 데이터 파일을 호스팅하는 디스크 그룹에 없습니다. 이로 인해 데이터 파일과 데이터 파일만 선택적으로 복원할 수 없습니다.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">이 절차에서는 활성 파일 시스템에 원하는 아카이브 로그가 여전히 존재한다고 가정합니다. 그렇지 않은 경우 아카이브 로그를 복원해야 합니다. 그렇지 않으면 RMAN/sqlplus를 스냅샷 디렉토리의 데이터로 리디렉션할 수 있습니다.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">또한 데이터베이스의 규모가 작은 경우 최종 사용자가 에서 직접 데이터 파일을 복구할 수 있습니다<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> 자동화 툴 또는 스토리지 관리자의 도움 없이 디렉토리를 실행하여<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">데이터 파일을 호스팅하는 디스크 그룹을 중지합니다. 절차는 선택한 논리적 볼륨 관리자에 따라 다릅니다. ASM을 사용할 경우 이 프로세스에서는 디스크 그룹을 마운트 해제해야 합니다. Linux에서는 파일 시스템을 마운트 해제하고 논리적 볼륨 및 볼륨 그룹을 비활성화해야 합니다. 목표는 복구할 타겟 볼륨 그룹의 모든 업데이트를 중지하는 것입니다.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">전체 복구가 필요한 경우 모든 재실행 로그를 재생합니다.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">이 절차에서는 활성 파일 시스템에 원하는 아카이브 로그가 여전히 존재한다고 가정합니다. 그렇지 않은 경우 아카이브 로그 LUN을 오프라인으로 전환하고 복원을 수행하여 아카이브 로그를 복원해야 합니다. 아카이브 로그를 전용 볼륨으로 분할하는 것이 유용한 예이기도 합니다. 아카이브 로그가 재실행 로그와 볼륨 그룹을 공유하는 경우 전체 LUN 세트를 복원하기 전에 재실행 로그를 다른 위치에 복사해야 합니다. 이 단계는 최종 기록된 트랜잭션의 손실을 방지합니다.</block>
  <block id="1536f0d3e3ee227abdec76f432b89cae" category="summary">Oracle 데이터 보호 SLA</block>
  <block id="e9c8b7044dfae7a21f1a9c4d08628a66" category="doc">복구 시간 목표, 복구 시점 목표 및 서비스 수준 계약</block>
  <block id="020e620c60ad38b75f0ff2a2fe4067b0" category="paragraph">데이터 보호 전략은 비즈니스 요구사항에 따라 정의되어야 합니다.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">이러한 요구 사항에는 복구 속도, 허용되는 최대 데이터 손실 및 백업 보존 요구 사항 등의 요인이 포함됩니다. 데이터 보호 계획도 데이터 보존 및 복원에 대한 다양한 규정 요구 사항을 고려해야 합니다. 마지막으로 사용자 또는 애플리케이션 오류로 인해 발생하는 일반적인 복구 방법부터 사이트의 완전한 손실을 포함하는 재해 복구 시나리오에 이르기까지 다양한 데이터 복구 시나리오를 고려해야 합니다.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">데이터 보호 및 복구 정책을 조금만 변경하면 스토리지, 백업 및 복구의 전체 아키텍처에 상당한 영향을 줄 수 있습니다. 데이터 보호 아키텍처의 복잡성을 방지하려면 설계 작업을 시작하기 전에 표준을 정의하고 문서화해야 합니다. 불필요한 기능이나 보호 수준은 불필요한 비용과 관리 부담을 초래하며, 초기에 간과한 요구 사항으로 인해 프로젝트가 잘못된 방향으로 진행되거나 최종 설계 변경이 필요할 수 있습니다.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">복구 시간 목표</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">RTO(복구 시간 목표)는 서비스 복구에 허용되는 최대 시간을 정의합니다. 예를 들어 인사 데이터베이스의 RTO는 24시간이 될 수 있습니다. 왜냐하면 업무 중에 이 데이터에 액세스하지 못하는 것이 매우 불편함에도 불구하고 비즈니스가 계속 운영될 수 있기 때문입니다. 반면 은행의 총계정원장을 지원하는 데이터베이스에는 분 또는 초 단위로 측정된 RTO가 있습니다. 실제 서비스 중단과 네트워크 패킷 손실과 같은 일상적인 이벤트를 구분하는 방법이 있어야 하므로 RTO 0은 불가능합니다. 하지만 제로에 가까운 RTO는 일반적인 요구사항입니다.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">복구 시점 목표</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">RPO(복구 지점 목표)는 허용되는 최대 데이터 손실을 정의합니다. 대부분의 경우 RPO는 스냅샷 또는 SnapMirror 업데이트 빈도에 의해서만 결정됩니다.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">경우에 따라 RPO를 보다 적극적으로 설정하여 특정 데이터를 보다 자주 보호할 수 있습니다. 데이터베이스 컨텍스트에서 RPO는 일반적으로 특정 상황에서 손실될 수 있는 로그 데이터의 양이 어느 정도인지에 관한 문제입니다. 제품 버그 또는 사용자 오류로 인해 데이터베이스가 손상된 일반적인 복구 시나리오에서 RPO는 0이어야 합니다. 즉, 데이터 손실이 없어야 합니다. 복구 절차에서는 데이터베이스 파일의 이전 복사본을 복원한 다음 로그 파일을 재생하여 데이터베이스 상태를 원하는 시점으로 되돌리는 작업을 수행합니다. 이 작업에 필요한 로그 파일이 이미 원래 위치에 있어야 합니다.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">비정상적인 시나리오에서는 로그 데이터가 손실될 수 있습니다. 예를 들어, 우발적 또는 악의적 경우입니다<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> 데이터베이스 파일의 경우 모든 데이터가 삭제될 수 있습니다. 유일한 옵션은 로그 파일을 포함하여 백업에서 복원하는 것이며, 일부 데이터가 손실될 수밖에 없습니다. 기존 백업 환경에서 RPO를 향상시킬 수 있는 유일한 옵션은 로그 데이터의 반복 백업을 수행하는 것입니다. 그러나 지속적인 데이터 이동과 백업 시스템을 지속적으로 실행하는 서비스로 유지 관리하기가 어렵기 때문에 이러한 문제에는 한계가 있습니다. 고급 스토리지 시스템의 이점 중 하나는 파일에 대한 우발적 또는 악의적 손상으로부터 데이터를 보호하여 데이터 이동 없이 더 높은 RPO를 제공하는 기능입니다.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">재해 복구에는 물리적 재해 발생 시 서비스를 복구하는 데 필요한 IT 아키텍처, 정책 및 절차가 포함됩니다. 여기에는 홍수, 화재 또는 악의적이거나 과실로 행동하는 사람이 포함될 수 있습니다.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">재해 복구는 단순한 복구 절차 그 이상입니다. 다양한 위험을 식별하고, 데이터 복구 및 서비스 연속성 요구 사항을 정의하고, 관련 절차에 따라 올바른 아키텍처를 제공하는 완전한 프로세스입니다.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">데이터 보호 요구 사항을 설정할 때는 일반적인 RPO 및 RTO 요구 사항과 재해 복구에 필요한 RPO 및 RTO 요구 사항을 구분해야 합니다. 일부 애플리케이션 환경에서는 비교적 일반적인 사용자 오류부터 데이터 센터 파괴에 이르는 데이터 손실 상황에 대해 0의 RPO와 0에 가까운 RTO가 필요합니다. 그러나 이러한 높은 수준의 보호를 위해서는 비용과 관리 상의 문제가 발생합니다.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">일반적으로 비재해 데이터 복구 요구사항은 두 가지 이유로 엄격해야 합니다. 첫째, 애플리케이션 버그와 사용자 오류로 인해 데이터가 손상되는 것은 거의 불가피한 시점까지 예상할 수 있습니다. 둘째, 스토리지 시스템이 폐기되지 않는 한 RPO 0과 낮은 RTO를 제공할 수 있는 백업 전략을 설계하는 것은 쉽지 않습니다. 쉽게 해결할 수 있는 심각한 위험을 해결하지 않을 이유가 없습니다. 따라서 로컬 복구에 대한 RPO 및 RTO 목표를 적극적으로 적용해야 합니다.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">재해 복구 RTO 및 RPO 요구 사항은 재해 가능성 및 관련 데이터 손실 또는 비즈니스 중단 결과에 따라 더 크게 달라집니다. RPO 및 RTO 요구 사항은 일반적인 원칙이 아닌 실제 비즈니스 요구 사항을 기반으로 해야 합니다. 여러 논리적 및 물리적 재해 시나리오를 고려해야 합니다.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">논리적 재해</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">논리적 재해에는 사용자, 애플리케이션 또는 OS 버그, 소프트웨어 오작동으로 인한 데이터 손상이 포함됩니다. 논리적 재해에는 바이러스 또는 웜이 있는 외부 사용자에 의한 악의적인 공격이나 응용 프로그램 취약점을 악용하는 공격도 포함될 수 있습니다. 이러한 경우 물리적 인프라스트럭처는 손상되지 않지만 기본 데이터는 더 이상 유효하지 않습니다.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">점점 더 일반적인 유형의 논리적 재해를 랜섬웨어라고 하며, 이를 공격 벡터가 데이터를 암호화하는 데 사용됩니다. 암호화는 데이터를 손상시키지 않지만 제3자에게 지불이 이루어질 때까지 데이터를 사용할 수 없게 합니다. 랜섬웨어 해킹을 특별히 도입한 기업이 점점 더 많아지고 있습니다. NetApp는 이러한 위협에 대해 변조 방지 스냅샷을 제공합니다. 따라서 스토리지 관리자도 구성된 만료일 전에 보호된 데이터를 변경할 수 없습니다.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">물리적 재해</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">물리적 재해에는 인프라의 구성 요소가 중복성을 넘어 데이터 손실이나 서비스 손실로 이어지는 장애가 포함됩니다. 예를 들어 RAID 보호는 디스크 드라이브 이중화를 제공하며 HBA를 사용하면 FC 포트 및 FC 케이블 이중화를 제공할 수 있습니다. 이러한 구성 요소의 하드웨어 장애는 예측 가능하며 가용성에 영향을 미치지 않습니다.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">엔터프라이즈 환경에서는 일반적으로 예측 가능한 유일한 물리적 재해 시나리오가 사이트의 완전한 손실인 시점까지 중복 구성 요소를 사용하여 전체 사이트의 인프라를 보호할 수 있습니다. 그런 다음 재해 복구 계획이 사이트 간 복제에 달려 있습니다.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">동기식 및 비동기식 데이터 보호</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">이상적인 환경에서는 모든 데이터를 지리적으로 분산된 사이트에 걸쳐 동기식으로 복제합니다. 이러한 복제는 다음과 같은 몇 가지 이유로 항상 실현 가능하지 않거나 가능한 경우가 있습니다.</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">애플리케이션/데이터베이스가 처리를 진행하기 전에 모든 변경 사항을 두 위치에 복제해야 하기 때문에 동기식 복제는 불가피하게 쓰기 지연 시간을 증가시킵니다. 이로 인해 발생할 수 있는 성능 영향은 용납되지 않으므로 동기식 미러링 사용을 배제할 수 있습니다.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">100% SSD 스토리지의 채택이 증가함에 따라 성능 기대치에는 수십만 IOPS와 1ms 미만의 지연 시간이 포함되므로 쓰기 지연 시간이 더 많이 발생하고 있습니다. 100% SSD 사용의 이점을 최대한 활용하려면 재해 복구 전략을 다시 세워야 할 수 있습니다.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">데이터 세트는 바이트 측면에서 계속 증가하고 있기 때문에 동기 복제를 지속할 수 있는 충분한 대역폭을 확보하는 데 어려움이 있습니다.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">또한 데이터 세트가 복잡해지면서 대규모 동기식 복제 관리에 따르는 문제가 발생합니다.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">클라우드 기반 전략에서는 복제 거리와 지연 시간이 더욱 길어져 동기식 미러링을 사용하는 것이 오히려 사라지는 경우가 많습니다.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp은 가장 까다로운 데이터 복구 요구사항을 위한 동기식 복제 솔루션과 향상된 성능과 유연성을 지원하는 비동기 솔루션을 제공합니다. 또한 NetApp 기술은 Oracle DataGuard와 같은 여러 타사 복제 솔루션과 원활하게 통합됩니다</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">보존 시간</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">데이터 보호 전략의 마지막 측면은 데이터 보존 시간이며, 이는 크게 달라질 수 있습니다.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">일반적으로 운영 사이트에서 14일 야간 백업을 수행하고 보조 사이트에 90일 동안 백업을 저장해야 합니다.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">많은 고객이 서로 다른 미디어에 저장된 분기별 독립 실행형 아카이브를 생성합니다.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">데이터베이스를 지속적으로 업데이트하면 기록 데이터가 필요하지 않을 수 있으며, 백업은 며칠 동안만 보존되어야 합니다.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">규정 요구 사항에 따라 365일 기간 내에 임의의 트랜잭션 시점까지 복구가 필요할 수 있습니다.</block>
  <block id="a83f7a3ea63946cbdc1977d641e8460c" category="summary">ONTAP 기반 Oracle 및 스냅샷의 역할</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">스냅샷 기반 백업</block>
  <block id="5e3f0537b2a1927f4a24b28e9157cc0b" category="paragraph">ONTAP에서 Oracle 데이터 보호의 기반은 NetApp Snapshot 기술입니다.</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">키 값은 다음과 같습니다.</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">* Simplicity. * 스냅샷은 특정 시점의 데이터 컨테이너 내용의 읽기 전용 복사본입니다.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">* 효율성. * 스냅샷은 생성 시점에 공간이 필요하지 않습니다. 공간은 데이터가 변경될 때만 사용됩니다.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">* 관리 효율성. * 스냅샷이 스토리지 OS의 기본 부분이기 때문에 스냅샷을 기반으로 하는 백업 전략은 구성 및 관리가 용이합니다. 스토리지 시스템의 전원이 켜져 있으면 백업을 생성할 준비가 된 것입니다.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">* 확장성. * 파일 및 LUN의 단일 컨테이너에 대해 최대 1024개의 백업을 유지할 수 있습니다. 복잡한 데이터 세트의 경우 일관된 단일 스냅샷 세트로 여러 데이터 컨테이너를 보호할 수 있습니다.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">볼륨에 1024개의 스냅샷이 포함되어 있는지 여부에 관계없이 성능에 영향을 주지 않습니다.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">많은 스토리지 공급업체가 스냅샷 기술을 제공하지만 ONTAP 내 스냅샷 기술은 고유한 특성을 가지고 있으며 엔터프라이즈 애플리케이션 및 데이터베이스 환경에 큰 이점을 제공합니다.</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">스냅샷 복사본은 기본 WAFL(Write Anywhere File Layout)의 일부입니다. 이러한 기술은 애드온 또는 외부 기술이 아닙니다. 따라서 스토리지 시스템이 백업 시스템이므로 관리가 간소화됩니다.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">스냅샷 복사본은 성능에 영향을 미치지 않습니다. 단, 기본 스토리지 시스템이 가득 찬 스냅샷에 많은 데이터가 저장되는 경우와 같이 일부 에지 사례는 예외입니다.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">"정합성 보장 그룹"이라는 용어는 일관된 데이터 모음으로 관리되는 스토리지 객체 그룹을 지칭하는 데 주로 사용됩니다. 특정 ONTAP 볼륨의 스냅샷은 정합성 보장 그룹 백업을 구성합니다.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">ONTAP 스냅샷은 또한 경쟁 기술보다 더 효과적으로 확장할 수 있습니다. 고객은 성능에 영향을 주지 않고 5개, 50개 또는 500개의 스냅샷을 저장할 수 있습니다. 볼륨에 현재 허용되는 최대 스냅숏 수는 1024개입니다. 추가 스냅샷 보존이 필요한 경우 스냅샷을 추가 볼륨에 단계적으로 적용할 수 있는 옵션이 있습니다.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">그 결과, ONTAP에서 호스팅되는 데이터 세트를 보호하는 것은 간단하며 확장성이 뛰어납니다. 백업에는 데이터를 이동할 필요가 없으므로 네트워크 전송 속도, 많은 수의 테이프 드라이브 또는 디스크 스테이징 영역의 제한이 아니라 비즈니스 요구에 맞게 백업 전략을 조정할 수 있습니다.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">스냅샷을 데이터 보호 전략으로 사용하는 것에 대해 자주 묻는 질문 중 하나는 "실제" 데이터와 스냅샷 데이터가 동일한 드라이브에 있다는 사실입니다. 이러한 드라이브가 손실되면 기본 데이터와 백업이 모두 손실됩니다.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">하지만 로컬 스냅샷만 사용할 수 있는 백업 전략이 되어서는 안 됩니다. 그렇기 때문에 NetApp에서는 스냅샷을 독립 드라이브 세트에 빠르고 효율적으로 복제할 수 있는 SnapMirror 및 SnapVault 복제 같은 기술을 제공합니다. 스냅샷과 스냅샷 복제를 갖춘 제대로 설계된 솔루션을 사용하면 분기별 아카이브로 테이프 사용을 최소화하거나 완전히 제거할 수 있습니다.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">ONTAP Snapshot 복사본을 사용하여 데이터를 보호하는 방법에는 여러 가지가 있으며, 스냅샷은 복제, 재해 복구, 클론 복제를 포함한 다른 ONTAP 기능의 기반입니다. 스냅샷 기술에 대한 전체 설명은 이 문서의 범위를 벗어나지만 다음 섹션에서는 일반적인 개요를 제공합니다.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">데이터 세트의 스냅샷을 생성하는 방법에는 두 가지가 있습니다.</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">충돌 시에도 정합성 보장 백업</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">애플리케이션 정합성이 보장되는 백업</block>
  <block id="7733cc553d118547b64c858cb4281f24" category="paragraph">데이터 세트의 장애 발생 시 정합성이 보장되는 백업은 단일 시점의 전체 데이터 세트 구조를 캡처하는 것을 의미합니다. 데이터 세트가 단일 NetApp FlexVol 볼륨에 저장된 경우 프로세스는 간단하며 언제든지 스냅샷을 생성할 수 있습니다. 데이터 세트가 여러 볼륨으로 확장되는 경우에는 정합성 보장 그룹(CG) 스냅샷을 생성해야 합니다. CG 스냅샷을 생성하는 옵션에는 NetApp SnapCenter 소프트웨어, 기본 ONTAP 일관성 그룹 기능, 사용자 유지보수 스크립트 등 여러 가지가 있습니다.</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">충돌 시에도 정합성 보장 백업은 백업 지점 복구가 충분할 때 주로 사용됩니다. 더 세부적인 복구가 필요한 경우 일반적으로 애플리케이션 정합성이 보장되는 백업이 필요합니다.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">"애플리케이션 정합성 보장"에서 "정합성 보장"이라는 단어가 잘못된 표현인 경우가 많습니다. 예를 들어 Oracle 데이터베이스를 백업 모드로 설정하는 것을 애플리케이션 정합성 보장 백업이라고 하지만 데이터가 어떤 식으로든 일관되지 않거나 정지되지 않습니다. 백업 내내 데이터가 계속 변경됩니다. 반면 대부분의 MySQL 및 Microsoft SQL Server 백업은 실제로 백업을 실행하기 전에 데이터를 정지합니다. VMware는 특정 파일의 일관성을 유지할 수도 있고 그렇지 않을 수도 있습니다.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">"정합성 보장 그룹"이란 스토리지 배열이 여러 스토리지 리소스를 단일 이미지로 관리하는 기능을 의미합니다. 예를 들어, 데이터베이스는 10개의 LUN으로 구성될 수 있습니다. 스토리지에서 이러한 10개의 LUN을 일관된 방식으로 백업, 복원 및 복제할 수 있어야 합니다. LUN의 이미지가 백업 시점에 일치하지 않으면 복구할 수 없습니다. 이러한 10개의 LUN을 복제하려면 모든 복제본이 서로 완벽하게 동기화되어야 합니다.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">ONTAP에 대해 설명할 때는 "일관성 그룹"이라는 용어가 자주 사용되지 않습니다. 왜냐하면 일관성이 항상 ONTAP 내의 볼륨 및 애그리게이트 아키텍처의 기본 기능이기 때문입니다. 다른 많은 스토리지 시스템은 LUN 또는 파일 시스템을 개별 유닛으로 관리합니다. 그런 다음 데이터 보호를 위해 "정합성 보장 그룹"으로 구성할 수도 있지만 이 작업은 구성에 있어 추가 단계입니다.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP는 항상 일관된 로컬 및 복제된 데이터 이미지를 캡처할 수 있었습니다. ONTAP 시스템의 다양한 볼륨이 일반적으로 공식적으로 일관성 그룹으로 설명되어 있는 것은 아니지만, 그것이 바로 그러한 볼륨입니다. 해당 볼륨의 스냅샷은 일관성 그룹 이미지이고, 해당 스냅샷에 대한 복원은 일관성 그룹 복원이며, SnapMirror 및 SnapVault에서 모두 일관성 그룹 복제를 제공합니다.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">정합성 보장 그룹 스냅샷</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">일관성 그룹 스냅샷(CG-스냅샷)은 기본 ONTAP 스냅샷 기술의 확장입니다. 표준 스냅샷 작업은 단일 볼륨 내에서 모든 데이터의 일관된 이미지를 생성하지만 여러 볼륨 및 여러 스토리지 시스템에 걸쳐 일관된 스냅샷 세트를 생성해야 하는 경우도 있습니다. 그 결과 하나의 개별 볼륨의 스냅샷과 동일한 방식으로 사용할 수 있는 스냅샷 세트가 생성됩니다. 로컬 데이터 복구에 사용하거나, 재해 복구를 위해 복제하거나, 일관된 단일 유닛으로 복제할 수 있습니다.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">CG-스냅샷의 가장 큰 용도는 12개의 컨트롤러를 포함하여 약 1PB의 데이터베이스 환경을 위한 것입니다. 이 시스템에서 생성된 CG 스냅샷이 백업, 복구 및 클론 생성에 사용되었습니다.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">대부분의 경우 데이터 세트가 여러 볼륨에 걸쳐 있고 쓰기 순서를 보존해야 하는 경우 선택한 관리 소프트웨어에서 CG 스냅샷이 자동으로 사용됩니다. 이러한 경우 CG-스냅샷의 기술적 세부 사항을 이해할 필요가 없습니다. 그러나 복잡한 데이터 보호 요구 사항이 데이터 보호 및 복제 프로세스를 세부적으로 제어해야 하는 경우도 있습니다. 몇 가지 옵션은 자동화 워크플로우 또는 맞춤형 스크립트를 사용하여 CG-스냅샷 API를 호출하는 것입니다. 최상의 옵션과 CG-스냅샷의 역할을 이해하려면 기술에 대한 자세한 설명이 필요합니다.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">CG 스냅샷 세트를 생성하는 프로세스는 2단계로 구성됩니다.</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">모든 타겟 볼륨에 쓰기 펜싱을 설정합니다.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">펜싱된 상태에서 해당 볼륨의 스냅샷을 생성합니다.</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">쓰기 펜싱은 연속적으로 설정됩니다. 즉, 펜싱 프로세스가 여러 볼륨에 설정되면 나중에 나타나는 볼륨에 계속 커밋되기 때문에 쓰기 I/O가 시퀀스의 첫 번째 볼륨에 고정됩니다. 이는 처음에 쓰기 순서를 보존해야 하는 요구 사항을 위반하는 것처럼 보일 수 있지만, 이는 호스트에서 비동기식으로 실행되며 다른 쓰기에 의존하지 않는 입출력에만 적용됩니다.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">예를 들어, 데이터베이스가 많은 비동기식 데이터 파일 업데이트를 발행하고 운영 체제가 I/O를 재주문하고 자체 스케줄러 구성에 따라 업데이트를 완료할 수 있습니다. 애플리케이션 및 운영 체제에서 쓰기 순서를 유지하기 위한 요구 사항을 이미 해제했기 때문에 이러한 유형의 입출력 순서를 보장할 수 없습니다.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">반대의 예로 대부분의 데이터베이스 로깅 작업은 동기적입니다. 입출력이 확인되고 이러한 쓰기 순서가 유지되어야 데이터베이스가 더 이상 로그 쓰기를 진행하지 않습니다. 로그 입출력이 펜싱된 볼륨에 도착하면 로그 입출력이 확인되지 않고 애플리케이션이 추가 쓰기를 차단합니다. 마찬가지로 파일 시스템 메타데이터 I/O는 일반적으로 동기식입니다. 예를 들어 파일 삭제 작업은 손실되지 않아야 합니다. xfs 파일 시스템이 있는 운영 체제에서 파일 및 xfs 파일 시스템 메타데이터를 업데이트한 입출력이 펜싱된 볼륨에 있는 해당 파일에 대한 참조를 제거하기 위해 삭제된 경우 파일 시스템 작업이 일시 중지됩니다. 따라서 CG 스냅샷 작업 중에 파일 시스템의 무결성이 보장됩니다.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">대상 볼륨에 쓰기 펜싱이 설정된 후에는 스냅샷을 생성할 준비가 됩니다. 볼륨의 상태가 종속 쓰기 관점에서 고정되므로 스냅샷을 정확하게 동시에 생성할 필요가 없습니다. CG-스냅샷을 생성하는 애플리케이션의 결함을 방지하기 위해 초기 쓰기 펜싱에는 구성 가능한 시간 초과가 포함되어 있습니다. 이 시간 초과는 ONTAP가 자동으로 펜싱을 해제하고 정의된 초 후에 쓰기 처리를 재개합니다. 시간 제한 기간이 만료되기 전에 모든 스냅샷이 생성되면 생성된 스냅샷 세트는 유효한 정합성 보장 그룹입니다.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">종속 쓰기 순서입니다</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">기술적 관점에서 정합성 보장 그룹의 핵심은 쓰기 순서, 특히 종속 쓰기 순서를 유지하는 것입니다. 예를 들어, 10개의 LUN에 쓰는 데이터베이스는 이들 모두에 동시에 쓰입니다. 많은 쓰기가 비동기적으로 실행되므로 쓰기 작업이 완료되는 순서는 중요하지 않으며 실제 완료 순서는 운영 체제 및 네트워크 동작에 따라 다릅니다.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">데이터베이스에서 추가 쓰기를 진행하려면 디스크에 일부 쓰기 작업이 있어야 합니다. 이러한 중요한 쓰기 작업을 종속 쓰기라고 합니다. 이후의 쓰기 입출력은 디스크에 이러한 쓰기가 있는지에 따라 달라집니다. 이러한 10개 LUN의 모든 스냅샷, 복구 또는 복제는 종속 쓰기 순서가 보장되도록 해야 합니다. 파일 시스템 업데이트는 쓰기 순서 종속 쓰기의 또 다른 예입니다. 파일 시스템 변경 순서를 보존해야 합니다. 그렇지 않으면 전체 파일 시스템이 손상될 수 있습니다.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">전략</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">스냅샷 기반 백업에는 다음과 같은 두 가지 기본 접근 방식이 있습니다.</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">스냅샷 보호 핫 백업</block>
  <block id="c81725eb350a685210d69762bd5d725d" category="paragraph">데이터베이스의 충돌 시에도 정합성 보장 백업은 데이터 파일, 재실행 로그, 제어 파일을 비롯한 전체 데이터베이스 구조를 단일 지점에서 캡처하는 것을 의미합니다. 데이터베이스를 단일 NetApp FlexVol 볼륨에 저장하면 프로세스가 단순해지며 언제든 스냅샷을 생성할 수 있습니다. 데이터베이스가 여러 볼륨으로 확장되는 경우에는 일관성 그룹(CG) 스냅샷을 생성해야 합니다. CG 스냅샷을 생성하는 옵션에는 NetApp SnapCenter 소프트웨어, 기본 ONTAP 일관성 그룹 기능, 사용자 유지보수 스크립트 등 여러 가지가 있습니다.</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">스냅샷에서 충돌 시에도 정합성 보장 백업은 백업 지점 복구가 충분할 때 주로 사용됩니다. 경우에 따라 아카이브 로그를 적용할 수 있지만 더 세분화된 시점 복구가 필요한 경우에는 온라인 백업을 적용하는 것이 좋습니다.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">스냅샷 기반 온라인 백업의 기본 절차는 다음과 같습니다.</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">에 데이터베이스를 배치합니다<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> 모드를 선택합니다.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">데이터 파일을 호스팅하는 모든 볼륨의 스냅샷을 생성합니다.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Exit(종료)<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> 모드를 선택합니다.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">명령을 실행합니다<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> 로그 보관을 수행합니다.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">아카이브 로그를 호스팅하는 모든 볼륨의 스냅샷을 생성합니다.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">이 절차를 따르면 백업 모드의 데이터 파일과 백업 모드 중에 생성된 주요 아카이브 로그가 포함된 스냅샷 세트가 만들어집니다. 데이터베이스를 복구하는 데에는 두 가지 요구사항이 있는데, 편의를 위해 제어 파일 같은 파일도 보호해야 하지만 데이터 파일과 아카이브 로그를 반드시 보호해야 합니다.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">고객마다 전략은 다르겠지만 이 전략은 거의 모든 경우에 결국은 아래에 설명된 동일한 원칙에 기반을 두고 수립됩니다.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">스냅샷 기반 복구</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Oracle 데이터베이스를 위해 볼륨 레이아웃을 설계할 때 첫 번째 내려야 할 결정은 볼륨 기반 NetApp SnapRestore(VBSR) 기술을 사용할 것이냐입니다.</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">볼륨 기반 SnapRestore는 볼륨을 이전 시점으로 거의 즉시 되돌릴 수 있게 합니다. 볼륨의 모든 데이터를 되돌릴 수 있기 때문에 VBSR은 모든 사용 사례에는 적합하지 않을 수 있습니다. 예를 들어, 데이터 파일, 재실행 로그, 아카이브 로그를 비롯한 전체 데이터베이스가 단일 볼륨에 저장되고 이 볼륨이 VBSR을 통해 복원되는 경우 최신 아카이브 로그와 재실행 데이터가 삭제되기 때문에 데이터가 손실됩니다.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">VBSR은 복원이 필요하지 않습니다. 대부분의 경우 파일을 기반으로 SFSR(Single File SnapRestore)을 사용하거나 스냅샷에서 액티브 파일 시스템으로 파일을 복사하여 데이터베이스를 복원할 수 있습니다.</block>
  <block id="2093e578085fede0f022c4efdb79c336" category="paragraph">VBSR은 데이터베이스가 대규모이거나 최대한 빨리 복구해야 할 경우에 적용하는 것이 좋으며 VBSR을 사용할 시 데이터 파일을 격리해야 합니다. NFS 환경에서는 다른 유형의 파일에 의해 손상되지 않은 전용 볼륨에 기존 데이터베이스의 데이터 파일을 저장해야 하며 SAN 환경에서는 전용 FlexVol 볼륨의 전용 LUN에 데이터 파일을 저장해야 합니다. Oracle 자동 스토리지 관리(ASM)와 같은 볼륨 관리자를 사용하는 경우 디스크 그룹도 데이터 파일 전용이어야 합니다.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">이런 방식으로 데이터 파일을 격리하면 다른 파일 시스템을 손상시키지 않고 이전 상태로 되돌릴 수 있습니다.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">스냅숏 예비 공간입니다</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">SAN 환경에 있는 Oracle 데이터의 각 볼륨에 대해 를 참조하십시오<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> LUN 환경에서 스냅샷에 대한 공간을 예약하는 것은 유용하지 않으므로 0으로 설정해야 합니다. 부분 예약 공간이 100으로 설정된 경우 LUN이 있는 볼륨의 스냅샷은 전체 데이터의 100% 턴오버를 처리하기 위해 스냅샷 예약 공간을 제외하고 볼륨에서 충분한 여유 공간을 필요로 합니다. 부분 예약이 더 낮은 값으로 설정된 경우 이에 따라 더 적은 양의 여유 공간이 필요하지만 항상 스냅숏 예비 공간이 제외됩니다. 즉, LUN 환경에서 스냅샷 예약 공간이 낭비됩니다.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">NFS 환경에는 다음 두 가지 옵션이 있습니다.</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">를 설정합니다<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> 예상되는 스냅샷 공간 소비량을 기준으로 합니다.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">를 설정합니다<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> 활성 및 스냅샷 공간 소비를 총체적으로 제로화하고 관리합니다.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">첫 번째 옵션으로<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> 0이 아닌 값(일반적으로 약 20%)으로 설정됩니다. 그러면 이 공간이 사용자로부터 숨겨집니다. 하지만 이 값은 활용률의 한계를 생성하지 않습니다. 20%가 예약된 데이터베이스에서 턴오버가 30%인 경우 스냅샷 공간은 20% 예약이라는 경계를 넘어 확장할 수 있으며 미예약 공간을 점유할 수 있습니다.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">예약을 20%와 같은 값으로 설정할 때 얻을 수 있는 가장 큰 이점은 일부 공간이 스냅샷에 항상 사용 가능한지 확인하는 것입니다. 예를 들어, 20%가 예약된 1TB 볼륨의 경우 데이터베이스 관리자(DBA)는 800GB의 데이터만 저장할 수 있을 것입니다. 이 구성은 스냅샷 소비를 위해 최소 200GB의 공간을 보장합니다.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">시기<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> 0으로 설정하면 볼륨의 모든 공간을 최종 사용자가 사용할 수 있어 가시성이 향상됩니다. DBA가 확인했을 때 스냅샷을 활용하는 볼륨이 1TB라면 이 1TB 공간이 액티브 데이터와 스냅샷 턴오버 간에 공유된다는 것을 알아야 합니다.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">이 두 옵션 중 최종 사용자가 특별히 선호하는 것은 없습니다.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">ONTAP 및 타사 스냅샷</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683.1은 타사 스냅샷 지원에 관련된 요구사항과 백업 및 복원 작업에 사용할 수 있는 여러 옵션을 설명합니다.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">타사 공급업체는 회사의 스냅샷이 다음과 같은 요구 사항을 준수함을 보증해야 합니다.</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">스냅샷이 Oracle에서 권장하는 복원 및 복구 작업에 통합되어야 합니다.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">스냅샷 지점에서 스냅샷의 데이터베이스 충돌이 일치해야 합니다.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">쓰기 순서는 각 파일에 대해 스냅샷 내에 보존됩니다.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">ONTAP 및 NetApp Oracle 관리 제품은 이러한 요구사항을 준수합니다.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">ONTAP을 사용한 Oracle 데이터 보호</block>
  <block id="6f1383567177df0041e76e845c3629f2" category="paragraph">가장 미션 크리티컬한 데이터는 데이터베이스에서 찾을 수 있습니다.</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">데이터에 액세스하지 않고는 기업을 운영할 수 없으며 경우에 따라서는 데이터가 비즈니스를 정의하기도 합니다. 이러한 데이터는 보호해야 합니다. 그러나 데이터 보호는 사용 가능한 백업을 보장하는 것 이상의 의미를 갖습니다. 백업을 안전하게 저장하는 것은 물론 빠르고 안정적으로 수행하는 것입니다.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">데이터 보호의 다른 측면은 데이터 복구입니다. 데이터에 액세스할 수 없으면 엔터프라이즈가 영향을 받으며 데이터를 복원하기 전까지 작동하지 않을 수 있습니다. 이 프로세스는 빠르고 안정적이어야 합니다. 마지막으로, 대부분의 데이터베이스는 재해로부터 보호해야 합니다. 즉, 데이터베이스의 복제본을 유지 관리해야 합니다. 복제본이 최신 상태여야 합니다. 또한 복제본을 완벽하게 작동하는 데이터베이스로 빠르고 간단하게 만들 수 있어야 합니다.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4591: Oracle 데이터 보호: 백업, 복구 및 복제 _ 를 대체합니다</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">계획 수립</block>
  <block id="0bf5784d6c307e4ee0371d46053937c0" category="summary">Oracle 성능 테스트</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">데이터베이스 스토리지 성능을 정확히 테스트한다는 것은 매우 복잡한 일입니다. 이 작업을 수행하려면 다음 문제에 대한 이해가 필요합니다.</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS 및 처리량</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">포그라운드와 백그라운드 I/O 작업 간의 차이</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">지연 시간이 데이터베이스에 미치는 영향</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">스토리지 성능에도 영향을 주는 수많은 OS 및 네트워크 설정</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">비스토리지 데이터베이스도 고려해야 합니다. 스토리지 성능이 더 이상 성능을 제한하는 요인이 아니기 때문에 스토리지 성능 최적화가 유용한 이점을 전혀 제공하지 않는 경우도 있습니다.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">네트워크 대역폭은 성능 한계의 공통된 원인으로 부상하고 있습니다. 예를 들어, 회전식 디스크 솔루션은 I/O 지연 시간이 매우 길기 때문에 종종 데이터베이스 성능의 병목 현상을 발생시킵니다. All-Flash 어레이를 통해 지연 시간 한계를 제거하고 나면 이번에는 네트워크가 장애물이 되는 경우가 많습니다. 이는 진정한 네트워크 연결의 시각화가 어려운 가상화 환경과 블레이드 시스템에서 특히 두드러지며 대역폭 한계로 인해 스토리지 시스템 자체를 최대한 활용할 수 없는 경우 성능 테스트가 복잡해질 수 있습니다.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">All-Flash 어레이의 지연 시간이 대폭 개선되었기 때문에 All-Flash 어레이의 성능을 회전식 디스크가 포함된 어레이와 비교하는 것은 일반적으로 불가능합니다. 테스트 결과는 대체로 중요하지 않습니다.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">데이터베이스는 스토리지 I/O에 의한 제약이 없기 때문에 최고의 IOPS 성능을 All-Flash 어레이와 비교하는 테스트는 대부분 유용하지 않습니다 한 어레이는 500K 랜덤 IOPS를 유지할 수 있고 다른 어레이는 300K를 유지할 수 있다고 가정해 봅시다. 이 차이는 데이터베이스가 실제로 99%의 시간을 CPU 처리에 사용하는 경우 아무런 상관이 없습니다. 워크로드는 스토리지 어레이의 전체 용량을 활용하지 않습니다. 이와 반대로, 최고 IOPS 용량은 스토리지 어레이가 최고 성능으로 로드될 것으로 예상되는 통합 플랫폼에서 매우 중요할 것입니다.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">어떤 스토리지 테스트에서든 지연 시간과 IOPS를 항상 고려하십시오. 시중의 많은 스토리지 어레이가 IOPS 레벨이 매우 높다는 주장을 펼치지만 지연 시간 때문에 이들 IOPS는 그러한 레벨에서 쓸모가 없습니다. All-Flash 어레이의 일반적인 타겟은 1ms 표시입니다. 더 나은 테스트 방식은 가능한 최대의 IOPS를 측정하는 것이 아니라 평균 지연 시간이 1ms를 넘기 전에 스토리지 어레이가 유지할 수 있도록 할 IOPS를 결정하는 것입니다.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Oracle Automatic Workload Repository 및 벤치마킹</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Oracle 성능 비교를 위한 이상적인 표준은 Oracle AWR(Automatic Workload Repository) 보고서입니다.</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">AWR 보고서에는 여러 유형이 있습니다. 스토리지 관점에서, 를 실행하여 생성된 보고서<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> 명령은 특정 데이터베이스 인스턴스를 대상으로 하고 지연 시간을 기반으로 스토리지 I/O 이벤트를 분석하는 상세한 히스토그램이 포함되어 있기 때문에 가장 종합적이고 유용합니다.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">2개의 성능 어레이를 비교할 때 가장 이상적인 방식은 각 어레이에서 같은 워크로드를 실행하여 워크로드를 정확히 타겟으로 하는 AWR 보고서를 생성하는 것입니다. 장시간 실행되는 워크로드의 경우, 시작 시간과 종료 시간을 아우르는 경과 시간을 토대로 단일 AWR 보고서를 사용할 수 있으며 여러 보고서로 AWR 데이터를 분석하는 것이 더 좋습니다. 예를 들어, 일괄 작업이 자정부터 오전 6시까지 실행된 경우 자정부터 오전 1시, 오전 1시부터 오전 2시 등등 일련의 1시간 간격 AWR 보고서를 생성하십시오.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">다른 경우에는 매우 짧은 쿼리를 최적화해야 합니다. 최고의 옵션은 쿼리가 시작될 때 생성된 AWR 스냅샷과 쿼리가 끝날 때 생성된 두 번째 AWR 스냅샷에 기반을 두고 AWR 보고서를 생성하는 것입니다. 그렇지 않으면, 분석 중인 쿼리의 활동을 명료하지 않게 만드는 백그라운드 활동을 최소화하기 위해 데이터베이스 서버가 정지되어야 합니다.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">AWR 보고서를 생성할 수 없는 경우 Oracle Statspack 보고서가 좋은 대안이 될 수 있는데 여기에는 AWR 보고서와 같은 I/O 통계 대부분이 포함되어 있습니다.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR과 문제 해결</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">AWR 보고서는 성능 문제 분석을 위한 가장 중요한 툴이기도 합니다.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">벤치마킹과 마찬가지로 성능 문제 해결을 위해서는 특정 워크로드를 정확하게 측정해야 합니다. NetApp 지원 센터에 성능 문제를 보고할 때 또는 NetApp이나 파트너 어카운트 팀과 협력하여 새로운 솔루션을 사용할 때는 가능하면 AWR 데이터를 제공하십시오.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">AWR 데이터를 제공할 때는 다음 요구사항을 고려하십시오.</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">를 실행합니다<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> 명령을 사용하여 보고서를 생성합니다. 출력은 텍스트 또는 HTML 형식으로 가능합니다.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Oracle RAC(Real Application Cluster)를 사용하는 경우 클러스터의 각 인스턴스에 대해 AWR 보고서를 생성합니다.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">문제가 존재했던 특정 시간을 타겟으로 합니다. AWR 보고서에서 허용되는 최대 경과 시간은 일반적으로 1시간입니다. 수 시간 동안 문제가 지속되거나 일괄 작업 같이 시간이 많이 걸리는 작업인 경우, 분석할 기간 전체를 포괄하는 1시간 간격 AWR 보고서를 여러 개 제공합니다.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">가능한 경우 AWR 스냅샷 간격을 15분으로 조정합니다. 이 설정을 통해 더 상세한 분석을 수행할 수 있으며 또한 의 추가 실행도 필요합니다<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> 각 15분 간격에 대한 보고서를 제공합니다.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">매우 짧은 실행 쿼리가 문제인 경우, 작업이 시작될 때 생성된 AWR 스냅샷과 작업이 종료될 때 생성된 두 번째 AWR 스냅샷에 기반을 두고 AWR 보고서를 제공합니다. 그렇지 않으면, 분석 중인 작업의 활동을 명료하지 않게 만드는 백그라운드 활동을 최소화하기 위해 데이터베이스 서버가 정지되어야 합니다.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">특정 시간에 성능 문제가 보고되었지만 그 외 시간에는 성능 문제가 없는 경우 비교를 위해 우수한 성능을 입증하는 추가 AWR 데이터를 제공합니다.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">CALIBRATE_IO 를 선택합니다</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">를 클릭합니다<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> 명령은 스토리지 시스템의 테스트, 비교 또는 벤치마크에 사용할 수 없습니다. Oracle 설명서에 명시된 것처럼 이 절차는 스토리지의 I/O 기능을 보정합니다.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">보정은 벤치마킹과 같지 않습니다. 이 명령의 목적은 데이터베이스 작업 보정을 위해 I/O를 발행하고 호스트에 발행된 I/O 레벨을 최적화하여 효율성을 개선하는 것입니다. 에 의해 수행되는 I/O 유형이기 때문입니다<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> 작동 방식은 실제 데이터베이스 사용자 I/O를 나타내지 않으며, 그 결과는 예측할 수 없으며, 재현이 불가능한 경우도 많습니다.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2 를 참조하십시오</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">Oracle 벤치마크인 SLOB2는 데이터베이스 성능을 평가하는 데 있어 선호되는 도구가 되었습니다. Kevin Closson이 개발했으며 에서 다운로드할 수 있습니다 <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. 설치하고 구성하는 데에는 몇 분 정도가 걸리며 실제 Oracle 데이터베이스를 사용하여 사용자가 정의 가능한 테이블스페이스에 I/O 패턴을 생성합니다. 이 툴은 I/O를 통해 All-Flash 어레이를 포화할 수 있는 소수의 테스트 옵션 중 하나이며 IOPS가 낮지만 지연 시간에 민감한 스토리지 워크로드를 시뮬레이션하기 위해 훨씬 낮은 레벨의 I/O를 생성하는 데 유용합니다.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">스윙벤치</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench는 데이터베이스 성능을 테스트하는 데 유용할 수 있지만 스토리지에 중점을 두어 Swingbench를 사용하는 것은 매우 어렵습니다. NetApp이 관찰한 결과, AFF 어레이에 상당한 로드가 될 정도의 I/O가 생성된 Swingbench 테스트는 없었습니다. 드문 경우지만 지연 시간 관점에서 스토리지를 평가하는 데 OET(Order Entry Test)를 사용할 수 있습니다. 이는 데이터베이스에 특정 쿼리의 알려진 지연 시간 종속성이 있는 상황에서 유용할 수 있습니다. All-Flash 어레이의 잠재적 지연 시간을 실현하려면 호스트와 네트워크가 적절히 구성되었는지 주의를 기울여 확인해야 합니다.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB는 TPC-C 및 TPC-H 벤치마크를 시뮬레이션하는 데이터베이스 테스트 툴입니다. 테스트를 제대로 실행하기 위해 대규모 데이터 세트를 구성하는 데에는 상당한 시간이 걸릴 수 있지만 이는 OLTP와 데이터 웨어하우스 애플리케이션의 성능을 평가하는 데 효과적인 툴이 될 수 있습니다.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">오리온</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">Oracle Orion 툴은 일반적으로 Oracle 9과 함께 사용되었지만 다양한 호스트 운영 체제의 변화에 따른 호환성이 보장되도록 유지보수되지 않았습니다. 이 툴은 운영 체제 및 스토리지 구성의 비호환성 때문에 Oracle 10 또는 Oracle 11에는 거의 사용되지 않습니다.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle은 이 툴을 재작성했고 Oracle 12c에 기본으로 설치했습니다. 이 제품은 개선이 되었고 실제 Oracle 데이터베이스에서와 같은 호출을 다수 사용하지만 Oracle에서와 정확히 같은 코드 경로 또는 I/O 동작을 사용하지는 않습니다. 예를 들어, 대부분의 Oracle I/O는 동시에 수행되는데 이는 I/O 작업이 포그라운드에서 완료되는 경우 I/O가 완료될 때까지 데이터베이스가 멈춘다는 뜻입니다. 랜덤 I/O를 통한 스토리지 시스템의 단순한 서비스 장애는 실제 Oracle I/O의 재현이 아니며 스토리지 어레이를 비교하거나 구성 변화의 영향을 측정하는 직접적인 방법을 제공하지 않습니다.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">그렇지만 특정 호스트-네트워크-스토리지 구성의 최대 성능에 관한 일반적인 측정이나 스토리지 시스템 상태를 알아내는 등 몇 가지 Orion 사용 사례가 있습니다. 매개 변수에 IOPS 고려사항, 처리량, 지연 시간을 포함하고 실제 워크로드를 충실히 복제하려 하는 한, 신중한 테스트를 통해 사용 가능한 Orion 테스트를 고안하여 스토리지 어레이를 비교하거나 구성 변경의 영향을 평가할 수 있습니다.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Oracle 데이터베이스에 대한 WAFL 조정</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Oracle 데이터베이스에 대한 WAFL 정렬 검증</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">올바른 WAFL 정렬은 우수한 성능을 얻는 데 매우 중요합니다. ONTAP이 4KB 유닛의 블록을 관리하기는 하나 ONTAP 4KB 유닛의 모든 작업을 수행하는 것은 아닙니다. 실제로 ONTAP은 다양한 크기의 블록 작업을 지원하지만 기본 계산은 4KB 유닛의 WAFL이 관리합니다.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">'정렬'이라는 용어는 Oracle I/O가 이러한 4KB 유닛에 대응하는 방식을 의미합니다. 최적의 성능을 얻으려면 Oracle 8KB 블록이 드라이브의 4KB WAFL 물리적 블록 2개에 상주해야 합니다. 블록이 2KB로 오프셋되면 이 블록은 4KB 블록 1개의 절반에 상주하며, 별도의 4KB 블록 전체 그리고 4KB 블록 1/3의 절반에 상주합니다. 이 방식은 성능 저하를 초래합니다.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">NAS 파일 시스템에서는 정렬이 문제가 되지 않습니다. Oracle 데이터 파일은 Oracle 블록 크기에 기반을 둔 파일의 시작에 맞춰 정렬됩니다. 따라서 블록 크기 8KB, 16KB, 32KB가 항상 정렬됩니다. 모든 블록 작업은 4킬로바이트 유닛에서 파일의 시작으로부터 오프셋됩니다.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">이와 반대로, LUN의 경우 일반적으로 오프셋을 생성하는 일종의 드라이버 헤더 또는 파일 시스템 메타데이터가 시작 부분에 포함되어 있습니다. 최신 운영 체제는 기본 4KB 섹터를 사용할 수 있는 물리적 드라이브를 위해 설계되었기 때문에 정렬이 문제가 되는 경우는 드물며, 여기서도 최적의 성능을 위해서는 I/O를 4KB 경계에 맞춰 정렬해야 합니다.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">그러나 몇 가지 예외가 있습니다. 데이터베이스가 4KB I/O에 최적화되지 않은 기존 운영 체제에서 마이그레이션되었을 수도 있고, 파티션이 생성될 때 사용자 오류에 의해 4KB 크기의 유닛이 아닌 오프셋이 발생했을 수도 있습니다.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">다음 예는 Linux에만 해당되며 모든 운영 체제에 맞게 절차를 조정할 수 있습니다.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">정렬</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">다음 예는 단일 파티션의 단일 LUN에서의 정렬 점검을 보여줍니다.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">먼저 드라이브에서 사용 가능한 모든 파티션을 사용하는 파티션을 만듭니다.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">다음 명령을 사용하여 정렬을 수학적으로 점검할 수 있습니다.</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">출력은 유닛이 512바이트이고 파티션의 시작이 32유닛이라는 것을 보여줍니다. 전체 32 x 512 = 16,834바이트이며 이는 모두 4KB WAFL 블록의 배수입니다. 이 파티션은 올바르게 정렬되었습니다.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">올바른 정렬을 확인하려면 다음 단계를 완료하십시오.</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">LUN의 UUID(Universally Unique Identifier)를 식별합니다.</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">ONTAP 컨트롤러의 노드 쉘에 들어갑니다.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">첫 번째 단계에서 식별된 타겟 UUID의 통계적 수집을 시작합니다.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">몇 가지 I/O를 수행합니다 를 사용하는 것이 중요합니다<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> 동기식이고 버퍼링되지 않도록 하는 인수입니다.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">이 명령을 사용할 때는 매우 주의해야 합니다. 의 후진<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> 및<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> 인수가 데이터를 삭제합니다.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">통계를 정지하고 정렬 히스토그램을 확인합니다. 모든 I/O는 에 있어야 합니다<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> 버킷: I/O가 4KB 블록 경계에 맞춰 정렬되었음을 나타냅니다.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">잘못 정렬됨</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">다음 예는 잘못 정렬된 I/O를 보여줍니다.</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">4KB 경계에 맞춰 정렬되지 않은 파티션을 생성합니다. 최신 운영 체제에서 이는 기본 동작이 아닙니다.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">명확히 정렬 불량입니다. I/O는 대부분 * 에 속합니다 <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> 버킷 - 예상 오프셋과 일치합니다. 파티션이 생성되었을 때 최적화된 기본값보다 장치로 512바이트 더 멀리 이동했으며 이는 히스토그램이 512바이트로 오프셋된다는 뜻입니다.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">또한<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> 통계는 0이 아닙니다. 즉, I/O가 수행되었지만 4KB 블록 전체를 채우지는 않았습니다.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">로깅 재실행</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">여기에 설명된 절차는 데이터 파일에 적용할 수 있습니다. Oracle 재실행 로그와 아카이브 로그는 I/O 패턴이 다릅니다. 예를 들어, 로깅 재실행은 단일 파일의 순환 덮어쓰기입니다. 기본값인 512바이트 블록 크기가 사용되는 경우 쓰기 통계는 다음과 같습니다.</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">I/O가 모든 히스토그램 버킷 전체에 분산되나 이것으로 인해 성능이 저하되지는 않습니다. 하지만 로깅 재실행 속도가 매우 높다면 4KB 블록 크기를 사용하여 이점을 얻을 수 있습니다. 이 경우에는 로깅 재실행 LUN이 제대로 정렬되었는지 확인하는 것이 좋습니다. 그러나 데이터 파일 정렬에서처럼 우수한 성능을 얻는 데 있어 이 작업이 반드시 필요한 것은 아닙니다.</block>
  <block id="f64f1c647516f5a47c00be152fdbf488" category="summary">Oracle 및 오래된 NFSv3 잠금</block>
  <block id="91d9710c9fee248ae3e9c4b810ae704f" category="doc">부실 NFSv3 잠금 및 Oracle 데이터베이스</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Oracle 데이터베이스 서버가 충돌하는 경우 재시작했을 때 부실 NFS 잠금에서 문제가 발생할 수 있습니다. 서버에서 이름 확인을 구성할 때 특별히 주의를 기울이면 이 문제를 피할 수 있습니다.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">이 문제가 발생하는 것은 잠금 생성과 잠금 해제가 두 가지의 약간 다른 호스트 이름 확인 방법을 사용하기 때문입니다. 여기에는 NLM(Network Lock Manager)와 NFS 클라이언트라는 2개의 프로세스가 관련되어 있습니다. NLM은 를 사용합니다<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> 를 사용하여 호스트 이름을 확인할 수 있습니다<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> 프로세스 사용<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. 운영 체제에서 이러한 부실 잠금을 제대로 삭제할 수 있으려면 이 호스트 이름이 일치해야 합니다. 예를 들어, 호스트가 찾고 있는 소유의 잠금이 필요할 수 있습니다<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>그러나 잠금이 호스트에 로 등록되었습니다<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. If(경우<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> 과(와) 같은 값을 반환하지 않습니다<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>그런 다음 잠금 해제 프로세스가 성공하지 못했습니다.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">다음 샘플 스크립트는 이름 확인이 완전히 일관되는지 확인합니다.</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">If(경우<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> 일치하지 않습니다<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>부실 잠금일 가능성이 있습니다. 예를 들어, 이 결과는 다음과 같이 잠재적 문제를 드러냅니다.</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">일반적으로 에서 호스트가 나타나는 순서를 변경하는 것이 해결책이 됩니다<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. 예를 들어, hosts 파일에 다음 항목이 포함되어 있다고 가정합니다.</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">이 문제를 해결하려면 정규화된 도메인 이름과 짧은 호스트 이름이 나타나는 순서를 변경합니다.</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> 이제 쇼트 값을 반환합니다<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> 의 출력과 일치하는 호스트 이름입니다<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. 이와 같이 서버 충돌이 일어나면 잠금이 자동으로 삭제됩니다.</block>
  <block id="547b870352d8464aadbe7bee63d6f3d1" category="summary">데이터베이스 가상화 소개</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">포함되었습니다</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">스토리지 프레젠테이션</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">하이퍼바이저가 아닌 VM의 iSCSI 이니시에이터에 의해 관리되는 iSCSI LUN</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">* 이식성. * VM이 파일 시스템을 소유하면 Oracle 환경을 이동하는 프로세스가 훨씬 간단해집니다. 가상화 게스트와 비가상화 게스트 간에 파일 시스템을 쉽게 이동할 수 있습니다.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">반가상화 드라이버</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">최적의 성능을 얻으려면 반가상화 네트워크 드라이버를 사용해야 합니다. 데이터 저장소를 사용할 때는 반가상화 SCSI 드라이버가 필요합니다. 에뮬레이션된 드라이버가 하이퍼바이저가 물리적 하드웨어의 동작을 모방면서 많은 CPU 시간을 사용하는 것과 대조적으로, 반가상화 장치 드라이버는 게스트가 하이퍼바이저에 더 긴밀히 통합될 수 있게 합니다.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">RAM 오버 커밋</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">RAM 오버 커밋이란 물리적 하드웨어에 있는 것보다 더 많은 가상화 RAM을 다양한 호스트에 구성하는 것을 의미합니다. 오버 커밋은 예기치 않은 성능 문제를 초래할 수 있습니다. 데이터베이스를 가상화할 때 Oracle SGA의 기본 블록이 하이퍼바이저에 의해 스토리지로 교체되면 안 됩니다. 교체할 경우 성능 결과가 매우 불안정해집니다.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792는 NVIDIA GPU(Graphics Processing Unit) 및 가상화 소프트웨어를 기반으로 하는 VMware Horizon 환경에서 NetApp HCI 615C를 사용하여 3D 그래픽 워크로드를 처리하는 방법에 대한 지침을 제공합니다.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">VMware Horizon 7을 지원하는 NetApp HCI for Virtual Desktop Infrastructure - 3D 그래픽을 통해 파워 유저의 역량을 강화하십시오</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792는 NVIDIA GPU(Graphics Processing Unit) 및 가상화 소프트웨어로 구동되는 VMware Horizon 환경에서 NetApp H615C 컴퓨팅 노드를 사용하여 3D 그래픽 워크로드를 처리하는 방법에 대한 지침을 제공합니다. 또한 H615C에 대한 SPECviewperf 13의 예비 테스트에서 얻은 결과를 제공합니다.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">이 문서에서는 VMware vSphere용 ONTAP 툴의 제품 보안에 대해 설명합니다.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">ONTAP에서 VVOL 사용</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">ONTAP에서 VVOL을 사용하려면 VMware vSphere 가상 어플라이언스를 위한 ONTAP 툴의 일부로 포함된 VASA 공급자 소프트웨어가 필요합니다.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">ONTAP 툴에는 vCenter UI 확장, REST API 서버, VMware Site Recovery Manager용 스토리지 복제 어댑터, 모니터링 및 호스트 구성 툴, VMware 환경을 보다 효율적으로 관리하는 데 도움이 되는 보고서 배열도 포함되어 있습니다.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">제품 및 문서</block>
  <block id="4fc5e15c4dc0d227bc5f8f26e4337083" category="paragraph">ONTAP FlexClone 라이센스(ONTAP One에 포함)와 ONTAP 툴 어플라이언스는 NetApp ONTAP에서 VVOL을 사용하는 데 필요한 유일한 추가 제품입니다. ONTAP 툴의 최신 릴리즈는 ESXi에서 실행되는 단일 통합 어플라이언스로 제공되므로 이전에 세 가지 다른 어플라이언스 및 서버의 기능을 사용할 수 있습니다. VVOL의 경우 특정 VVOL 기능을 제공하는 VASA Provider와 함께 ONTAP 툴 vCenter UI 확장 또는 REST API를 vSphere와 함께 ONTAP 기능을 위한 일반 관리 툴 및 사용자 인터페이스로 사용하는 것이 중요합니다. SRA 구성 요소는 기존 데이터 저장소용으로 포함되어 있지만 VMware Site Recovery Manager는 VVol용 SRA를 사용하지 않고, VVol 복제를 위해 VASA 공급자를 활용하는 SRM 8.3 이상에서 새로운 서비스를 구현합니다.</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">ONTAP 툴 iSCSI 또는 FCP를 사용하는 경우 VASA 공급자 아키텍처</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">ONTAP 툴 VASA 공급자 아키텍처, 240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">제품 설치</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">새로 설치하려면 가상 어플라이언스를 vSphere 환경에 구축하십시오. ONTAP 툴의 현재 릴리즈는 자동으로 vCenter에 등록되고 기본적으로 VASA Provider가 설정됩니다. ESXi 호스트 및 vCenter Server 정보 외에도 어플라이언스에 대한 IP 주소 구성 세부 정보도 필요합니다. 앞서 설명했듯이, VASA Provider를 사용하려면 VVOL을 위해 사용할 ONTAP 클러스터에 ONTAP FlexClone 라이센스가 이미 설치되어 있어야 합니다. 이 어플라이언스에는 가용성을 보장하기 위한 감시 기능이 내장되어 있으며 Best Practice는 VMware High Availability 및 옵션으로 Fault Tolerance 기능을 사용하여 구성해야 합니다. 자세한 내용은 섹션 4.1을 참조하십시오. 어플라이언스를 다시 시작하지 못할 수 있으므로 ONTAP 툴 어플라이언스 또는 VCSA(vCenter Server Appliance)를 VVol 스토리지로 설치하거나 이동하지 마십시오.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">ONTAP 도구의 현재 위치 업그레이드는 NetApp Support 사이트(NSS)에서 다운로드할 수 있는 업그레이드 ISO 파일을 사용하여 지원됩니다. 어플라이언스를 업그레이드하려면 Deployment and Setup Guide(배포 및 설정 가이드) 지침을 따르십시오.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">VMware vSphere용 ONTAP 툴 사이징 가이드</block>
  <block id="e4e51979718d88ce483f9477be981a76" category="paragraph">가상 어플라이언스의 크기를 조정하고 구성 제한에 대한 자세한 내용은 다음 기술 문서를 참조하십시오.<block ref="a75738ed95b0811ed0edd1b8ef0d9568" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">제품 설명서</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">다음 문서는 ONTAP 도구를 배포하는 데 도움이 됩니다.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">문서 리포지토리 및 amp;#44; 전체 내용은 docs.netapp.com 링크를 참조하십시오</block>
  <block id="7f21741a70426baea3ee41488da86af4" category="paragraph"><block ref="56b49132b20e341764c8aa067751e8a5" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">시작하십시오</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">릴리스 정보</block>
  <block id="2645deadffb8af180b8a35da3d034ad8" category="list-text"><block ref="2645deadffb8af180b8a35da3d034ad8" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">VMware vSphere용 ONTAP 툴에 대해 자세히 알아보십시오</block>
  <block id="a0aaeda90fe2ef02fba791bc7c35645c" category="list-text"><block ref="a0aaeda90fe2ef02fba791bc7c35645c" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">ONTAP 도구 빠른 시작</block>
  <block id="324b0410f22fb210bbf88e1ee7e97428" category="list-text"><block ref="324b0410f22fb210bbf88e1ee7e97428" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">ONTAP 툴 구축</block>
  <block id="354336d78d1f0a156dcd5221d341dfd0" category="list-text"><block ref="354336d78d1f0a156dcd5221d341dfd0" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">ONTAP 툴을 업그레이드합니다</block>
  <block id="33a77e1014f1325d6ba19639a6c95d48" category="list-text"><block ref="33a77e1014f1325d6ba19639a6c95d48" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">ONTAP 도구를 사용합니다</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">기존 데이터 저장소 프로비저닝</block>
  <block id="f27fe8f858d8a91950e214753b95722c" category="list-text"><block ref="f27fe8f858d8a91950e214753b95722c" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">VVOL 데이터 저장소를 프로비저닝합니다</block>
  <block id="0c2552c3930f472b2d120f30d7aa0415" category="list-text"><block ref="0c2552c3930f472b2d120f30d7aa0415" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">역할 기반 액세스 제어를 구성합니다</block>
  <block id="644ae78061acbb2254be4de3ea454b06" category="list-text"><block ref="644ae78061acbb2254be4de3ea454b06" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">원격 진단 구성</block>
  <block id="fc0330812838aba14025bd70d41b943d" category="list-text"><block ref="fc0330812838aba14025bd70d41b943d" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">고가용성을 구성합니다</block>
  <block id="5027a18a60c68e05df84cd699af74497" category="list-text"><block ref="5027a18a60c68e05df84cd699af74497" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">데이터 저장소 보호 및 관리</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">기존 데이터 저장소 보호</block>
  <block id="c8ac931d575d89c007212a35c8dde74c" category="list-text"><block ref="8f91d2113ff32de18906bad1cd446b0d" category="inline-link-rx"></block> SRM 사용</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">VVOL 기반 가상 머신 보호</block>
  <block id="710b15d782f0c2c0411066b86644a12d" category="list-text"><block ref="7741c74d7508dc983fa4af0dff0bdda1" category="inline-link-rx"></block> SRM 사용</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">기존 데이터 저장소 및 가상 머신을 모니터링합니다</block>
  <block id="bac3b262bb348a54f9986c2b5dbf6024" category="list-text"><block ref="bac3b262bb348a54f9986c2b5dbf6024" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">VVOL 데이터 저장소 및 가상 머신을 모니터링합니다</block>
  <block id="75c07b623699e1947d011983a7823584" category="list-text"><block ref="75c07b623699e1947d011983a7823584" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">제품 설명서 외에도 유용한 지원 기술 자료 문서가 있습니다.</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">VASA 공급자 대시보드</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">VASA Provider에는 개별 VVol VM에 대한 성능 및 용량 정보가 포함된 대시보드가 포함되어 있습니다. 이 정보는 ONTAP에서 직접 제공하며 상위 5개 VM의 지연 시간, IOPS, 처리량, 가동 시간, 상위 5개 데이터 저장소의 지연 시간 및 IOPS를 포함합니다. ONTAP 9.7 이상을 사용하는 경우 기본적으로 활성화됩니다. 초기 데이터를 가져와 대시보드에 표시하는 데 최대 30분이 걸릴 수 있습니다.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">ONTAP 툴 VVol 대시보드</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">ONTAP 툴 VVol 대시보드, 400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">모범 사례</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">* 제한 *</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">최대 구성</block>
  <block id="bc8259e306c73b2969e7ac6297000e64" category="paragraph">일반적으로 ONTAP는 VMware에서 정의한 VVOL 한계를 지원합니다(참조<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>)를 클릭합니다. 다음 표에는 VVOL의 크기 및 개수에 대한 특정 ONTAP 제한이 요약되어 있습니다. 항상 을 확인하십시오<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> 업데이트된 LUN 및 파일 수 및 크기 제한</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">* ONTAP VVOL 한계 *</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">용량/기능</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN(SCSI 또는 NVMe-oF)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">최대 VVol 크기</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62TiB *</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">FlexVol 볼륨당 최대 VVol 수</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">20억</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">ONTAP 노드당 VVol의 최대 개수</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">최대 12,288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">500억</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">ONTAP 쌍당 최대 VVol 수</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">최대 24,576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">ONTAP 클러스터당 최대 VVol 수</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">최대 98,304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">특정 클러스터 제한이 없습니다</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">최대 QoS 개체(공유 정책 그룹 및 개별 VVol 서비스 수준)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">12,000 ~ ONTAP 9.3, 40,000(ONTAP 9.4 이상)</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">ONTAP 9.12.1P2 이상을 실행하는 ASA 시스템 또는 AFF 및 FAS 시스템에 따른 크기 제한.</block>
  <block id="d27c43bb3cdcbfa3852bb91192ffb849" category="list-text">SAN VVOL(NVMe 네임스페이스 또는 LUN)의 수는 플랫폼에 따라 다릅니다. 항상 을 확인하십시오<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> 업데이트된 LUN 및 파일 수 및 크기 제한</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">vSphere에서 ONTAP VVOL을 사용하는 것은 간단하며 게시된 vSphere 방법을 따릅니다(사용 중인 ESXi 버전에 대한 VMware 설명서의 vSphere 스토리지 아래에서 가상 볼륨 작업 참조). 다음은 ONTAP와 관련하여 고려해야 할 몇 가지 추가 사례입니다.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">* VMware vSphere의 UI 확장 또는 REST API용 ONTAP 툴을 사용하여 VVOL 데이터 저장소 * * 및 프로토콜 엔드포인트 프로비저닝 *</block>
  <block id="9507d4f97aceb8d05fc962dd53f082af" category="cell">일반 vSphere 인터페이스를 통해 VVOL 데이터 저장소를 생성할 수도 있지만, ONTAP 툴을 사용하면 필요에 따라 프로토콜 엔드포인트를 자동으로 생성하고, ONTAP 모범 사례와 정의된 스토리지 용량 프로필을 준수하여 FlexVol 볼륨을 생성할 수 있습니다. 호스트/클러스터/데이터 센터를 마우스 오른쪽 버튼으로 클릭하고 _ONTAP tools_and_provision datastore_를 선택합니다. 마법사에서 원하는 VVOL 옵션을 선택하기만 하면 됩니다.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">* ONTAP 툴 어플라이언스 또는 VCSA(vCenter Server Appliance)를 관리하는 VVol 데이터 저장소에 저장하지 마십시오. *</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">이로 인해 어플라이언스를 재부팅해야 할 경우 "닭과 달걀"이 발생할 수 있습니다. 재부팅하는 동안에는 자체 VVOL을 다시 바인딩할 수 없기 때문입니다. 다른 ONTAP 툴과 vCenter 구축을 통해 관리되는 VVol 데이터 저장소에 저장할 수 있습니다.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">* 다양한 ONTAP 릴리즈에서 VVOL을 운영하는 것을 방지합니다. *</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">VASA Provider의 다양한 릴리즈에서 QoS, 특성 등과 같은 지원되는 스토리지 기능이 변경되었으며, 일부는 ONTAP 릴리즈에 따라 달라집니다. ONTAP 클러스터에서 다른 릴리즈를 사용하거나 서로 다른 릴리즈를 가진 클러스터 간에 VVOL을 이동하면 예기치 않은 동작 또는 규정 준수 경보가 발생할 수 있습니다.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">* VVOL을 위해 NVMe/FC 또는 FCP를 사용하기 전에 파이버 채널 패브릭을 존*합니다</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">4개 노드인 400을 포함하는 단일 이니시에이터 조닝</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 최신 SAN ONTAP 9_에 대한 모범 사례</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 NVMe-oF_로 최신 SAN 구현 및 구성</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">* 필요에 따라 지원 FlexVols를 계획합니다. *</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">ONTAP 클러스터에 워크로드를 분산하거나, 다양한 정책 옵션을 지원하거나, 허용되는 LUN 또는 파일 수를 늘리기 위해 VVOL 데이터 저장소에 여러 백업 볼륨을 추가하는 것이 좋습니다. 하지만 최대 스토리지 효율성이 필요한 경우에는 모든 백업 볼륨을 단일 Aggregate에 배치하십시오. 또는 최대 클론 복제 성능이 필요한 경우 단일 FlexVol 볼륨을 사용하고 템플릿 또는 콘텐츠 라이브러리를 동일한 볼륨에 유지하는 것을 고려해 보십시오. VASA Provider는 마이그레이션, 클론 생성 및 스냅샷을 비롯한 다양한 VVOL 스토리지 작업을 ONTAP로 오프로드합니다. 단일 FlexVol 볼륨 내에서 이 작업을 수행할 경우 공간 효율적인 파일 클론이 사용되며 거의 즉시 사용할 수 있습니다. FlexVol 볼륨 전체에 걸쳐 복사본을 빠르게 생성하여 인라인 중복제거 및 압축을 사용할 수 있지만, 백그라운드 작업이 백그라운드 중복제거 및 압축을 사용하는 볼륨에서 실행될 때까지 최대 스토리지 효율성이 복구되지 않을 수 있습니다. 소스 및 타겟에 따라 일부 효율성이 저하될 수 있습니다.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">* SCP(스토리지 기능 프로필)를 간단하게 유지합니다. *</block>
  <block id="33e2905cb722c14575a9bff81ba78b39" category="cell">필요하지 않은 기능은 ANY 로 설정하여 지정하지 마십시오. 이렇게 하면 FlexVol 볼륨을 선택하거나 생성할 때 발생하는 문제를 최소화할 수 있습니다. 예를 들어 VASA Provider 7.1 이전 버전에서는 압축이 기본 SCP 설정인 No로 설정되어 있으면 AFF 시스템에서도 압축을 해제하려고 시도합니다.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">* 기본 SCP를 예제 템플릿으로 사용하여 고유한 템플릿을 만듭니다. *</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">* 모든 프로토콜 모범 사례를 따르십시오. *</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">NFS v3,500을 통해 VVOL을 사용한 네트워크 구성</block>
  <block id="6cacb3f1edd09835a2ad07d72f488e2a" category="paragraph">NetApp ONTAP 소프트웨어는 20년 이상 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션으로, 관리를 단순화하는 동시에 비용을 절감할 수 있는 혁신적인 기능을 지속적으로 추가하고 있습니다.</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">본 문서에서는 구축 간소화 및 오류 감소를 위한 모범 사례와 함께 최신 제품 정보 및 사용 사례를 비롯하여 VMware VVOL(vSphere Virtual Volumes)의 ONTAP 기능에 대해 다룹니다.</block>
  <block id="c7448b194ba68bddce48f1d11d5d7db7" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4400: VMware VVol(vSphere 가상 볼륨)을 NetApp ONTAP _ 로 대체합니다</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">모범 사례는 가이드 및 호환성 목록 등의 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 이러한 방법은 효과가 있거나 지원되는 유일한 방법이 아닐 수 있지만, 일반적으로 대부분의 고객의 요구를 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">이 문서는 ONTAP TOOLS 9.12 릴리스에서 지원되는 vSphere 8.0 업데이트 1의 새로운 VVOL 기능을 포함하도록 업데이트되었습니다.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">VVol(가상 볼륨) 개요</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">NetApp은 VMware와 협력하여 2012년에 vSphere 5용 VASA(vSphere APIs for Storage Awareness)를 지원하기 시작했습니다. 이 초기 VASA Provider는 프로비저닝 시 데이터 저장소를 필터링하고 나중에 정책 준수 여부를 확인하는 데 사용할 수 있는 프로파일의 스토리지 용량 정의를 허용합니다. 시간이 지나면서 프로비저닝 시 더 많은 자동화를 가능하게 하는 새로운 기능을 추가하고 개별 스토리지 오브젝트를 가상 머신 파일 및 가상 디스크에 사용하는 가상 볼륨 또는 VVol을 추가하였습니다. 이러한 오브젝트는 LUN, 파일일 수 있으며 현재 vSphere 8-NVMe namespaces.NetApp 와 함께 2015년 vSphere 6과 함께 출시된 VVOL을 위한 참조 파트너로 VMware와 긴밀하게 협력했으며, vSphere 8에서 NVMe over Fabrics를 사용하는 VVOL을 위한 설계 파트너로 다시 활동했습니다. NetApp은 ONTAP의 최신 기능을 활용하기 위해 VVOL을 지속적으로 개선합니다.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">다음과 같은 몇 가지 구성 요소를 알고 있어야 합니다.</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">* VASA 공급자 *</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">이 소프트웨어 구성 요소는 VMware vSphere와 스토리지 시스템 간의 통신을 처리합니다. ONTAP의 경우 VASA Provider는 VMware vSphere용 ONTAP 툴(짧은 경우 ONTAP 툴)이라는 어플라이언스에서 실행됩니다. ONTAP 툴에는 vCenter 플러그인, VMware Site Recovery Manager용 SRA(스토리지 복제 어댑터), 자체 자동화 구축을 위한 REST API 서버도 포함되어 있습니다. vCenter에 ONTAP 툴이 구성 및 등록되면 vCenter UI 내에서 직접 또는 REST API 자동화를 통해 거의 모든 스토리지 요구 사항을 관리할 수 있으므로 더 이상 ONTAP 시스템과 직접 상호 작용할 필요가 없습니다.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">* 프로토콜 엔드포인트(PE) *</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">프로토콜 엔드포인트는 ESXi 호스트와 VVol 데이터 저장소 간의 I/O용 프록시입니다. ONTAP VASA Provider는 이러한 프로토콜을 자동으로 생성합니다. 즉, VVols 데이터 저장소의 FlexVol 볼륨당 프로토콜 엔드포인트 LUN(4MB 크기) 1개 또는 데이터 저장소에서 FlexVol 볼륨을 호스팅하는 스토리지 노드의 NFS 인터페이스(LIF)당 NFS 마운트 지점 1개 중 하나입니다. ESXi 호스트는 개별 VVol LUN 및 가상 디스크 파일이 아니라 이러한 프로토콜 엔드포인트를 직접 마운트합니다. 필요한 인터페이스 그룹 또는 내보내기 정책과 함께 VASA Provider가 프로토콜 엔드포인트를 자동으로 생성, 마운트, 마운트 해제 및 삭제할 때 이를 관리할 필요가 없습니다.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">* VPE(Virtual Protocol Endpoint) *</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">vSphere 8의 새로운 기능으로, VVOL과 NVMe-oF(NVMe over Fabrics)를 사용하면 프로토콜 엔드포인트 개념이 ONTAP에서 더 이상 의미가 없습니다. 그 대신 첫 번째 VM의 전원이 켜지자마자 각 ANA 그룹의 ESXi 호스트에 의해 가상 PE가 자동으로 인스턴스화됩니다. ONTAP는 데이터 저장소에서 사용하는 각 FlexVol 볼륨에 대해 ANA 그룹을 자동으로 생성합니다.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">VVOL을 위한 NVMe-oF를 사용할 경우 추가적인 이점은 VASA Provider에 필요한 바인딩 요청이 없다는 것입니다. 대신 ESXi 호스트는 VPE를 기반으로 내부적으로 VVol 바인딩 기능을 처리합니다. 따라서 VVOL 바인딩 스톰이 서비스에 영향을 줄 수 있는 기회가 줄어듭니다.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe 및 가상 볼륨</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">VMware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">자세한 내용은 을 참조하십시오<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> 켜짐<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="61def0b14af00df4eb90bcd79d858a8b" category="cell">* 가상 볼륨 데이터 저장소 *</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">가상 볼륨 데이터 저장소는 VASA Provider에서 생성 및 유지 관리하는 VVol 컨테이너의 논리적 데이터 저장소 표현입니다. 컨테이너는 VASA Provider에서 관리하는 스토리지 시스템에서 프로비저닝된 스토리지 용량 풀을 나타냅니다. ONTAP 툴은 여러 FlexVol 볼륨(백업 볼륨이라고 함)을 단일 VVOL 데이터 저장소에 할당할 수 있도록 지원하며, 이러한 VVOL 데이터 저장소는 ONTAP 클러스터의 여러 노드로 확장하여 플래시와 하이브리드 시스템을 서로 다른 기능으로 결합할 수 있습니다. 관리자는 프로비저닝 마법사 또는 REST API를 사용하여 새 FlexVol 볼륨을 생성하거나, 사용 가능한 경우 스토리지 백업을 위해 미리 생성된 FlexVol 볼륨을 선택할 수 있습니다.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">* 가상 볼륨(VVol) *</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">VVOL은 VVOL 데이터 저장소에 저장된 실제 가상 머신 파일 및 디스크입니다. VVOL(단일)이라는 용어는 단일 특정 파일, LUN 또는 네임스페이스를 의미합니다. ONTAP는 데이터 저장소에서 사용하는 프로토콜에 따라 NVMe 네임스페이스, LUN 또는 파일을 생성합니다. VVOL에는 여러 가지 유형이 있으며, 가장 일반적인 유형은 Config(메타데이터 파일), Data(가상 디스크 또는 VMDK) 및 Swap(VM의 전원을 켤 때 생성됨)입니다. VMware VM 암호화로 보호되는 VVol은 다른 유형일 것입니다. VMware VM 암호화를 ONTAP 볼륨 또는 애그리게이트 암호화와 혼동해서는 안 됩니다.</block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">관리 기준 정책</block>
  <block id="34d2b7d8b570ede7a638d070656b7b81" category="paragraph">VASA(VMware vSphere APIs for Storage Awareness)를 사용하면 VM 관리자가 스토리지 팀과 상호 작용하지 않고도 VM 프로비저닝에 필요한 스토리지 기능을 손쉽게 사용할 수 있습니다. VASA 이전에는 VM 관리자가 VM 스토리지 정책을 정의할 수 있었지만 대개 문서 또는 명명 규칙을 사용하여 스토리지 관리자와 협력하여 적절한 데이터 저장소를 식별해야 했습니다. VASA를 사용하면 vCenter 관리자가 적절한 사용 권한을 사용하여 vCenter 사용자가 VM을 프로비저닝하는 데 사용할 수 있는 다양한 스토리지 기능을 정의할 수 있습니다. VM 스토리지 정책과 데이터 저장소 스토리지 기능 프로필 간의 매핑을 통해 vCenter는 선택을 위해 호환 가능한 데이터 저장소 목록을 표시할 수 있을 뿐 아니라 Aria(이전의 vRealize) Automation 또는 Tanzu Kubernetes Grid와 같은 다른 기술을 사용하여 할당된 정책에서 스토리지를 자동으로 선택할 수 있습니다. 이러한 접근 방식을 스토리지 정책 기반 관리라고 합니다. 스토리지 기능 프로파일과 정책은 기존 데이터 저장소에도 사용할 수 있지만 여기서는 VVOL 데이터 저장소에 초점을 맞춥니다.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">두 가지 요소가 있습니다.</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">* SCP(Storage Capability Profile) *</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">SCP(Storage Capability Profile)는 vCenter 관리자가 ONTAP에서 이러한 기능을 관리하는 방법을 실제로 이해하지 않고도 필요한 스토리지 기능을 정의할 수 있는 스토리지 템플릿 형식입니다. 관리자는 템플릿 스타일의 접근 방식을 사용하여 일관되고 예측 가능한 방식으로 스토리지 서비스를 쉽게 제공할 수 있습니다. SCP에 설명된 기능에는 성능, 프로토콜, 스토리지 효율성 및 기타 기능이 포함됩니다. 특정 기능은 버전에 따라 다릅니다. vCenter UI의 ONTAP tools for VMware vSphere 메뉴를 사용하여 생성됩니다. REST API를 사용하여 SCP를 생성할 수도 있습니다. 개별 기능을 선택하여 수동으로 생성하거나 기존(기존) 데이터 저장소에서 자동으로 생성할 수 있습니다.</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">* VM 스토리지 정책 *</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">VM 스토리지 정책은 vCenter의 정책 및 프로필 아래에 생성됩니다. VVOL의 경우 NetApp VVOL 스토리지 유형 공급자에서 규칙을 사용하여 규칙 집합을 생성합니다. ONTAP 도구는 개별 규칙을 지정하지 않고 SCP를 간단히 선택할 수 있는 간단한 방법을 제공합니다.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">위에서 설명한 것처럼 정책을 사용하면 볼륨 프로비저닝 작업을 간소화할 수 있습니다. 적절한 정책을 선택하기만 하면 VASA Provider에서 해당 정책을 지원하는 VVOL 데이터 저장소를 표시하고 VVOL을 호환되는 개별 FlexVol 볼륨에 배치합니다(그림 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">스토리지 정책을 사용하여 VM 구축</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">스토리지 정책을 사용하여 가상 머신 구축</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">VM이 프로비저닝되면 VASA Provider는 규정 준수를 계속 확인하고 백업 볼륨이 정책을 더 이상 준수하지 않을 경우 vCenter에서 경고를 VM 관리자에게 보냅니다(그림 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">VM 스토리지 정책 준수</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">가상 시스템 저장소 정책 준수</block>
  <block id="e08bc5b354c3e8058003a662e0f7cade" category="section-title">NetApp VVOL을 지원합니다</block>
  <block id="234ad0324c313ec05d0fa6fe8d430967" category="paragraph">NetApp ONTAP는 2012년 최초 릴리즈 이후로 VASA 사양을 지원했습니다. 다른 NetApp 스토리지 시스템은 VASA를 지원할 수 있지만, 이 문서에서는 현재 지원되는 ONTAP 9 릴리즈에 대해 중점적으로 설명합니다.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP를 참조하십시오</block>
  <block id="4d53a8e49ac64213ffccdd970a35171e" category="paragraph">AFF, ASA 및 FAS 시스템 기반의 ONTAP 9 외에도 NetApp은 ONTAP Select에서 VMware 워크로드, AWS에서 VMware 클라우드를 사용하는 NetApp ONTAP용 Amazon FSx, Azure VMware 솔루션을 사용하는 Azure NetApp Files, Google Cloud VMware Engine을 사용하는 Cloud Volumes Service 및 Equinix의 NetApp 프라이빗 스토리지 등을 지원합니다. 그러나 특정 기능은 서비스 공급자 및 사용 가능한 네트워크 연결에 따라 달라질 수 있습니다. vSphere 게스트에서 이러한 구성에 저장된 데이터에 액세스할 수 있을 뿐만 아니라 Cloud Volumes ONTAP도 사용할 수 있습니다.</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">하이퍼스케일러 환경은 기존의 NFS v3 데이터 저장소로만 제한되므로, VVOL은 온프레미스 ONTAP 시스템이나 전 세계 NetApp 파트너 및 서비스 공급자가 호스팅하는 것과 같은 온프레미스 시스템의 모든 기능을 제공하는 클라우드 연결 시스템에서만 사용할 수 있습니다.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">ONTAP 제품 설명서</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_ ONTAP에 대한 자세한 내용은 을(를) 참조하십시오<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597 을 참조하십시오</block>
  <block id="9a03bb7ec5329e35d98c7b12b63c4df0" category="paragraph">_ ONTAP 및 VMware vSphere Best Practice에 대한 자세한 내용은 를 참조하십시오<block ref="fc9815e7b1405959c49ad47e9a23e3a5" category="inline-link-rx"></block>_</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">ONTAP와 함께 VVOL을 사용할 때의 이점</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">VMware는 2015년에 VASA 2.0을 통해 VVol 지원을 도입하면서 "외부 스토리지(SAN/NAS)를 위한 새로운 운영 모델을 제공하는 통합 및 관리 프레임워크"라고 설명했습니다. 이 운영 모델은 ONTAP 스토리지와 함께 다양한 이점을 제공합니다.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">섹션 1.2에서 설명한 대로 정책 기반 관리를 통해 미리 정의된 정책을 사용하여 VM을 프로비저닝하고 관리할 수 있습니다. 이를 통해 다음과 같은 여러 가지 방법으로 IT를 운영할 수 있습니다.</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">* 속도를 높이십시오. * ONTAP 툴을 사용하면 vCenter 관리자가 스토리지 용량 할당 작업을 위해 스토리지 팀과 티켓을 열 필요가 없습니다. 하지만 vCenter 및 ONTAP 시스템의 ONTAP 툴 RBAC 역할은 필요한 경우 특정 기능에 대한 액세스를 제한하여 독립 팀(예: 스토리지 팀) 또는 동일한 팀의 독립 활동을 계속 지원합니다.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">* 보다 현명한 프로비저닝. * 스토리지 시스템 기능은 VASA API를 통해 노출되므로 VM 관리자가 스토리지 시스템 관리 방법을 이해하지 않고도 프로비저닝 워크플로우를 통해 고급 기능을 활용할 수 있습니다.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">신속한 프로비저닝 * 다양한 스토리지 기능을 단일 데이터 저장소에서 지원하고 VM 정책에 따라 VM에 적합한 대로 자동으로 선택할 수 있습니다.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">* 실수를 피하십시오. * 스토리지 및 VM 정책은 미리 개발되고 VM을 프로비저닝할 때마다 스토리지를 사용자 지정할 필요 없이 필요에 따라 적용됩니다. 정의된 정책에서 스토리지 기능이 떨어지면 규정 준수 알람이 발생합니다. 앞서 언급한 것처럼, ICP는 초기 프로비저닝을 예측 가능하고 반복 가능하게 만드는 동시에, ICP를 기반으로 하는 VM 스토리지 정책을 수립하여 정확한 배치를 보장합니다.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">* 더 나은 용량 관리. * VASA 및 ONTAP 툴을 사용하면 필요한 경우 업계 애그리게이트 레벨까지 스토리지 용량을 확인할 수 있으며, 용량 부족 시 여러 계층의 알림을 제공할 수 있습니다.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">최신 SAN에서 VM 세부 관리</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">파이버 채널과 iSCSI를 사용하는 SAN 스토리지 시스템은 ESX에 대해 VMware에서 최초로 지원되었지만 스토리지 시스템에서 개별 VM 파일과 디스크를 관리할 수 있는 기능이 부족했습니다. 대신 LUN이 프로비저닝되고 VMFS가 개별 파일을 관리합니다. 따라서 스토리지 시스템에서 개별 VM 스토리지 성능, 클론 복제 및 보호를 직접 관리하는 것이 어렵습니다. VVOL은 ONTAP의 강력한 고성능 SAN 기능을 통해 이미 사용 중인 NFS 스토리지를 사용하는 고객이 더욱 세분화된 스토리지 기능을 이용할 수 있도록 합니다.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">이제 vSphere 8 및 VMware vSphere 9.12 이상을 위한 ONTAP 툴을 사용하여, 기존 SCSI 기반 프로토콜을 위한 VVOL에서 사용하는 것과 동일한 세분화된 제어를 NVMe over Fabrics를 사용하여 최신 파이버 채널 SAN에서 사용할 수 있으며, 규모에 따라 훨씬 더 뛰어난 성능을 제공합니다. vSphere 8.0 업데이트 1을 사용하면 하이퍼바이저 스토리지 스택에서 I/O 변환 없이 VVOL을 사용하여 완벽한 엔드 투 엔드 NVMe 솔루션을 구축할 수 있습니다.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">스토리지 오프로드 기능</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">효율성 보장</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">VAAI는 스토리지로 오프로드되는 다양한 작업을 제공하지만 VASA Provider에서 해결하는 데 약간의 차이가 있습니다. SAN VAAI는 VMware 관리 스냅샷을 스토리지 시스템으로 오프로드할 수 없습니다. NFS VAAI는 VM 관리 스냅샷을 오프로드할 수 있지만 스토리지 네이티브 스냅샷을 사용하여 VM을 배치하는 데 제한이 있습니다. VVOL은 가상 머신 디스크에 개별 LUN, 네임스페이스 또는 파일을 사용하므로 ONTAP는 파일 또는 LUN을 빠르고 효율적으로 복제하여 델타 파일이 더 이상 필요하지 않은 VM 세부 스냅샷을 생성할 수 있습니다. 또한 NFS VAAI는 핫(전원 켜짐) Storage vMotion 마이그레이션에 대한 클론 작업 오프로딩을 지원하지 않습니다. 기존 NFS 데이터 저장소에서 VAAI를 사용할 때 마이그레이션을 오프로드하려면 VM의 전원을 꺼야 합니다. ONTAP 툴의 VASA Provider를 사용하면 핫 및 콜드 마이그레이션을 위해 스토리지 효율성이 뛰어난 거의 즉각적인 복제본을 생성할 수 있으며, VVOL의 볼륨 간 마이그레이션을 위해 거의 즉각적인 복제본을 지원할 수 있습니다. 이러한 상당한 스토리지 효율성 혜택을 통해 에서 VVOL 워크로드를 충분히 활용할 수 있습니다<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> 프로그램. 마찬가지로 VAAI를 사용한 교차 볼륨 클론이 요구 사항을 충족하지 못할 경우 VVol의 복제 환경이 개선되어 비즈니스 과제를 해결할 수 있습니다.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">VVOL의 일반적인 사용 사례</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">이러한 이점 외에도 VVOL 스토리지의 일반적인 사용 사례도 있습니다.</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">* VM의 온디맨드 프로비저닝 *</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">프라이빗 클라우드 또는 서비스 공급자 IaaS</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Aria(이전의 vRealize) 제품군, OpenStack 등을 통해 자동화 및 오케스트레이션 활용</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">* 일등석 디스크(FCD) *</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">VMware Tanzu Kubernetes Grid[TKG] 영구 볼륨.</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">독립적인 VMDK 라이프사이클 관리를 통해 Amazon EBS와 유사한 서비스 제공</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">* 임시 VM의 온디맨드 프로비저닝 *</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">테스트/개발 연구소</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">교육 환경</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">VVOL의 일반적인 이점</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">위와 같은 사용 사례에서 VVOL을 최대한 활용했을 때 VVOL은 다음과 같은 구체적인 개선을 제공합니다.</block>
  <block id="13491b3af50183642ea0035b2d1f95f9" category="list-text">클론은 단일 볼륨 내에서 또는 ONTAP 클러스터의 여러 볼륨에 빠르게 생성되며, 이는 기존 VAAI 지원 클론과 비교할 때 이점이 있습니다. 또한 스토리지 효율성도 뛰어납니다. 볼륨 내의 클론은 FlexClone 볼륨과 같이 ONTAP 파일 클론을 사용하며 소스 VVol 파일/LUN/네임스페이스의 변경 내용만 저장합니다. 따라서 운영 또는 기타 애플리케이션 용도로 장기간 사용할 VM을 빠르게 생성하고, 공간을 최소화하고, VM 수준 보호(VMware vSphere용 NetApp SnapCenter 플러그인, VMware 관리 스냅샷 또는 VADP 백업 사용) 및 성능 관리(ONTAP QoS 사용)를 활용할 수 있습니다.</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">VVol은 vSphere CSI와 함께 TKG를 사용할 때 이상적인 스토리지 기술로서 vCenter 관리자가 관리하는 개별 스토리지 클래스 및 용량을 제공합니다.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">이름에서 알 수 있듯이, Amazon EBS와 유사한 서비스는 FCD를 통해 제공될 수 있습니다. 이는 FCD VMDK는 vSphere의 일등석 시민이며 연결된 VM과 별도로 관리할 수 있는 수명주기를 가지고 있기 때문입니다.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">VVOL 보호</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">VASA 공급자 고가용성</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">NetApp VASA Provider는 vCenter 플러그인 및 REST API 서버(이전의 VSC(Virtual Storage Console)) 및 스토리지 복제 어댑터와 함께 가상 어플라이언스의 일부로 실행됩니다. VASA Provider를 사용할 수 없는 경우 VVol을 사용하는 VM은 계속 실행됩니다. 그러나 새로운 VVOL 데이터 저장소를 생성할 수 없으며 VVol은 vSphere에서 생성하거나 바인딩할 수 없습니다. 즉, vCenter에서 VVOL의 생성을 요청할 수 없기 때문에 VVOL을 사용하는 VM의 전원을 켤 수 없습니다. 실행 중인 VM은 VVol을 새 호스트에 바인딩할 수 없으므로 vMotion을 사용하여 다른 호스트로 마이그레이션할 수 없습니다.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7.1 이상은 새로운 기능을 지원하여 필요할 때 서비스를 사용할 수 있도록 합니다. VASA Provider 및 통합 데이터베이스 서비스를 모니터링하는 새로운 Watchdog 프로세스가 포함되어 있습니다. 오류가 감지되면 로그 파일을 업데이트한 다음 서비스를 자동으로 다시 시작합니다.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">소프트웨어, 호스트 하드웨어 및 네트워크의 장애로부터 다른 미션 크리티컬 VM을 보호하는 데 사용되는 동일한 가용성 기능을 사용하여 vSphere 관리자가 추가 보호를 구성해야 합니다. 이러한 기능을 사용하기 위해 가상 어플라이언스에 추가 구성이 필요하지 않습니다. 표준 vSphere 방식을 사용하여 구성하기만 하면 됩니다. 이러한 기능은 테스트를 거쳤으며 NetApp에서 지원됩니다.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">VMware vSphere용 ONTAP 툴 설명서(ONTAP 툴에 대한 고가용성 구성)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">장애가 발생할 경우 호스트 클러스터의 다른 호스트에서 VM을 다시 시작하도록 vSphere High Availability를 손쉽게 구성할 수 있습니다. vSphere Fault Tolerance는 지속적으로 복제되고 어느 시점에서든 인계받을 수 있는 보조 VM을 생성하여 가용성을 높여 줍니다. 이러한 기능에 대한 추가 정보는 에서 확인할 수 있습니다<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>및 VMware vSphere 설명서(ESXi 및 vCenter Server에서 vSphere 가용성 확인)</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">ONTAP 툴 VASA Provider는 FlexVol 볼륨 메타데이터 내에 VVol 정보가 저장된 관리되는 ONTAP 시스템에 VVOL 구성을 실시간으로 자동 백업합니다. 어떤 이유로든 ONTAP 도구 어플라이언스를 사용할 수 없게 되는 경우 새 도구를 쉽고 빠르게 배포하고 구성을 가져올 수 있습니다. VASA Provider 복구 단계에 대한 자세한 내용은 이 KB 문서를 참조하십시오.</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">VASA Provider 재해 복구 - 해결 가이드를 수행하는 방법</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">VVOL 복제</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">많은 ONTAP 고객은 NetApp SnapMirror를 사용하여 기존 데이터 저장소를 2차 스토리지 시스템으로 복제한 다음, 재해 발생 시 2차 시스템을 사용하여 개별 VM 또는 전체 사이트를 복구합니다. 대부분의 경우 고객은 VMware vSphere용 NetApp SnapCenter 플러그인과 같은 백업 소프트웨어 제품 또는 VMware의 사이트 복구 관리자(ONTAP 툴의 스토리지 복제 어댑터 포함)와 같은 재해 복구 솔루션과 같은 소프트웨어 툴을 사용하여 이를 관리합니다.</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">VVOL 복제를 관리하려면 소프트웨어 툴에 대한 이 요구사항이 더 중요합니다. 일부 측면은 기본 기능(예: VMware에서 관리하는 VVOL 스냅샷)을 통해 관리할 수 있지만(예: 빠르고 효율적인 파일 또는 LUN 클론을 사용하는 ONTAP로 오프로드됨) 복제 및 복구를 관리하려면 일반적으로 오케스트레이션이 필요합니다. VVOL에 대한 메타데이터는 ONTAP와 VASA Provider에 의해 보호되지만 보조 사이트에서 이를 사용하려면 추가 처리가 필요합니다.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">ONTAP 툴 9.7.1 을 VMware SRM(Site Recovery Manager) 8.3 릴리스와 함께 사용하면 NetApp SnapMirror 기술을 활용하여 재해 복구 및 마이그레이션 워크플로우 오케스트레이션에 대한 지원이 추가되었습니다.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">ONTAP 툴 9.7.1을 사용한 SRM 지원 초기 릴리즈에서는 VFlexVol을 사전 생성하고 이를 VVOL 데이터 저장소의 백업 볼륨으로 사용하기 전에 SnapMirror 보호를 활성화해야 했습니다. ONTAP 도구 9.10부터는 더 이상 이 프로세스가 필요하지 않습니다. 이제 기존의 백업 볼륨에 SnapMirror 보호를 추가하고 VM 스토리지 정책을 업데이트하여 SRM과 통합된 재해 복구 및 마이그레이션 오케스트레이션 및 자동화 기능을 통해 정책 기반 관리를 활용할 수 있습니다.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">현재 VMware SRM은 NetApp에서 지원하는 VVOL을 위한 유일한 재해 복구 및 마이그레이션 자동화 솔루션이며, ONTAP 툴은 VVOL 복제를 활성화하기 전에 vCenter에 등록된 SRM 8.3 이상 서버의 존재를 ONTAP 툴 REST API를 활용하여 자체 서비스를 생성할 수 있지만</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">SRM을 사용한 VVol 복제</block>
  <block id="4d30574e6d5bc9a71718858eeb30774c" category="inline-image-macro">SRM을 사용한 VVol 복제, 300</block>
  <block id="5844b0ec1ad8db5185ec67effeb9a7b7" category="paragraph"><block ref="5844b0ec1ad8db5185ec67effeb9a7b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">MetroCluster 지원</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">ONTAP 툴은 MetroCluster 전환을 트리거할 수 없지만, 동일한 vMSC(vSphere Metro Storage Cluster) 구성에서 VVOL을 지원하는 볼륨을 위한 NetApp MetroCluster 시스템은 지원합니다. MetroCluster 시스템의 전환은 일반적인 방식으로 처리됩니다.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">NetApp SnapMirror 비즈니스 연속성(SM-BC)을 vMSC 구성의 기반으로 사용할 수도 있지만, 현재 VVOL에서 지원되지 않습니다.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">NetApp MetroCluster에 대한 자세한 내용은 다음 가이드를 참조하십시오.</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_TR-4689 MetroCluster IP 솔루션 아키텍처 및 설계 _</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 NetApp MetroCluster 솔루션 아키텍처 및 설계 _</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 NetApp MetroCluster_ 기반 VMware vSphere 지원</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">VVOL 백업 개요</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">게스트 내 백업 에이전트 사용, 백업 프록시에 VM 데이터 파일 연결 또는 VMware VADP 같은 정의된 API 사용과 같은 VM을 보호하기 위한 몇 가지 방법이 있습니다. VVOL은 동일한 메커니즘을 사용하여 보호할 수 있으며 많은 NetApp 파트너가 VVOL을 포함한 VM 백업을 지원합니다.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">앞서 언급했듯이 VMware vCenter 관리 스냅샷은 공간 효율적이고 빠른 ONTAP 파일/LUN 클론으로 오프로드됩니다. 이러한 스냅샷은 빠른 수동 백업에 사용할 수 있지만 vCenter에 의해 최대 32개의 스냅샷으로 제한됩니다. 필요에 따라 vCenter를 사용하여 스냅샷을 생성하고 되돌릴 수 있습니다.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">SnapCenter SCV(VMware vSphere) 플러그인 4.6부터 ONTAP 도구 9.10 이상과 함께 사용할 경우 SnapMirror 및 SnapVault 복제를 지원하는 ONTAP FlexVol 볼륨 스냅샷을 활용하여 충돌 시에도 정합성이 보장되는 VVol 기반 VM 백업 및 복구를 지원합니다. 볼륨당 최대 1023개의 스냅샷이 지원됩니다. 또한 SCV는 미러 볼트 정책이 적용된 SnapMirror를 사용하여 보조 볼륨에 더 많은 스냅샷을 더 오래 보존할 수 있습니다.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">vSphere 8.0 지원은 격리된 로컬 플러그인 아키텍처를 사용하는 SCV 4.7에 도입되었습니다. 새로운 원격 플러그인 아키텍처로 완전히 전환된 SCV 4.8에 vSphere 8.0U1 지원이 추가되었습니다.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">VMware vSphere용 SnapCenter 플러그인을 사용한 VVol 백업</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">이제 NetApp SnapCenter를 사용하여 태그 및/또는 폴더를 기반으로 VVol용 리소스 그룹을 생성하여 VVol 기반 VM에 대해 ONTAP의 FlexVol 기반 스냅샷을 자동으로 활용할 수 있습니다. 이를 통해 환경 내에서 VM이 동적으로 프로비저닝될 때 자동으로 VM을 보호하는 백업 및 복구 서비스를 정의할 수 있습니다.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">VMware vSphere용 SnapCenter 플러그인은 vCenter 확장으로 등록된 독립 실행형 어플라이언스로 구축되며, vCenter UI 또는 REST API를 통해 관리되며 백업 및 복구 서비스 자동화를 지원합니다.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">SnapCenter 아키텍처</block>
  <block id="3b345c0fb5d2f0451ef84d991b21dcac" category="inline-image-macro">SnapCenter 아키텍처, 300</block>
  <block id="af9bca7d8452705ba7f607cd036dba01" category="paragraph"><block ref="af9bca7d8452705ba7f607cd036dba01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">다른 SnapCenter 플러그인은 이 작성 시점에 VVol을 지원하지 않으므로 이 문서의 독립 실행형 배포 모델에 대해 중점적으로 살펴보겠습니다.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">SnapCenter는 ONTAP FlexVol 스냅샷을 사용하기 때문에 vSphere에 오버헤드가 발생하지 않으며, vCenter 관리 스냅샷을 사용하여 기존 VM에서 볼 수 있는 성능 패널도 없습니다. 또한 SCV의 기능은 REST API를 통해 노출되기 때문에 VMware Aria Automation, Ansible, Terraform 및 거의 표준 REST API를 사용할 수 있는 기타 자동화 툴과 같은 툴을 사용하여 자동화된 워크플로우를 쉽게 생성할 수 있습니다.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">REST API 개요</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">SnapCenter REST API에 대한 자세한 내용은 를 참조하십시오<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">VMware vSphere REST API용 SnapCenter 플러그인</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">VMware vSphere REST API용 SnapCenter 플러그인에 대한 자세한 내용은 을 참조하십시오<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">다음 모범 사례를 사용하면 SnapCenter 배포를 최대한 활용할 수 있습니다.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV는 vCenter Server RBAC와 ONTAP RBAC를 모두 지원하며 플러그인이 등록될 때 자동으로 생성되는 사전 정의된 vCenter 역할을 포함합니다. 지원되는 RBAC 유형에 대해 자세히 알아볼 수 있습니다<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">vCenter UI를 사용하여 설명된 사전 정의된 역할을 사용하여 최소 권한 계정 액세스를 할당합니다<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">SnapCenter 서버와 함께 SCV를 사용하는 경우 _SnapCenterAdmin_role을 할당해야 합니다.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC는 SCV에서 사용되는 스토리지 시스템을 추가 및 관리하는 데 사용되는 사용자 계정을 의미합니다. ONTAP RBAC는 VVOL 기반 백업에 적용되지 않습니다. ONTAP RBAC 및 SCV에 대해 자세히 알아보십시오<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">SnapMirror를 사용하여 소스 볼륨의 전체 복제본을 사용하여 백업 데이터 세트를 두 번째 시스템으로 복제합니다. 앞서 언급했듯이 소스 볼륨 스냅샷 보존 설정과 관계없이 백업 데이터의 장기 보존을 위해 미러 볼트(mirror-vault) 정책을 사용할 수도 있습니다. 두 가지 메커니즘 모두 VVOL에서 지원됩니다.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">SCV에는 VVOL 기능을 위해 VMware vSphere용 ONTAP 툴도 필요하므로 항상 NetApp IMT(Interoperability Matrix Tool)에서 특정 버전 호환성을 확인하십시오</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">VMware SRM에서 VVol 복제를 사용하는 경우 정책 RPO 및 백업 일정을 고려해야 합니다</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">조직에서 정의한 RPO(복구 시점 목표)를 충족하는 보존 설정으로 백업 정책 설계</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">백업이 실행될 때 상태를 알리도록 리소스 그룹의 알림 설정을 구성합니다(아래 그림 10 참조).</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">리소스 그룹 알림 옵션</block>
  <block id="c728df76dc3609672a7969e320e39e32" category="inline-image-macro">리소스 그룹 알림 옵션, 300</block>
  <block id="45281309785094533b5880fe6d0fd1ea" category="paragraph"><block ref="45281309785094533b5880fe6d0fd1ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">이 문서를 사용하여 SCV를 시작하십시오</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">VMware vSphere용 SnapCenter 플러그인에 대해 자세히 알아보십시오</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">VMware vSphere용 SnapCenter 플러그인 구축</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">문제 해결</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">NetApp Support 사이트</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">VMware vSphere용 ONTAP 툴</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">NetApp Support 사이트은 NetApp 가상화 제품에 대한 다양한 기술 자료 문서 외에도 에 대한 편리한 랜딩 페이지 도 제공합니다<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> 제품. 이 포털은 NetApp 커뮤니티에서 기사, 다운로드, 기술 보고서 및 VMware Solutions 토론에 대한 링크를 제공합니다. 이 제품은 다음 위치에서 사용할 수 있습니다.</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_NetApp Support 사이트 _</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">추가 솔루션 설명서는 여기에서 확인할 수 있습니다.</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_가상화를 위한 NetApp 솔루션 _</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">제품 문제 해결</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">vCenter 플러그인, VASA 공급자, 스토리지 복제 어댑터 등과 같은 ONTAP 툴의 다양한 구성 요소는 NetApp 문서 저장소에 함께 정리되어 있습니다. 그러나 각 기술 문서는 별도의 하위 섹션을 가지고 있으며 특정 문제 해결 절차가 있을 수 있습니다. VASA Provider에서 발생할 수 있는 가장 일반적인 문제를 해결합니다.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">VASA Provider UI 문제</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">기사</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">때때로 vCenter vSphere Web Client에서 Serenity 구성 요소에 문제가 발생하여 VASA Provider for ONTAP 메뉴 항목이 표시되지 않는 경우가 있습니다. 구축 가이드 또는 이 기술 자료에서 VASA 공급자 등록 문제 해결 을 참조하십시오<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">VVOL 데이터 저장소 프로비저닝이 실패합니다</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">VVOL 데이터 저장소를 생성할 때 vCenter 서비스가 시간 초과되는 경우가 있습니다. 이 문제를 해결하려면 VMware-SPS 서비스를 다시 시작한 다음 vCenter 메뉴(Storage &gt; New Datastore)를 사용하여 VVol 데이터 저장소를 다시 마운트합니다. 관리 가이드의 vCenter Server 6.5와 함께 VVol 데이터 저장소 프로비저닝이 실패하는 경우 이에 대해 다룹니다.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">Unified Appliance를 Mount ISO로 업그레이드하지 못했습니다</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">vCenter의 버그로 인해 Unified Appliance를 한 릴리즈에서 다음 릴리즈로 업그레이드하는 데 사용되는 ISO가 마운트되지 않을 수 있습니다. vCenter에서 ISO를 어플라이언스에 연결할 수 있는 경우 이 Knowledgebase의 프로세스를 따르십시오<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> 를 눌러 해결합니다.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">VVOL 스토리지 구축</block>
  <block id="2a5f3dc8d46246216b293c9e41979269" category="paragraph">기존 데이터 저장소에 ONTAP를 사용하는 기존 vSphere 환경에서는 처음 두 단계가 필요하지 않을 수 있습니다. 이미 ONTAP 툴을 사용하여 VMFS 또는 기존 NFS 기반 스토리지를 관리, 자동화 및 보고할 수 있습니다. 이러한 단계는 다음 섹션에서 자세히 설명합니다.</block>
  <block id="841db3655338a0c3dc36cf2761bfdafd" category="list-text">SVM(Storage Virtual Machine)과 프로토콜 구성을 생성합니다. NVMe/FC, NFSv3, NFSv4.1, iSCSI, FCP, 여러 옵션을 함께 사용할 수도 있습니다. ONTAP System Manager 마법사 또는 클러스터 셸 명령줄을 사용할 수 있습니다.</block>
  <block id="10818a8ad4f650a48d78d728278d4cb3" category="list-text">각 스위치/패브릭 연결마다 노드당 하나 이상의 LIF가 있어야 합니다. 모범 사례로서, FCP, iSCSI 또는 NVMe 기반 프로토콜에 대해 노드당 두 개 이상의 를 생성합니다.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">현재 볼륨을 생성할 수 있지만 _Provision Datastore_wizard에서 볼륨을 생성하는 것이 더 간단합니다. 이 규칙의 유일한 예외는 VMware Site Recovery Manager에서 VVol 복제를 사용하려는 경우입니다. 기존 SnapMirror 관계가 있는 기존 FlexVol 볼륨에서는 더욱 쉽게 설정할 수 있습니다. SPBM 및 ONTAP 도구를 통해 관리되기 때문에 VVOL에 사용할 볼륨에서 QoS를 활성화하지 마십시오.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">NetApp Support 사이트에서 다운로드한 OVA를 사용하여 VMware vSphere용 ONTAP 툴을 구축합니다.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">환경에 맞게 ONTAP 툴을 구성합니다.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">ONTAP 클러스터를 _ 스토리지 시스템 _ 의 ONTAP 도구에 추가합니다</block>
  <block id="731ce7392ae254e2050191ae92cafb14" category="list-text">ONTAP 툴과 SRA는 클러스터 레벨과 SVM 레벨 자격 증명을 모두 지원하지만 VASA Provider는 스토리지 시스템에 대한 클러스터 레벨 자격 증명만 지원합니다. 이는 VVOL에 사용되는 대부분의 API가 클러스터 수준에서만 사용 가능하기 때문입니다. 따라서 VVOL을 사용할 계획인 경우 클러스터 범위 자격 증명을 사용하여 ONTAP 클러스터를 추가해야 합니다.</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">ONTAP 데이터 LIF가 VMkernel 어댑터와 다른 서브넷에 있는 경우 ONTAP 툴의 설정 메뉴에서 선택한 서브넷 목록에 VMkernel 어댑터 서브넷을 추가해야 합니다. 기본적으로 ONTAP 툴은 로컬 서브넷 액세스만 허용하여 스토리지 트래픽을 보호합니다.</block>
  <block id="5a6d084090f063797fc6b863d2817d98" category="list-text">ONTAP 툴에는 사용하거나 볼 수 있는 미리 정의된 여러 정책이 함께 제공됩니다 <block ref="434866eb159632a70c4db034544336ef" category="inline-xref-macro-rx"></block> SCP 생성에 대한 지침을 참조하십시오.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">vCenter의 _ONTAP tools_ 메뉴를 사용하여 _provision datastore_wizard를 시작합니다.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">의미 있는 이름을 제공하고 원하는 프로토콜을 선택합니다. 데이터 저장소에 대한 설명도 제공할 수 있습니다.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">VVOL 데이터 저장소에서 지원할 하나 이상의 SCP를 선택합니다. 이렇게 하면 프로필과 일치하지 않는 ONTAP 시스템이 모두 필터링됩니다. 결과 목록에서 원하는 클러스터와 SVM을 선택합니다.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">마법사를 사용하여 지정된 각 SCP에 대해 새 FlexVol 볼륨을 생성하거나 적절한 라디오 버튼을 선택하여 기존 볼륨을 사용합니다.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">vCenter UI의 _Policies 및 Profiles_ 메뉴에서 데이터 저장소에 사용될 각 SCP에 대한 VM 정책을 생성합니다.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">"NetApp.clustered.Data.ONTAP.VP.VVol" 스토리지 규칙 세트를 선택합니다. "NetApp.clustered.Data.ONTAP.VP.VASA10" 스토리지 규칙 세트는 비 VVOL 데이터 저장소를 사용하여 SPBM을 지원하는 데 사용됩니다</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">VM 스토리지 정책을 생성할 때 이름으로 스토리지 용량 프로필을 지정합니다. 이 단계에서는 복제 탭을 사용하여 SnapMirror 정책 일치를 구성하고 태그 탭을 사용하여 태그 기반 일치를 구성할 수도 있습니다. 선택할 수 있으려면 태그가 이미 생성되어 있어야 합니다.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Select storage(스토리지 선택) 에서 VM Storage Policy(VM 스토리지 정책) 및 Compatible datastore(호환 데이터 저장소)를 선택하여 VM을 생성합니다.</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">기존 데이터 저장소에서 VVOL으로 VM 마이그레이션</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">기존 데이터 저장소에서 VVOL 데이터 저장소로 VM을 마이그레이션하는 작업은 기존 데이터 저장소 간에 VM을 이동하는 것처럼 간단합니다. VM을 선택한 다음 작업 목록에서 마이그레이션 을 선택하고 마이그레이션 유형 _change storage only_를 선택합니다. SAN VMFS에서 VVOL으로의 마이그레이션을 위해 vSphere 6.0 이상에서는 마이그레이션 복제 작업이 오프로드되지만 NAS VMDK에서 VVOL으로 마이그레이션하지는 않습니다.</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">정책을 사용하여 VM 관리</block>
  <block id="4b746813f1085683be4f71c8affea233" category="paragraph">정책 기반 관리로 스토리지 프로비저닝을 자동화하려면 다음이 필요합니다.</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">스토리지 기능 프로필(SCP)을 사용하여 스토리지 기능(ONTAP 노드 및 FlexVol 볼륨)을 정의합니다.</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">정의된 SCP에 매핑되는 VM 스토리지 정책을 생성합니다.</block>
  <block id="67c819108c4ef294ac28a51197046dfc" category="paragraph">NetApp은 VASA Provider 7.2부터 기능과 매핑을 간소화하여 이후 버전에서 지속적으로 기능을 개선했습니다. 이 섹션에서는 이러한 새로운 접근 방식에 초점을 맞춥니다. 이전 릴리즈에서는 더 많은 수의 기능을 지원했고 이 기능을 스토리지 정책에 개별적으로 매핑할 수 있었지만, 이 방식은 더 이상 지원되지 않습니다.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">ONTAP 툴 릴리즈에 의한 스토리지 기능 프로파일 기능</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">* SCP 기능 *</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">* 기능 값 *</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">* 릴리스 지원 *</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">* 참고 *</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">* 압축 *</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">예, 아니요, 모두</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">7.2 이상에서 AFF에 대해 필수입니다.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">* 데이터 중복 제거 *</block>
  <block id="6868f879256c802b106616a006671848" category="cell">7.2 이상에서 AFF에 대한 약탈적.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">* 암호화 *</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7.2 이상</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">암호화된 FlexVol 볼륨을 선택/생성합니다. ONTAP 라이센스가 필요합니다.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">* 최대 IOPS *</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7.1 이상, 그러나 차이</block>
  <block id="c0f84018aff4ff4a1cf4012a8b82e509" category="cell">7.2 이상에서 QoS 정책 그룹 아래에 나열되어 있습니다. 을 참조하십시오 <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block> 를 참조하십시오.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">* 개인 정보 *</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS에는 ONTAP Select과 같은 비 AFF 시스템도 포함됩니다. AFF에는 ASA가 포함되어 있습니다.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">* 프로토콜 *</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4.1, iSCSI, FCP, NVMe/FC, 모두</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7.1 이하, 9.10 이상</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7.2-9.8은 "모든" 기능을 제공합니다. 9.10부터 다시 시작합니다. 여기서 NFS 4.1과 NVMe/FC가 원래 목록에 추가되었습니다.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">* 공간 예약(씬 프로비저닝) *</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">얇은 두께(모두)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">차이점만 있는 모든 것</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">7.1 이전 버전에서 씬 프로비저닝이라고 하며, 이 경우에도 임의의 값을 사용할 수 있습니다. 7.2에서 Space Reserve라고 합니다. 모든 릴리즈에는 기본적으로 Thin 이 사용됩니다.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">* 계층화 정책 *</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">모두, 없음, 스냅샷, 자동</block>
  <block id="00917abc35f0d57db6562a886997c4e8" category="cell">FabricPool에 사용됨 - ONTAP 9.4 이상이 설치된 AFF 또는 ASA가 필요합니다. NetApp StorageGRID와 같은 사내 S3 솔루션을 사용하지 않는 한 스냅샷만 사용하는 것이 좋습니다.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">스토리지 용량 프로파일 생성</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">NetApp VASA Provider는 사전 정의된 여러 SCP와 함께 제공됩니다. vCenter UI를 사용하거나 REST API를 사용하여 자동화를 통해 새로운 SCP를 수동으로 생성할 수 있습니다. 새 프로파일에 기능을 지정하거나 기존 프로파일을 클론 생성하거나 기존 기존 데이터 저장소에서 프로파일을 자동 생성하여 프로파일을 생성할 수 있습니다. 이 작업은 ONTAP 도구의 메뉴를 사용하여 수행합니다. 스토리지 기능 프로파일 _ 을(를) 사용하여 프로파일을 만들거나 복제하고 _ 스토리지 매핑 _ 을(를) 사용하여 프로파일을 자동 생성합니다.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">ONTAP 툴 9.10 이상을 위한 스토리지 용량</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">"ONTAP 도구 9.10 이상을 위한 스토리지 기능", 300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="049b6d7b78dd8ffebadb5a0be2261637" category="paragraph">* VVOL 데이터 저장소 생성 *
필요한 SCP를 생성한 후 이를 사용하여 VVOL 데이터 저장소(및 선택적으로 데이터 저장소용 FlexVol 볼륨)를 생성할 수 있습니다. VVOL 데이터 저장소를 생성할 호스트, 클러스터 또는 데이터 센터를 마우스 오른쪽 버튼으로 클릭한 다음 _ONTAP tools_&gt;_Provision Datastore_를 선택합니다. 데이터스토어에 의해 지원되는 하나 이상의 SCP를 선택한 다음 기존 FlexVol 볼륨에서 선택하거나 데이터 저장소에 새 FlexVol 볼륨을 프로비저닝합니다. 마지막으로 정책에 지정된 SCP가 없는 VM과 스왑 VVol(고성능 스토리지가 필요하지 않음)에 사용할 데이터 저장소의 기본 SCP를 지정합니다.</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">VM 스토리지 정책을 생성하는 중입니다</block>
  <block id="b4f6f65777757af7630fae901718e51e" category="paragraph">이전 릴리스는 유사하지만 에서 언급한 바와 같습니다 <block ref="68072d20e775e4558feadbec7ba8f768" category="inline-xref-macro-rx"></block>, 옵션이 다를 수 있습니다.</block>
  <block id="52896487a6472798e1d6cbc9a95ec51e" category="section-title">ONTAP 툴을 사용하여 VM 스토리지 정책 생성 VASA Provider 9.10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">"ONTAP 툴을 사용한 VM 스토리지 정책 생성 VASA Provider 9.10", 300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">ONTAP 도구 9.10 이상을 사용하여 성능을 관리합니다</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP tools 9.10은 자체 균형 배치 알고리즘을 사용하여 VVOL 데이터 저장소 내의 최상의 FlexVol 볼륨에 새로운 VVOL을 배치합니다. 지정된 SCP와 일치하는 FlexVol 볼륨을 기준으로 배치됩니다. 이렇게 하면 데이터 저장소 및 백업 스토리지가 지정된 성능 요구 사항을 충족할 수 있습니다.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">최소 및 최대 IOPS와 같은 성능 기능을 변경하려면 특정 구성에 약간의 주의가 필요합니다.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">* 최소 및 최대 IOPS * 는 SCP에서 지정하고 VM 정책에 사용할 수 있습니다.</block>
  <block id="404e0fefd61512a9f144586382a62641" category="list-text">SCP에서 IOPS를 변경하면 VM 정책이 편집된 후 이를 사용하는 VM에 다시 적용되기 전까지 VVol의 QoS가 변경되지 않습니다(참조) <block ref="2358041c73953300d39d98366deee80d" category="inline-xref-macro-rx"></block>)를 클릭합니다. 또는 원하는 IOPS로 새 SCP를 생성하고 정책을 변경하여 사용할 수 있도록 변경합니다(VM에 다시 적용). 일반적으로, 서로 다른 서비스 계층에 대해 별도의 SCP와 VM 스토리지 정책을 간단히 정의하고 VM에서 VM 스토리지 정책을 간단히 변경하는 것이 좋습니다.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">AFF 및 FAS 특성은 IOP 설정이 다릅니다. 최소 및 최대 모두 AFF에서 사용할 수 있습니다. 하지만 비 AFF 시스템은 최대 IOP 설정만 사용할 수 있습니다.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">정책을 변경한 후 VVOL을 마이그레이션해야 하는 경우도 있습니다(수동으로 또는 VASA Provider 및 ONTAP에 의해 자동으로).</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">일부 변경 사항은 마이그레이션이 필요하지 않습니다(예: Max IOPS 변경, 위에서 설명한 대로 VM에 즉시 적용 가능).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">VVOL을 저장하는 현재 FlexVol 볼륨에서 정책 변경을 지원할 수 없는 경우(예: 플랫폼에서 요청된 암호화 또는 계층화 정책을 지원하지 않음), vCenter에서 VM을 수동으로 마이그레이션해야 합니다.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">ONTAP 툴은 현재 지원되는 버전의 ONTAP로 개별 비공유 QoS 정책을 생성합니다. 따라서 각 개별 VMDK는 고유한 IOP 할당을 받게 됩니다.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">VM 스토리지 정책을 다시 적용합니다</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">"VM 스토리지 정책 다시 적용" ,300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)와 NFS(v3 및 v4.1), 게스트 연결을 위한 SMB 또는 S3와 같은 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. 고객은 자체 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">ONTAP용 가상화 툴</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp은 ONTAP 및 vSphere와 함께 사용하여 가상화 환경을 관리할 수 있는 몇 가지 독립 실행형 소프트웨어 툴을 제공합니다.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">다음 툴은 ONTAP 라이센스와 함께 추가 비용 없이 제공됩니다. 그림 1을 참조하여 vSphere 환경에서 이러한 툴이 함께 작동하는 방식을 보여 줍니다.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">VMware vSphere용 ONTAP 툴은 ONTAP 스토리지를 vSphere와 함께 사용하기 위한 일련의 툴입니다. 이전에 VSC(Virtual Storage Console)라고도 하는 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 향상하고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이러한 ONTAP 툴을 모범 사례로 사용하는 것이 좋습니다. 여기에는 서버 어플라이언스, vCenter, VASA Provider 및 Storage Replication Adapter를 위한 사용자 인터페이스 확장이 포함됩니다. ONTAP 툴의 거의 모든 기능을 대부분의 최신 자동화 툴에서 사용 가능한 단순한 REST API를 사용하여 자동화할 수 있습니다.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">* vCenter UI 확장. * ONTAP 툴 UI 확장은 호스트 및 스토리지 관리, 정보 포틀릿 및 vCenter UI에서 직접 기본 경고 기능을 관리할 수 있는 사용이 간편한 컨텍스트 기반 메뉴를 횡령함으로써 운영 팀과 vCenter 관리자의 업무를 간소화합니다.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">* VASA Provider for ONTAP. * VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. 이 제품은 구축 편의성을 위해 VMware vSphere용 ONTAP 툴의 일부로 단일 가상 어플라이언스로 제공됩니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. 이를 통해 VVol(VMware Virtual Volumes) 지원, 스토리지 기능 프로필 관리, 개별 VM VVol 성능, 용량 모니터링 및 프로파일 규정 준수에 대한 경보를 수행할 수 있습니다.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">* 스토리지 복제 어댑터. * SRA는 VMware SRM(Site Recovery Manager)과 함께 사용되어 운영 사이트와 재해 복구 사이트 간의 데이터 복제를 관리하고 DR 복제본을 중단 없이 테스트합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. Windows SRM 서버 및 SRM 어플라이언스에는 SRA 서버 어플라이언스와 SRA 어댑터가 모두 포함됩니다.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">다음 그림에서는 vSphere용 ONTAP 툴을 보여 줍니다.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">VMware VAAI용 NFS 플러그인</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">VMware VAAI용 NetApp NFS 플러그인은 ESXi 호스트에서 ONTAP의 NFS 데이터 저장소와 함께 VAAI 기능을 사용할 수 있도록 지원하는 플러그인입니다. 클론 작업을 위한 복제 오프로드, 일반 가상 디스크 파일에 대한 공간 예약 및 스냅샷 오프로드를 지원합니다. 복사 작업을 스토리지로 오프로드하는 것이 반드시 완료되기만은 않습니다. 그러나 이 작업은 네트워크 대역폭 요구 사항을 줄이고 CPU 주기, 버퍼 및 큐와 같은 호스트 리소스를 오프로드합니다. VMware vSphere용 ONTAP 툴을 사용하여 ESXi 호스트 또는 지원되는 경우 VLCM(vSphere Lifecycle Manager)에 플러그인을 설치할 수 있습니다.</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. 또한 VM 정합성 보장 스냅샷의 선택 옵션을 계속 허용하므로 VMware 스냅샷을 생성하기 전에 하이퍼바이저의 입출력 중지 기능을 활용할 수 있습니다.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">스토리지 정책 기반 관리 및 VVOL</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">VASA(VMware vSphere APIs for Storage Awareness)를 사용하면 스토리지 관리자가 잘 정의된 기능을 사용하여 데이터 저장소를 쉽게 구성할 수 있으며 VM 관리자는 필요할 때마다 상호 작용하지 않고도 데이터 저장소를 사용하여 VM을 프로비저닝할 수 있습니다.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">가상화 스토리지 운영을 간소화하고 사소한 작업을 많이 피하는 방법을 알아보려면 이 접근 방식을 살펴보시기 바랍니다.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">VASA 이전에는 VM 관리자가 VM 스토리지 정책을 정의할 수 있었지만 대개 문서 또는 명명 규칙을 사용하여 스토리지 관리자와 협력하여 적절한 데이터 저장소를 식별해야 했습니다. 스토리지 관리자는 VASA를 통해 성능, 계층화, 암호화, 복제를 비롯한 다양한 스토리지 기능을 정의할 수 있습니다. 볼륨 또는 볼륨 세트에 대한 기능 세트를 SCP(Storage Capability Profile)라고 합니다.</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">SCP는 VM의 데이터 VVol에 대한 최소 및/또는 최대 QoS를 지원합니다. 최소 QoS는 AFF 시스템에서만 지원됩니다. VMware vSphere용 ONTAP 툴에는 ONTAP 시스템에서 VVOL을 위한 VM 레벨의 세분화된 성능과 논리적 용량을 보여주는 대시보드가 포함되어 있습니다.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">다음 그림은 VMware vSphere 9.8 VVol 대시보드를 위한 ONTAP 툴을 보여 줍니다.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">스토리지 용량 프로필을 정의한 후에는 요구 사항을 식별하는 스토리지 정책을 사용하여 VM을 프로비저닝하는 데 사용할 수 있습니다. VM 스토리지 정책과 데이터 저장소 스토리지 용량 프로파일 간의 매핑을 통해 vCenter에서 선택할 수 있는 호환 데이터 저장소 목록을 표시할 수 있습니다. 이러한 접근 방식을 스토리지 정책 기반 관리라고 합니다.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">VASA는 스토리지를 쿼리하고 스토리지 기능 집합을 vCenter에 반환하는 기술을 제공합니다. VASA 공급업체 공급자는 스토리지 시스템 API 및 구성 요소 및 vCenter에서 인식할 수 있는 VMware API 간의 변환을 제공합니다. NetApp의 VASA Provider for ONTAP는 VMware vSphere 어플라이언스 VM을 위한 ONTAP 툴의 일부로 제공됩니다. 또한, vCenter 플러그인은 VVOL 데이터 저장소를 프로비저닝 및 관리하기 위한 인터페이스를 제공하며 SCP(스토리지 기능 프로필)를 정의합니다.</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400 을 참조하십시오</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP는 VMFS 및 NFS VVOL 데이터 저장소를 모두 지원합니다. SAN 데이터 저장소와 VVOL을 함께 사용하면 VM 수준 정밀도와 같은 NFS의 몇 가지 이점이 있습니다. 다음은 고려해야 할 몇 가지 모범 사례이며 에서 추가 정보를 찾을 수 있습니다<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">VVOL 데이터 저장소는 여러 클러스터 노드의 여러 FlexVol 볼륨으로 구성될 수 있습니다. 가장 간단한 방법은 볼륨에 기능이 다른 경우에도 단일 데이터 저장소를 사용하는 것입니다. SPBM은 호환 볼륨이 VM에 사용되는지 확인합니다. 하지만 모든 볼륨은 단일 ONTAP SVM에 속하고 단일 프로토콜을 사용하여 액세스해야 합니다. 각 프로토콜당 하나의 LIF로 충분합니다. 스토리지 기능이 릴리즈별로 다를 수 있으므로 단일 VVOL 데이터 저장소 내에서 여러 ONTAP 릴리즈를 사용하는 것은 피하십시오.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 VVOL 데이터 저장소를 만들고 관리합니다. 데이터 저장소와 해당 프로필을 관리하는 것 외에도 필요한 경우 데이터 저장소에 액세스하기 위한 프로토콜 엔드포인트가 자동으로 생성됩니다. LUN을 사용하는 경우 LUN PES는 LUN ID 300 이상을 사용하여 매핑됩니다. ESXi 호스트 고급 시스템 설정을 확인합니다<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> 300보다 높은 LUN ID 번호를 허용합니다(기본값: 1,024). 이 단계를 수행하려면 vCenter에서 ESXi 호스트를 선택한 다음 구성 탭을 선택하고 을 찾습니다<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> 고급 시스템 설정 목록에서 선택합니다.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">VMware vSphere를 위한 VASA Provider, vCenter Server(어플라이언스 또는 Windows 기반) 또는 ONTAP 툴을 VVOL 데이터 저장소에 설치하거나 마이그레이션하지 마십시오. 상호 의존하기 때문에 정전이 발생하거나 기타 데이터 센터가 중단될 경우 이를 관리할 수 없습니다.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">VASA Provider VM을 정기적으로 백업합니다. VASA Provider가 포함된 기존 데이터 저장소의 시간별 스냅샷을 적어도 생성합니다. VASA Provider 보호 및 복구에 대한 자세한 내용은 다음을 참조하십시오<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">다음 그림은 VVol 구성 요소를 보여줍니다.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 솔루션을 구축하는 모범 사례를 설명합니다.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">VVol(Virtual Volumes) 및 SPBM(Storage Policy Based Management)</block>
  <block id="a42f13867ea459821488608dc4d1b7c4" category="paragraph">NetApp은 VVOL(vSphere Virtual Volumes)을 개발하여 초기 설계 파트너로 VMware와 협력하여 VVOL과 VMware VASA(vSphere API for Storage Awareness)를 조기에 지원하고 아키텍처 입력을 제공했습니다. 이 접근 방식은 VM 세부 스토리지 관리를 VMFS에 제공할 뿐만 아니라 SPBM(Storage Policy Based Management)을 통한 스토리지 프로비저닝 자동화를 지원합니다.</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM은 가상화 환경에서 사용 가능한 스토리지 서비스와 정책을 통해 프로비저닝된 스토리지 요소 간의 추상화 계층 역할을 하는 프레임워크를 제공합니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. 그런 다음 관리자는 프로비저닝된 스토리지 풀에 대해 가상 머신 워크로드 요구 사항을 일치시킬 수 있으므로 VM별 또는 가상 디스크 레벨의 다양한 설정을 세부적으로 제어할 수 있습니다.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP은 스토리지 업계에서 VVOL을 선도하여 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 VM 세부 관리의 발전을 이끌고 있습니다.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">VMware vSphere 가상 볼륨, SPBM 및 ONTAP에 대한 자세한 내용은 을 참조하십시오<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">스냅샷을 사용하여 성능에 영향을 주지 않고 VM 또는 데이터 저장소를 신속하게 복사한 다음, SnapMirror를 사용하여 보조 시스템으로 전송하여 장기적인 오프 사이트 데이터 보호를 실현합니다. 이러한 접근 방식은 변경된 정보만 저장하여 스토리지 공간과 네트워크 대역폭을 최소화합니다.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">권장</block>
  <block id="022e604112aa3d1870f0da5e7806f48b" category="paragraph">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. 또한 VM 정합성 보장 스냅샷의 선택 옵션을 계속 허용하므로 VMware 스냅샷을 생성하기 전에 하이퍼바이저의 입출력 중지 기능을 활용할 수 있습니다. 그러나 VMware 스냅샷의 성능 때문에 게스트 파일 시스템을 중지해야 하는 경우가 아니면 일반적으로 이러한 스냅샷을 사용하지 않는 것이 좋습니다. 대신 일반적인 보호를 위해 스냅샷을 사용하고 SnapCenter 플러그인과 같은 애플리케이션 툴을 사용하여 SQL Server 또는 Oracle과 같은 트랜잭션 데이터를 보호하십시오. 이러한 스냅샷은 VMware(정합성 보장) 스냅샷과는 다르며 장기간 보호에 적합합니다.  VMware 스냅샷은 전용입니다<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> 성능 및 기타 효과로 인한 단기 사용.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">이러한 플러그인은 물리적 환경과 가상 환경 모두에서 데이터베이스를 보호하는 확장된 기능을 제공합니다. vSphere를 사용하면 RDM LUN에 데이터가 저장되어 있는 SQL Server 또는 Oracle 데이터베이스, 게스트 OS에 직접 연결된 iSCSI LUN 또는 VMFS 또는 NFS 데이터 저장소의 VMDK 파일을 보호할 수 있습니다. 플러그인을 사용하면 다양한 유형의 데이터베이스 백업을 지정할 수 있고, 온라인 또는 오프라인 백업을 지원하고, 로그 파일과 함께 데이터베이스 파일을 보호할 수 있습니다. 플러그인은 백업 및 복구 외에도 개발 또는 테스트 용도로 데이터베이스 클론 복제도 지원합니다.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">다음 그림은 SnapCenter 구축의 예를 보여 줍니다.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">향상된 재해 복구 기능을 위해 ONTAP용 NetApp SRA를 VMware Site Recovery Manager와 함께 사용하는 것이 좋습니다. 데이터 저장소를 DR 사이트로 복제할 수 있을 뿐만 아니라, 복제된 데이터 저장소를 클론 복제하여 DR 환경에서 무중단 테스트를 수행할 수도 있습니다. SRA에 내장된 자동화를 통해 운영 중단이 해결된 후 재해 복구 및 운영 재보호 작업도 쉽게 수행할 수 있습니다.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">마지막으로, 최고 수준의 데이터 보호를 위해 NetApp MetroCluster를 사용하는 VMware vMSC(vSphere Metro Storage Cluster) 구성을 고려해 보십시오. vMSC는 동기식 복제와 스토리지 기반 클러스터링이 결합된 VMware 인증 솔루션으로, 고가용성 클러스터의 이점을 동일하게 제공하고 별도의 사이트에 분산하여 사이트 재해로부터 보호합니다. NetApp MetroCluster은 단일 스토리지 구성 요소 장애로부터 투명하게 복구하고 사이트 재해 발생 시 단일 명령 복구를 통해 동기식 복제를 위한 비용 효율적인 구성을 제공합니다. vMSC는 에 자세히 설명되어 있습니다<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">NetApp ONTAP 소프트웨어는 약 20년 동안 VMware vSphere 환경을 위한 최고의 스토리지 솔루션으로, 혁신적인 기능을 지속적으로 추가하여 관리를 단순화하는 동시에 비용을 절감했습니다. 이 문서에서는 구축을 간소화하고 위험을 줄이며 관리를 단순화하는 최신 제품 정보 및 모범 사례를 비롯하여 vSphere용 ONTAP 솔루션에 대해 소개합니다.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">유니파이드 스토리지</block>
  <block id="8b02311a9d2f587eb4c447455c3df68f" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다.</block>
  <block id="7242358e2514a48e7044717140cacb4b" category="paragraph">이 접근 방식은 원래 하나의 스토리지 시스템에서 NAS 및 SAN 프로토콜을 모두 지원한다는 것을 언급했으며, ONTAP는 NAS에서 그 원래 강점과 함께 SAN을 위한 최고의 플랫폼이 되었습니다.</block>
  <block id="4947dc197f31edea82b3fdab9dc68fdc" category="paragraph">SVM(스토리지 가상 머신)은 클라이언트가 ONTAP 소프트웨어를 실행하는 시스템에 액세스할 수 있도록 지원하는 논리적 구성입니다. SVM은 논리 인터페이스(LIF)를 통해 여러 데이터 액세스 프로토콜을 통해 데이터를 동시에 제공할 수 있습니다. SVM은 CIFS 및 NFS와 같은 NAS 프로토콜을 통해 파일 레벨 데이터 액세스를 지원하고, iSCSI, FC/FCoE, NVMe와 같은 SAN 프로토콜을 통해 블록 레벨 데이터 액세스를 제공합니다. SVM은 SAN 및 NAS 클라이언트에 데이터를 동시에 독립적으로 제공할 수 있습니다.</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c46d272642e0999c025f67e9de315c9" category="paragraph">vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브를 위한 SATA 어레이, 클라우드를 위한 별도의 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">스토리지 가상화</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">SVM, 유니파이드 스토리지 및 클라이언트 액세스에 대한 자세한 내용은 를 참조하십시오<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">VMware 스토리지 분산 리소스 스케줄러입니다</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware SDRS(Storage Distributed Resource Scheduler)는 현재 입출력 지연 시간 및 공간 사용량을 기반으로 스토리지에 VM을 배치하는 vSphere 기능입니다.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">그런 다음 데이터 저장소 클러스터(Pod라고도 함)의 데이터 저장소 간에 VM 또는 VMDK를 중단 없이 이동하여 VM 또는 VMDK를 데이터 저장소 클러스터에 배치할 최상의 데이터 저장소를 선택합니다. 데이터 저장소 클러스터는 vSphere 관리자의 관점에서 단일 사용 단위로 집계되는 유사한 데이터 저장소의 모음입니다.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">SDRS를 VMware vSphere용 NetApp ONTAP 툴과 함께 사용하는 경우 먼저 플러그인을 사용하여 데이터 저장소를 생성한 다음 vCenter를 사용하여 데이터 저장소 클러스터를 생성한 다음 여기에 데이터 저장소를 추가해야 합니다. 데이터 저장소 클러스터가 생성된 후 세부 정보 페이지의 프로비저닝 마법사에서 추가 데이터 저장소를 데이터 저장소 클러스터에 직접 추가할 수 있습니다.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">SDRS에 대한 기타 ONTAP 모범 사례는 다음과 같습니다.</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">클러스터의 모든 데이터 저장소는 동일한 유형의 스토리지(예: SAS, SATA 또는 SSD)를 사용하고 모든 VMFS 또는 NFS 데이터 저장소이며 복제 및 보호 설정이 동일해야 합니다.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">기본(수동) 모드에서 SDRS 사용을 고려하십시오. 이 접근 방식을 통해 권장 사항을 검토하고 적용 여부를 결정할 수 있습니다. VMDK 마이그레이션의 영향을 숙지하십시오.</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">SDRS에서 VMDK를 데이터 저장소 간에 이동할 경우 ONTAP 클론 생성 또는 중복 제거를 통한 공간 절약이 손실됩니다. 중복제거를 재실행하여 이러한 절약 효과를 다시 실현할 수 있습니다.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">SDRS가 VMDK를 이동한 후 NetApp는 소스 데이터 저장소에서 스냅샷을 다시 생성하는 것이 좋습니다. 그렇지 않으면 공간이 이동된 VM에 의해 잠기기 때문입니다.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">동일한 애그리게이트에서 데이터 저장소 간에 VMDK를 이동하는 것은 효과가 거의 없으며 SDRS는 애그리게이트를 공유할 수 있는 다른 워크로드를 파악할 수 없습니다.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">ONTAP 기반의 VMware vSphere</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4597: VMware vSphere for ONTAP _ 을(를) 대체합니다</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">모범 사례는 가이드 및 호환성 목록 등의 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 모든 환경에서 작동하는 유일한 지원 방법은 아니지만 일반적으로 대부분의 고객 요구를 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">VMware 호환성 가이드 를 참조하십시오</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">이 문서는 vSphere 7.0 이상에서 실행되는 최신 릴리즈의 ONTAP(9.x)에 포함된 기능을 중점적으로 다룹니다. 를 참조하십시오<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> 및<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> 특정 릴리스와 관련된 자세한 내용은 를 참조하십시오.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">ONTAP for vSphere를 선택해야 하는 이유</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">수많은 고객들이 vSphere용 스토리지 솔루션으로 ONTAP을 선택한 이유가 있습니다. 예를 들어 SAN 및 NAS 프로토콜을 모두 지원하는 유니파이드 스토리지 시스템, 공간 효율적인 스냅샷을 사용하는 강력한 데이터 보호 기능, 애플리케이션 데이터를 관리하는 데 도움이 되는 다양한 툴이 있습니다. 하이퍼바이저와 별도로 스토리지 시스템을 사용하면 다양한 기능을 오프로드하고 vSphere 호스트 시스템에 대한 투자를 극대화할 수 있습니다. 이렇게 하면 호스트 리소스가 애플리케이션 워크로드에 집중되도록 할 뿐 아니라 스토리지 작업에서 애플리케이션에 미치는 랜덤 성능 영향을 방지할 수 있습니다.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">ONTAP와 vSphere를 함께 사용하면 호스트 하드웨어 및 VMware 소프트웨어 비용을 절감할 수 있습니다. 또한 일관된 고성능을 통해 저렴한 비용으로 데이터를 보호할 수 있습니다. 가상화된 워크로드는 이동적이기 때문에 Storage vMotion을 사용하여 동일한 스토리지 시스템에서 VMFS, NFS 또는 VVol 데이터 저장소 간에 VM을 이동하는 다양한 접근 방식을 탐색할 수 있습니다.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">고객이 오늘날 가치를 제공하는 주요 요소는 다음과 같습니다.</block>
  <block id="442c1f0ac31c3d71b638125e0a8b51da" category="list-text">* 유니파이드 스토리지. * ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다. 이 접근 방식은 원래 NAS 및 SAN 프로토콜을 모두 갖추고 있으며, ONTAP는 NAS에서 그 원래 강점이 되었던 SAN을 위한 선도적인 플랫폼이 되었습니다. vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브를 위한 SATA 어레이, 클라우드를 위한 별도의 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">* 가상 볼륨 및 스토리지 정책 기반 관리. * NetApp는 VVol(vSphere Virtual Volumes)을 개발하는 데 있어 VMware와 함께 초기 설계 파트너로, VVol 및 VASA(VMware vSphere API for Storage Awareness)에 대한 아키텍처 입력 및 조기 지원을 제공했습니다. 이 접근 방식은 VMFS에 세분화된 VM 스토리지 관리를 제공할 뿐만 아니라 스토리지 정책 기반 관리를 통해 스토리지 용량 할당 자동화도 지원했습니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. ONTAP은 VVOL 스케일의 스토리지 산업을 선도하며 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 세부적인 VM 관리 기능의 혁신을 이끌고 있습니다.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">* 스토리지 효율성. * NetApp는 프로덕션 워크로드를 위한 데이터 중복 제거 기능을 최초로 제공했지만 이 분야의 첫 번째 또는 마지막 혁신은 아니었습니다. 성능에 영향을 미치지 않는 공간 효율적인 데이터 보호 메커니즘인 스냅샷과 FlexClone ® 기술을 사용하여 운영 및 백업용으로 VM의 읽기/쓰기 복사본을 즉시 생성했습니다. NetApp은 계속해서 중복제거, 압축, 제로 블록 중복제거 등과 같은 인라인 기능을 제공하여 고가의 SSD에서 최대한의 스토리지를 짜내었습니다. 가장 최근에 ONTAP은 컴팩션을 사용하여 소규모 I/O 작업 및 파일을 디스크 블록에 포장한 기능을 추가했습니다. 이러한 기능을 결합하여 고객은 VSI의 경우 최대 5:1, VDI의 경우 최대 30:1의 비용을 절감할 수 있었습니다.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">* 하이브리드 클라우드. * 사내 프라이빗 클라우드, 퍼블릭 클라우드 인프라 또는 둘 모두의 장점인 하이브리드 클라우드에 사용하건 간에, ONTAP 솔루션을 사용하면 데이터 패브릭을 구축하여 데이터 관리를 간소화하고 최적화할 수 있습니다. 고성능 All-Flash 시스템으로 시작한 다음 디스크 또는 클라우드 스토리지 시스템과 커플하여 데이터 보호 및 클라우드 컴퓨팅을 지원합니다. Azure, AWS, IBM 또는 Google 클라우드 중에서 선택하여 비용을 최적화하고 종속 문제를 방지합니다. OpenStack 및 컨테이너 기술에 대한 고급 지원을 필요에 따라 활용합니다. 또한 NetApp은 ONTAP용 클라우드 기반 백업(SnapMirror 클라우드, Cloud Backup Service 및 Cloud Sync), 스토리지 계층화 및 아카이빙 툴(FabricPool)을 제공하여 운영 비용을 줄이고 광범위한 클라우드 활용을 지원합니다.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">* 그 이상. * NetApp AFF A-Series 어레이의 탁월한 성능을 활용하여 가상화 인프라를 가속하고 비용을 관리하십시오. 스케일아웃 ONTAP 클러스터를 사용하면 유지보수, 업그레이드, 스토리지 시스템 전체 교체 등 운영 중단 없이 완벽하게 수행할 수 있습니다. 추가 비용 없이 NetApp 암호화 기능으로 유휴 데이터를 보호합니다. 세분화된 서비스 품질 기능을 통해 성능이 비즈니스 서비스 수준을 충족하는지 확인합니다. 모두 업계 최고의 엔터프라이즈 데이터 관리 소프트웨어인 ONTAP에 포함된 광범위한 기능에 속합니다.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">권장되는 ESXi 호스트 및 기타 ONTAP 설정</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp은 NetApp 테스트를 기반으로 ONTAP에서 올바르게 동작하도록 ESXi 호스트 다중 경로와 HBA 시간 초과 설정 세트를 개발했습니다. 이러한 설정은 VMware vSphere용 ONTAP 툴을 사용하여 쉽게 설정할 수 있습니다. 요약 대시보드의 호스트 시스템 윈도우에서 설정 편집 을 클릭하거나 vCenter에서 호스트를 마우스 오른쪽 버튼으로 클릭한 다음 ONTAP 도구 &gt; 권장 값 설정 으로 이동합니다. 다음은 9.8 릴리즈의 현재 권장되는 호스트 설정입니다.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">* 호스트 설정 *</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">* NetApp 권장 가치 *</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">* 재부팅 필요 *</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">* ESXi 고급 구성 *</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3. HardwareAcceleratedLocking</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">기본값 유지(1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">아니요</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete 를 참조하십시오</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="3aca64366573d9850e0148ce2a38164c" category="cell">기본값(0)을 유지하지만 필요한 경우 변경할 수 있습니다.
자세한 내용은 을 참조하십시오 <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6매핑 해제</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">VMware vSphere API: 어레이 통합(VAAI)</block>
  <block id="e385d2442208cc1e23ca841b1f217380" category="cell">기본값 유지(1)
자세한 내용은 을 참조하십시오 <block ref="d124e203790e5f214a195f69cd068c6d" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">* NFS 설정 *</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">vSphere 6.0 이상, 32로 설정.
다른 모든 NFS 구성은 30으로 설정합니다</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">예</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">net.TcpipHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">대부분의 vSphere 6.X 릴리즈에서는 512MB로 설정합니다.
6.5U3, 6.7U3 및 7.0 이상의 경우 1024MB로 설정합니다.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">vSphere 6.0 이상, 256으로 설정
다른 모든 NFS 구성은 64로 설정됩니다.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.최대 볼륨</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">vSphere 6.0 이상, 256으로 설정</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">vSphere 6.0 이상으로, 128로 설정합니다</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures 를 참조하십시오</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">모든 NFS 구성에 대해 10으로 설정합니다</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency 를 선택합니다</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">모든 NFS 구성에 대해 12로 설정합니다</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">모든 NFS 구성에 대해 5로 설정합니다.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP입니다</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">vSphere 7.0 이상, 128로 설정</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">* FC/FCoE 설정 *</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">경로 선택 정책</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">ALUA를 사용하는 FC 경로를 사용할 때 RR(라운드 로빈)으로 설정합니다. 다른 모든 설정에 대해 고정으로 설정합니다.
이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다.
고정 값은 이전 비 ALUA 구성에 대한 값이며 프록시 I/O를 방지하는 데 도움이 됩니다 다시 말해, 7-Mode에서 Data ONTAP를 실행하는 환경에서 I/O가 고가용성(HA) 쌍의 다른 노드로 이동하는 것을 돕니다</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize 를 참조하십시오</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">모든 설정에 대해 32로 설정합니다.
이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold를 참조하십시오</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">모든 설정에 대해 8로 설정합니다.
이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC HBA 시간 초과</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">기본값을 사용합니다.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC HBA 시간 초과</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">iSCSI 설정 *</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">모든 iSCSI 경로에 대해 RR(라운드 로빈)으로 설정합니다.
이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">모든 설정에 대해 32로 설정합니다.
이 값을 설정하면 I/O 오류가 방지됩니다</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1-NFS 고급 구성 옵션 MaxQueueDepth는 VMware vSphere ESXi 7.0.1 및 VMware vSphere ESXi 7.0.2를 사용할 때 의도한 대로 작동하지 않을 수 있습니다. 참조하십시오 <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP 툴은 ONTAP FlexVol 볼륨 및 LUN을 생성할 때 특정 기본 설정도 지정합니다.</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">* ONTAP 도구 *</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">* 기본 설정 *</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">스냅숏 예비 공간(-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">분할 예약(-fractional-reserve)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">액세스 시간 업데이트(-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">거짓</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">최소 미리 읽기(-min-readahead)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">예약된 스냅샷</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">스토리지 효율성</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">활성화됨</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">볼륨 보장</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">없음(씬 프로비저닝됨)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">볼륨 자동 크기 조정</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN 공간 예약</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">사용 안 함</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">LUN 공간 할당</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">성능을 위한 다중 경로 설정</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">현재 사용 가능한 ONTAP 툴에 의해 구성되지 않은 상태에서 NetApp에서는 다음과 같은 구성 옵션을 제안합니다.</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356)을 참조하십시오</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">고성능 환경에서 또는 단일 LUN 데이터 저장소에서 성능을 테스트할 때는 라운드 로빈(VMW_PSP_RR) 경로 선택 정책(PSP)의 로드 밸런싱 설정을 기본 IOPS 설정인 1000에서 값 1로 변경하는 것이 좋습니다. VMware KB를 참조하십시오<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">경로 선택 플러그인 및 정책</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">vSphere 6.7 업데이트 1에서 VMware는 라운드 로빈 PSP에 새로운 지연 시간 로드 밸런싱 메커니즘을 도입했습니다. 새로운 옵션은 I/O에 가장 적합한 경로를 선택할 때 I/O 대역폭과 경로 지연 시간을 고려합니다 한 경로에 다른 경로보다 더 많은 네트워크 홉이 있거나 NetApp All SAN 어레이 시스템을 사용하는 경우와 같이 비등가 경로 연결이 있는 환경에서 이 홉을 사용하면 도움이 될 수 있습니다. 을 참조하십시오<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">추가 문서</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">ONTAP와 함께 VMware vSphere 7.x를 사용합니다</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">ONTAP와 함께 VMware vSphere 8.x를 사용합니다</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">NVMe-oF의 경우 자세한 내용은 ONTAP를 사용하는 ESXi 7.x용 NVMe-oF 호스트 구성 을 참조하십시오</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">NVMe-oF의 경우 자세한 내용은 ONTAP를 사용하는 ESXi 8.x용 NVMe-oF 호스트 구성 을 참조하십시오</block>
  <block id="842acd8b4932f6c9329df8e0fefe8b9b" category="paragraph">vSphere 7을 사용하는 FCP 및 iSCSI의 경우 자세한 내용은 을 참조하십시오<block ref="f3eae508de4d3c1748a9c65337197b21" category="inline-link-rx"></block>
vSphere 8을 사용하는 FCP 및 iSCSI의 경우 자세한 내용은 을 참조하십시오<block ref="3f8db75ee0177b85df9cdf31ddb51abe" category="inline-link-rx"></block>
vSphere 7을 사용하는 NVMe-oF의 경우 자세한 내용은 을 참조하십시오<block ref="6c040a6e611e78bb9d0ad92946e613ea" category="inline-link-rx"></block>
vSphere 8을 사용하는 NVMe-oF의 경우 자세한 내용은 을 참조하십시오<block ref="030788e4c7bbe3137759b534ea62d7d9" category="inline-link-rx"></block></block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">VM 및 데이터 저장소 클론 생성</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">vSphere에서 VM, 가상 디스크, VVOL 또는 데이터 저장소를 복제할 수 있습니다. 복제된 개체는 대개 자동화된 프로세스를 통해 추가로 사용자 지정할 수 있습니다. vSphere는 전체 복제본 클론과 연결된 클론을 모두 지원하며, 이 클론에서는 원래 객체와 별도로 변경 사항을 추적합니다.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">연결된 클론은 공간을 절약하는 데 좋지만 vSphere에서 VM에 대해 처리하는 I/O 양을 늘려 해당 VM 및 호스트의 성능에 영향을 줄 수 있습니다. 따라서 NetApp 고객은 스토리지 시스템 기반 복제본을 사용하여 두 가지 이점을 모두 최대한 활용할 수 있습니다. 즉, 효율적인 스토리지 사용과 향상된 성능을 모두 활용할 수 있습니다.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">다음 그림은 ONTAP 클론을 보여 줍니다.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">클론 복제는 일반적으로 VM, VVOL 또는 데이터 저장소 레벨의 다양한 메커니즘을 통해 ONTAP 소프트웨어를 실행하는 시스템으로 오프로드될 수 있습니다. 여기에는 다음이 포함됩니다.</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">NetApp VASA(vSphere APIs for Storage Awareness) 공급자를 사용하여 VVOL을 이동합니다.  ONTAP 클론은 vCenter에서 관리하는 VVol 스냅샷을 지원하는 데 사용되며 이 스냅샷은 I/O 효과가 최소화되어 생성 및 삭제가 가능합니다.  vCenter를 사용하여 VM을 복제할 수도 있으며, 단일 데이터 저장소/볼륨 내에서 또는 데이터 저장소/볼륨 간에 ONTAP로 오프로드됩니다.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">VAAI(vSphere API – Array Integration)를 사용한 vSphere 클론 생성 및 마이그레이션 SAN 및 NAS 환경 모두에서 VM 클론 복제 작업을 ONTAP로 오프로드할 수 있습니다(NetApp은 NFS용 VAAI를 지원하기 위해 ESXi 플러그인을 제공합니다).  vSphere는 NAS 데이터 저장소의 콜드(전원이 꺼진) VM에 대한 작업만 오프로드하는 반면, 핫 VM(클론 생성 및 Storage vMotion)에 대한 작업도 SAN에 오프로드됩니다. ONTAP는 소스, 대상 및 설치된 제품 라이센스를 기반으로 가장 효율적인 방식을 사용합니다. 이 기능은 VMware Horizon View에서 사용할 수도 있습니다.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA(VMware Site Recovery Manager와 함께 사용) 이 경우 클론은 DR 복제본의 복구를 중단 없이 테스트하는 데 사용됩니다.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">SnapCenter와 같은 NetApp 툴을 사용한 백업 및 복구 VM 클론은 백업 작업을 확인하는 데 사용되며 개별 파일을 복제할 수 있도록 VM 백업을 마운트하는 데 사용됩니다.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">ONTAP 오프로드 클론 복제는 VMware, NetApp 및 타사 툴에서 호출할 수 있습니다. ONTAP로 오프로드되는 클론에는 여러 가지 이점이 있습니다. 대부분의 경우 오브젝트 변경에만 스토리지가 필요한 공간 효율적이며, 데이터를 읽고 쓰는 데는 추가 성능 영향이 없으며, 고속 캐시에서 블록을 공유하여 성능을 향상할 수도 있습니다. 또한 CPU 사이클과 네트워크 I/O를 ESXi 서버에서 오프로드합니다. FlexClone 라이센스가 있는 경우 FlexVol 볼륨을 사용하는 기존 데이터 저장소 내에서 복사 오프로드를 빠르고 효율적으로 수행할 수 있지만, FlexVol 볼륨 간의 복사 속도가 느려질 수 있습니다. VM 템플릿을 클론의 소스로 유지 관리하는 경우 빠르고 공간 효율적인 클론을 위해 데이터 저장소 볼륨(폴더 또는 콘텐츠 라이브러리를 사용하여 구성) 내에 배치하는 것이 좋습니다.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">ONTAP 내에서 직접 볼륨 또는 LUN을 복제하여 데이터 저장소를 복제할 수도 있습니다. NFS 데이터 저장소를 사용하면 FlexClone 기술을 통해 전체 볼륨을 클론 복제할 수 있으며, ONTAP에서 클론을 내보내고 ESXi에서 다른 데이터 저장소로 마운트할 수 있습니다. VMFS 데이터 저장소의 경우 ONTAP는 LUN 내에 하나 이상의 LUN을 포함하여 볼륨 또는 전체 볼륨 내에서 LUN을 클론 복제할 수 있습니다. VMFS를 포함하는 LUN은 ESXi 이니시에이터 그룹(igroup)에 매핑한 다음 ESXi에 의해 재서명하여 일반 데이터 저장소로 마운트하고 사용해야 합니다. 일부 임시 사용 사례에서는 재서명 없이 클론 생성된 VMFS를 마운트할 수 있습니다. 데이터 저장소의 클론을 생성한 후에는 해당 데이터 저장소 내의 VM을 개별적으로 클론 복제된 VM처럼 등록, 재구성 및 사용자 지정할 수 있습니다.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">경우에 따라 라이센스가 부여된 추가 기능을 사용하여 백업용 SnapRestore 또는 FlexClone과 같은 복제를 향상시킬 수 있습니다. 이러한 라이센스는 라이센스 번들에 추가 비용 없이 포함되는 경우가 많습니다. VVOL 클론 복제 작업에는 FlexClone 라이센스가 필요하며, 하이퍼바이저에서 ONTAP로 오프로드되는 VVOL의 관리형 스냅샷을 지원하기 위해서는 FlexClone 라이센스가 필요합니다. FlexClone 라이센스는 데이터 저장소/볼륨 내에서 사용할 때 특정 VAAI 기반 클론을 개선할 수도 있습니다. 블록 복사본 대신 즉각적이고 공간 효율적인 복사본을 생성합니다.  또한 SRA에서는 DR 복제본의 복구를 테스트할 때, 클론 작업을 위한 SnapCenter 및 개별 파일을 복원할 백업 복사본을 찾아볼 때 사용됩니다.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">네트워크 구성</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">다음은 고려해야 할 몇 가지 사항입니다.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">원하는 경우 점보 프레임을 사용할 수 있으며 네트워크에서 지원됩니다(특히 iSCSI 사용 시). 사용하는 경우 스토리지와 ESXi 호스트 간 경로에서 모든 네트워크 디바이스, VLAN 등에 동일하게 구성되었는지 확인합니다. 그렇지 않으면 성능 또는 연결 문제가 나타날 수 있습니다. MTU는 ESXi 가상 스위치, VMkernel 포트 및 각 ONTAP 노드의 물리적 포트 또는 인터페이스 그룹에서도 동일하게 설정되어야 합니다.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182 를 참조하십시오</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">ONTAP 클러스터 내의 클러스터 네트워크 포트에서 네트워크 흐름 제어를 사용하지 않도록 설정하는 것만 좋습니다. NetApp은 데이터 트래픽에 사용되는 나머지 네트워크 포트에 대한 모범 사례를 위해 다른 권장사항을 제공하지 않습니다. 필요에 따라 활성화하거나 비활성화해야 합니다. 을 참조하십시오<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> 흐름 제어에 대한 자세한 배경 정보</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">ESXi 및 ONTAP 스토리지 어레이가 이더넷 스토리지 네트워크에 연결되어 있는 경우, 이러한 시스템이 RSTP(Rapid Spanning Tree Protocol) 에지 포트로 연결되거나 Cisco PortFast 기능을 사용하여 연결되는 이더넷 포트를 구성하는 것이 좋습니다. Cisco PortFast 기능을 사용하고 ESXi 서버 또는 ONTAP 스토리지 어레이에 802.1Q VLAN 트렁킹을 사용하는 환경에서는 스패닝 트리 포트패스트 트렁크 기능을 활성화하는 것이 좋습니다.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">Link Aggregation에 대해 다음 모범 사례를 따르는 것이 좋습니다.</block>
  <block id="301c77ecc6cdfa6ebde6c8164cffae0c" category="list-text">Cisco vPC(Virtual PortChannel)와 같은 멀티섀시 링크 통합 그룹 접근 방식을 사용하여 두 개의 별도 스위치 섀시에 있는 포트의 링크 집계를 지원하는 스위치를 사용합니다.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">LACP가 구성된 dvSwitch 5.1 이상을 사용하지 않는 한 ESXi에 연결된 스위치 포트에 대해 LACP를 사용하지 않도록 설정합니다.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">LACP를 사용하여 IP 해시를 사용하는 동적 멀티모드 인터페이스 그룹을 통해 ONTAP 스토리지 시스템에 대한 링크 애그리게이트를 생성합니다.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">ESXi에서 IP 해시 팀 구성 정책을 사용합니다.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">다음 표에는 네트워크 구성 항목에 대한 요약과 설정이 적용되는 위치가 나와 있습니다.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">항목</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">스위치</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">노드</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP 주소입니다</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">아니요**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Link Aggregation</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">가상 스위치</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">아니요 *</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel 및 VM 포트 그룹</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">흐름 제어</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">스패닝 트리</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU(점보 프레임의 경우)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">가상 스위치 및 VMkernel 포트(9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">예(최대로 설정)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">예(9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">페일오버 그룹</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">예(생성)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">예(선택)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">* SVM LIF는 VLAN, MTU 및 기타 설정이 있는 포트, 인터페이스 그룹 또는 VLAN 인터페이스에 연결됩니다. 하지만 SVM 레벨에서 설정을 관리하지 않습니다.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">** 이러한 디바이스에는 자체 관리 IP 주소가 있지만 이러한 주소는 ESXi 스토리지 네트워킹의 맥락에서 사용되지 않습니다.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN(FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">vSphere에서는 블록 스토리지 LUN을 사용하는 세 가지 방법이 있습니다.</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">VMFS 데이터 저장소 사용</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">RDM(Raw Device Mapping) 사용</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">VM 게스트 OS에서 소프트웨어 이니시에이터에 의해 액세스 및 제어되는 LUN입니다</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS는 공유 스토리지 풀인 데이터 저장소를 제공하는 고성능 클러스터 파일 시스템입니다. VMFS 데이터 저장소는 FC, iSCSI, FCoE 또는 NVMe 네임스페이스를 사용하여 액세스할 수 있는 LUN으로 구성할 수 있으며 NVMe/FC 프로토콜을 통해 액세스할 수 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. ONTAP 최대 LUN 크기는 일반적으로 16TB입니다. 따라서 64TB의 최대 크기 VMFS 5 데이터 저장소(이 섹션의 첫 번째 표 참조)는 16TB LUN 4개를 사용하여 생성됩니다(모든 SAN 어레이 시스템은 64TB의 최대 VMFS LUN 크기를 지원합니다). ONTAP LUN 아키텍처에는 작은 개별 큐 깊이가 없기 때문에 ONTAP의 VMFS 데이터 저장소는 상대적으로 간단한 방식으로 기존 스토리지 아키텍처보다 더 큰 규모로 확장할 수 있습니다.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">vSphere에는 NMP(기본 경로 다중화)라고 하는 여러 스토리지 디바이스 경로에 대한 기본 지원이 포함되어 있습니다. NMP는 지원되는 스토리지 시스템의 스토리지 유형을 감지하고 NMP 스택을 자동으로 구성하여 사용 중인 스토리지 시스템의 기능을 지원합니다.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">NMP 및 NetApp ONTAP는 모두 ALUA(Asymmetric Logical Unit Access)를 지원하여 최적화된 경로와 최적화되지 않은 경로를 협상합니다. ONTAP에서 ALUA에 최적화된 경로는 액세스하는 LUN을 호스팅하는 노드의 타겟 포트를 사용하여 직접 데이터 경로를 따릅니다. vSphere와 ONTAP 모두에서 ALUA는 기본적으로 사용하도록 설정되어 있습니다. NMP는 ONTAP 클러스터를 ALUA로 인식하며 ALUA 스토리지 어레이 유형 플러그인을 사용합니다 <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) 및 라운드 로빈 경로 선택 플러그인을 선택합니다 <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>)를 클릭합니다.</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6은 최대 256개의 LUN과 최대 1,024개의 LUN 총 경로를 지원합니다. 이러한 제한을 초과하는 LUN 또는 경로는 ESXi에서 표시되지 않습니다. 최대 LUN 수를 가정할 때 경로 제한에서는 LUN당 경로 수를 4개까지 지정할 수 있습니다. 대규모 ONTAP 클러스터에서는 LUN 제한보다 먼저 경로 제한에 도달할 수 있습니다. 이 제한을 해결하기 위해 ONTAP은 릴리즈 8.3 이상에서 선택적 LUN 맵(SLM)을 지원합니다.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080 을 참조하십시오</block>
  <block id="e9e7de5d01d51034d9114fd8f16c9144" category="paragraph">SLM은 특정 LUN에 경로를 알리는 노드를 제한합니다. NetApp 모범 사례로서, SVM당 노드당 하나 이상의 LIF를 가지고 SLM을 사용하여 LUN 및 HA 파트너를 호스팅하는 노드에 공고되는 경로를 제한하는 것입니다. 다른 경로가 존재하지만 기본적으로 알려지지 않습니다. SLM 내에서 ADD 및 REMOVE 노드 인수로 보급된 경로를 수정할 수 있습니다. 8.3 이전 릴리즈에서 생성된 LUN은 모든 경로를 광고하고 호스팅 HA 쌍의 경로만 광고하도록 수정해야 합니다. SLM에 대한 자세한 내용은 의 섹션 5.9를 참조하십시오<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. 이전 portset 방법을 사용하여 LUN에 사용 가능한 경로를 더 줄일 수도 있습니다. Portsets는 igroup의 이니시에이터가 LUN을 볼 수 있는 가시적인 경로의 수를 줄여 줍니다.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM은 기본적으로 활성화되어 있습니다. 포트 세트를 사용하지 않는 경우 추가 구성이 필요하지 않습니다.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Data ONTAP 8.3 이전에 생성된 LUN의 경우 를 실행하여 SLM을 수동으로 적용합니다<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> LUN 보고 노드를 제거하고 LUN 소유 노드 및 해당 HA 파트너에 대한 LUN 액세스를 제한하는 명령입니다.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">블록 프로토콜(iSCSI, FC 및 FCoE)은 고유한 이름과 함께 LUN ID 및 일련 번호를 사용하여 LUN에 액세스합니다. FC 및 FCoE는 WWNs 및 WWPN(Worldwide Name)을 사용하며 iSCSI는 IQN(iSCSI Qualified Name)을 사용합니다. 스토리지 내 LUN의 경로는 블록 프로토콜에는 의미가 없으며 프로토콜의 어느 곳에도 표시되지 않습니다. 따라서 LUN만 포함된 볼륨은 내부적으로 마운트할 필요가 없으며, 데이터 저장소에 사용되는 LUN이 포함된 볼륨에는 접합 경로가 필요하지 않습니다. ONTAP의 NVMe 하위 시스템은 비슷하게 작동합니다.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">기타 모범 사례:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">가용성과 이동성을 극대화하기 위해 ONTAP 클러스터의 각 노드에서 논리 인터페이스(LIF)를 생성해야 합니다. ONTAP SAN 모범 사례는 노드당 물리적 포트 2개와 LIF를 각 패브릭에 대해 하나씩 사용하는 것입니다. ALUA는 경로를 구문 분석하고 활성 최적화(직접) 경로와 최적화되지 않은 활성 경로를 식별하는 데 사용됩니다. ALUA는 FC, FCoE 및 iSCSI에 사용됩니다.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">iSCSI 네트워크의 경우 여러 가상 스위치가 있을 때 NIC 티밍을 사용하여 서로 다른 네트워크 서브넷에 있는 여러 VMkernel 네트워크 인터페이스를 사용합니다. 또한 여러 물리적 스위치에 연결된 여러 물리적 NIC를 사용하여 HA를 제공하고 처리량을 늘릴 수 있습니다. 다음 그림은 다중 경로 연결의 예입니다. ONTAP에서 둘 이상의 스위치에 연결된 2개 이상의 링크를 사용하여 페일오버에 단일 모드 인터페이스 그룹을 구성하거나 LACP 또는 다중 모드 인터페이스 그룹과 함께 다른 Link-Aggregation 기술을 사용하여 HA와 링크 집계의 이점을 제공합니다.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">대상 인증을 위해 ESXi에서 CHAP(Challenge-Handshake Authentication Protocol)를 사용하는 경우 CLI를 사용하여 ONTAP에서도 구성해야 합니다 <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) 또는 System Manager를 사용할 경우(스토리지 &gt; SVM &gt; SVM 설정 &gt; 프로토콜 &gt; iSCSI에서 이니시에이터 보안 편집).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 LUN 및 igroup을 생성하고 관리합니다. 이 플러그인은 서버의 WWPN을 자동으로 확인하여 적절한 igroup을 생성합니다. 또한 모범 사례에 따라 LUN을 구성하고 올바른 igroup에 매핑합니다.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">물리적 및 가상 호환성 모드</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">RDM은 관리하기가 더 어려울 수 있고 앞에서 설명한 대로 제한된 경로를 사용할 수도 있으므로 주의해서 사용합니다. ONTAP LUN은 둘 다 지원합니다<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">ONTAP NVMe/FC 호스트 구성 가이드</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684를 참조하십시오</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">vSphere 7.0에서 NVMe/FC를 사용하는 방법에 대한 자세한 내용은 다음을 참조하십시오<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> 및<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>다음 그림에서는 vSphere 호스트에서 ONTAP LUN으로의 다중 경로 연결을 보여 줍니다.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">vSphere를 사용하면 엔터프라이즈급 NFS 스토리지를 사용하여 ESXi 클러스터의 모든 노드에 대한 데이터 저장소에 대한 동시 액세스를 제공할 수 있습니다. 데이터 저장소 섹션에서 언급한 것처럼, NFS를 vSphere와 함께 사용할 경우 사용 편의성과 스토리지 효율성 가시성의 이점이 있습니다.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">vSphere와 함께 ONTAP NFS를 사용할 때는 다음과 같은 Best Practice를 따르는 것이 좋습니다.</block>
  <block id="c05061b6d3055b83136fa96cb38f0f9a" category="list-text">ONTAP 클러스터의 각 노드에서 각 SVM에 대해 단일 논리 인터페이스(LIF)를 사용합니다. 데이터 저장소당 LIF의 과거 권장사항은 더 이상 필요하지 않습니다. 직접 액세스(LIF 및 동일한 노드의 데이터 저장소)가 가장 좋지만 성능 영향이 일반적으로 최소(마이크로초)이기 때문에 간접 액세스에 대해 걱정하지 마십시오.</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware는 VMware Infrastructure 3 이후 NFSv3을 지원했습니다. vSphere 6.0은 NFSv4.1에 대한 지원을 추가하여 Kerberos 보안과 같은 일부 고급 기능을 지원합니다. NFSv3에서는 클라이언트측 잠금을 사용하는 경우 NFSv4.1은 서버 측 잠금을 사용합니다. ONTAP 볼륨은 두 프로토콜을 통해 내보낼 수 있지만 ESXi는 하나의 프로토콜을 통해서만 마운트할 수 있습니다. 이 단일 프로토콜 마운트는 다른 ESXi 호스트가 다른 버전을 통해 동일한 데이터 저장소를 마운트하는 것을 배제하지 않습니다. 모든 호스트가 동일한 버전과 동일한 잠금 스타일을 사용하도록 마운트할 때 사용할 프로토콜 버전을 지정해야 합니다. 호스트 간에 NFS 버전을 혼합하지 마십시오. 가능한 경우 호스트 프로필을 사용하여 규정 준수 여부를 확인하십시오.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">NFSv3과 NFSv4.1 간에는 자동 데이터 저장소가 변환되지 않으므로 새로운 NFSv4.1 데이터 저장소를 생성하고 Storage vMotion을 사용하여 VM을 새 데이터 저장소로 마이그레이션합니다.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">의 NFS v4.1 상호 운용성 표 노트를 참조하십시오<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> 지원을 위해 필요한 특정 ESXi 패치 수준</block>
  <block id="24aaa4a688e881fa13d31656a85d40a9" category="list-text">NFS 내보내기 정책은 vSphere 호스트의 액세스를 제어하는 데 사용됩니다. 여러 볼륨(데이터 저장소)에 하나의 정책을 사용할 수 있습니다. NFSv3에서 ESXi는 sys(UNIX) 보안 스타일을 사용하며 VM을 실행하려면 루트 마운트 옵션이 필요합니다. ONTAP에서 이 옵션을 수퍼 유저라고 하며, 수퍼유저 옵션을 사용할 때 익명 사용자 ID를 지정할 필요가 없습니다. 에 대해 다른 값을 사용하여 정책 규칙을 내보냅니다<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> 및<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> ONTAP 툴을 사용하여 SVM 검색 문제를 일으킬 수 있습니다. 샘플 정책은 다음과 같습니다.</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">클라이언트 일치 사양: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">ro 액세스 규칙: sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">rw 액세스 규칙: sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">익명 UID</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">슈퍼유저: sys</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">NFS 데이터 저장소 볼륨은 SVM의 루트 볼륨에서 접합되므로 ESXi에서 루트 볼륨에 액세스하여 데이터 저장소 볼륨을 탐색하고 마운트해야 합니다. 루트 볼륨 및 데이터 저장소 볼륨의 교차점이 중첩된 다른 볼륨에 대한 내보내기 정책에는 읽기 전용 액세스를 부여하는 ESXi 서버에 대한 규칙 또는 규칙이 포함되어야 합니다. 다음은 VAAI 플러그인을 사용하는 루트 볼륨에 대한 샘플 정책입니다.</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">액세스 프로토콜: NFS(NFS3 및 nfs4 모두 포함)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW 액세스 규칙: 사용 안 함(루트 볼륨에 대한 최상의 보안)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">슈퍼유저:sys(VAAI를 사용하는 루트 볼륨에도 필요)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">VMware vSphere용 ONTAP 툴 사용(가장 중요한 모범 사례):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">VMware vSphere용 ONTAP 툴을 사용하면 엑스포트 정책의 관리를 자동으로 간소화할 수 있으므로 데이터 저장소를 프로비저닝할 수 있습니다.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">플러그인을 사용하여 VMware 클러스터용 데이터 저장소를 생성할 때 단일 ESX Server가 아닌 클러스터를 선택합니다. 이 옵션을 선택하면 데이터 저장소가 클러스터의 모든 호스트에 자동으로 마운트됩니다.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">플러그인 마운트 기능을 사용하여 기존 데이터 저장소를 새 서버에 적용합니다.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">VMware vSphere용 ONTAP 툴을 사용하지 않는 경우 모든 서버 또는 추가 액세스 제어가 필요한 각 서버 클러스터에 대해 단일 엑스포트 정책을 사용하십시오.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">ONTAP는 접합을 사용하여 트리에서 볼륨을 정렬하는 유연한 볼륨 네임스페이스 구조를 제공하지만, 이 접근 방식에는 vSphere의 가치가 없습니다. 스토리지의 네임스페이스 계층에 관계없이 데이터 저장소의 루트에 각 VM에 대한 디렉토리를 생성합니다. 따라서 가장 좋은 방법은 SVM의 루트 볼륨에서 vSphere의 볼륨에 대한 접합 경로를 마운트하는 것입니다. 이것이 바로 VMware vSphere용 ONTAP 툴이 데이터 저장소를 프로비저닝하는 방법입니다. 중첩된 연결 경로가 없다는 것은 루트 볼륨 이외의 볼륨에 종속되지 않으며 볼륨을 오프라인으로 전환하거나 의도적으로 파괴하더라도 다른 볼륨에 대한 경로에 영향을 주지 않는다는 것을 의미합니다.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">NFS 데이터 저장소의 NTFS 파티션에 4K 블록 크기가 적합합니다. 다음 그림에서는 vSphere 호스트에서 ONTAP NFS 데이터 저장소로의 접속을 보여 줍니다.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">다음 표에는 NFS 버전 및 지원되는 기능이 나와 있습니다.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">vSphere 기능</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">vMotion 및 Storage vMotion입니다</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">고가용성</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">내결함성</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">호스트 프로파일</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS를 참조하십시오</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">스토리지 I/O 제어</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">가상 볼륨</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">하드웨어 가속(VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos 인증</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">예(AES, krb5i를 지원하도록 vSphere 6.5 이상에서 향상)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">다중 경로 지원</block>
  <block id="8a18e0a50dc5755c294477cb16507a6c" category="doc">FlexGroups의 약자입니다</block>
  <block id="f9ac230f370c7937167d25093c4ce9b9" category="paragraph">FlexGroup은 대규모 데이터 저장소의 생성을 간소화하고 여러 구성 볼륨을 자동으로 생성하여 ONTAP 시스템의 성능을 극대화합니다. 전체 ONTAP 클러스터의 강력한 기능을 갖춘 확장 가능한 단일 vSphere 데이터 저장소에 FlexGroup with vSphere를 사용하십시오.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">ONTAP 9.8은 vSphere 워크로드를 사용한 광범위한 시스템 테스트 외에도 FlexGroup 데이터 저장소를 위한 새로운 복제 오프로드 메커니즘도 추가합니다. 이렇게 하면 향상된 복제 엔진을 사용하여 소스 및 대상 모두에서 액세스할 수 있도록 하면서 백그라운드에서 구성 요소간에 파일을 복사할 수 있습니다. 여러 복사본은 필요할 때 규모에 따라 구성 요소 내에서 즉시 사용 가능한 공간 효율적인 파일 클론을 사용합니다.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">또한 ONTAP 9.8은 FlexGroup 파일에 대한 새로운 파일 기반 성능 메트릭(IOPS, 처리량, 지연 시간)을 추가하며, 이러한 메트릭은 VMware vSphere 대시보드 및 VM 보고서용 ONTAP 툴에서 확인할 수 있습니다. VMware vSphere 플러그인용 ONTAP 툴을 사용하면 최대 및/또는 최소 IOPS의 조합을 사용하여 서비스 품질(QoS) 규칙을 설정할 수도 있습니다. 데이터 저장소의 모든 VM에 대해 또는 특정 VM에 대해 개별적으로 설정할 수 있습니다.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">다음은 NetApp에서 개발한 몇 가지 추가 모범 사례입니다.</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">FlexGroup 프로비저닝 기본값을 사용합니다. VMware vSphere용 ONTAP 툴은 vSphere 내에서 FlexGroup를 생성 및 마운트하기 때문에 권장되지만, ONTAP System Manager 또는 명령줄은 특수한 요구 사항에 사용될 수 있습니다. 또한 vSphere에서 테스트한 구성 요소이므로 노드당 구성 멤버 수와 같은 기본값을 사용합니다.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">FlexGroup 데이터 저장소를 사이징할 때 FlexGroup는 더 큰 네임스페이스를 생성하는 여러 개의 작은 FlexVol 볼륨으로 구성되어 있습니다. 따라서 가장 큰 가상 머신의 크기를 최소 8배 이상 사이징해야 합니다. 예를 들어 환경에 6TB VM이 있는 경우 48TB 이하의 크기로 FlexGroup 데이터 저장소를 구성할 수 있습니다.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">FlexGroup에서 데이터 저장소 공간을 관리할 수 있도록 허용합니다. vSphere 데이터 저장소에서 자동 크기 조정 및 Elastic Sizing을 테스트했습니다. 데이터 저장소가 전체 용량에 근접하면 VMware vSphere용 ONTAP 툴 또는 다른 툴을 사용하여 FlexGroup 볼륨의 크기를 조정할 수 있습니다. FlexGroup는 용량 및 inode의 균형을 유지하며, 용량이 허용하는 경우 폴더(VM) 내의 파일에 우선 순위를 지정합니다.</block>
  <block id="b48b55db402c8085e1d333cad214232b" category="list-text">VMware 및 NetApp은 현재 일반적인 다중 경로 네트워킹 접근 방식을 지원하지 않습니다. NFSv4.1에서는 NetApp이 pNFS를 지원하는 반면 VMware는 세션 트렁킹을 지원합니다. NFSv3은 볼륨에 대한 여러 물리적 경로를 지원하지 않습니다. ONTAP 9.8이 포함된 FlexGroup의 경우 간접 액세스의 영향은 일반적으로 최소(마이크로초)이므로 VMware vSphere용 ONTAP 툴을 단일 마운트로 설정하는 것이 좋습니다. 라운드 로빈 DNS를 사용하여 FlexGroup의 서로 다른 노드에 있는 LIF 간에 ESXi 호스트를 배포할 수 있지만, 이렇게 하려면 VMware vSphere용 ONTAP 툴 없이 FlexGroup를 생성하고 마운트해야 합니다. 그러면 성능 관리 기능을 사용할 수 없습니다.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">FlexGroup vSphere 데이터 저장소 지원은 9.8 릴리즈에서 VM 1,500대까지 테스트되었습니다.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">복제 오프로드에 VMware VAAI용 NFS 플러그인을 사용하십시오. FlexGroup 데이터 저장소 내에서 클론 생성이 향상되지만 FlexVol는 FlexGroup 및/또는 ONTAP 볼륨 간에 VM을 복제할 때 ESXi 호스트 복제본보다 성능이 크게 향상되지는 않습니다.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">VMware vSphere 9.8용 ONTAP 툴을 사용하여 ONTAP 메트릭(대시보드 및 VM 보고서)을 사용하여 FlexGroup VM의 성능을 모니터링하고 개별 VM의 QoS를 관리할 수 있습니다. 이러한 메트릭은 현재 ONTAP 명령 또는 API를 통해 사용할 수 없습니다.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS(최대/최소 IOPS)는 개별 VM 또는 해당 시점에 데이터 저장소의 모든 VM에 설정할 수 있습니다. 모든 VM에서 QoS를 설정하면 별도의 VM별 설정이 대체됩니다. 설정은 향후 새 VM이나 마이그레이션된 VM으로 확장되지 않습니다. 새 VM에 QoS를 설정하거나 데이터 저장소의 모든 VM에 QoS를 다시 적용하십시오.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">SnapCenter Plug-in for VMware vSphere 릴리즈 4.4는 운영 스토리지 시스템의 FlexGroup 데이터 저장소에 있는 VM의 백업 및 복구를 지원합니다. FlexGroup를 보조 시스템에 복제하기 위해 SnapMirror를 수동으로 사용할 수 있지만 SCV 4.4는 보조 복사본을 관리하지 않습니다.</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">서비스 품질(QoS)</block>
  <block id="8fdd6138f63aa45f1c51b48d9a01b19d" category="paragraph">처리량 제한은 배포 전에 알 수 없는 워크로드 또는 테스트 워크로드를 제어하여 다른 워크로드에 영향을 미치지 않도록 하는 데 유용합니다. 이러한 워크로드는 식별된 후 대규모 워크로드를 제한하는 데 사용할 수도 있습니다. ONTAP 9.2의 SAN 오브젝트 및 ONTAP 9.3의 NAS 오브젝트에 대해 일관된 성능을 제공하기 위해 IOPS를 기반으로 하는 최소 서비스 레벨도 지원됩니다.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">NFS 데이터 저장소를 사용하면 QoS 정책을 전체 FlexVol 볼륨 또는 해당 볼륨 내의 개별 VMDK 파일에 적용할 수 있습니다. ONTAP LUN을 사용하는 VMFS 데이터 저장소의 경우 FlexVol가 VMFS 파일 시스템을 인식하지 못하기 때문에 QoS 정책을 LUN 또는 개별 LUN을 포함하는 ONTAP 볼륨에 적용할 수 있지만 개별 VMDK 파일은 적용할 수 없습니다. VVOL을 사용할 경우 스토리지 용량 프로파일 및 VM 스토리지 정책을 사용하여 개별 VM에 최소 및/또는 최대 QoS를 설정할 수 있습니다.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">개체에 대한 QoS 최대 처리량 제한은 Mbps 및/또는 IOPS로 설정할 수 있습니다. 둘 다 사용되는 경우 첫 번째 제한에 도달한 값은 ONTAP에 의해 적용됩니다. 워크로드에는 여러 개체가 포함될 수 있으며 QoS 정책을 하나 이상의 워크로드에 적용할 수 있습니다. 정책이 여러 워크로드에 적용될 경우 워크로드는 정책의 총 한도를 공유합니다. 중첩된 개체는 지원되지 않습니다(예: 볼륨 내의 파일은 각각 고유한 정책을 가질 수 없음). QoS 최소값을 IOPS에서만 설정할 수 있습니다.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">현재 ONTAP QoS 정책을 관리하고 객체에 적용하는 데 사용할 수 있는 툴은 다음과 같습니다.</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">ONTAP CLI를 참조하십시오</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP 시스템 관리자</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">ONTAP를 위한 NetApp PowerShell Toolkit</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">VMware vSphere VASA Provider용 ONTAP 툴</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">NFS에서 VMDK에 QoS 정책을 할당하려면 다음 지침을 따르십시오.</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">정책을 에 적용해야 합니다<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> 여기에는 가 아닌 실제 가상 디스크 이미지가 포함됩니다<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (가상 디스크 설명자 파일) 또는<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (VM 설명자 파일).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">가상 스왑 파일과 같은 다른 VM 파일에 정책을 적용하지 마십시오 <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>)를 클릭합니다.</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">vSphere Web Client를 사용하여 파일 경로(Datastore &gt; Files)를 찾을 때는 의 정보가 결합되어 있다는 점을 유념하십시오<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> 및<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> 의 이름을 가진 파일 하나가 표시됩니다<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> 그러나 의 크기는<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. 추가<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> 파일 이름에 올바른 경로를 입력합니다.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">VMFS 및 RDM을 포함하여 LUN에 QoS 정책을 할당하려면 ONTAP vSphere용 ONTAP 툴 홈 페이지의 스토리지 시스템 메뉴에서 SVM(SVM으로 표시됨), LUN 경로 및 일련 번호를 확인할 수 있습니다. 스토리지 시스템(SVM)을 선택한 다음 관련 오브젝트 &gt; SAN을 선택합니다.  ONTAP 툴 중 하나를 사용하여 QoS를 지정할 때 이 접근 방식을 사용합니다.</block>
  <block id="cc97a1a52adc0bd6f188de1545eea887" category="paragraph">VMware vSphere 또는 Virtual Storage Console 7.1 이상을 위한 ONTAP 툴을 VVOL 기반 VM에 최대 및 최소 QoS를 손쉽게 할당할 수 있습니다. VVOL 컨테이너에 대한 스토리지 기능 프로필을 생성할 때 성능 기능에서 최대 및/또는 최소 IOPS 값을 지정한 다음 이 SCP를 VM의 스토리지 정책에 참조합니다. VM을 생성하거나 기존 VM에 정책을 적용할 때 이 정책을 사용합니다.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup 데이터 저장소는 VMware vSphere 9.8 이상용 ONTAP 툴을 사용할 때 향상된 QoS 기능을 제공합니다. 데이터 저장소 또는 특정 VM의 모든 VM에 대해 QoS를 쉽게 설정할 수 있습니다. 자세한 내용은 이 보고서의 FlexGroup 섹션을 참조하십시오.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS 및 VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP QoS 및 VMware vSphere 스토리지 I/O 제어(SIOC)는 vSphere 및 스토리지 관리자가 ONTAP 소프트웨어를 실행하는 시스템에서 호스팅되는 vSphere VM의 성능을 관리하는 데 함께 사용할 수 있는 보완 기술입니다. 다음 표에 나와 있는 것처럼 각 툴마다 고유한 강점이 있습니다. VMware vCenter와 ONTAP의 범위가 서로 다르기 때문에 한 시스템에서 일부 객체를 보고 관리할 수 있으며 다른 객체는 볼 수 없습니다.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">속성</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP QoS를 참조하십시오</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">활성화 시</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">정책이 항상 활성화되어 있습니다</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">경합이 있을 때 활성(데이터 저장소 지연 시간이 임계값을 초과함)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">단위 유형</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, MBps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, 공유</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">vCenter 또는 애플리케이션 범위</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">다양한 vCenter 환경, 기타 하이퍼바이저 및 애플리케이션</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">단일 vCenter Server</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">VM에서 QoS를 설정하시겠습니까?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK는 NFS에만 해당합니다</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">NFS 또는 VMFS의 VMDK입니다</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">LUN(RDM)에 QoS를 설정하시겠습니까?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">LUN(VMFS)에서 QoS를 설정하시겠습니까?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">볼륨에 QoS를 설정하시겠습니까(NFS 데이터 저장소)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">SVM(테넌트)에서 QoS를 설정하시겠습니까?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">정책 기반 접근 방식?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">예. 정책의 모든 워크로드에서 공유하거나 정책의 각 워크로드에 전체적으로 적용할 수 있습니다.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">예, vSphere 6.5 이상에서 가능합니다.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">라이센스가 필요합니다</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">ONTAP에 포함되어 있습니다</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">엔터프라이즈급 플러스</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware SDRS(Storage Distributed Resource Scheduler)는 현재 입출력 지연 시간 및 공간 사용량을 기반으로 스토리지에 VM을 배치하는 vSphere 기능입니다. 그런 다음 데이터 저장소 클러스터(Pod라고도 함)의 데이터 저장소 간에 VM 또는 VMDK를 중단 없이 이동하여 VM 또는 VMDK를 데이터 저장소 클러스터에 배치할 최상의 데이터 저장소를 선택합니다. 데이터 저장소 클러스터는 vSphere 관리자의 관점에서 단일 사용 단위로 집계되는 유사한 데이터 저장소의 모음입니다.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">VASA(VMware vSphere APIs for Storage Awareness)를 사용하면 스토리지 관리자가 잘 정의된 기능을 사용하여 데이터 저장소를 쉽게 구성할 수 있으며 VM 관리자는 필요할 때마다 상호 작용하지 않고도 데이터 저장소를 사용하여 VM을 프로비저닝할 수 있습니다. 가상화 스토리지 운영을 간소화하고 사소한 작업을 많이 피하는 방법을 알아보려면 이 접근 방식을 살펴보시기 바랍니다.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">클라우드 마이그레이션 및 백업</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP의 또 다른 강점은 하이브리드 클라우드를 광범위하게 지원하여 사내 프라이빗 클라우드의 시스템을 퍼블릭 클라우드 기능과 병합하는 것입니다. 다음은 vSphere와 함께 사용할 수 있는 몇 가지 NetApp 클라우드 솔루션입니다.</block>
  <block id="e18ab5f123ad4ce169202479f07f3f0f" category="list-text">* 클라우드 볼륨. * Amazon Web Services를 위한 NetApp Cloud Volumes Service 또는 Google Cloud Platform과 ANF를 위한 Azure NetApp Files는 주요 퍼블릭 클라우드 환경에서 고성능 멀티 프로토콜 관리형 스토리지 서비스를 제공합니다. VMware Cloud VM 게스트가 직접 사용할 수 있습니다.</block>
  <block id="9625e7e8b7b951b4ac75beee0139b407" category="list-text">* Cloud Volumes ONTAP. * NetApp Cloud Volumes ONTAP 데이터 관리 소프트웨어는 선택한 클라우드에서 데이터에 제어, 보호, 유연성 및 효율성을 제공합니다. Cloud Volumes ONTAP는 NetApp ONTAP 스토리지 소프트웨어를 기반으로 하는 클라우드 네이티브 데이터 관리 소프트웨어입니다. Cloud Manager와 함께 사용하면 사내 ONTAP 시스템과 함께 Cloud Volumes ONTAP 인스턴스를 구축하고 관리할 수 있습니다. 스냅샷과 SnapMirror 복제를 포함한 통합 데이터 관리와 함께 고급 NAS 및 iSCSI SAN 기능을 활용합니다.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">* 클라우드 서비스. * Cloud Backup Service 또는 SnapMirror 클라우드를 사용하여 퍼블릭 클라우드 스토리지를 사용하는 사내 시스템의 데이터를 보호합니다. Cloud Sync를 사용하면 NAS, 오브젝트 저장소 및 Cloud Volumes Service 스토리지에서 데이터를 마이그레이션하고 동기화 상태를 유지할 수 있습니다.</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">VM의 스냅샷을 더 많이 저장합니다</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">* FabricPool. * FabricPool는 ONTAP 데이터를 빠르고 쉽게 계층화할 수 있도록 지원합니다. 콜드 블록은 퍼블릭 클라우드 또는 프라이빗 StorageGRID 오브젝트 저장소의 오브젝트 저장소로 마이그레이션할 수 있으며, ONTAP 데이터에 다시 액세스할 때 자동으로 호출됩니다. 또는 SnapVault에서 이미 관리하는 데이터를 보호하기 위해 개체 계층을 세 번째 수준으로 사용할 수도 있습니다. 이 접근 방식을 통해 다음을 수행할 수 있습니다<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> 주요 및/또는 보조 ONTAP 스토리지 시스템</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">* ONTAP Select. * NetApp 소프트웨어 정의 스토리지를 사용하여 프라이빗 클라우드를 인터넷으로 원격 시설 및 사무소로 확장할 수 있습니다. ONTAP Select를 사용하여 블록 및 파일 서비스와 엔터프라이즈 데이터 센터에서 사용하는 vSphere 데이터 관리 기능을 지원할 수 있습니다.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">VM 기반 애플리케이션을 설계할 때는 미래의 클라우드 이동성을 고려해 보십시오. 예를 들어, 애플리케이션과 데이터 파일을 함께 배치하는 대신 데이터에 대해 별도의 LUN 또는 NFS 내보내기를 사용합니다. 따라서 VM 및 데이터를 클라우드 서비스로 별도로 마이그레이션할 수 있습니다.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">vSphere 데이터 암호화</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">오늘날, 암호화를 통해 유휴 데이터를 보호해야 하는 요구가 증가하고 있습니다. 처음에는 금융 및 의료 정보에 초점을 맞추었지만 파일, 데이터베이스 또는 기타 데이터 유형에 관계없이 모든 정보를 보호하는 데 대한 관심이 높아지고 있습니다.</block>
  <block id="f131c8f285a9ebc44140235877aecbe5" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템을 사용하면 유휴 데이터를 쉽게 보호할 수 있습니다. NetApp 스토리지 암호화(NSE)는 ONTAP가 포함된 자체 암호화 디스크 드라이브를 사용하여 SAN 및 NAS 데이터를 보호합니다. NetApp은 또한 디스크 드라이브에서 볼륨을 암호화하는 단순한 소프트웨어 기반 접근 방식으로 NetApp 볼륨 암호화 및 NetApp 애그리게이트 Encryption도 제공합니다. 이 소프트웨어 암호화는 특수 디스크 드라이브나 외부 키 관리자가 필요하지 않으며 ONTAP 고객이 추가 비용 없이 사용할 수 있습니다. 클라이언트 또는 애플리케이션을 중단하지 않고 업그레이드하거나 사용할 수 있으며 온보드 키 관리자를 포함하여 FIPS 140-2 레벨 1 표준에 따라 검증을 받았습니다.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">VMware vSphere에서 실행되는 가상화된 애플리케이션의 데이터를 보호하기 위한 몇 가지 접근 방식이 있습니다. 한 가지 방법은 게스트 OS 수준에서 VM 내부의 소프트웨어로 데이터를 보호하는 것입니다. vSphere 6.5와 같은 최신 하이퍼바이저는 VM 수준에서 암호화를 지원하는 또 다른 대안으로, 그러나 NetApp 소프트웨어 암호화는 간단하고 쉬우며 다음과 같은 이점을 제공합니다.</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">* 가상 서버 CPU에 영향을 미치지 않습니다. * 일부 가상 서버 환경에서는 애플리케이션에 사용할 수 있는 모든 CPU 사이클이 필요하지만 하이퍼바이저 레벨 암호화를 위해서는 최대 5배의 CPU 리소스가 필요하다는 결과가 있습니다. 암호화 소프트웨어가 암호화 워크로드를 오프로드하는 인텔의 AES-NI 명령 집합을 지원하더라도(NetApp 소프트웨어 암호화처럼), 이전 서버와 호환되지 않는 새로운 CPU가 필요하기 때문에 이 접근 방식은 적합하지 않을 수 있습니다.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">* 온보드 키 관리자가 포함되어 있습니다. * NetApp 소프트웨어 암호화는 추가 비용 없이 온보드 키 관리자를 포함하므로 구입 및 사용이 복잡한 고가용성 키 관리 서버 없이 쉽게 시작할 수 있습니다.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">* 스토리지 효율성에 영향을 미치지 않습니다. * 데이터 중복 제거 및 압축과 같은 스토리지 효율성 기술이 현재 널리 사용되고 있으며 플래시 디스크 미디어를 비용 효율적으로 사용하는 데 핵심적인 역할을 합니다. 그러나 암호화된 데이터는 일반적으로 중복제거되거나 압축할 수 없습니다. NetApp 하드웨어 및 스토리지 암호화는 다른 접근법과는 달리 낮은 수준에서 작동하며 업계 최고의 NetApp 스토리지 효율성 기능을 충분히 활용할 수 있도록 합니다.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">* 데이터스토어의 세분화된 암호화. * NetApp Volume Encryption을 사용하면 각 볼륨에 고유한 AES 256비트 키를 사용할 수 있습니다. 변경해야 하는 경우 단일 명령을 사용하여 변경할 수 있습니다. 이 접근 방식은 테넌트가 여러 개이거나 서로 다른 부서 또는 애플리케이션에 대해 독립적인 암호화를 증명해야 하는 경우에 유용합니다. 이 암호화는 개별 VM을 관리하는 것보다 훨씬 쉬운 데이터 저장소 수준에서 관리됩니다.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">소프트웨어 암호화를 간단하게 시작할 수 있습니다. 라이센스를 설치한 후 암호를 지정하여 온보드 키 관리자를 구성한 다음 새 볼륨을 생성하거나 스토리지 측 볼륨 이동을 수행하여 암호화를 설정합니다. NetApp은 향후 VMware 툴 릴리즈에서 암호화 기능에 대한 통합 지원을 추가하기 위해 노력하고 있습니다.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager는 가상 인프라의 VM에 대한 가시성을 제공하고 가상 환경에서 스토리지 및 성능 문제를 모니터링하고 문제를 해결할 수 있도록 지원합니다.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">ONTAP 기반의 일반적인 가상 인프라 구축에는 컴퓨팅, 네트워크 및 스토리지 계층 전체에 분산된 다양한 구성 요소가 있습니다. VM 애플리케이션의 성능 지연은 각 계층의 다양한 구성 요소에 의해 발생하는 지연 시간의 조합으로 인해 발생할 수 있습니다.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">다음 스크린샷은 Active IQ Unified Manager 가상 머신 보기를 보여 줍니다.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager는 가상 환경의 기본 하위 시스템을 토폴로지 뷰에서 제공하므로 컴퓨팅 노드, 네트워크 또는 스토리지에서 지연 시간 문제가 발생했는지 여부를 확인할 수 있습니다. 또한 개선 단계를 수행하고 기본 문제를 해결하는 데 성능 지연이 발생하는 특정 개체를 중점적으로 보여 줍니다.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">다음 스크린샷은 AIQUM 확장 토폴로지를 보여줍니다.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">데이터 저장소 및 프로토콜</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">7개의 프로토콜을 사용하여 ONTAP 소프트웨어를 실행하는 시스템의 데이터 저장소에 VMware vSphere를 연결합니다.</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE 를 참조하십시오</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">iSCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP 및 iSCSI는 vSphere VMFS(Virtual Machine File System)를 사용하여 ONTAP FlexVol 볼륨에 포함된 ONTAP LUN 또는 NVMe 네임스페이스 내에 VM을 저장하는 블록 프로토콜입니다. VMware는 vSphere 7.0부터 운영 환경에서는 더 이상 소프트웨어 FCoE를 지원하지 않습니다. NFS는 VMFS 없이 VM을 데이터 저장소(단순한 ONTAP 볼륨)에 배치하는 파일 프로토콜입니다. SMB(CIFS), iSCSI, NVMe/TCP 또는 NFS를 게스트 OS에서 ONTAP로 직접 사용할 수도 있습니다.</block>
  <block id="2b19cb432f68f1ba3dc7b0f175a14778" category="inline-link">VMware 구성 최대값</block>
  <block id="f8ca1b19553d4c965e40e9eeb1eb5aca" category="paragraph">다음 표에서는 ONTAP에서 vSphere가 지원하는 기존 데이터 저장소 기능을 보여 줍니다. 이 정보는 VVOL 데이터 저장소에 적용되지 않지만 일반적으로 지원되는 ONTAP 릴리즈를 사용하는 vSphere 6.x 이상 릴리즈에 적용됩니다. 상담도 할 수 있습니다<block ref="61b579b455015dfa2bbf16bf62f07f93" category="inline-link-rx"></block> 특정 제한 사항을 확인하기 위한 특정 vSphere 릴리즈</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">기능/특징</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe - oF</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">형식</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS 또는 RDM(Raw Device Mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS 또는 RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS를 참조하십시오</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">해당 없음</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">최대 데이터 저장소 또는 LUN 수</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">호스트당 LUN 1024개</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">서버당 LUN 1024개</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">서버당 256개의 Names입니다</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256개의 마운트
기본 NFS. MaxVolumes는 8입니다. VMware vSphere용 ONTAP 툴을 사용하여 256으로 늘리십시오.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">최대 데이터 저장소 크기입니다</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">FlexGroup 볼륨에서 100TB FlexVol 볼륨 이상</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">최대 데이터 저장소 파일 크기입니다</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TB</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">ONTAP 9.12.1P2 이상이 설치된 62TB</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">LUN 또는 파일 시스템당 최적의 큐 크기</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">자동 협상</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">NFS.MaxQueueDepth in 을 참조하십시오<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">다음 표에는 지원되는 VMware 스토리지 관련 기능이 나와 있습니다.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">마이그레이션</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">마이그레이션</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA입니다</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDRS(Storage Distributed Resource Scheduler)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware VADP(vStorage APIs for Data Protection) 지원 백업 소프트웨어</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">VM 내의 MSCS(Microsoft Cluster Service) 또는 장애 조치 클러스터링</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">예 *</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">지원되지 않습니다</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">내결함성</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">사이트 복구 관리자</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">V3만 해당**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">씬 프로비저닝된 VM(가상 디스크)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">예
VAAI를 사용하지 않는 경우 NFS에서 모든 VM에 대해 이 설정이 기본값입니다.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">VMware 기본 다중 경로</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">예, 새로운 HPP(High Performance Plugin) 사용</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">다음 표에는 지원되는 ONTAP 스토리지 관리 기능이 나와 있습니다.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">데이터 중복제거</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">어레이에 대한 비용 절감</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">데이터 저장소의 절감 효과</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">씬 프로비저닝</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">데이터 저장소 또는 RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">데이터 저장소</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">데이터 저장소 크기를 조정합니다</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">성장만 하십시오</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">확장, 자동 확장 및 축소</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Windows, Linux 애플리케이션용 SnapCenter 플러그인(게스트)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 모니터링 및 호스트 구성</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 프로비저닝</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">다음 표에는 지원되는 백업 기능이 나와 있습니다.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">ONTAP 스냅샷</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM은 복제된 백업에서 지원됩니다</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">volume SnapMirror를 선택합니다</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VMDK 이미지 액세스</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP 지원 백업 소프트웨어</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP 지원 백업 소프트웨어, vSphere Client 및 vSphere Web Client 데이터 저장소 브라우저</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VMDK 파일 레벨 액세스</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP 지원 백업 소프트웨어, Windows만 해당</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP 지원 백업 소프트웨어 및 타사 애플리케이션</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP 세분성</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">데이터 저장소 또는 VM</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Windows Server 장애 조치 클러스터링에 대한 설치</block>
  <block id="45f7e6f7f6f0f4093754d7d48810e17f" category="paragraph">* NetApp은 VMFS 데이터 저장소에 다중 writer 지원 VMDK가 아닌 Microsoft 클러스터에 게스트 내 iSCSI를 사용할 것을 권장합니다. 이 접근 방식은 Microsoft 및 VMware에서 완벽하게 지원되며 ONTAP(사내 또는 클라우드의 ONTAP 시스템에 대한 SnapMirror)를 통해 뛰어난 유연성을 제공하고 쉽게 구성 및 자동화할 수 있으며 SnapCenter를 통해 보호할 수 있습니다. vSphere 7은 새로운 클러스터 VMDK 옵션을 추가합니다. 이는 클러스터 VMDK를 지원하는 FC 프로토콜을 통해 데이터 저장소를 제공해야 하는 멀티writer 지원 VMDK와 다릅니다. 기타 제한 사항이 적용됩니다. VMware를 참조하십시오<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> 구성 지침 설명서.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">** NVMe-oF 및 NFS v4.1을 사용하는 데이터 저장소에는 vSphere 복제가 필요합니다. 스토리지 기반 복제는 SRM에서 지원되지 않습니다.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">스토리지 프로토콜 선택</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 모든 주요 스토리지 프로토콜을 지원하므로 고객은 기존 및 계획된 네트워킹 인프라, 직원 기술에 따라 환경에 가장 적합한 프로토콜을 선택할 수 있습니다. NetApp 테스트 결과, 유사한 회선 속도에서 실행되는 프로토콜 간에는 일반적으로 차이가 거의 없으므로 원시 프로토콜 성능보다 네트워크 인프라 및 직원 기능에 초점을 맞추는 것이 가장 좋습니다.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">프로토콜 선택을 고려할 때 다음과 같은 요소가 유용할 수 있습니다.</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">* 현재 고객 환경 * IT 팀은 일반적으로 이더넷 IP 인프라 관리에 능숙하지만, 모든 팀이 FC SAN 패브릭 관리에 능숙하지는 않습니다. 그러나 스토리지 트래픽용으로 설계되지 않은 범용 IP 네트워크를 사용하는 것은 잘 작동하지 않을 수 있습니다. 현재 보유하고 있는 네트워킹 인프라, 계획된 개선 사항, 이를 관리할 직원의 기술 및 가용성을 고려하십시오.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">* 손쉬운 설정 * FC 패브릭의 초기 구성(추가 스위치 및 케이블 연결, 조닝, HBA 및 펌웨어의 상호 운용성 검증) 외에도 블록 프로토콜은 LUN 생성 및 매핑과 게스트 OS의 검색 및 포맷이 필요합니다. NFS 볼륨을 생성 및 내보낸 후에는 ESXi 호스트에 의해 마운트되며 사용할 수 있습니다. NFS에는 특별한 하드웨어 검증 또는 관리 펌웨어가 없습니다.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* 손쉬운 관리. * SAN 프로토콜을 사용할 경우 더 많은 공간이 필요한 경우 LUN 증가, 새로운 크기를 검색하기 위한 재검색, 파일 시스템 확장 등 몇 가지 단계가 필요합니다. LUN을 증대할 수는 있지만 LUN 크기를 줄이는 것은 불가능하므로 사용하지 않는 공간을 복구하려면 추가 작업이 필요합니다. NFS를 사용하면 위나 아래로 쉽게 사이징할 수 있으며, 이러한 크기 조정은 스토리지 시스템에서 자동화할 수 있습니다. SAN은 게스트 OS TRIM/UNMAP 명령을 통해 공간 재확보를 제공하여 삭제된 파일의 공간을 어레이로 반환할 수 있도록 합니다. 이러한 유형의 공간 재확보는 NFS 데이터 저장소에서 더 어렵습니다.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">* 스토리지 공간 투명성. * 씬 프로비저닝이 즉시 절약 효과를 반환하므로 NFS 환경에서는 일반적으로 스토리지 사용률을 쉽게 확인할 수 있습니다. 마찬가지로, 같은 데이터 저장소 또는 다른 스토리지 시스템 볼륨에 있는 다른 VM에 대해서도 중복 제거 및 클론 생성 절약 효과를 즉시 사용할 수 있습니다. 일반적으로 VM 밀도는 NFS 데이터 저장소에서 더 높으며, 관리할 데이터 저장소 수를 줄여 데이터 중복 제거 비용을 절감할 수 있습니다.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">데이터 저장소 레이아웃</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">ONTAP NFS 데이터 저장소를 사용하여 vSphere를 구축하면 관리가 용이한 고성능 구축이 가능하기 때문에 블록 기반 스토리지 프로토콜로는 얻을 수 없는 VM-데이터 저장소 비율을 제공할 수 있습니다. 이 아키텍처를 사용하면 데이터 저장소 밀도가 10배 증가하여 데이터 저장소 수가 서로 관련지어 줄어들 수 있습니다. 더 큰 데이터 저장소가 스토리지 효율성에 이점을 제공하고 운영 이점을 제공할 수 있지만, 하드웨어 리소스의 최대 성능을 얻기 위해 최소 4개의 데이터 저장소(FlexVol 볼륨)를 사용하여 VM을 단일 ONTAP 컨트롤러에 저장하는 것이 좋습니다. 이 방법을 사용하면 복구 정책이 서로 다른 데이터 저장소를 설정할 수도 있습니다. 비즈니스 요구 사항에 따라 다른 사람보다 더 자주 백업하거나 복제할 수 있는 경우도 있습니다. FlexGroup 볼륨은 설계상 확장되므로 성능을 위해 여러 데이터 저장소가 필요하지 않습니다.</block>
  <block id="e15ed0ec7af4278259b7618024b3e7ce" category="list-text">NetApp은 대부분의 NFS 데이터 저장소에 FlexVol 볼륨을 사용할 것을 권장합니다. ONTAP 9.8부터 FlexGroup 볼륨은 데이터 저장소로도 사용할 수 있으며, 일반적으로 특정 활용 사례에 권장됩니다. qtree와 같은 다른 ONTAP 스토리지 컨테이너는 현재 VMware vSphere용 ONTAP 툴 또는 VMware vSphere용 NetApp SnapCenter 플러그인에서 지원되지 않으므로 일반적으로 권장되지 않습니다. 그렇지만 단일 볼륨에서 데이터 저장소를 여러 Qtree로 구축하면 고도의 자동화 환경에서 데이터 저장소 레벨 할당량 또는 VM 파일 클론의 이점을 누릴 수 있습니다.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">FlexVol 볼륨 데이터 저장소의 적절한 크기는 약 4TB에서 8TB입니다. 이 크기는 성능, 관리 용이성 및 데이터 보호 측면에서 우수한 균형 점입니다. 작게 시작하고(예: 4TB) 필요에 따라 데이터 저장소를 최대 100TB까지 확장할 수 있습니다. 작은 데이터 저장소가 백업이나 재해 발생 후 복구 속도가 빨라지므로 클러스터 간에 빠르게 이동할 수 있습니다. ONTAP 자동 크기 조정을 사용하면 사용된 공간이 변경될 때 볼륨을 자동으로 확대 및 축소할 수 있습니다. VMware vSphere 데이터 저장소 용량 할당 마법사용 ONTAP 툴은 새 데이터 저장소에 대해 기본적으로 자동 크기 조정을 사용합니다. System Manager 또는 명령줄을 사용하여 확장 및 축소 임계값과 최대 및 최소 크기를 추가로 사용자 지정할 수 있습니다.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">또는 FC, iSCSI 또는 FCoE에서 액세스하는 LUN으로 VMFS 데이터 저장소를 구성할 수도 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. VMFS 데이터 저장소의 크기는 최대 64TB이고 최대 32개의 2TB LUN(VMFS 3) 또는 단일 64TB LUN(VMFS 5)으로 구성될 수 있습니다. ONTAP의 최대 LUN 크기는 대부분의 시스템에서 16TB이고, All-SAN 어레이 시스템에서 128TB입니다. 따라서 16TB LUN 4개를 사용하여 대부분의 ONTAP 시스템에서 VMFS 5 데이터 저장소의 최대 크기를 생성할 수 있습니다. 여러 LUN(하이엔드 FAS 또는 AFF 시스템 사용)을 사용하는 높은 I/O 워크로드에 성능 이점이 있을 수 있지만, 데이터 저장소 LUN을 생성, 관리 및 보호하고 가용성 위험을 높이는 관리 복잡성이 추가되어 이러한 이점을 얻을 수 있습니다. 일반적으로 각 데이터 저장소마다 큰 단일 LUN을 사용하는 것이 좋으며 16TB 데이터 저장소를 넘어서는 특별한 요구 사항이 있는 경우에만 확장할 것을 권장합니다. NFS와 마찬가지로, 단일 ONTAP 컨트롤러에서 성능을 최대화하기 위해 여러 데이터 저장소(볼륨)를 사용하는 것을 고려합니다.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">기존 게스트 운영 체제(OS)는 최고의 성능과 스토리지 효율성을 위해 스토리지 시스템과 조율해야 했습니다. 그러나 Red Hat과 같은 Microsoft 및 Linux 배포업체에서 제공하는 최신 공급업체 지원 OS는 더 이상 가상 환경에서 파일 시스템 파티션을 기본 스토리지 시스템의 블록과 일치시킬 필요가 없습니다. 조정이 필요한 이전 OS를 사용하는 경우 NetApp 지원 기술 자료에서 "VM 정렬"을 사용하는 문서를 검색하거나 NetApp 세일즈 또는 파트너 담당자에게 TR-3747 사본을 요청합니다.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">게스트 OS 내에서 조각 모음 유틸리티를 사용하지 마십시오. 이 유틸리티는 성능 이점을 제공하지 않으며 스토리지 효율성 및 스냅샷 공간 사용에 영향을 줍니다. 또한 게스트 OS에서 가상 데스크톱에 대한 검색 인덱싱을 해제하는 것도 고려하십시오.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP은 혁신적인 스토리지 효율성 기능으로 업계에서 최고의 가용성을 제공하므로 사용 가능한 디스크 공간을 최대한 활용할 수 있습니다. AFF 시스템은 기본 인라인 중복제거 및 압축을 사용해 이 효율성을 더욱 높여줍니다. 데이터는 애그리게이트 내 모든 볼륨에서 중복 제거되므로, 더 이상 단일 데이터 저장소 내에서 유사한 운영 체제 및 유사한 애플리케이션을 그룹화할 필요가 없으며 절약 효과를 극대화할 수 있습니다.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">ONTAP 기반의 Oracle 데이터베이스</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">1등급 디스크(또는 개선된 가상 디스크)는 vSphere 6.5 이상을 사용하는 VM과 독립적으로 vCenter 관리 디스크를 사용할 수 있습니다. 주로 API에서 관리되지만, VVOL은 특히 OpenStack 또는 Kubernetes 툴로 관리할 때 유용합니다. ONTAP 및 VMware vSphere용 ONTAP 툴을 통해 지원됩니다.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">데이터 저장소 및 VM 마이그레이션</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">다른 스토리지 시스템의 기존 데이터 저장소에서 ONTAP로 VM을 마이그레이션할 때 다음 몇 가지 사항을 염두에 두어야 합니다.</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Storage vMotion을 사용하여 대량의 가상 머신을 ONTAP로 이동합니다. 이 접근 방식은 실행 중인 VM에 중단 없이 적용할 수 있을 뿐만 아니라 인라인 중복제거 및 압축과 같은 ONTAP 스토리지 효율성 기능을 사용하여 마이그레이션 시 데이터를 처리할 수 있습니다. vCenter 기능을 사용하여 인벤토리 목록에서 여러 VM을 선택한 다음 적절한 시간에 마이그레이션을 예약합니다(작업을 클릭하는 동안 Ctrl 키 사용).</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">적절한 대상 데이터 저장소로 마이그레이션을 신중하게 계획할 수 있지만, 대개 대량으로 마이그레이션한 다음 필요에 따라 나중에 구성하는 것이 더 간단합니다. 서로 다른 스냅샷 일정과 같은 특정 데이터 보호 요구 사항이 있는 경우 이 방법을 사용하여 다른 데이터 저장소로 마이그레이션할 수 있습니다.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">대부분의 VM 및 해당 스토리지는 실행 중(핫) 마이그레이션될 수 있지만 다른 스토리지 시스템에서 ISO, LUN 또는 NFS 볼륨과 같은 연결된(데이터 저장소 아님) 스토리지를 마이그레이션하려면 콜드 마이그레이션이 필요할 수 있습니다.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="096f2185af16e07c387a7fbe50df957a" category="list-text">보다 신중한 마이그레이션이 필요한 가상 머신에는 연결된 스토리지를 사용하는 데이터베이스와 애플리케이션이 포함됩니다. 일반적으로 마이그레이션 관리에 애플리케이션 툴을 사용하는 것을 고려합니다. Oracle의 경우 RMAN 또는 ASM과 같은 Oracle 툴을 사용하여 데이터베이스 파일을 마이그레이션할 수 있습니다. 을 참조하십시오<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> 를 참조하십시오. 마찬가지로 SQL Server의 경우 SQL Server Management Studio 또는 SnapManager for SQL Server 또는 SnapCenter와 같은 NetApp 툴을 사용하는 것이 좋습니다.</block>
  <block id="09485b54473eee31422696bf0217d714" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 가장 중요한 Best Practice는 VMware vSphere용 ONTAP 툴 플러그인(이전의 가상 스토리지 콘솔)을 설치하고 사용하는 것입니다. 이 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용할 때 스토리지 관리를 간소화하고, 가용성을 높이고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. 데이터 저장소를 프로비저닝하는 모범 사례를 사용하고 다중 경로 및 HBA 시간 초과를 위해 ESXi 호스트 설정을 최적화합니다(부록 B에 설명되어 있음). vCenter 플러그인이기 때문에 vCenter 서버에 접속하는 모든 vSphere 웹 클라이언트에서 사용할 수 있습니다.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">이 플러그인은 vSphere 환경에서 다른 ONTAP 툴을 사용하는 데에도 도움이 됩니다. VMware VAAI용 NFS 플러그인을 설치하면 VM 클론 생성 작업, 일반 가상 디스크 파일에 대한 공간 예약 및 ONTAP 스냅샷 오프로드를 위해 ONTAP로 복사 오프로드를 수행할 수 있습니다.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">일반적으로, vCenter 내에서 VMware vSphere 인터페이스에 ONTAP 툴을 사용하여 기존 데이터 저장소와 VVOL 데이터 저장소를 프로비저닝하면 모범 사례를 따를 수 있습니다.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">일반 네트워킹</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 네트워크 설정을 구성하는 것은 다른 네트워크 구성과 마찬가지로 간단합니다. 다음은 고려해야 할 몇 가지 사항입니다.</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Cisco vPC(Virtual PortChannel)와 같은 다중 섀시 링크 통합 그룹 접근 방식을 사용하여 두 개의 별도 스위치 섀시에 있는 포트의 링크 집계를 지원하는 스위치를 사용합니다.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">네트워크 관리</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">LACP를 사용하여 포트 또는 IP 해시가 있는 동적 멀티모드 인터페이스 그룹이 있는 ONTAP 스토리지 시스템용 링크 애그리게이트를 생성합니다. 을 참조하십시오<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> 추가 지침을 참조하십시오.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">정적 링크 통합(예: EtherChannel) 및 표준 vSwitch를 사용하거나 vSphere Distributed Switches를 사용하여 LACP 기반 링크 집계를 사용하는 경우 ESXi에서 IP 해시 팀 구성 정책을 사용하십시오. Link Aggregation을 사용하지 않는 경우 대신 "원래 가상 포트 ID를 기반으로 하는 Route"를 사용합니다.</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">FlexGroup 볼륨</block>
  <block id="bf985cdd1506d49ea0773c8997e0b723" category="paragraph">ONTAP 9.8은 VMware vSphere용 ONTAP 툴 및 VMware vSphere용 SnapCenter 플러그인과 함께 vSphere의 FlexGroup 볼륨 데이터 저장소에 대한 지원을 추가합니다. FlexGroup은 대규모 데이터 저장소의 생성을 간소화하고 여러 구성 볼륨을 자동으로 생성하여 ONTAP 시스템의 성능을 극대화합니다. 전체 ONTAP 클러스터의 성능을 지원하는 확장 가능한 단일 vSphere 데이터 저장소가 필요하거나 새로운 FlexGroup 클론 복제 메커니즘의 이점을 활용할 수 있는 클론 생성 워크로드가 매우 큰 경우 vSphere와 함께 FlexGroup를 사용하십시오.</block>
  <block id="83bcea036e70c0f011b083b2325b7a4b" category="paragraph">ONTAP 9.8은 vSphere 워크로드를 사용한 광범위한 시스템 테스트 외에도 FlexGroup 데이터 저장소를 위한 새로운 복제 오프로드 메커니즘도 추가합니다. 즉, 처음 몇 개의 클론을 사용하여 각 구성 볼륨의 로컬 캐시를 채우는 업데이트된 복사본 엔진을 사용합니다. 그런 다음 이 로컬 캐시를 사용하여 필요에 따라 VM 클론을 신속하게 인스턴스화합니다.</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">다음 시나리오를 고려해 보십시오.</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">8개 구성 요소로 구성된 새 FlexGroup를 만들었습니다</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">새 FlexGroup에 대한 캐시 시간 초과는 160분으로 설정됩니다</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">이 시나리오에서는 처음 8개의 클론이 로컬 파일 클론이 아닌 전체 복제본이 됩니다. 160초 시간 초과가 만료되기 전에 해당 VM을 추가로 클로닝할 경우 각 구성 요소 내의 파일 클론 엔진을 라운드 로빈 방식으로 사용하여 구성 볼륨에 거의 즉각적으로 생성되는 복사본을 생성합니다.</block>
  <block id="b368b4dbd46dd778776d405dc46d2033" category="paragraph">볼륨이 수신하는 모든 새 클론 작업은 시간 초과를 재설정합니다. 예제 FlexGroup의 구성 볼륨이 시간 초과 전에 클론 요청을 수신하지 못하면 해당 특정 VM의 캐시가 지워지고 볼륨을 다시 채워야 합니다. 또한 원본 클론의 소스가 변경된 경우(예: 템플릿을 업데이트함) 충돌을 방지하기 위해 각 구성요소의 로컬 캐시가 무효화됩니다. 캐시는 튜닝 가능하며 운영 환경의 요구 사항에 맞게 설정할 수 있습니다.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">FlexGroup 캐시를 최대한 활용할 수 없지만 신속한 볼륨 간 클로닝이 필요한 환경에서는 VVOL을 사용하는 것이 좋습니다. VVOL을 통한 교차 볼륨 클로닝은 기존 데이터 저장소를 사용하는 것보다 훨씬 빠르며 캐시에 의존하지 않습니다.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI: FlexGroup 볼륨에서 캐싱은 어떻게 작동합니까?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">VAAI에서 FlexGroups를 사용하는 방법에 대한 자세한 내용은 다음 KB 문서를 참조하십시오.<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="eafcbe529f542610c50d02e4a2fffcd6" category="paragraph">ONTAP 9.8에는 FlexGroup 볼륨 파일에 대한 새로운 파일 기반 성능 메트릭(IOPS, 처리량, 지연 시간)이 추가되었으며, 이러한 메트릭은 VMware vSphere 대시보드 및 VM 보고서용 ONTAP 툴에서 확인할 수 있습니다. VMware vSphere 플러그인용 ONTAP 툴을 사용하면 최대 및/또는 최소 IOPS의 조합을 사용하여 서비스 품질(QoS) 규칙을 설정할 수도 있습니다. 데이터 저장소의 모든 VM에 대해 또는 특정 VM에 대해 개별적으로 설정할 수 있습니다.</block>
  <block id="b8c631b88d7be5f1105be2f8c7ff3213" category="list-text">FlexGroup 볼륨 프로비저닝 기본값을 사용합니다. VMware vSphere용 ONTAP 툴은 vSphere 내에서 FlexGroup를 생성 및 마운트하기 때문에 권장되지만, ONTAP System Manager 또는 명령줄은 특수한 요구 사항에 사용될 수 있습니다. 심지어 vSphere에서 가장 철저하게 테스트된 항목이므로 노드당 구성 요소 구성원 수와 같은 기본값을 사용하십시오. 즉, 구성 요소의 수 또는 배치 변경과 같은 기본값이 아닌 설정은 여전히 전체 지원됩니다.</block>
  <block id="301593c45668093a7eb242d138c597a3" category="list-text">FlexGroup 기반 데이터 저장소의 크기를 결정할 때 FlexGroup은 더 큰 네임스페이스를 생성하는 여러 개의 작은 FlexVol 볼륨으로 구성됩니다. 따라서 8개 구성 요소와 함께 FlexGroup를 사용할 때는 데이터 저장소를 최대 가상 머신 크기의 8배 이상으로 사이징해야 합니다. 예를 들어 환경에 6TB VM이 있는 경우 48TB 이하의 크기로 FlexGroup 데이터 저장소를 구성할 수 있습니다.</block>
  <block id="04cc9e0b9478cc704d42735886027630" category="list-text">복제 오프로드에 VMware VAAI용 NFS 플러그인을 사용하십시오. 앞에서 설명한 것처럼 FlexGroup 데이터 저장소 내에서 클론 생성이 향상되지만 FlexVol 및/또는 FlexGroup 볼륨 간에 VM을 복사할 때 ONTAP는 ESXi 호스트 복사본에 비해 상당한 성능 이점을 제공하지 않습니다. 따라서 VAAI 또는 FlexGroups를 사용하기로 결정할 때 복제 워크로드를 고려하십시오. 구성 볼륨의 수를 수정하는 것이 FlexGroup 기반 클로닝을 최적화하는 한 가지 방법입니다. 와 마찬가지로 캐시 시간 초과를 튜닝합니다.</block>
  <block id="b9e0a0134c0815e50bb71d8dd7e367b6" category="list-text">QoS(최대/최소 IOPS)는 개별 VM 또는 해당 시점에 데이터 저장소의 모든 VM에 설정할 수 있습니다. 모든 VM에서 QoS를 설정하면 별도의 VM별 설정이 대체됩니다. 설정은 향후 새 VM이나 마이그레이션된 VM으로 확장되지 않습니다. 새 VM에 QoS를 설정하거나 데이터 저장소의 모든 VM에 QoS를 다시 적용하십시오. 또한 FlexGroup QoS 정책은 VM이 다른 데이터 저장소로 마이그레이션되는 경우에도 VM을 따라하지도 않습니다. 이는 다른 데이터 저장소로 마이그레이션할 경우 QoS 정책 설정을 유지할 수 있는 VVol과 다릅니다.</block>
  <block id="1133ff8355478000111c8b1969e32770" category="list-text">VMware vSphere 릴리즈 4.4 이상용 SnapCenter 플러그인은 운영 스토리지 시스템의 FlexGroup 데이터 저장소에 있는 VM의 백업 및 복구를 지원합니다. SCV 4.6에는 FlexGroup 기반 데이터 저장소에 대한 SnapMirror 지원이 추가되었습니다.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">기존 가상 어플라이언스로 전환한 ONTAP 툴은 다양한 새로운 기능, 더 높은 제한, 새로운 VVOL 지원을 제공합니다.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">SRM 및 ONTAP 도구의 새로운 기능</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">vSphere 및 Site Recovery Manager의 최신 버전입니다</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">SRM 8.7 이상 릴리즈와 ONTAP 도구 9.12 이상 릴리즈를 통해 이제 VMware vSphere 8 업데이트 1에서 실행되는 VM을 보호할 수 있습니다.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp은 약 20년 동안 VMware와 긴밀한 파트너 관계를 유지하고 있으며, 최대한 빠른 시일 내에 최신 릴리즈를 지원하기 위해 노력하고 있습니다. 항상 NetApp 상호 운용성 매트릭스 툴(IMT) 에서 적격 소프트웨어의 최신 조합을 확인하십시오.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">NetApp IMT는 에서 확인할 수 있습니다 <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">VVol 지원(그리고 SRM에서도 SPBM(Storage Policy Based Management)이 중요한 이유)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">8.3 릴리스부터 SRM은 이제 VVol을 활용하는 복제의 SPBM(Storage Policy Based Management)과 iSCSI, FCP 및 NFS v3을 사용하는 데이터 저장소의 스토리지 기반 복제를 지원합니다. 이를 위해 VASA 관련 작업을 위해 vCenter 서버의 SMS 서비스와 통신하는 새로운 SRM VVol 공급자 서비스를 포함하도록 SRM 서버가 업데이트되었습니다.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">이 아키텍처의 한 가지 이점은 모든 것이 VASA를 통해 처리되므로 SRA가 더 이상 필요하지 않는다는 것입니다.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM은 vSphere 툴박스에 포함된 강력한 툴로, 프라이빗 및 하이브리드 클라우드 환경의 자동화 프레임워크에서 간편하고 예측 가능하며 일관된 스토리지 서비스를 사용할 수 있습니다. 기본적으로 SPBM을 사용하면 다양한 고객 기반의 요구 사항을 충족하는 서비스 클래스를 정의할 수 있습니다. SRM을 사용하면 강력한 업계 표준 재해 복구 오케스트레이션 및 자동화가 필요한 중요 워크로드에 대한 복제 기능을 고객에게 제공할 수 있습니다.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">FCP 또는 iSCSI의 VVol 아키텍처 예:</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">어플라이언스 기반 SRM 서버 지원</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">이제 Photon OS 기반 SRM 서버는 기존 Windows 기반 플랫폼뿐만 아니라 지원됩니다.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">이제 기본 SRM 서버 유형에 관계없이 SRA 어댑터를 설치할 수 있습니다.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6를 지원합니다</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6은 이제 다음과 같은 제한 사항으로 지원됩니다.</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">vCenter 6.7 이상</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">SRM 8.2(8.1, 8.3 및 8)에서는 지원되지 않습니다. 4개 지원)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">상호 운용성 매트릭스 툴</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">를 확인하십시오<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> 최신 버전의 경우.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">향상된 성능</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">운영 성능은 SRM 작업 실행을 위한 핵심 요구 사항입니다. 최신 RTO 및 RPO의 요구 사항을 충족하기 위해 ONTAP 도구가 포함된 SRA에 세 가지 새로운 개선 사항이 추가되었습니다.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">* 동시 재보호 작업 지원. * SRA 9.7.1에서 처음 도입된 이 기능을 사용하면 두 개 이상의 복구 계획에서 동시에 재보호를 실행할 수 있으므로 페일오버 또는 마이그레이션 후 데이터 저장소를 재보호하는 데 필요한 시간을 줄이고 RTO 및 RPO 매개 변수를 계속 유지할 수 있습니다.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">* ONTAP Tools 9.8은 NAS 전용 최적화 모드를 새로 추가했습니다. * SVM 범위 계정을 사용하고 NFS 기반 데이터 저장소만 있는 ONTAP 클러스터에 연결할 때 지원되는 환경에서 NAS 전용 최적화 모드를 사용하여 최대 성능을 실현할 수 있습니다.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">* ONTAP 툴 9.12에 ONTAP의 SnapMirror 빠른 재동기화 기능이 추가되었습니다. * 이를 통해 프로세스 후 스토리지 효율성 절약 효과를 다시 계산할 필요 없이 미러를 빠르게 재동기화할 수 있습니다. 이 기능은 기본적으로 사용되지 않지만 기존 재동기화가 너무 오래 걸리거나 시간이 초과되는 대규모 환경에서는 사용할 수 있습니다.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">더 뛰어난 확장성</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">ONTAP 도구 SRA는 이제 SRM 8.3 이상에서 사용할 경우 최대 500개의 보호 그룹(PG)을 지원할 수 있습니다.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">오랫동안 기다려온 새로운 기능은 미션 크리티컬 애플리케이션에 볼륨 세분화 제로 RPO 데이터 복제 솔루션을 제공하는 ONTAP 9.5 이상의 SM-S(SnapMirror Synchronous)입니다. SM-S에는 ONTAP 도구 9.8 이상이 필요합니다.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST API 지원</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">이제 REST API를 통해 SRA 서버 구성을 관리할 수 있습니다. 자동화 워크플로 구축을 지원하기 위해 Swagger UI가 추가되었으며 ONTAP 툴 어플라이언스 에서 확인할 수 있습니다<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP는 2002년 현대적인 데이터 센터에 도입된 이후 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션이며, 비용을 절감하는 동시에 관리를 단순화하는 혁신적인 기능을 지속적으로 추가하고 있습니다.</block>
  <block id="0a0e655ee9ba6467857ebf014a268f29" category="doc">NetApp ONTAP를 사용하는 VMware 사이트 복구 관리자</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">이 문서는 이전에 게시된 기술 보고서 _TR-4900: VMware 사이트 복구 관리자를 ONTAP_ 로 대체합니다</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">모범 사례는 가이드 및 호환성 도구와 같은 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 권장 모범 사례가 귀사의 환경에 적합하지 않은 경우도 있지만, 일반적으로 대부분의 고객 요구사항을 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">이 문서는 VMware vSphere 9.12용 ONTAP 툴(NetApp 스토리지 복제 어댑터[SRA] 및 VASA 공급자[VP] 포함)과 함께 사용되는 ONTAP 9의 최신 릴리즈와 VMware Site Recovery Manager 8.7의 기능에 중점을 둡니다.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">SRM에 ONTAP를 사용해야 하는 이유</block>
  <block id="36c28121fc6c9b02a38c0b6c92654e9a" category="paragraph">ONTAP 소프트웨어로 구동되는 NetApp 데이터 관리 플랫폼은 SRM을 위해 가장 널리 채택된 스토리지 솔루션 중 일부입니다. 그 이유는 다양합니다. 업계에서 정의한 스토리지 효율성, 멀티 테넌시, 서비스 품질 제어, 공간 효율적인 스냅샷을 통한 데이터 보호, SnapMirror를 통한 복제를 제공하는 안전하고 뛰어난 성능의 유니파이드 프로토콜(NAS와 SAN을 함께 사용) 데이터 관리 플랫폼을 사용하기 때문입니다. 이 모든 기능은 기본 하이브리드 멀티 클라우드 통합을 활용하여 VMware 워크로드를 보호하고 다양한 자동화 및 오케스트레이션 툴을 손쉽게 사용할 수 있도록 지원합니다.</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">어레이 기반 복제에 SnapMirror를 사용하면 ONTAP의 가장 검증되고 성숙한 기술 중 하나를 활용할 수 있습니다. SnapMirror를 사용하면 전체 VM 또는 데이터 저장소가 아닌 변경된 파일 시스템 블록만 복제하여 안전하고 효율성이 높은 데이터 전송을 이용할 수 있습니다. 이러한 블록조차도 중복제거, 압축, 컴팩션과 같은 공간 절약 효과를 활용합니다. 최신 ONTAP 시스템은 이제 버전에 상관없이 SnapMirror를 사용하므로 소스 및 타겟 클러스터를 유연하게 선택할 수 있습니다. SnapMirror는 실제로 재해 복구에 사용할 수 있는 가장 강력한 툴 중 하나가 되었습니다.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">기존 NFS, iSCSI 또는 파이버 채널 연결 데이터 저장소(VVOL 데이터 저장소 지원)를 사용하는 경우 SRM은 재해 복구 또는 데이터 센터 마이그레이션 계획 및 오케스트레이션을 위해 최상의 ONTAP 기능을 활용하는 강력한 타사 오퍼링을 제공합니다.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">SRM이 ONTAP 9를 활용하는 방법</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM은 세 가지 주요 구성 요소가 포함된 가상 어플라이언스인 ONTAP for VMware vSphere와 통합하여 ONTAP 시스템의 고급 데이터 관리 기술을 활용합니다.</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">vCenter 플러그인을 사용하면 이전에 VSC(Virtual Storage Console)라고 부르던 기능을 통해 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 높이며, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이 플러그인을 사용하는 것이 좋습니다.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. VVOL(VMware Virtual Volumes)을 통해 스토리지 기능 프로필(VVOL 복제 기능 포함)과 개별 VM VVol 성능을 지원하고 관리할 수 있습니다. 또한 용량을 모니터링하고 프로파일 준수를 위한 알람을 제공합니다. SRM과 함께 VASA Provider for ONTAP를 사용하면 SRM 서버에 SRA 어댑터를 설치할 필요 없이 VVOL 기반 가상 머신을 지원할 수 있습니다.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA는 SRM과 함께 사용되어 기존 VMFS 및 NFS 데이터 저장소의 프로덕션 및 재해 복구 사이트 간에 VM 데이터 복제를 관리하고 DR 복제본의 무중단 테스트를 수행합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. SRA 서버 어플라이언스와 Windows SRM 서버용 SRA 어댑터 및 SRM 어플라이언스가 모두 포함됩니다.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">VASA Provider 설정에서 비 VVol 데이터 저장소 및/또는 활성화된 VVol 복제를 보호하기 위해 SRM 서버에 SRA 어댑터를 설치 및 구성한 후에는 재해 복구를 위해 vSphere 환경을 구성하는 작업을 시작할 수 있습니다.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA 및 VASA Provider는 SRM 서버에 대한 명령 및 제어 인터페이스를 제공하여 VMware VM(가상 시스템)이 포함된 ONTAP FlexVol과 이들을 보호하는 SnapMirror 복제를 관리합니다.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">SRM 8.3부터 SRM 서버에 새로운 SRM VVol Provider 제어 경로가 도입되어 vCenter Server와 통신하고 SRA를 사용하지 않고도 VASA Provider와 통신할 수 있게 되었습니다. 따라서 VASA는 긴밀한 통합을 위한 완벽한 API를 제공하므로 SRM 서버가 ONTAP 클러스터에 대한 훨씬 더 깊은 제어를 활용할 수 있게 되었습니다.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM은 NetApp의 독점 FlexClone 기술을 사용하여 DR 계획을 중단 없이 테스트하여 DR 사이트에 있는 보호된 데이터 저장소의 거의 즉각적인 클론을 생성할 수 있습니다. SRM은 안전한 테스트를 위한 샌드박스를 생성하여 실제 재해 발생 시 조직 및 고객이 보호를 받을 수 있도록 함으로써 재해 발생 시 조직의 장애 조치 실행 능력을 확실히 제공합니다.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">실제 재해 또는 계획된 마이그레이션이 있는 경우 SRM을 사용하면 최종 SnapMirror 업데이트(선택한 경우)를 통해 데이터 세트에 대한 최신 변경 사항을 보낼 수 있습니다. 그런 다음 미러를 해제하고 데이터 저장소를 DR 호스트에 마운트합니다. 이 시점에서 사전 계획된 전략에 따라 임의의 순서로 VM을 자동으로 켤 수 있습니다.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">ONTAP 및 기타 사용 사례를 지원하는 SRM: 하이브리드 클라우드 및 마이그레이션</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Equinix의 NetApp 프라이빗 스토리지</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">SRM 배포를 ONTAP 고급 데이터 관리 기능과 통합하면 로컬 스토리지 옵션에 비해 확장성과 성능이 크게 향상됩니다. 그 이상의 것은 하이브리드 클라우드의 유연성을 제공합니다. 하이브리드 클라우드를 사용하면 FabricPool StorageGRID와 같은 사내 S3 저장소일 수 있는를 사용하여 고성능 어레이에서 선호하는 하이퍼스케일러를 사용하여 사용하지 않는 데이터 블록을 계층화하여 비용을 절감할 수 있습니다. 또한 CVO(Cloud Volumes ONTAP) 또는 를 사용하여 소프트웨어 정의 ONTAP Select 또는 클라우드 기반 DR이 있는 에지 기반 시스템에 SnapMirror를 사용할 수도 있습니다<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> AWS(Amazon Web Services), Microsoft Azure 및 GCP(Google Cloud Platform)를 이용하여 클라우드에 완전히 통합된 스토리지, 네트워킹 및 컴퓨팅 서비스 스택을 구축할 수 있습니다.</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">그런 다음, FlexClone을 통해 스토리지 설치 공간이 거의 0에 가까운 클라우드 서비스 공급자의 데이터 센터 내에서 테스트 페일오버를 수행할 수 있습니다. 이제 조직을 보호하는 데 드는 비용이 그 어느 때보다 줄어듭니다.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">또한 SRM은 SnapMirror를 활용하여 VM을 하나의 데이터 센터에서 다른 데이터 센터로 효율적으로 전송하거나 자체 또는 NetApp 파트너 서비스 공급자의 수를 통해 동일한 데이터 센터 내에서 효율적으로 전송하여 계획된 마이그레이션을 실행하는 데 사용할 수 있습니다.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">복제 토폴로지</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다. 물리적 구성 요소는 논리적 클러스터 리소스가 구성되는 공유 리소스 풀을 제공합니다. 애플리케이션과 호스트는 볼륨 및 LIF가 포함된 SVM을 통해서만 데이터에 액세스합니다.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">각 NetApp SVM은 VMware vCenter Site Recovery Manager에서 어레이로 취급됩니다. SRM은 특정 어레이 간(또는 SVM 간) 복제 레이아웃을 지원합니다.</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">단일 VM은 VMDK(Virtual Machine Disk) 또는 RDM 같은 데이터를 소유할 수 없습니다. 이러한 데이터를 여러 SRM 스토리지에서 소유할 수 없는 이유는 다음과 같습니다.</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM에는 개별 물리적 컨트롤러가 아닌 SVM만 표시됩니다.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">SVM은 하나의 클러스터에서 여러 노드에 걸쳐 있는 LUN 및 볼륨을 제어할 수 있습니다.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">모범 사례</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">지원 가능성을 확인하려면 이 규칙을 염두에 두십시오. SRM 및 NetApp SRA를 사용하여 VM을 보호하려면 VM의 모든 부분이 하나의 SVM에만 존재해야 합니다. 이 규칙은 보호 사이트와 복구 사이트 모두에 적용됩니다.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">지원되는 SnapMirror 레이아웃</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">다음 그림은 SRM 및 SRA에서 지원하는 SnapMirror 관계 레이아웃 시나리오를 보여 줍니다. 복제된 볼륨의 각 VM은 각 사이트의 한 SRM 어레이(SVM)에만 데이터를 소유합니다.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">지원되는 Array Manager 레이아웃입니다</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">SRM에서 ABR(스토리지 기반 복제)을 사용하면 다음 스크린샷과 같이 보호 그룹이 단일 스토리지 쌍으로 격리됩니다. 이 시나리오에서는<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> 및<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> 로 피어링됩니다<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> 및<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> Insight 설문조사에 응답해 주세요. 그러나 보호 그룹을 생성할 때는 두 스토리지 쌍 중 하나만 선택할 수 있습니다.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">지원되지 않는 레이아웃입니다</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">지원되지 않는 구성에는 개별 VM이 소유하는 여러 SVM에 데이터(VMDK 또는 RDM)가 있습니다. 다음 그림에 표시된 예에서는<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> SRM을 사용하여 보호하도록 구성할 수 없는 이유<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> 에서 2개의 SVM에 데이터가 있습니다.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">개별 NetApp 볼륨이 하나의 소스 SVM에서 동일한 SVM의 여러 대상 또는 서로 다른 SVM에 복제된 모든 복제 관계를 SnapMirror 팬아웃(fan-out)이라고 합니다. SRM에서는 팬아웃이 지원되지 않습니다. 다음 그림에 표시된 예에서는<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> SnapMirror를 사용하여 서로 다른 두 위치에 복제되므로 SRM에서 보호를 위해 구성할 수 없습니다.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror 계단식 배열</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM은 소스 볼륨이 타겟 볼륨에 복제되고 해당 타겟 볼륨도 SnapMirror를 통해 다른 타겟 볼륨으로 복제되는 SnapMirror 관계의 다중 구간 기능을 지원하지 않습니다. 다음 그림에 표시된 시나리오에서는 사이트 간 장애 조치에 SRM을 사용할 수 없습니다.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror 및 SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">NetApp SnapVault 소프트웨어를 사용하면 NetApp 스토리지 시스템 간에 엔터프라이즈 데이터를 디스크 기반으로 백업할 수 있습니다. SnapVault와 SnapMirror는 동일한 환경에 공존할 수 있지만 SRM은 SnapMirror 관계의 페일오버만 지원합니다.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA는 를 지원합니다<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> 정책 유형.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault는 처음부터 ONTAP 8.2를 위해 재구축되었습니다. 이전 Data ONTAP 7-Mode 사용자에게도 유사한 점이 있긴 하지만, 이 버전의 SnapVault에서는 여러 가지 기능이 크게 향상되었습니다. 한 가지 중요한 발전은 SnapVault 전송 중에 운영 데이터의 스토리지 효율성을 유지할 수 있는 기능입니다.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">중요한 아키텍처 변화는 ONTAP 9의 SnapVault가 7-Mode SnapVault와 마찬가지로 qtree 레벨이 아닌 볼륨 레벨에서 복제된다는 점입니다. 이 설정은 SnapVault 관계의 소스가 볼륨이어야 하며 해당 볼륨이 SnapVault 보조 시스템의 자체 볼륨으로 복제되어야 함을 의미합니다.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">SnapVault가 사용되는 환경에서는 특히 이름이 지정된 스냅샷이 운영 스토리지 시스템에 생성됩니다. 구축된 구성에 따라 SnapVault 스케줄이나 NetApp Active IQ Unified Manager 같은 애플리케이션을 통해 운영 시스템에 명명된 스냅샷을 생성할 수 있습니다. 그런 다음 기본 시스템에서 생성된 명명된 스냅샷이 SnapMirror 대상에 복제되고 이 스냅샷에서 SnapVault 대상에 볼트가 됩니다.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">소스 볼륨은 DR 사이트의 SnapMirror 대상에 복제되는 계단식 구성으로 생성할 수 있으며, 이 구성에서는 볼륨을 SnapVault 타겟에 저장할 수 있습니다. 한 대상이 SnapMirror 대상이고 다른 대상이 SnapVault 대상인 팬아웃 관계에 소스 볼륨을 생성할 수도 있습니다. 그러나 SRM 페일오버 또는 복제 반전이 발생할 경우 SnapMirror 대상 볼륨을 볼트의 소스로 사용하도록 SRA는 SnapVault 관계를 자동으로 재구성하지 않습니다.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">SnapMirror 및 SnapVault for ONTAP 9에 대한 최신 정보는 를 참조하십시오<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">SnapVault 및 SRM이 동일한 환경에서 사용되는 경우 SnapVault 백업이 일반적으로 DR 사이트의 SnapMirror 대상에서 수행되는 SnapMirror와 SnapVault 다중 구간 구성을 사용하는 것이 좋습니다. 재해가 발생할 경우 이 구성을 사용하면 운영 사이트에 액세스할 수 없습니다. 복구 사이트에서 SnapVault 대상을 유지하면 복구 사이트에서 운영 중인 동안 SnapVault 백업을 계속할 수 있도록 장애 조치 후 SnapVault 백업을 재구성할 수 있습니다.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">VMware 환경에서 각 데이터 저장소에는 UUID(Universal Unique Identifier)가 있으며 각 VM에는 고유한 MOID(Managed Object ID)가 있습니다. 이러한 ID는 장애 조치 또는 장애 복구 중에 SRM에 의해 유지되지 않습니다. 데이터 저장소 UUID 및 VM MOID는 SRM에서 페일오버 중에 유지되지 않으므로 이러한 ID에 의존하는 모든 애플리케이션은 SRM 페일오버 후에 재구성해야 합니다. 애플리케이션의 예로는 SnapVault 복제를 vSphere 환경과 조정하는 NetApp Active IQ Unified Manager가 있습니다.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">다음 그림은 SnapVault 계단식으로 구성된 SnapMirror를 보여 줍니다. SnapVault 대상이 DR 사이트 또는 운영 사이트의 운영 중단으로 인해 영향을 받지 않는 3차 사이트에 있는 경우, 페일오버 후 백업을 계속할 수 있도록 환경을 재구성할 수 있습니다.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">다음 그림에서는 SRM을 사용하여 SnapMirror 복제를 기본 사이트로 되돌린 후의 구성을 보여 줍니다. 또한 SnapVault 백업이 현재 SnapMirror 소스에서 발생하도록 환경이 재구성되었습니다. 이 설정은 SnapMirror SnapVault 팬아웃 구성입니다.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">SRM이 페일백을 수행하고 SnapMirror 관계의 두 번째 반전을 수행한 후 운영 데이터가 기본 사이트로 돌아갑니다. 이 데이터는 SnapMirror 및 SnapVault 백업을 통해 DR 사이트로 페일오버 전의 방식과 동일하게 보호됩니다.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Site Recovery Manager 환경에서 Qtree 사용</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">qtree는 NAS에 대한 파일 시스템 할당량을 적용할 수 있는 특수 디렉토리입니다. ONTAP 9에서는 qtree를 생성할 수 있으며 qtree는 SnapMirror로 복제된 볼륨에 존재할 수 있습니다. 그러나 SnapMirror에서는 개별 qtree 또는 qtree 레벨 복제의 복제를 허용하지 않습니다. 모든 SnapMirror 복제는 볼륨 레벨에만 있습니다. 이러한 이유로 SRM에서는 qtree를 사용하지 않는 것이 좋습니다.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">FC 및 iSCSI 혼합 환경</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">지원되는 SAN 프로토콜(FC, FCoE 및 iSCSI)을 통해 ONTAP 9는 LUN 서비스를 제공합니다. 즉, LUN을 생성하여 연결된 호스트에 매핑할 수 있습니다. 클러스터는 여러 컨트롤러로 구성되며, 개별 LUN에 대한 다중 경로 I/O를 통해 관리되는 여러 논리적 경로가 있습니다. 호스트에서 ALUA(Asymmetric Logical Unit Access)가 사용되므로 LUN에 대한 최적화된 경로가 선택되고 데이터 전송을 위해 활성화됩니다. LUN에 대한 최적화된 경로(예: 포함된 볼륨이 이동됨)가 변경되면 ONTAP 9가 자동으로 해당 변경 사항을 인식하고 중단 없이 조정합니다. 최적화된 경로를 사용할 수 없게 되면 ONTAP는 무중단으로 다른 사용 가능한 경로로 전환할 수 있습니다.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM 및 NetApp SRA는 한 사이트에서 FC 프로토콜을 사용하고 다른 사이트에서는 iSCSI 프로토콜을 사용할 수 있도록 지원합니다. 하지만 동일한 ESXi 호스트 또는 동일한 클러스터의 다른 호스트에 FC 연결 데이터 저장소와 iSCSI 연결 데이터 저장소를 함께 사용할 수는 없습니다. SRM 페일오버 또는 테스트 페일오버 중에 SRM은 요청에 따라 ESXi 호스트의 모든 FC 및 iSCSI 이니시에이터를 포함하므로 SRM에서는 이 구성이 지원되지 않습니다.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM 및 SRA는 보호 사이트와 복구 사이트 간에 혼합 FC 및 iSCSI 프로토콜을 지원합니다. 그러나 각 사이트는 동일한 사이트에서 두 프로토콜을 모두 구성하지 않고 FC 또는 iSCSI 프로토콜을 하나만 사용하여 구성해야 합니다. FC와 iSCSI 프로토콜을 동일한 사이트에 모두 구성해야 하는 경우 일부 호스트는 iSCSI를 사용하고 다른 호스트는 FC를 사용하는 것이 좋습니다. 또한 이 경우에는 VM이 호스트 그룹 또는 다른 그룹으로 페일오버되도록 SRM 리소스 매핑을 설정하는 것이 좋습니다.</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">VVOL 복제 사용 시 SRM 문제 해결</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다. 예를 들어, 어레이 관리자 개념은 없습니다. 따라서,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> 및<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> 명령은 표시되지 않습니다.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">문제 해결 시 아래 나열된 새 워크플로를 이해하는 것이 좋습니다.</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">queryReplicationPeer: 두 오류 도메인 간의 복제 계약을 검색합니다.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">queryFaultDomain: 오류 도메인 계층을 검색합니다.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">queryReplicationGroup: 소스 또는 타겟 도메인에 있는 복제 그룹을 검색합니다.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: 소스와 대상 간의 데이터를 동기화합니다.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">queryPointInTimeReplica: 타겟의 시점 복제본을 검색합니다.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">testFailoverReplicationGroupStart: 테스트 대체 작동을 시작합니다.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">testFailoverReplicationGroupStop: 테스트 대체 작동을 종료합니다.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: 현재 테스트 중인 그룹을 프로덕션 환경으로 승격합니다.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">prepareFailoverReplicationGroup: 재해 복구를 준비합니다.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">failoverReplicationGroup: 재해 복구를 실행합니다.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">reverseReplicateGroup: 역방향 복제를 시작합니다.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">queryMatchingContainer: 지정된 정책으로 프로비저닝 요청을 충족할 수 있는 컨테이너(호스트 또는 복제 그룹과 함께)를 찾습니다.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">queryResourceMetadata: VASA 공급자에서 모든 리소스의 메타데이터를 검색하며 리소스 사용률을 queryMatchingContainer 함수에 대한 응답으로 반환할 수 있습니다.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">VVOL 복제 구성 시 가장 일반적인 오류는 SnapMirror 관계를 검색하지 못하는 것입니다. 이 문제는 볼륨 및 SnapMirror 관계가 ONTAP 도구 모음 외부에서 생성되기 때문에 발생합니다. 따라서 항상 SnapMirror 관계가 완전히 초기화되었는지, 그리고 복제된 VVol 데이터 저장소를 생성하기 전에 두 사이트의 ONTAP 도구에서 재검색을 실행하는 것이 좋습니다.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">추가 정보</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: ONTAP용 VMware vSphere
<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨
<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드
<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC ONTAP용 사용자 생성기
<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">VMware vSphere 리소스를 위한 ONTAP 툴
<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager 설명서
<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">상호 운용성 매트릭스 툴(IMT)</block>
  <block id="97cd1357ea4a16b44bd9e360127a1a9d" category="paragraph">을 참조하십시오<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> NetApp Support 사이트에서 본 문서에 기술된 제품과 기능 버전이 귀사의 환경에서 지원되는지 확인하십시오. NetApp IMT에는 NetApp이 지원하는 구성을 설계하는 데 사용할 수 있는 제품 구성요소 및 버전이 정의되어 있습니다. 구체적인 결과는 게시된 기술사양과 그에 따른 고객 설치 환경에 따라 달라집니다.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">배포 모범 사례</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SMT를 위한 SVM 레이아웃 및 Segmentation</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다. 한 SVM의 SVM 사용자는 다른 SVM에서 리소스를 액세스하거나 관리할 수 없습니다. 이렇게 하면 동일한 클러스터에서 고유한 SRM 워크플로우를 관리하는 여러 사업부에 대해 별도의 SVM을 생성하여 ONTAP 기술을 활용함으로써 전반적인 스토리지 효율성을 높일 수 있습니다.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">보안 제어를 개선하면서 성능을 향상할 뿐만 아니라 SVM 범위 계정 및 SVM 관리 LIF를 사용하여 ONTAP를 관리하는 것을 고려해 보십시오. SRA는 물리적 리소스를 포함하여 전체 클러스터의 모든 리소스를 처리할 필요가 없으므로 SVM 범위 연결을 사용할 때 기본적으로 성능이 향상됩니다. 대신, 특정 SVM에 추상화된 논리적 자산만 이해해야 합니다.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">NAS 프로토콜만 사용하는 경우(SAN 액세스 없음), 다음 매개 변수를 설정하여 새로운 NAS 최적화 모드를 활용할 수도 있습니다(SRA 및 VASA는 어플라이언스에서 동일한 백엔드 서비스를 사용하기 때문에 이름이 동일함).</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">의 제어판에 로그인합니다<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> 웹 기반 CLI 인터페이스를 클릭합니다.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">명령을 실행합니다<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">명령을 실행합니다<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">명령을 실행합니다<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">VVOL을 위한 ONTAP 툴 및 고려사항 배포</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">VVOL이 포함된 SRM을 사용하려면 클러스터 범위 자격 증명 및 클러스터 관리 LIF를 사용하여 스토리지를 관리해야 합니다. 이는 VASA Provider가 VM 스토리지 정책에 필요한 정책을 충족하기 위해 기본 물리적 아키텍처를 이해해야 하기 때문입니다. 예를 들어, All-Flash 스토리지가 필요한 정책이 있는 경우 VASA Provider는 모든 All-Flash 시스템을 확인할 수 있어야 합니다.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">또 다른 구축 모범 사례는 관리 중인 VVOL 데이터 저장소에 ONTAP 툴 어플라이언스를 저장하지 않는 것입니다. 어플라이언스가 오프라인이므로 어플라이언스에 대한 스왑 VVol을 생성할 수 없으므로 VASA Provider의 전원을 켤 수 없는 상황이 발생할 수 있습니다.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">ONTAP 9 시스템 관리 모범 사례</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">앞서 언급했듯이 클러스터 또는 SVM 범위의 자격 증명 및 관리 LIF를 사용하여 ONTAP 클러스터를 관리할 수 있습니다. 최적의 성능을 위해 VVOL을 사용하지 않을 때마다 SVM 범위 자격 증명 사용을 고려할 수 있습니다. 그러나 이렇게 하면 일부 요구 사항을 인식하고 일부 기능을 사용할 수 없게 됩니다.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">기본 vsadmin SVM 계정에는 ONTAP 툴 작업을 수행하는 데 필요한 액세스 수준이 없습니다. 따라서 새 SVM 계정을 생성해야 합니다.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">ONTAP 9.8 이상을 사용 중인 경우 NetApp은 ONTAP 시스템 관리자의 사용자 메뉴와 ONTAP 툴 어플라이언스에서 사용할 수 있는 JSON 파일을 함께 사용하여 RBAC 최소 권한 사용자 계정을 만드는 것이 좋습니다<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. 관리자 암호를 사용하여 JSON 파일을 다운로드합니다. SVM 또는 클러스터 범위 어카운트에 사용할 수 있습니다.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">NetApp Support 사이트 Toolchest</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">ONTAP 9.6 이하를 사용하는 경우 에서 사용할 수 있는 RBAC 사용자 작성 도구(RUC)를 사용해야 합니다<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">vCenter UI 플러그인, VASA Provider 및 SRA 서버는 모두 완전히 통합된 서비스이므로 ONTAP용 vCenter UI 툴에서 스토리지를 추가하는 것과 동일한 방식으로 SRM에서 SRA 어댑터에 스토리지를 추가해야 합니다. 그렇지 않으면 SRA 서버는 SRA 어댑터를 통해 SRM에서 전송되는 요청을 인식하지 못할 수 있습니다.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">SVM 범위 자격 증명을 사용할 때는 NFS 경로 검사가 수행되지 않습니다. 물리적 위치가 SVM에서 논리적으로 추상화되기 때문입니다. 하지만 최신 ONTAP 시스템은 간접 경로를 사용할 때 눈에 띄는 성능 저하가 더 이상 발생하지 않으므로 이는 우려의 원인이 아닙니다.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">스토리지 효율성으로 인한 애그리게이트 공간 절약은 보고되지 않을 수 있습니다.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">지원되는 경우 로드 공유 미러를 업데이트할 수 없습니다.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">SVM 범위 자격 증명으로 관리되는 ONTAP 시스템에서는 EMS 로깅이 수행되지 않을 수 있습니다.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">가능하면 항상 ONTAP 툴을 사용하여 데이터 저장소와 볼륨을 프로비저닝하십시오. 이렇게 하면 볼륨, 접합 경로, LUN, igroup, 엑스포트 정책이 및 기타 설정은 호환되는 방식으로 구성됩니다.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">운영 모범 사례</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM은 SRA를 통해 어레이 기반 복제를 사용할 때 ONTAP 9를 통해 iSCSI, 파이버 채널 및 NFS 버전 3을 지원합니다. SRM은 기존 데이터 저장소 또는 VVOL 데이터 저장소를 사용하는 NFS 버전 4.1에 대한 어레이 기반 복제를 지원하지 않습니다.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">접속을 확인하려면 항상 대상 ONTAP 클러스터에서 DR 사이트의 새 테스트 데이터 저장소를 마운트하고 마운트 해제할 수 있는지 확인하십시오. 데이터 저장소 연결에 사용할 각 프로토콜을 테스트합니다. 모범 사례는 ONTAP 툴을 사용하여 테스트 데이터 저장소를 생성하는 것입니다. 이는 SRM의 지시에 따라 모든 데이터 저장소 자동화를 수행하기 때문입니다.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN 프로토콜은 각 사이트에서 동종이어야 합니다. NFS와 SAN을 혼합할 수 있지만 SAN 프로토콜을 사이트 내에서 혼합하면 안 됩니다. 예를 들어 사이트 A에서는 FCP를, 사이트 B에서는 iSCSI를 사용할 수 있습니다 사이트 A에서 FCP와 iSCSI를 둘 다 사용해서는 안 됩니다 그 이유는 SRA가 복구 사이트에 혼합 igroup을 생성하지 않으며 SRM은 SRA에 제공된 이니시에이터 목록을 필터링하지 않기 때문입니다.</block>
  <block id="62a631034cae40cfcee909c69c12c5b3" category="paragraph">자동 크기 조정이 필요한 비상 용량을 충분히 제공할 수 없는 경우 공간이 부족한 경우 가동 시간을 유지하기 위해 스냅샷을 자동으로 제거하도록 NetApp ONTAP 9를 구성할 수 있습니다. 이 기능의 기본 설정은 SnapMirror에 의해 생성된 스냅샷을 자동으로 삭제하지 않습니다. SnapMirror 스냅샷이 삭제된 경우 NetApp SRA는 영향을 받는 볼륨에 대해 복제를 역순으로 재동기화할 수 없습니다. ONTAP이 SnapMirror 스냅샷을 삭제하지 못하도록 하려면 스냅샷 자동 삭제 기능을 구성하여 시도하십시오.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">볼륨을 자동으로 확장하거나 축소하도록 구성</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">볼륨 자동 크기 조정을 로 설정해야 합니다<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> SAN 데이터 저장소 및 가 포함된 볼륨의 경우<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> NFS 데이터 저장소입니다. 에 대해 자세히 알아보십시오 <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">SPBM(Storage Policy Based Management) 및 VVol</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">다음 스크린샷에서는 VM 스토리지 정책 생성 마법사에 표시되는 SnapMirror 일정의 예를 보여 줍니다.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">ONTAP VASA Provider는 이기종 스토리지로의 페일오버를 지원합니다. 예를 들어, 시스템은 에지 위치의 ONTAP Select에서 코어 데이터 센터의 AFF 시스템으로 페일오버할 수 있습니다. 스토리지의 유사성에 관계없이 항상 복제 가능 VM 스토리지 정책에 대한 스토리지 정책 매핑 및 역매핑을 구성하여 복구 사이트에서 제공되는 서비스가 기대 사항 및 요구 사항을 충족하는지 확인해야 합니다. 다음 스크린샷에서는 샘플 정책 매핑을 보여 줍니다.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">VVOL 데이터 저장소의 복제된 볼륨을 생성합니다</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">VVOL 및 SRM의 경우 한 가지 주의해야 합니다. 보호 VM과 보호되지 않은 VM을 동일한 VVOL 데이터 저장소에 혼합하지 마십시오. 그 이유는 SRM을 사용하여 DR 사이트로 페일오버할 때 보호 그룹에 속한 VM만 DR에서 온라인 상태로 전환되기 때문입니다. 따라서 SnapMirror를 DR에서 운영 환경으로 다시 되돌릴 때 페일오버되지 않은 VM을 덮어쓰거나 중요한 데이터를 포함할 수 있습니다.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">스토리지 쌍 정보</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">SRM에서 어레이 쌍을 구성할 때는 항상 ONTAP 툴에 추가한 것과 같은 방법으로 SRM에 어레이 쌍을 추가해야 합니다. 즉, 이들은 동일한 사용자 이름, 암호 및 관리 LIF를 사용해야 합니다. 이 요구 사항은 SRA가 어레이와 제대로 통신하도록 보장합니다. 다음 스크린샷은 ONTAP 툴에 클러스터가 표시되는 방식과 이를 어레이 관리자에 추가하는 방법을 보여 줍니다.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">복제 그룹 정보</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">복제 그룹에는 함께 복구되는 가상 머신의 논리적 컬렉션이 포함됩니다. ONTAP 툴 VASA Provider는 자동으로 복제 그룹을 생성합니다. ONTAP SnapMirror 복제는 볼륨 레벨에서 수행되기 때문에 볼륨의 모든 VM이 동일한 복제 그룹에 속해 있습니다.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">복제 그룹에 대한 마지막 고려 사항은 각 그룹이 기본적으로 논리적 정합성 보장 그룹이라는 점입니다(SRM 정합성 보장 그룹과 혼동하지 마십시오). 볼륨의 모든 VM이 동일한 스냅샷을 사용하여 함께 전송되기 때문입니다. 따라서 VM이 서로 일치해야 하는 경우 동일한 FlexVol에 VM을 저장하는 것이 좋습니다.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">보호 그룹 정보</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">보호 그룹은 보호 사이트에서 함께 복구되는 그룹으로 VM 및 데이터 저장소를 정의합니다. 보호 사이트는 정상적인 정상 상태 작업 중에 보호 그룹에 구성된 VM이 존재하는 곳입니다. SRM이 보호 그룹에 대해 여러 스토리지 관리자를 표시할 수 있지만 보호 그룹은 여러 스토리지 관리자를 포괄할 수 없습니다. 따라서 서로 다른 SVM의 데이터 저장소에 VM 파일을 확장해서는 안 됩니다.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">복구 계획에 대해 설명합니다</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">복구 계획은 동일한 프로세스에서 복구할 보호 그룹을 정의합니다. 동일한 복구 계획에서 여러 보호 그룹을 구성할 수 있습니다. 또한 복구 계획 실행을 위한 추가 옵션을 사용하기 위해 단일 보호 그룹을 여러 복구 계획에 포함할 수 있습니다.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">복구 계획을 사용하면 SRM 관리자가 우선 순위 그룹에 VM을 1(가장 높음)에서 5(가장 낮음)까지 할당하고 3(중간)을 기본값으로 지정하여 복구 워크플로를 정의할 수 있습니다. 우선 순위 그룹 내에서 VM을 종속성에 맞게 구성할 수 있습니다.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp은 애플리케이션 팀과 협력하여 페일오버 시나리오에 필요한 운영 순서를 파악하고 그에 따라 복구 계획을 수립하는 것이 좋습니다.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">테스트 대체 작동</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">또한, 특히 VM 스토리지를 재구성한 후에는 게스트 내 애플리케이션 기능을 확인하는 것이 좋습니다.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">테스트 복구 작업이 수행되면 VM에 대한 전용 테스트 버블 네트워크가 ESXi 호스트에 생성됩니다. 그러나 이 네트워크는 물리적 네트워크 어댑터에 자동으로 연결되지 않으므로 ESXi 호스트 간에 연결을 제공하지 않습니다. DR 테스트 중에 서로 다른 ESXi 호스트에서 실행 중인 VM 간의 통신을 허용하기 위해 DR 사이트의 ESXi 호스트 간에 물리적 전용 네트워크가 생성됩니다. 테스트 네트워크가 전용인지 확인하기 위해 테스트 버블 네트워크를 물리적으로 또는 VLAN 또는 VLAN 태깅을 사용하여 분리할 수 있습니다. VM이 복구될 때 실제 운영 시스템과 충돌할 수 있는 IP 주소를 사용하여 운영 네트워크에 배치할 수 없으므로 이 네트워크를 운영 네트워크와 분리해야 합니다. SRM에서 복구 계획을 생성할 때 생성된 테스트 네트워크를 테스트 중에 VM을 연결할 전용 네트워크로 선택할 수 있습니다.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">테스트를 검증하고 더 이상 필요하지 않은 후에는 정리 작업을 수행합니다. 정리 작업을 실행하면 보호된 VM이 초기 상태로 돌아가고 복구 계획이 준비 상태로 재설정됩니다.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">페일오버 고려 사항</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">이 가이드에 언급된 작업 순서 외에 사이트 장애 조치 시 몇 가지 다른 고려 사항이 있습니다.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">사이트 간 네트워크 차이는 문제가 될 수 있습니다. 일부 환경에서는 운영 사이트와 DR 사이트 모두에서 동일한 네트워크 IP 주소를 사용할 수 있습니다. 이러한 기능을 확장 가상 LAN(VLAN) 또는 확장 네트워크 설정이라고 합니다. 다른 환경에서는 DR 사이트와 관련하여 운영 사이트에서 서로 다른 네트워크 IP 주소(예: VLAN)를 사용해야 할 수 있습니다.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">SRM의 NSX-T 옵션</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware는 이 문제를 해결할 수 있는 여러 가지 방법을 제공합니다. VMware NSX-T Data Center와 같은 네트워크 가상화 기술은 운영 환경의 계층 2에서 계층 7까지 전체 네트워킹 스택을 추상화하여 보다 휴대성이 뛰어난 솔루션을 제공합니다. 에 대해 자세히 알아보십시오 <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">VMware 설명서</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">복구 계획에서 각 VM의 속성을 편집하지 않고도 여러 VM에 서로 다른 네트워크 설정을 적용하도록 SRM을 구성하려면 VMware에서 DR-IP-customizer라는 도구를 제공합니다. 이 유틸리티를 사용하는 방법은 을 참조하십시오 <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">재보호</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">복구 후에는 복구 사이트가 새 운영 사이트가 됩니다. 복구 작업이 SnapMirror 복제를 중단했기 때문에 새 프로덕션 사이트는 이후의 재해로부터 보호되지 않습니다. 모범 사례는 복구 후 즉시 새 프로덕션 사이트를 다른 사이트로 보호하는 것입니다. 원래 운영 사이트가 작동 중인 경우 VMware 관리자는 원래 운영 사이트를 새 복구 사이트로 사용하여 새 운영 사이트를 보호할 수 있으므로 보호 방향을 효과적으로 바꿀 수 있습니다. 재보호는 비치명적인 오류에서만 사용할 수 있습니다. 따라서 원래 vCenter Server, ESXi Server, SRM Server 및 해당 데이터베이스를 최종적으로 복구할 수 있어야 합니다. 사용할 수 없는 경우 새 보호 그룹과 새 복구 계획을 생성해야 합니다.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">장애 복구 작업은 기본적으로 이전과 다른 방식으로 장애 조치입니다. 모범 사례로서, 원래 사이트가 장애 복구를 시도하기 전에 허용 가능한 수준의 기능으로 복구되었는지 또는 다시 말해 원래 사이트로 장애 조치를 수행하는 것이 좋습니다. 원래 사이트가 여전히 손상된 경우 장애가 충분히 해결될 때까지 페일백을 지연해야 합니다.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">또 다른 장애 복구 모범 사례는 재보호 완료 후 그리고 최종 장애 복구를 수행하기 전에 항상 테스트 장애 조치를 수행하는 것입니다. 이렇게 하면 원래 사이트에 있는 시스템이 작업을 완료할 수 있는지 확인합니다.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">원래 사이트를 다시 보호합니다</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">페일백 후 재보호를 실행하면 기본적으로 환경이 원래 상태로 전환되며, 이때 SnapMirror 복제가 운영 사이트에서 복구 사이트로 다시 실행됩니다.</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">NetApp ONTAP Tools for VMware vSphere를 사용한 소프트웨어 엔지니어링에서는 다음과 같은 안전한 개발 활동을 활용합니다.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">* 위협 모델링. * 위협 모델링의 목적은 소프트웨어 개발 수명 주기 초기에 피처, 부품 또는 제품의 보안 결함을 발견하기 위한 것입니다. 위협 모델은 응용 프로그램의 보안에 영향을 주는 모든 정보의 구조적 표현입니다. 본질적으로 보안 렌즈를 통해 응용 프로그램과 환경을 볼 수 있습니다.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">* DAST(Dynamic Application Security Testing). * 이 기술은 실행 중인 응용 프로그램의 취약한 상태를 감지하도록 설계되었습니다. DAST는 웹 활성화 애플리케이션의 노출된 HTTP 및 HTML 인터페이스를 테스트합니다.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">* 타사 코드 통화. * 오픈 소스 소프트웨어(OSS)를 통한 소프트웨어 개발의 일환으로 제품에 통합된 OSS와 관련된 보안 취약점을 해결해야 합니다. 이는 새로운 OSS 버전에 새로 발견된 취약점이 언제든지 보고될 수 있기 때문에 지속적인 노력입니다.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">* 취약성 검사. * 취약성 검사의 목적은 NetApp 제품이 고객에게 공개되기 전에 NetApp 제품의 알려진 공통 보안 취약점을 감지하는 것입니다.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* 침투 테스트 * 침투 테스트는 시스템, 웹 응용 프로그램 또는 네트워크를 평가하여 공격자가 악용할 수 있는 보안 취약점을 찾는 프로세스입니다. NetApp의 침투 테스트(펜 테스트)는 승인되고 신뢰할 수 있는 타사 기업의 그룹에 의해 수행됩니다. 이러한 테스트 범위에는 정교한 악용 방법이나 도구를 사용하는 악의적인 침입자나 해커에 유사한 응용 프로그램 또는 소프트웨어에 대한 공격이 포함됩니다.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">제품 보안 기능</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">VMware vSphere용 NetApp ONTAP 툴에는 각 릴리즈에 다음과 같은 보안 기능이 포함되어 있습니다.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">* 로그인 배너. * SSH는 기본적으로 비활성화되어 있으며 VM 콘솔에서 활성화된 경우 1회만 로그인할 수 있습니다. 사용자가 로그인 프롬프트에 사용자 이름을 입력하면 다음 로그인 배너가 표시됩니다.</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">경고:* 이 시스템에 대한 무단 액세스는 금지되며 법률로 기소됩니다. 이 시스템에 액세스하면 무단 사용이 의심되는 경우 사용자의 조치를 모니터링할 수 있다는 데 동의하는 것입니다.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">사용자가 SSH 채널을 통한 로그인을 완료하면 다음 텍스트가 표시됩니다.</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">* 역할 기반 액세스 제어(RBAC). * 두 가지 유형의 RBAC 컨트롤이 ONTAP 도구에 연결되어 있습니다.</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">기본 vCenter Server 권한</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">이 링크</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">vCenter 플러그인별 권한 자세한 내용은 을 참조하십시오<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">* 암호화된 통신 채널. * 모든 외부 통신은 TLS 버전 1.2를 사용하여 HTTPS를 통해 이루어집니다.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">* 최소 포트 노출. * 필요한 포트만 방화벽에서 열립니다.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">다음 표에서는 열려 있는 포트의 세부 정보를 설명합니다.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4/V6 포트 번호</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">방향</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">기능</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">인바운드</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">REST API용 HTTPS 연결</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043을 참조하십시오</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS 연결</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060입니다</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">HTTPS 연결
https 연결을 통한 SOAP에 사용됩니다
클라이언트가 ONTAP 도구 API 서버에 연결할 수 있도록 하려면 이 포트를 열어야 합니다.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH(기본적으로 비활성화됨)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080입니다</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS 연결 - VP 및 SRA - 루프백에서만 내부 연결</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">HTTPS 연결 - VP 및 SRA
https 연결을 통한 SOAP에 사용됩니다</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP 트랩 패킷입니다</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527년</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">내부 전용</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby 데이터베이스 포트, 이 컴퓨터와 자체 사이에서만, 외부 연결은 허용되지 않음 -- 내부 연결만</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">양방향</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">ONTAP 클러스터에 연결하는 데 사용됩니다</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">* CA(인증 기관) 서명 인증서 지원. * VMware vSphere용 ONTAP 툴은 CA 서명 인증서를 지원합니다. 자세한 내용은 다음을 참조하십시오<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">* 감사 로깅. * 지원 번들은 다운로드할 수 있으며 매우 자세히 설명되어 있습니다. ONTAP 도구는 모든 사용자 로그인 및 로그아웃 활동을 별도의 로그 파일에 기록합니다. VASA API 호출은 전용 VASA 감사 로그(로컬 CXF.log)에 기록됩니다.</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">암호 정책 * 다음 암호 정책을 따릅니다.</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">암호는 로그 파일에 기록되지 않습니다.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">암호는 일반 텍스트로 전달되지 않습니다.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">암호는 설치 과정 중에 구성됩니다.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">암호 기록은 구성 가능한 매개 변수입니다.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">최소 암호 사용 기간은 24시간으로 설정됩니다.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">암호 필드에 대한 자동 완성 기능이 비활성화됩니다.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP 도구는 SHA256 해싱을 사용하여 저장된 모든 자격 증명 정보를 암호화합니다.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">SnapCenter 플러그인 VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphere 소프트웨어 엔지니어링은 다음과 같은 안전한 개발 활동을 사용합니다.</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">* DAST(Dynamic Application Security Testing). * 실행 상태의 응용 프로그램에서 취약한 상태를 감지하도록 설계된 기술입니다. DAST는 웹 활성화 애플리케이션의 노출된 HTTP 및 HTML 인터페이스를 테스트합니다.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">* 타사 코드 통화. * 소프트웨어를 개발하고 오픈 소스 소프트웨어(OSS)를 사용하는 과정에서 제품에 통합된 OSS와 관련된 보안 취약점을 해결하는 것이 중요합니다. 이는 항상 OSS 구성 요소 버전에 새로 발견된 취약점이 보고될 수 있기 때문에 지속적으로 발생하는 것입니다.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* 침투 테스트 * 침투 테스트는 시스템, 웹 응용 프로그램 또는 네트워크를 평가하여 공격자가 악용할 수 있는 보안 취약점을 찾는 프로세스입니다. NetApp의 침투 테스트(펜 테스트)는 승인되고 신뢰할 수 있는 타사 기업의 그룹에 의해 수행됩니다. 이러한 테스트 범위에는 정교한 악용 방법이나 도구를 사용하는 악의적인 침입자나 해커 같은 응용 프로그램 또는 소프트웨어에 대한 공격이 포함됩니다.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">제품 보안 문제의 대응 활동.* 보안 취약점은 회사 내외부에서 발견되며, 적절한 시기에 해결하지 못할 경우 NetApp의 평판에 심각한 위험을 초래할 수 있습니다. 이 프로세스를 용이하게 하기 위해 PSIRT(Product Security Incident Response Team)는 취약점을 보고 및 추적합니다.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">VMware vSphere용 NetApp SnapCenter 플러그인에는 각 릴리즈마다 다음과 같은 보안 기능이 포함되어 있습니다.</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">* 제한된 셸 액세스. * SSH는 기본적으로 비활성화되어 있으며, VM 콘솔에서 활성화된 경우에만 1회 로그인이 허용됩니다.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">로그인 배너에 액세스 경고 * 로그인 프롬프트에 사용자 이름을 입력하면 다음 로그인 배너가 표시됩니다.</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">사용자가 SSH 채널을 통해 로그인을 완료하면 다음 출력이 표시됩니다.</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">* 역할 기반 액세스 제어(RBAC). * 두 가지 유형의 RBAC 컨트롤이 NetApp ONTAP 도구에 연결되어 있습니다.</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">기본 vCenter Server 권한</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">역할 기반 액세스 제어(RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">VMware vCenter 플러그인별 권한 자세한 내용은 을 참조하십시오<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">* 암호화된 통신 채널. * 모든 외부 통신은 TLS를 사용하여 HTTPS를 통해 이루어집니다.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">다음 표에는 열려 있는 포트 세부 정보가 나와 있습니다.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">TCP v4/V6 포트 번호</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144를 참조하십시오</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">OVA GUI에 대한 HTTPS 연결</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH(기본적으로 비활성화됨)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306입니다</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL(내부 연결에만 해당, 외부 연결은 기본적으로 비활성화됨)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx(데이터 보호 서비스)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">SSL 인증서를 생성 및/또는 VMware vSphere용 SnapCenter 플러그인(SCV)으로 가져오는 방법</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">* CA(인증 기관) 서명 인증서 지원 * VMware vSphere용 SnapCenter 플러그인은 CA 서명 인증서의 기능을 지원합니다. 을 참조하십시오<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">* 암호 정책 * 다음 암호 정책이 적용됩니다.</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">모든 자격 증명 정보는 SHA256 해싱을 사용하여 저장됩니다.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*기본 운영 체제 이미지.* 이 제품은 제한된 액세스 및 쉘 액세스가 비활성화된 OVA용 Debian Base OS와 함께 제공됩니다. 이렇게 하면 공격 발생 가능성이 줄어듭니다. 모든 SnapCenter 릴리스 기본 운영 체제는 보안 범위를 극대화하기 위해 최신 보안 패치로 업데이트됩니다.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp은 VMware vSphere 어플라이언스인 SnapCenter 플러그인과 관련된 소프트웨어 기능 및 보안 패치를 개발한 다음 고객에게 번들 소프트웨어 플랫폼으로 배포합니다. 이러한 어플라이언스에는 특정 Linux 하위 운영 체제 종속성 및 NetApp의 독점 소프트웨어가 포함되어 있으므로 하위 운영 체제를 변경하지 않는 것이 좋습니다. 이 경우 NetApp 어플라이언스에 영향을 줄 가능성이 매우 높기 때문입니다. 이는 NetApp의 어플라이언스 지원 기능에 영향을 미칠 수 있습니다. 보안 관련 문제를 해결하기 위해 NetApp은 어플라이언스의 최신 코드 버전을 테스트하고 구축할 것을 권장합니다.</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">ONTAP 기반 MySQL</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">I/O 스케줄러</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Linux 커널은 블록 장치의 I/O를 스케줄링하여 낮은 레벨의 제어를 허용합니다.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Linux의 다양한 배포 버전에서의 기본값은 상당히 다릅니다. MySQL은 를 사용할 것을 권장합니다<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> 또는 a<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Linux에서 네이티브 비동기식 I/O(AIO)를 사용하는 I/O 스케줄러. 일반적으로 NetApp 고객 및 내부 테스트가 NoOps를 통해 더 나은 결과를 나타냈습니다.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">MySQL의 InnoDB 스토리지 엔진은 Linux의 비동기 I/O 하위 시스템(네이티브 AIO)을 사용하여 데이터 파일 페이지에 대한 읽기 및 쓰기 요청을 수행합니다. 이 동작은 에 의해 제어됩니다<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> 구성 옵션 - 기본적으로 활성화되어 있습니다. 기본 AIO를 사용할 경우 입출력 스케줄러 유형이 입출력 성능에 더 큰 영향을 미칩니다. 벤치마크를 수행하여 워크로드 및 환경에 가장 적합한 결과를 제공하는 I/O 스케줄러를 결정합니다.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">I/O 스케줄러 구성에 관한 관련 Linux 및 MySQL 설명서를 참조하십시오.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">스토리지 구성</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">InnoDB_log_file_size입니다</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">InnoDB 로그 파일 크기에 적합한 크기를 선택하는 것은 쓰기 작업과 서버 충돌 후 적절한 복구 시간을 갖는 데 중요합니다.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">많은 트랜잭션이 파일에 로그인되기 때문에 로그 파일 크기는 쓰기 작업에 중요합니다. 레코드가 수정되면 변경 내용이 테이블스페이스에 즉시 다시 기록되지 않습니다. 대신 변경 내용이 로그 파일 끝에 기록되고 페이지가 더티(dirty)로 표시됩니다. InnoDB는 로그를 사용하여 랜덤 I/O를 순차적 I/O로 변환합니다</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">로그가 가득 차면 로그 파일의 공간을 확보하기 위해 더티 페이지가 테이블스페이스에 순서대로 기록됩니다. 예를 들어 트랜잭션 중에 서버가 충돌하고 쓰기 작업이 로그 파일에만 기록된다고 가정합니다. 서버가 다시 가동되기 전에 로그 파일에 기록된 변경 내용이 재생되는 복구 단계를 거쳐야 합니다. 로그 파일에 있는 항목이 많을수록 서버가 복구하는 데 더 오래 걸립니다.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">이 예에서 로그 파일 크기는 복구 시간과 쓰기 성능에 모두 영향을 줍니다. 로그 파일 크기에 적합한 숫자를 선택할 때는 복구 시간과 쓰기 성능의 균형을 맞춥니다. 일반적으로 128M과 512M 사이의 모든 것이 좋은 가치가 있습니다.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">ONTAP의 MySQL 데이터베이스</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL 및 MariaDB 및 Percona MySQL을 포함한 그 변종은 세계에서 가장 인기있는 데이터베이스입니다.</block>
  <block id="478f00c3805e92ad9e8a7cd4f335a020" category="admonition">ONTAP 및 MySQL 데이터베이스에 대한 이 문서는 이전에 게시된 _TR-4722: NetApp ONTAP 모범 사례에 기반한 MySQL 데이터베이스를 대체합니다. _</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">InnoDB_flush_method 를 참조하십시오</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">innodb_flush_method 매개 변수는 InnoDB가 로그 및 데이터 파일을 열고 플러시하는 방법을 지정합니다.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">최적화</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">InnoDB 최적화에서 이 매개 변수를 설정하면 해당되는 경우 데이터베이스 성능이 조정됩니다.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">다음 옵션은 InnoDB를 통해 파일을 플러시하는 것입니다.</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB는 를 사용합니다<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> 데이터 및 로그 파일을 모두 플러시하기 위한 시스템 호출입니다. 이 옵션이 기본 설정입니다.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB는 를 사용합니다<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> 로그 파일을 열고 플러시하는 옵션과 데이터 파일을 플러시하기 위한 fsync() 옵션을 선택합니다. InnoDB는 사용하지 않습니다<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> 유닉스의 많은 변종에서 그것에 문제가 있기 때문에 직접.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB는 를 사용합니다<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> 옵션(또는<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Solaris의 경우)를 사용하여 데이터 파일을 열고 사용합니다<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> 데이터 및 로그 파일을 모두 플러시합니다. 이 옵션은 일부 GNU/Linux 버전, FreeBSD 및 Solaris에서 사용할 수 있습니다.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB는 를 사용합니다<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> 입출력 플러싱 중에 옵션을 사용할 수 있지만 이 옵션은 를 건너뜁니다<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> 이후 시스템 호출 이 옵션은 일부 파일 시스템 유형(예: XFS)에는 적합하지 않습니다. 파일 시스템에 가 필요한지 확실하지 않은 경우<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> 예를 들어 모든 파일 메타데이터를 보존하려면 시스템 호출을 사용합니다<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> 옵션을 선택합니다.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">관찰</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">NetApp 랩 테스트에서 는 를 선택합니다<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> 기본 옵션은 NFS 및 SAN에서 사용되었으며 에 비해 성능이 탁월했습니다<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. 으로 플러시 방법을 사용하는 동안<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> ONTAP에서는 클라이언트가 4096 블록의 테두리에서 많은 싱글바이트 쓰기를 직렬 방식으로 기록하는 것을 확인했습니다. 이러한 쓰기는 네트워크에서 지연 시간이 증가하고 성능이 저하됩니다.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">Open_file_limits 를 참조하십시오</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">를 클릭합니다<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> 매개 변수는 운영 체제에서 mysqld를 열도록 허용하는 파일 수를 결정합니다.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">런타임에 이 매개 변수의 값은 시스템에서 허용하는 실제 값이며 서버 시작 시 지정한 값과 다를 수 있습니다. MySQL이 열려 있는 파일 수를 변경할 수 없는 시스템의 값은 0입니다. 효과<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> 값은 시스템 시작 시 지정된 값(있는 경우)과 의 값을 기반으로 합니다<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> 및<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> 다음 수식을 사용하여 다음을 실행합니다.</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 이상<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> 를 누릅니다 <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> x 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> x 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">양수인 경우 운영 체제 제한</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">운영 체제 제한이 무한대인 경우:<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> 시작 시 값이 지정되고 없는 경우 5,000입니다</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">서버는 이 네 개의 최대 값을 사용하여 파일 설명자의 수를 가져오려고 시도합니다. 이렇게 많은 설명자를 얻을 수 없는 경우 서버는 시스템에서 허용하는 수만큼 얻기를 시도합니다.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">InnoDB_LRU_scan_depth 를 선택합니다</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">를 클릭합니다<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> 매개 변수는 InnoDB 버퍼 풀에 대한 플러시 작업의 알고리즘 및 휴리스틱에 영향을 줍니다.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">이 매개 변수는 I/O 집약적인 워크로드를 성능 전문가에 주로 적용됩니다. 각 버퍼 풀 인스턴스에 대해 이 매개 변수는 LRU(Least Recently Used) 페이지 목록에서 페이지 클리너 스레드가 계속 스캔해야 하는 범위를 지정하며 플러시할 더티 페이지를 찾습니다. 이 백그라운드 작업은 초당 한 번 수행됩니다.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">값을 위 또는 아래로 조정하여 사용 가능한 페이지 수를 최소화할 수 있습니다. 스캔에 상당한 성능 비용이 들 수 있으므로 값을 필요 이상으로 설정하지 마십시오. 또한 버퍼 풀 인스턴스의 수를 변경할 때 이 매개 변수를 조정하는 것도 고려하십시오. 그 이유는 무엇입니까<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> 페이지 클리너 스레드에서 초당 수행하는 작업 양을 정의합니다.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">기본값보다 작은 설정은 대부분의 워크로드에 적합합니다. 일반적인 작업 부하에서 여유 I/O 용량이 있는 경우에만 이 값을 높이는 것이 좋습니다. 반면, 쓰기 집약적 워크로드에서 I/O 용량이 포화되면 특히 버퍼 풀이 있는 경우 값을 줄이십시오.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">InnoDB_buffer_pool_size입니다</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">InnoDB 버퍼 풀은 모든 튜닝 작업에서 가장 중요한 부분입니다.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB는 인덱스 캐싱 및 데이터 조정, 적응형 해시 인덱스, 삽입 버퍼 및 내부적으로 사용되는 기타 많은 데이터 구조를 위해 버퍼 풀에 크게 의존합니다. 버퍼 풀은 또한 쓰기 작업을 스토리지에 즉시 수행할 필요가 없도록 데이터의 변경 사항을 버퍼링하여 성능을 개선합니다. 버퍼 풀은 InnoDB의 필수 부분이며 그에 따라 크기를 조정해야 합니다. 버퍼 풀 크기를 설정할 때는 다음 요소를 고려하십시오.</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">전용 InnoDB 전용 시스템의 경우 버퍼 풀 크기를 사용 가능한 RAM의 80% 이상으로 설정합니다.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">MySQL 전용 서버가 아닌 경우 크기를 RAM의 50%로 설정합니다.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">파일 설명자</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">이를 사용하여 새 연결을 열고, 캐시에 테이블을 저장하고, 복잡한 쿼리를 해결하기 위한 임시 테이블을 만들고, 영구 테이블에 액세스합니다. 필요한 경우 mysqld가 새 파일을 열 수 없는 경우 제대로 작동하지 않을 수 있습니다. 이 문제의 일반적인 증상은 오류 24, "열려 있는 파일이 너무 많음"입니다. mysqld가 동시에 열 수 있는 파일 설명자의 수는 에 의해 정의됩니다<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> 구성 파일에 설정된 옵션입니다 <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>)를 클릭합니다. 그러나<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> 또한 운영 체제의 제한에 따라 다릅니다. 이러한 의존성으로 인해 변수를 보다 복잡하게 설정할 수 있습니다.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL을 설정할 수 없습니다<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> 에 지정된 값보다 높은 옵션<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. 따라서 필요에 따라 MySQL이 파일을 열 수 있도록 운영 체제 수준에서 이러한 제한을 명시적으로 설정해야 합니다. Linux에서 파일 제한을 확인하는 방법에는 두 가지가 있습니다.</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">를 클릭합니다<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> 명령어는 허용되거나 잠기는 매개변수에 대한 자세한 설명을 빠르게 제공합니다. 이 명령을 실행하여 변경한 사항은 영구적이지 않으며 시스템 재부팅 후 삭제됩니다.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">의 변경 사항<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> 파일은 영구적이며 시스템 재부팅의 영향을 받지 않습니다.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">사용자 MySQL의 하드 제한과 소프트 제한값을 모두 변경해야 합니다. 다음 내용은 구성에서 발췌한 것입니다.</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">동시에 에서 동일한 설정을 업데이트합니다<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> 열려 있는 파일 제한을 완전히 사용합니다.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">InnoDB_flush_log_at_TRx_commit입니다</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">데이터에 변경 사항이 있을 때 변경 사항이 스토리지에 즉시 기록되지 않습니다.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">대신 로그 버퍼에 데이터가 기록됩니다. 로그 버퍼는 InnoDB가 로그 파일에 기록된 버퍼 변경 사항에 할당하는 메모리의 일부입니다. InnoDB는 트랜잭션이 커밋될 때, 버퍼가 가득 찰 때 또는 초당 한 번씩 이벤트가 먼저 발생하는 경우 버퍼를 로그 파일로 플러시합니다. 이 프로세스를 제어하는 구성 변수는 innodb_flush_log_at_TRx_commit입니다. 값 옵션은 다음과 같습니다.</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">를 설정합니다<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB는 InnoDB 버퍼 풀에 있는 수정된 데이터를 로그 파일(IB_LOGFILE)에 쓰고 로그 파일(스토리지에 쓰기)을 매초마다 플러시합니다. 그러나 트랜잭션이 커밋되면 아무 작업도 수행하지 않습니다. 전원 장애나 시스템 충돌이 발생한 경우 플러시되지 않은 데이터는 로그 파일에 기록되지 않으므로 복구할 수 없습니다.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">를 설정합니다<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB 는 트랜잭션 로그에 로그 버퍼를 쓰고 모든 트랜잭션에 대해 내구성 있는 저장소로 플러시합니다. 예를 들어, 모든 트랜잭션 커밋에 대해 InnoDB는 로그에 쓴 다음 스토리지에 씁니다. 스토리지 속도가 느리면 성능에 부정적인 영향을 줍니다. 예를 들어 초당 InnoDB 트랜잭션 수가 줄어듭니다.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">를 설정합니다<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>InnoDB 는 모든 커밋에서 로그 파일에 로그 버퍼를 쓰지만 스토리지에 데이터를 쓰지 않습니다. InnoDB는 1초에 한 번씩 데이터를 플러시합니다. 전원 장애 또는 시스템 충돌이 발생하더라도 로그 파일에서 옵션 2 데이터를 사용할 수 있으며 복구할 수 있습니다.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">성과가 주요 목표인 경우 값을 2로 설정합니다. InnoDB는 모든 트랜잭션 커밋이 아니라 1초에 한 번씩 드라이브에 쓰기 때문에 성능이 크게 향상됩니다. 전원 장애 또는 충돌이 발생하면 트랜잭션 로그에서 데이터를 복구할 수 있습니다.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">데이터 안전이 주요 목표인 경우 값을 1로 설정하여 모든 트랜잭션 커밋에 대해 InnoDB가 드라이브로 플러시합니다. 그러나 성능에 영향을 줄 수 있습니다.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">* NetApp는 성능 향상을 위해 nodb_flush_log_TRx_commit 값을 2로 설정할 것을 권장합니다.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">InnoDB_IO_capacity의 약어입니다</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">InnoDB 플러그인에서는 MySQL 5.7에서 innodb_io_capacity라는 새 매개 변수가 추가되었습니다.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">InnoDB가 수행하는 최대 IOPS 수를 제어합니다(더티 페이지의 플러싱 비율과 삽입 버퍼[ibuf] 배치 크기 포함). innodb_io_capacity 매개 변수는 버퍼 풀에서 페이지를 플러시하거나 변경 버퍼에서 데이터를 병합하는 등 InnoDB 백그라운드 작업에 의한 IOPS의 상한을 설정합니다.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">innodb_io_capacity 매개 변수를 시스템이 초당 수행할 수 있는 대략적인 입출력 작업 수로 설정합니다. 가장 좋은 방법은 설정을 가능한 낮게 유지하는 것이지만, 너무 낮게 설정하면 배경 활동이 느려지는 것이 좋습니다. 설정이 너무 높으면 버퍼 풀에서 데이터가 제거되고 캐싱을 위해 너무 빨리 버퍼를 삽입하여 상당한 이점을 얻을 수 있습니다.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">* NetApp는 NFS에서 이 설정을 사용할 경우 IOPS(Sysbench/FiO)의 테스트 결과를 분석하고 그에 따라 매개변수를 설정할 것을 권장합니다. InnoDB 버퍼 풀에서 원하는 것보다 더 많은 수정 또는 더티 페이지가 표시되지 않는 한 플러싱과 퍼징에 가능한 가장 작은 값을 사용합니다.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">작업량에 더 낮은 값이 충분하지 않다는 사실이 입증되지 않는 한 20,000개 이상의 극단적인 값을 사용하지 마십시오.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">InnoDB_IO_CAPACITY 매개변수는 플러싱 속도 및 관련 I/O를 조절합니다</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">이 매개 변수 또는 innodb_io_capacity_max 매개 변수를 너무 높게 설정하고 조기 플러시로 I/O 작업을 낭비하면 성능이 심각하게 저하될 수 있습니다.</block>
  <block id="d32067c550345cae14e678b4def6aa22" category="doc">SAN을 통한 MySQL</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">일반적인 2개 볼륨 모델을 사용하여 SAN과 MySQL을 구성하는 두 가지 옵션이 있습니다.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">입출력 및 용량 요구 사항이 단일 LUN 파일 시스템의 제한 범위 내에 있는 경우 더 작은 데이터베이스를 한 쌍의 표준 LUN에 배치할 수 있습니다. 예를 들어, 약 2K 랜덤 IOPS가 필요한 데이터베이스는 단일 LUN의 단일 파일 시스템에서 호스팅될 수 있습니다. 마찬가지로, 크기가 100GB인 데이터베이스도 관리 문제를 일으키지 않고 단일 LUN에 적합합니다.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">데이터베이스가 클수록 여러 개의 LUN이 필요합니다. 예를 들어, 100K IOPS가 필요한 데이터베이스에는 일반적으로 8개 이상의 LUN이 필요할 수 있습니다. 드라이브에 대한 SCSI 채널 수가 충분하지 않기 때문에 단일 LUN에 병목 현상이 발생합니다. 마찬가지로 단일 10TB LUN에서는 10TB 데이터베이스를 관리하기가 어렵습니다. 논리적 볼륨 관리자는 여러 LUN의 성능과 용량 기능을 함께 결합하여 성능과 관리 효율성을 높이도록 설계되었습니다.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">두 경우 모두 한 쌍의 ONTAP 볼륨으로 충분합니다. 간단한 구성을 사용하면 데이터 파일 LUN이 로그 LUN과 마찬가지로 전용 볼륨에 배치됩니다. 논리적 볼륨 관리자를 구성하면 데이터 파일 볼륨 그룹의 모든 LUN이 전용 볼륨에 있고 로그 볼륨 그룹의 LUN은 두 번째 전용 볼륨에 있게 됩니다.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">* NetApp는 * SAN에서 MySQL 배포를 위해 두 개의 파일 시스템을 사용할 것을 권장합니다.</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">첫 번째 파일 시스템은 테이블스페이스, 데이터 및 인덱스를 포함한 모든 MySQL 데이터를 저장합니다.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">두 번째 파일 시스템은 모든 로그(바이너리 로그, 느린 로그 및 트랜잭션 로그)를 저장합니다.</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">이러한 방식으로 데이터를 분리해야 하는 이유는 다음과 같습니다.</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">데이터 파일과 로그 파일의 I/O 패턴은 다릅니다. 이들 포트를 분리하면 QoS 제어에서 더 많은 옵션을 사용할 수 있습니다.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">스냅샷 기술을 최적으로 사용하려면 데이터 파일을 독립적으로 복원할 수 있는 기능이 필요합니다. 데이터 파일을 로그 파일과 함께 사용하면 데이터 파일 복구가 방해됩니다.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">NetApp SnapMirror 기술을 사용하여 데이터베이스에 단순한 RPO 재해 복구 기능을 제공할 수 있지만 데이터 파일 및 로그에 대해 서로 다른 복제 일정이 필요합니다.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">필요한 경우 모든 ONTAP 기능을 사용할 수 있도록 미래에 대비한 솔루션을 이 기본적인 두 볼륨 레이아웃을 사용하십시오.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp는 다음과 같은 기능 때문에 ext4 파일 시스템으로 드라이브를 포맷할 것을 권장합니다.</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">JFS(저널링 파일 시스템)에서 사용되는 블록 관리 기능과 XFS(확장 파일 시스템)의 지연 할당 기능에 대한 확장 접근 방식</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">ext4는 최대 1개의 exbibyte(2의 60바이트)의 파일 시스템과 최대 16테비바이트(16*2 40바이트)의 파일을 허용합니다. 반대로 ext3 파일 시스템은 최대 파일 시스템 크기 16TB와 최대 파일 크기 2TB만 지원합니다.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">ext4 파일 시스템에서 다중 블록 할당(mballoc)은 ext3에서와 같이 파일에 대해 하나씩 할당하는 대신 단일 작업으로 파일에 대해 여러 블록을 할당합니다. 이 구성은 블록 할당자를 여러 번 호출하는 오버헤드를 줄이고 메모리 할당을 최적화합니다.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">XFS가 대부분의 Linux 배포판의 기본값이지만 메타데이터를 다르게 관리하므로 일부 MySQL 구성에 적합하지 않습니다.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">* NetApp는 기존 블록 LUN 크기에 맞추기 위해 mkfs 유틸리티와 함께 4K 블록 크기 옵션을 사용할 것을 권장합니다.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">NetApp LUN은 데이터를 4KB 물리적 블록에 저장하여 8개의 512바이트 논리적 블록을 생성합니다.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">동일한 블록 크기를 설정하지 않을 경우 I/O가 물리적 블록과 올바르게 정렬되지 않고 RAID 그룹에 있는 두 개의 드라이브에 쓰므로 지연 시간이 발생합니다.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">원활한 읽기/쓰기 작업을 위해 I/O를 맞추는 것이 중요합니다. 하지만 물리적 블록의 시작이 아닌 논리적 블록에서 I/O가 시작하면 I/O가 정렬 불량이 됩니다. I/O 작업은 물리적 블록의 첫 번째 논리적 블록인 논리적 블록에서 시작할 때만 정렬됩니다.</block>
  <block id="282155126a94a0702cfd80daf38d4362" category="doc">구성 개요</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">매개 변수</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">값</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">inoDB_doublewrite입니다</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync를 참조하십시오</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11g</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">InnoDB_buffer_pool_instances입니다</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit를 선택합니다</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">이 섹션에 설명된 매개 변수를 설정하려면 MySQL 구성 파일(my.cnf)에서 변경해야 합니다. NetApp 모범 사례는 사내에서 수행된 테스트의 결과입니다.</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">MySQL 데이터베이스의 컨테이너화가 갈수록 보편화되고 있습니다.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">낮은 수준의 컨테이너 관리는 거의 항상 Docker를 통해 수행됩니다. OpenShift, Kubernetes와 같은 컨테이너 관리 플랫폼을 사용하면 대규모 컨테이너 환경을 더욱 간편하게 관리할 수 있습니다. 컨테이너화의 이점은 하이퍼바이저에 대한 라이센스를 부여할 필요가 없으므로 비용이 저렴합니다. 또한 컨테이너를 사용하면 여러 데이터베이스를 서로 격리하여 실행하면서 동일한 기본 커널과 운영 체제를 공유할 수 있습니다. 컨테이너는 마이크로초 단위로 프로비저닝할 수 있습니다.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Astra Trident 문서</block>
  <block id="d4f640fe6950a1baff001f5601c7fbd7" category="paragraph">NetApp은 Astra Trident를 제공하여 스토리지의 고급 관리 기능을 제공합니다. 예를 들어, Kubernetes에서 생성된 컨테이너에서 Astra Trident를 사용하면 해당 계층에 스토리지를 자동으로 프로비저닝하고, 엑스포트 정책을 적용하고, NetApp 스냅샷 복사본 정책을 설정하고, 컨테이너 하나를 다른 컨테이너에 복제할 수 있습니다. 자세한 내용은 를 참조하십시오 <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">MySQL 파일 구조</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">파일 구조</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB는 스토리지와 MySQL 서버 사이의 중간 계층 역할을 하며 데이터를 드라이브에 저장합니다.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">오류: 그래픽 이미지를 찾을 수 없습니다</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">MySQL I/O는 두 가지 유형으로 분류됩니다.</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">랜덤 파일 I/O</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">순차적 파일 I/O</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">데이터 파일을 무작위로 읽고 덮어써서 IOPS가 높아집니다. 따라서 SSD 스토리지를 사용하는 것이 좋습니다.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">재실행 로그 파일과 바이너리 로그 파일은 트랜잭션 로그입니다. 순차적으로 작성되므로 쓰기 캐시가 있는 HDD에서 우수한 성능을 얻을 수 있습니다. 순차적 읽기는 복구 시 발생하지만, 일반적으로 로그 파일 크기가 데이터 파일보다 작고 순차 읽기가 랜덤 읽기(데이터 파일에서 발생)보다 빠르므로 성능 문제가 발생하는 경우는 거의 없습니다.</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">이중 쓰기 버퍼는 InnoDB의 특별한 기능입니다. InnoDB는 먼저 플러시된 페이지를 이중 쓰기 버퍼에 쓴 다음 데이터 파일의 올바른 위치에 페이지를 씁니다. 이 프로세스는 페이지 손상을 방지합니다. 이중 쓰기 버퍼가 없으면 드라이브에 쓰기 프로세스 중에 전원 오류가 발생하면 페이지가 손상될 수 있습니다. 이중 쓰기 버퍼에 쓰는 작업이 순차적이기 때문에 HDD에 맞게 고도로 최적화되어 있습니다. 복구 시 순차적 읽기가 발생합니다.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">ONTAP NVRAM은 이미 쓰기 보호를 제공하고 있기 때문에 이중 쓰기 버퍼링이 필요하지 않습니다. MySQL에는 매개 변수가 있습니다.<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>이중 쓰기 버퍼를 사용하지 않도록 설정합니다. 이 기능은 성능을 크게 향상시킬 수 있습니다.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">INSERT 버퍼는 InnoDB의 특별한 기능이기도 합니다. 고유하지 않은 보조 인덱스 블록이 메모리에 없으면 InnoDB는 임의의 I/O 작업을 방지하기 위해 INSERT 버퍼에 엔트리를 삽입합니다. 주기적으로 삽입 버퍼가 데이터베이스의 보조 인덱스 트리에 병합됩니다. 삽입 버퍼는 I/O 요청을 동일한 블록에 병합하여 I/O 작업 수를 줄입니다. 랜덤 I/O 작업은 순차적일 수 있습니다. 인서트 버퍼는 또한 HDD에 대해 고도로 최적화되어 있습니다. 순차적 쓰기와 읽기는 정상 작업 중에 발생합니다.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">실행 취소 세그먼트는 임의 I/O 방향입니다. 다중 버전 동시성(MVCC)을 보장하려면 InnoDB가 실행 취소 세그먼트에 이전 영상을 등록해야 합니다. 실행 취소 세그먼트에서 이전 이미지를 읽으려면 임의 읽기가 필요합니다. 반복 가능한 읽기(예: mysqldump - 단일 트랜잭션)로 긴 트랜잭션을 실행하거나 긴 쿼리를 실행하면 임의 읽기가 발생할 수 있습니다. 따라서 SSD에 실행 취소 세그먼트를 저장하는 것이 더 좋습니다. 짧은 트랜잭션이나 쿼리만 실행할 경우 랜덤 읽기는 문제가 되지 않습니다.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp는 InnoDB I/O 특성으로 인해 다음과 같은 스토리지 디자인 레이아웃을 권장합니다.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">단일 볼륨으로 MySQL의 랜덤 및 순차적 I/O 지향 파일을 저장합니다</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">MySQL의 순수 순차 I/O 중심 파일을 저장하는 또 다른 볼륨입니다</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">또한 이 레이아웃은 데이터 보호 정책 및 전략을 설계하는 데 도움이 됩니다.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">을 사용하여 이 매개 변수를 끌 수 있습니다<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> 벤치마크용 또는 데이터 무결성 또는 가능한 오류보다 최고 성능에 더 관심이 있는 경우. InnoDB는 double-write라는 파일 플러시 기술을 사용합니다. InnoDB는 데이터 파일에 페이지를 쓰기 전에 이중 쓰기 버퍼라는 인접 영역에 페이지를 씁니다. 이중 쓰기 버퍼에 대한 쓰기 및 플러시가 완료된 후 InnoDB는 데이터 파일의 적절한 위치에 페이지를 씁니다. 페이지 쓰기 중에 운영 체제 또는 mysqld 프로세스가 충돌하는 경우 InnoDB는 나중에 충돌 복구 중에 이중 쓰기 버퍼에서 올바른 페이지 복사본을 찾을 수 있습니다.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">* NetApp는 이중 쓰기 버퍼를 비활성화 * 할 것을 권장합니다. ONTAP NVRAM은 동일한 기능을 제공한다. 이중 버퍼링은 불필요하게 성능을 저하시킵니다.</block>
  <block id="dd5a2a602f713562e0f9f0fd8385660e" category="doc">NFS를 통한 MySQL</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">MySQL 설명서에서는 NAS 구축에 NFSv4를 사용할 것을 권장합니다.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">ONTAP NFS 전송 크기</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">기본적으로 ONTAP는 NFS IO 크기를 64K로 제한합니다. MySQL 데이터베이스의 랜덤 IO는 최대 64K 이하라는 훨씬 더 작은 블록 크기를 사용합니다. 대형 블록 IO는 일반적으로 병렬화되므로 최대 64K 역시 제한이 없습니다.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">일부 워크로드는 최대 64K로 인해 제한이 발생합니다. 특히, 전체 테이블 스캔 백업 작업과 같은 단일 스레드 작업은 데이터베이스가 더 적은 수의 입출력을 수행할 수 있는 경우 더 빠르고 효율적으로 실행됩니다. 데이터베이스 워크로드에서 ONTAP의 최적의 IO 처리 크기는 256K입니다. 아래에 나열된 특정 운영 체제에 대한 NFS 마운트 옵션이 그에 따라 64K에서 256K로 업데이트되었습니다.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">ONTAP에서 허용되는 최대 전송 크기를 현재 마운트된 NFS 파일 시스템의 rsize/wsize 값보다 작게 줄이지 마십시오. 이로 인해 일부 운영 체제에서 중단되거나 심지어 데이터 손상이 발생할 수 있습니다. 예를 들어, NFS 클라이언트가 현재 rsize/wsize 65536으로 설정되어 있는 경우 클라이언트 자체가 제한되므로 영향을 미치지 않고 ONTAP 최대 전송 크기를 65536에서 1048576 사이에서 조정할 수 있습니다. 최대 전송 크기를 65536 미만으로 줄이면 가용성 또는 데이터가 손상될 수 있습니다.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp 권장*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">다음 NFSv4 fstab(/etc/fstab) 설정 설정:</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">NFSv3의 일반적인 문제는 정전 후 잠긴 InnoDB 로그 파일이었습니다. 시간을 사용하거나 로그 파일을 전환하여 이 문제를 해결했습니다. 그러나 NFSv4에는 잠금 작업이 있으며 열려 있는 파일 및 위임을 추적합니다.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP은 많은 엔터프라이즈 애플리케이션 및 데이터베이스 기술을 위한 데이터 관리 및 데이터 보호의 기초입니다. 다음 페이지에서는 ONTAP 및 엔터프라이즈 애플리케이션 및 인프라에 대한 모범 사례와 구현 절차에 대한 지침을 제공합니다.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server를 참조하십시오</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Microsoft SQL Server 데이터 보호</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">오픈 소스 데이터베이스</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">ONTAP의 MariaDB 및 MySQL</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">ONTAP의 PostgreSQL</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Oracle 데이터베이스</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">ONTAP 기반의 Oracle</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Oracle 데이터 보호</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Oracle 마이그레이션</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA를 참조하십시오</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">SAP 솔루션</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">AFF 및 FC를 사용하는 SAP HANA</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">AFF 및 NFS를 포함하는 SAP HANA</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">ONTAP을 사용한 VVOL(가상 볼륨</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">ONTAP를 사용하는 VMware 사이트 복구 관리자</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">엔터프라이즈 애플리케이션</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">제공합니다</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA 및 AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">설정</block>
  <block id="c476a4701643b158f9f5d57bcc91951d" category="sidebar">스냅샷 기술</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="sidebar">워크로드</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">공유 인스턴스와 전용 인스턴스 비교</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">메모리 구성</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">tempdb 파일</block>
  <block id="6fb6843bd9a214011969c02729c7d671" category="sidebar">스토리지 고려 사항</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">데이터 보안</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">용량 제한</block>
  <block id="4d2caccc34711835f6ff99da411ac04e" category="sidebar">스토리지 가상 머신</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">페일오버 및 전환</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">데이터 파일 및 재실행 블록 크기</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">Oracle RAC를 참조하십시오</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">호스트 구성</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux 및 ASMlib 및 AFD를 지원합니다</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">논리 인터페이스</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">이더넷 구성</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">FC SAN 구성</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">LVM 스트라이핑</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">구성</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS(dNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">NFS 리스 및 잠금</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">NFS 캐싱</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">ASM 재확보 유틸리티</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">계층화 정책</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">오브젝트 저장소로 데이터를 전송하는 중입니다</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">오브젝트 저장소에서 데이터를 검색하는 중입니다</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">계층화 전략</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">전체 파일</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">부분 파일</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">파일을 선택합니다</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">데이터 가용성</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">데이터 무결성</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">스냅샷 기반 온라인 백업</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">스토리지 스냅샷 최적화된 백업</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">물리적 아키텍처</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">논리적 아키텍처</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="3f23f85f537c810b6eca3c767c3ff00c" category="sidebar">Oracle 페일오버</block>
  <block id="5783cab279142a801ff0fd0a03b607d5" category="sidebar">MetroCluster에 단일 인스턴스</block>
  <block id="ea98d1b4d8c0f4b9e705df8dcdf77730" category="sidebar">SM-BC에 단일 인스턴스</block>
  <block id="39520db4a78ddf352897eac9b11c5890" category="sidebar">SM-BC 기반 Oracle RAC</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">실패 시나리오</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Oracle 데이터베이스 마이그레이션</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">절차를 참조하십시오</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">호스트 데이터 복사</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">외부 LUN 임포트</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">완료</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">프로토콜 변환</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">추가 참고 사항</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">성능 최적화 및 벤치마킹</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">부실 NFS 잠금입니다</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">유니파이드 스토리지</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">포함되었습니다</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">가상 볼륨 및 스토리지 정책 기반 관리</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">클론 복제</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">QoS를 참조하십시오</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">관리 기반의 스토리지 정책</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">권장 설정</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">VVOL 스토리지 구축</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">제품 보안</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">VMware vSphere용 SnapCenter 플러그인</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">컨테이너화</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">ONTAP 툴 VASA Provider는 관리되는 ESXi 호스트의 검색된 이니시에이터를 기반으로 ONTAP에서 FCP 및 iSCSI igroup과 NVMe 서브시스템을 관리합니다. 그러나 조닝을 관리하기 위해 파이버 채널 스위치와 통합되지 않습니다. 조닝은 Best Practice에 따라 수행해야 프로비저닝이 수행될 수 있습니다. 다음은 4개의 ONTAP 시스템에 대한 단일 이니시에이터 조닝의 예입니다.</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">단일 이니시에이터 조닝:</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">자세한 모범 사례는 다음 문서를 참조하십시오.</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="4047245d73abc6e3ae8bf58ec063e52e" category="paragraph">포함된 CP는 대부분의 범용 용도에 적합하지만, 요구 사항은 다를 수 있습니다.</block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">* 최대 IOPS를 사용하여 알 수 없는 VM을 제어하거나 VM을 테스트하는 것을 고려해 보십시오. *</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">VASA Provider 7.1에서 처음 사용할 수 있는 Max IOPS를 사용하면 알 수 없는 워크로드를 위해 IOPS를 특정 VVOL으로 제한하여 다른 중요한 워크로드에 미치는 영향을 방지할 수 있습니다. 성능 관리에 대한 자세한 내용은 표 4를 참조하십시오.</block>
  <block id="bdbd10905a1446f944699405bca52654" category="paragraph">* 충분한 데이터 LIF가 있는지 확인하십시오. *
HA 쌍당 최소 2개의 LIF를 생성합니다. 작업 부하에 따라 더 많은 작업이 필요할 수 있습니다.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">선택한 프로토콜에 관련된 NetApp 및 VMware의 기타 모범 사례 가이드를 참조하십시오. 일반적으로 이미 언급한 것 이외의 다른 변경 사항은 없습니다.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">* NFS v3을 통한 VVol을 사용한 네트워크 구성의 예 *</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">NFS 전송 크기</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14ce62ac76fa34a51093e6bcf11a2fd1" category="paragraph">데이터베이스 백업의 주요 고려사항은 NetApp 스냅샷 기술을 활용하는 것입니다. NetApp SnapCenter로 조정할 수 있는 RTO 및 RPO를 달성하기 위해 애플리케이션 정합성이 보장되는 백업 및 데이터베이스 레이아웃을 고려해야 합니다.</block>
  <block id="2c024bdc7d0e87e8ba0f473024d45a4e" category="paragraph">서버 및 데이터베이스 설정을 수정하면 데이터베이스 성능을 향상시키고 효율성을 높일 수 있습니다.</block>
  <block id="861f074a1ecd9d1cc088d2fe81903565" category="paragraph"><block ref="861f074a1ecd9d1cc088d2fe81903565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="710e9cd79e3865d47122a799f425b31f" category="paragraph"><block ref="710e9cd79e3865d47122a799f425b31f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5e31e9b7075c2926dba10053509346b" category="paragraph">스토리지 효율성은 RAID, 프로비저닝(전체 레이아웃 및 활용률), 미러링, 기타 데이터 보호 기술의 조합입니다. Snapshot 복사본, 씬 프로비저닝, FlexClone과 같은 NetApp 기술은 인프라의 기존 스토리지를 최적화하고 향후 스토리지 지출을 연기하거나 피할 수 있도록 함으로써 비용 이점을 만드는 데 도움이 됩니다. 이러한 기술을 함께 사용할수록 더 많은 비용을 절감할 수 있습니다.</block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25cec91f17a8619119f76c8adbace583" category="paragraph">또한 압축 블록 정렬에 대한 내용은 섹션을 참조하십시오 <block ref="0faffd62be034c86d531acfee84d252e" category="inline-link-macro-rx"></block>. 8KB 압축 블록 경계에 맞춰 정렬된 레이아웃은 4KB 경계에도 맞춰집니다.</block>
  <block id="38ac6f4e1538397bd4f659237ec03ebf" category="paragraph"><block ref="38ac6f4e1538397bd4f659237ec03ebf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f01518e5f3b18a9ea241bc63a3475dbd" category="paragraph"><block ref="f01518e5f3b18a9ea241bc63a3475dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Oracle 데이터 보호 개요</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">장거리 마이그레이션을 위해서는 일반적으로 에 설명된 로그 전달 프로세스와 같이 보다 창의적인 접근 방식이 필요합니다 <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. 장거리 IP 네트워크는 LAN 또는 SAN 속도와 가까운 곳에서는 거의 대역폭을 가지지 않습니다. 한 예로, NetApp는 아카이브 로그 생성 속도가 매우 높은 220TB 데이터베이스의 장거리 마이그레이션을 지원했습니다. 이 방법은 가능한 최대 대역폭을 제공하기 때문에 데이터 전송을 위해 선택한 방식은 테이프를 매일 배송하는 방식이었습니다.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">예를 들어 10TB 데이터베이스를 복사하려면 일반적으로 약 7시간이 소요됩니다. 비즈니스 요구 사항이 7시간 동안 중단되는 경우 파일 복사는 쉽고 안전한 마이그레이션 옵션입니다. 5시간이 허용되지 않는 경우 간단한 로그 전달 프로세스를 수행합니다(참조 <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>)를 최소한의 노력으로 설정하여 컷오버 시간을 약 15분으로 단축할 수 있습니다. 이 시간 동안 데이터베이스 관리자가 이 프로세스를 완료할 수 있습니다. 15분이 허용되는 경우 스크립팅을 통해 최종 컷오버 프로세스를 자동화하여 컷오버 시간을 단 몇 분으로 단축할 수 있습니다. 언제든지 마이그레이션의 속도를 높일 수 있지만 시간과 노력을 들여야 합니다. 컷오버 시간 목표는 비즈니스에 허용되는 성과를 기준으로 해야 합니다.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">의 단계를 수행해야 zpool을 생성할 수 있습니다 <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> 수행됩니다. 절차를 정확하게 수행하지 않으면 I/O 정렬로 인해 심각한 성능 저하가 야기될 수 있습니다. ONTAP에서 최적의 성능을 얻으려면 I/O를 드라이브의 4K 경계에 맞춰 정렬해야 합니다. zpool에 생성된 파일 시스템은 라는 매개 변수를 통해 제어되는 유효 블록 크기를 사용합니다<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, 명령을 실행하여 볼 수 있습니다<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">파티션이 기본값 32섹터 대신 33섹터 오프셋으로 생성되었습니다. 에 설명된 절차를 반복합니다 <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. 히스토그램은 다음과 같이 나타납니다.</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">LUN의 크기를 늘립니다</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">기존 볼륨 그룹에 LUN을 추가하고 포함된 논리적 볼륨을 늘립니다</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">igroup(이니시에이터 그룹)은 ONTAP LUN 마스킹 아키텍처의 일부입니다. 호스트에 처음으로 액세스 권한이 부여되지 않으면 새로 생성된 LUN에 액세스할 수 없습니다. 이 작업은 액세스 권한을 부여해야 할 FC WWN 또는 iSCSI 이니시에이터 이름을 나열하는 igroup을 생성하여 수행합니다. 이 보고서가 작성된 시점을 기준으로 FLI는 FC LUN에 대해서만 지원됩니다. 그러나 에 나와 있는 것처럼 iSCSI 사후 마이그레이션으로 변환하는 작업은 간단합니다 <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">따라서 DBA는 데이터가 삭제된 후 스토리지 시스템의 공간을 재확보할 수 있습니다. ONTAP는 0을 가로채고 LUN의 공간을 재할당합니다. 스토리지 시스템 내에 데이터가 기록되지 않으므로 재확보 프로세스가 매우 빠릅니다.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">ONTAP 스토리지 시스템은 VM 및 가상 디스크용 데이터 저장소를 유연하게 생성할 수 있습니다. VSC를 사용하여 vSphere용 데이터 저장소를 프로비저닝할 때는 섹션에 나와 있는 ONTAP 모범 사례가 많이 적용되지만 <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>) 다음은 고려해야 할 몇 가지 추가 지침입니다.</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">경우에 따라 데이터 저장소가 필요하지 않을 수도 있습니다. 최상의 성능과 관리 효율성을 얻으려면 데이터베이스 및 일부 애플리케이션과 같은 높은 I/O 애플리케이션에 데이터 저장소를 사용하지 마십시오. 대신 게스트에 의해 또는 RDM을 통해 관리되는 NFS 또는 iSCSI 파일 시스템과 같은 게스트 소유 파일 시스템을 고려해 보십시오. 구체적인 애플리케이션 지침은 해당 애플리케이션에 대한 NetApp 기술 보고서를 참조하십시오. 예를 들면, 다음과 같습니다. <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> 에는 유용한 세부 정보와 함께 가상화에 대한 섹션이 있습니다.</block>
  <block id="3cd9527ff0ddb17e00c08bdb4cd1a776" category="paragraph">vSphere에서 VM 스토리지 정책을 사용하여 스토리지 입출력 제어 또는 vSphere 암호화와 같은 선택적 기능을 관리합니다. 특정 스토리지 기능을 VM에 적용하기 위해 VVOL과 함께 사용되기도 합니다. “NetApp.clustered.Data.ONTAP.VP.VVol” 스토리지 유형 및 “ProfileName” 규칙을 사용하여 정책을 통해 특정 SCP를 VM에 적용합니다. ONTAP 툴 VASA Provider의 예는 링크: vmware-vVols-ontap.html#모범 사례 [NFS v3을 통한 vVols를 사용한 네트워크 구성 예]를 참조하십시오. “NetApp.clustered.Data.ONTAP.VP.VASA10” 스토리지에 대한 규칙은 비 VVOL 기반 데이터 저장소와 함께 사용됩니다.</block>
  <block id="36ad91be49fdde7d3fadeba0fb782510" category="paragraph">스토리지 정책을 생성한 후에는 에 나와 있는 것처럼 새 VM을 프로비저닝할 때 사용할 수 있습니다 <block ref="d202b3fe265f968d81802fcec9f3c381" category="inline-link-macro-rx"></block>. VASA Provider 7.2에서 성능 관리 기능을 사용하기 위한 지침은 에서 설명합니다 <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block>.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">시기<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> 이(기본값)을 사용하도록 설정하면 InnoDB는 모든 데이터를 두 번 저장합니다. 먼저 이중 쓰기 버퍼에 데이터를 저장한 다음 실제 데이터 파일에 저장합니다.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">PostgreSQL에 대한 호스트 구성</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">PostgreSQL에 대한 스토리지 구성입니다</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">PostgreSQL에 대한 데이터 보호</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Microsoft SQL Server에 대한 데이터베이스 구성</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Microsoft SQL Server에 대한 스토리지 구성</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Oracle Database에 대한 데이터베이스 구성</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Oracle Database에 대한 호스트 구성</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Oracle Database용 네트워크 구성</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Oracle Database용 스토리지 구성</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">MySQL용 데이터베이스 구성</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">MySQL의 호스트 구성</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">MySQL의 스토리지 구성입니다</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">ONTAP 기반 SAN을 사용한 PostgreSQL 데이터베이스</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">SAN 파일 시스템을 사용한 PostgreSQL</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">SAN을 사용하는 PostgreSQL 데이터베이스는 일반적으로 xfs 파일 시스템에서 호스팅되지만 다른 데이터베이스는 OS 공급업체에서 지원하는 경우 사용할 수 있습니다</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">단일 LUN은 일반적으로 최대 100K IOPS를 지원할 수 있지만, IO 집약적인 데이터베이스는 일반적으로 LVM을 스트라이핑과 함께 사용해야 합니다.</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">PostgreSQL 데이터베이스는 NFSv3 또는 NFSv4 파일 시스템에서 호스팅할 수 있습니다. 가장 좋은 옵션은 데이터베이스 외부의 요인에 따라 달라집니다.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">예를 들어 특정 클러스터 환경에서는 NFSv4 잠금 동작이 더 바람직할 수 있습니다. (를 참조하십시오 <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> 참조)</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">그렇지 않으면 성능을 포함하여 데이터베이스 기능이 거의 동일해야 합니다. 유일한 요구 사항은 를 사용하는 것입니다<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> 마운트 옵션. 소프트 타임아웃이 복구할 수 없는 입출력 오류를 생성하지 않도록 하기 위해 필요합니다.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">NFSv4를 프로토콜로 선택하는 경우 NetApp에서는 NFSv4.1을 사용할 것을 권장합니다. NFSv4.1에서는 NFSv4 프로토콜의 몇 가지 기능이 개선되어 NFSv4.0에 대한 복구 성능이 향상되었습니다.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">일반 데이터베이스 워크로드에 다음 마운트 옵션을 사용하십시오.</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">ONTAP 레벨에서 전송 크기를 늘리면 다음과 같은 마운트 옵션이 사용됩니다.</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">NFSv3 TCP 슬롯 테이블</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">NFSv3을 Linux와 함께 사용할 경우에는 TCP 슬롯 테이블을 올바르게 설정하는 것이 중요합니다.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Snapshot 복사본</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">스토리지 스냅샷은 타겟 데이터의 시점 복제본입니다. ONTAP은 다양한 정책을 설정하고 볼륨당 최대 1024개의 스냅샷을 저장하는 기능을 제공합니다. ONTAP의 스냅샷은 공간 효율적입니다. 공간은 원래 데이터 세트의 변경이 있을 때만 사용됩니다. 또한 읽기 전용입니다. 스냅샷은 삭제할 수 있지만 변경할 수는 없습니다.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">경우에 따라 ONTAP에서 스냅샷을 직접 예약할 수 있습니다. 스냅샷을 생성하기 전에 SnapCenter와 같은 소프트웨어가 애플리케이션 또는 OS 작업을 조율해야 할 수도 있습니다. 워크로드에 가장 적합한 접근 방식이 무엇이든 공격적인 스냅샷 전략은 부팅 LUN에서 업무상 중요한 데이터베이스에 이르는 모든 항목의 백업에 자주 쉽게 액세스할 수 있도록 하여 데이터 보안을 제공할 수 있습니다.</block>
  <block id="210c45246ad11e0b53bdb20b64266780" category="paragraph">* 참고 *: ONTAP 플렉시블 볼륨 또는 더 간단히 말하면 볼륨은 LUN과 동의어가 아닙니다. 볼륨은 파일 또는 LUN 같은 데이터를 위한 관리 컨테이너입니다. 예를 들어, 모든 LUN이 단일 볼륨에 포함된 8개의 LUN 스트라이프 세트에 데이터베이스를 배치할 수 있습니다.</block>
  <block id="ad590deba1cd4423ee565e822c3a91d1" category="paragraph">스냅샷에 대한 자세한 내용을 보려면 을 클릭합니다 <block ref="211d7effcac0cb0488144c6fc8b3cb7c" category="inline-link-macro-rx"></block></block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">변조 방지 스냅샷</block>
  <block id="d2e783db61d20da61c761d4d473bed14" category="paragraph">ONTAP 9.12.1부터 스냅샷은 읽기 전용일 뿐 아니라 실수로 또는 의도적으로 삭제되지 않도록 보호할 수 있습니다. 이 기능을 변조 방지 스냅샷이라고 합니다. 스냅샷 정책을 통해 보존 기간을 설정하고 적용할 수 있습니다. 생성된 스냅샷은 만료 날짜에 도달할 때까지 삭제할 수 없습니다. 관리 또는 지원 센터 재정의가 없습니다.</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">이렇게 하면 침입자, 악의적 내부자 또는 랜섬웨어 공격으로 인해 ONTAP 시스템 자체에 대한 액세스 결과가 발생했더라도 백업이 손상될 수 있습니다. 빈번한 스냅샷 스케줄과 결합하면 RPO가 매우 낮은 매우 강력한 데이터 보호 기능을 얻을 수 있습니다.</block>
  <block id="c64db0c79e66c1c0e5b932c5d2dedfea" category="paragraph">변조 방지 스냅샷에 대한 자세한 내용을 보려면 을 클릭합니다 <block ref="134603be635c039f9224bff191c6103c" category="inline-link-macro-rx"></block></block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">SnapMirror 복제</block>
  <block id="1bb837ddfb635c39a6c6e23d847823f9" category="paragraph">스냅샷을 원격 시스템에 복제할 수도 있습니다. 여기에는 원격 시스템에 보존 기간이 적용되고 적용되는 변조 방지 스냅샷이 포함됩니다. 그 결과 로컬 스냅샷과 동일한 데이터 보호 이점을 얻을 수 있지만 데이터는 두 번째 스토리지 시스템에 위치합니다. 이렇게 하면 원래 스토리지를 폐기해도 백업이 손상되지 않습니다.</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">두 번째 시스템은 관리 보안을 위한 새로운 옵션도 엽니다. 예를 들어, 일부 NetApp 고객은 운영 스토리지 시스템과 2차 스토리지 시스템의 인증 자격 증명을 분리합니다. 한 명의 관리자가 두 시스템에 액세스할 수 없으므로 악의적인 관리자가 모든 데이터 복사본을 삭제할 수 없습니다.</block>
  <block id="e805272dcce51c35975e830e5ee9ecaf" category="paragraph">SnapMirror에 대한 자세한 내용을 보려면 를 클릭합니다 <block ref="9abdfd5d94773cf0a996248d1d722cac" category="inline-link-macro-rx"></block></block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">스토리지 가상 머신</block>
  <block id="d5174dd4c760ef1a826b3e5bc22215e5" category="paragraph">새로 구성된 ONTAP 스토리지 시스템은 가상 시스템을 생성할 때까지 어떤 사용자도 지원할 수 없기 때문에 새로 프로비저닝된 VMware ESX Server와 유사합니다. ONTAP를 사용하면 스토리지 관리의 가장 기본적인 장치가 되는 SVM(스토리지 가상 시스템)을 만들 수 있습니다. 각 SVM에는 자체 스토리지 리소스, 프로토콜 구성, IP 주소 및 FCP WWN이 있습니다.  이것이 ONTAP 멀티 테넌시의 토대입니다.</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">예를 들어, 중요 운영 워크로드에 1개의 SVM을, 개발 활동을 위해 다른 네트워크 세그먼트에 2차 SVM을 구성할 수 있습니다. 그런 다음 운영 SVM에 대한 액세스를 특정 관리자로 제한하고, 개발자에게는 개발 SVM에서 스토리지 리소스를 더욱 포괄적으로 제어할 수 있습니다. 특히 중요한 눈 전용 데이터를 저장하려면 재무 및 HR 팀에 세 번째 SVM을 제공해야 할 수도 있습니다.</block>
  <block id="18519d16720b1e13890c2639657b5bf8" category="paragraph">SVM에 대한 자세한 내용을 보려면 를 클릭합니다 <block ref="a06a0fd566387240178b1c926e07cb7b" category="inline-link-macro-rx"></block></block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">관리 RBAC</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP는 관리 로그인을 위한 강력한 RBAC(역할 기반 액세스 제어)를 제공합니다. 일부 관리자는 전체 클러스터 액세스가 필요할 수 있고 일부 관리자는 특정 SVM에 대해서만 액세스해야 할 수도 있습니다. 고급 헬프데스크 직원은 볼륨 크기를 늘릴 수 있어야 합니다. 그 결과, 관리 사용자에게 업무 수행에 필요한 액세스 권한을 부여할 수 있으며 그 이상의 권한은 없습니다. 또한 다양한 공급업체의 PKI를 사용하여 이러한 로그인을 보호하고 ssh 키에만 대한 액세스를 제한하며 실패한 로그인 시도 잠금을 적용할 수 있습니다.</block>
  <block id="6ae13b0198daa7d13d79a8631297e64d" category="paragraph">관리 액세스 제어에 대한 자세한 내용을 보려면 을 클릭합니다 <block ref="db5be08b697b5ef26e0e94da1d5f4970" category="inline-link-macro-rx"></block></block>
  <block id="671a94a08dff3cf44fad087e2346c8b0" category="section-title">다중 요소 인증</block>
  <block id="c6595c32ea3c4aa315aa5c66b88b0a54" category="paragraph">ONTAP와 특정 기타 NetApp 제품은 이제 다양한 방법을 사용한 다단계 인증을 지원합니다. 결과적으로 손상된 사용자 이름/암호만으로는 FOB 또는 스마트폰 앱과 같은 두 번째 요소의 데이터가 없는 보안 스레드가 아닙니다.</block>
  <block id="945c88a63c229c39ee73ab5592b3ef63" category="paragraph">자세한 내용을 보려면 을 클릭합니다 <block ref="03628d0cd13b6640ef56c399aa1c2070" category="inline-link-macro-rx"></block></block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">API RBAC입니다</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">자동화를 위해서는 API 호출이 필요하지만, 모든 툴에 전체 관리 액세스가 필요한 것은 아닙니다. 자동화 시스템의 보안을 유지하기 위해 RBAC는 API 레벨에서도 사용할 수 있습니다. 자동화 사용자 계정을 필요한 API 호출로 제한할 수 있습니다. 예를 들어, 모니터링 소프트웨어는 변경 액세스가 필요하지 않고 읽기 액세스만 있으면 됩니다. 스토리지를 프로비저닝하는 워크플로우에는 스토리지를 삭제하는 기능이 필요하지 않습니다.</block>
  <block id="97ad75902b447ba6b23cabdb10252ce8" category="paragraph">자세한 내용을 보려면 를 시작하십시오 <block ref="d3dd665f13f927a9546f36768f8407dd" category="inline-link-macro-rx"></block></block>
  <block id="cb93ad4589e6e6834d2627d2ef8c8456" category="section-title">다중 관리 검증</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">여러 "요소" 인증은 각각 고유한 자격 증명을 가진 두 명의 관리자가 특정 작업을 승인하도록 요구함으로써 더욱 더 나아가 수행할 수 있습니다. 여기에는 로그인 권한 변경, 진단 명령 실행, 데이터 삭제가 포함됩니다.</block>
  <block id="e890d04cd745ac382688bbb307655e81" category="paragraph">다중 관리자 확인(MAV)에 대한 자세한 내용을 보려면 을 클릭합니다 <block ref="88f84d4fec0424d978600980bf11baf0" category="inline-link-macro-rx"></block></block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">순차적 IO가 많이 필요할 경우 다음 섹션에서 설명하는 대로 NFS 전송 크기를 늘릴 수 있습니다.</block>
  <block id="f8fd5d7386ed935c8520d4e04b029e93" category="paragraph">다음 섹션에서는 몇 가지 중요 메모리 구성 설정에 대해 설명합니다.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">이 문서는 이전에 게시된 기술 보고서_TR-4590: Microsoft SQL Server에 대한 모범 사례 가이드를 ONTAP_ 로 대체합니다</block>
  <block id="1f6b7ed754cfe3488cf91c21c13ec49a" category="paragraph">데이터베이스 환경의 보안은 데이터베이스 자체를 관리하는 것 이상의 다각적인 작업입니다. NetApp은 데이터베이스 인프라의 스토리지 측면을 보호하기 위해 설계된 몇 가지 고유한 기능을 제공합니다.</block>
  <block id="15d2f797f7375b32cb5e92538291f2af" category="list-text"><block ref="15d2f797f7375b32cb5e92538291f2af" category="inline-link-rx"></block></block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">이전 가이드에서는 데이터 지역성에 LIF를 생성하는 것이 권장되었습니다. 다시 말해, 볼륨을 물리적으로 소유한 노드에 있는 LIF를 사용하여 데이터 저장소를 항상 마운트합니다. 이는 ONTAP 9의 최신 버전에서 더 이상 필요하지 않습니다. 가능한 한 언제든지, 클러스터 범위 자격 증명이 있을 경우 ONTAP 툴은 데이터를 로컬에 있는 LIF 간 로드 밸런싱을 계속 선택하지만 고가용성 또는 성능이 필요하지 않습니다.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM은 데이터 저장소 수를 최소화하여 복구 계획에서 보호 그룹을 최소화할 때 가장 잘 작동합니다. 따라서 RTO가 중요한 SRM 보호 환경에서 VM 밀도 최적화를 고려해야 합니다.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">DRS(Distributed Resource Scheduler)를 사용하여 보호 및 복구 ESXi 클러스터의 로드 균형을 조정합니다. 페일백을 계획하는 경우 재보호 를 실행하면 이전에 보호된 클러스터가 새 복구 클러스터가 됩니다. DRS는 양방향으로 진행되는 배치의 균형을 유지하는 데 도움이 됩니다.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">가능하면 SRM에서 IP 사용자 지정을 사용하지 마십시오. 이렇게 하면 RTO가 증가할 수 있습니다.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">SRM 8.3부터 VVol 데이터 저장소를 사용하는 VM 보호가 지원됩니다. 다음 스크린샷과 같이 ONTAP 도구 설정 메뉴에서 VVOL 복제가 활성화된 경우 VASA Provider가 SnapMirror 스케줄을 VM 스토리지 정책에 표시합니다.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">다음 예에서는 VVOL 복제 활성화를 보여 줍니다.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">이전 VVOL 데이터 저장소와 달리 복제된 VVOL 데이터 저장소는 복제를 활성화한 상태로 처음부터 생성해야 하며 SnapMirror 관계가 있는 ONTAP 시스템에서 미리 생성된 볼륨을 사용해야 합니다. 이를 위해서는 클러스터 피어링 및 SVM 피어링 같은 요소를 사전에 구성해야 합니다. 이러한 작업은 ONTAP 관리자가 수행해야 합니다. 여러 사이트에서 ONTAP 시스템을 관리하는 사람과 vSphere 작업을 주로 담당하는 사람 간에 책임을 엄격하게 분리할 수 있기 때문입니다.</block>
  <block id="e4ad04c89e34f6ca94c87cd68315b108" category="paragraph">vSphere 관리자 대신 새로운 요구 사항이 적용됩니다. 볼륨은 ONTAP 도구의 범위를 벗어나 생성되므로 정기적으로 예약된 재검색 기간까지 ONTAP 관리자가 수행한 변경 사항을 인식하지 못합니다. 이러한 이유로 VVOL과 함께 사용할 볼륨 또는 SnapMirror 관계를 만들 때마다 항상 재검색을 실행하는 것이 모범 사례입니다. 다음 스크린샷에 표시된 대로 호스트 또는 클러스터를 마우스 오른쪽 버튼으로 클릭하고 NetApp ONTAP tools &gt; 호스트 및 스토리지 데이터 업데이트를 선택합니다.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">각 스토리지 쌍에 대해 스토리지 관리자가 생성됩니다. SRM 및 ONTAP 툴을 사용하면 클러스터 자격 증명을 사용해도 SVM의 범위에서 각 어레이 페어링을 수행할 수 있습니다. 따라서 각 테넌트가 관리하기 위해 할당된 SVM에 따라 테넌트 간에 DR 워크플로우를 분할할 수 있습니다. 특정 클러스터에 대해 여러 어레이 관리자를 생성할 수 있으며 비대칭적일 수 있습니다. 서로 다른 ONTAP 9 클러스터 간에 팬아웃 또는 팬할 수 있습니다. 예를 들어, 클러스터 1의 SVM-A 및 SVM-B를 클러스터 2의 SVM-C, 클러스터 3의 SVM-D 또는 그 반대로 복제할 수 있습니다.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">복제 그룹과 FlexVol 볼륨 간에 VM을 배포하는 방법은 여러 가지 요소를 고려해야 합니다. 동일한 볼륨에서 유사한 VM을 그룹화하면 집계 수준 중복 제거 기능이 없는 기존 ONTAP 시스템에서 스토리지 효율성이 향상될 수 있지만 그룹화하면 볼륨 크기가 증가하고 볼륨 I/O 동시성이 줄어듭니다. 최신 ONTAP 시스템에서는 동일한 애그리게이트의 FlexVol 볼륨에 VM을 분산하여 애그리게이트 레벨 중복제거를 활용하고 여러 볼륨에서 더 많은 I/O 병렬화를 수행하여 성능과 스토리지 효율성의 균형을 최적으로 유지할 수 있습니다. 아래에 설명된 보호 그룹에 여러 복제 그룹이 포함될 수 있으므로 볼륨에서 VM을 함께 복구할 수 있습니다. 이 레이아웃의 단점은 볼륨 SnapMirror에서는 애그리게이트 중복제거를 고려하지 않기 때문에 블록을 여러 번 유선으로 전송할 수 있다는 것입니다.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">예를 들어, 데이터베이스에 Microsoft SQL Server를 사용하는 계층 1 비즈니스 크리티컬 애플리케이션을 가질 수 있습니다. 따라서 우선 순위 그룹 1에 VM을 배치하기로 결정합니다. 우선 순위 그룹 1 내에서 서비스를 가져오기 위한 주문 계획을 시작합니다. Microsoft SQL Server 전에 Microsoft Windows 도메인 컨트롤러가 부팅되기를 원할 것입니다. 이 경우 응용 프로그램 서버 이전에 온라인 상태가 되어야 합니다. 이러한 모든 VM을 우선 순위 그룹에 추가한 다음 종속성이 지정된 우선 순위 그룹 내에서만 적용되기 때문에 종속성을 설정합니다.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">모범 사례로서, 보호된 VM 스토리지의 구성을 변경할 때마다 항상 테스트 페일오버를 수행하십시오. 이렇게 하면 재해 발생 시 Site Recovery Manager가 예상 RTO 목표 내에서 서비스를 복구할 수 있다는 것을 신뢰할 수 있습니다.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">또한 SRM은 VM이 복구될 때 VM의 네트워크 구성을 변경할 수 있는 기능을 제공합니다. 이러한 재구성에는 IP 주소, 게이트웨이 주소 및 DNS 서버 설정과 같은 설정이 포함됩니다. 개별 VM이 복구될 때 개별 VM에 적용되는 다양한 네트워크 설정은 복구 계획에서 VM의 속성 설정에서 지정할 수 있습니다.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">장애 복구 후 다시 보호 기능을 실행하기 전에 모든 이해 관계자에게 서비스가 정상으로 돌아왔는지 확인해야 합니다.</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">데이터베이스 파일 및 파일 그룹</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">LUN 정렬</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">LUN 수와 LUN 크기입니다</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">LUN 크기 조정</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">LVM 스트라이핑</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO 및 SLA를 충족할 수 있습니다</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">백업 및 복구 기초</block>
  <block id="3403aac944f3cb6e2d2c7f7d52bc44b9" category="paragraph">데이터가 기하급수적으로 늘어남에 따라 데이터 관리가 기업의 복잡성이 더욱더 복잡해지고 있습니다. 이러한 복잡성으로 인해 라이센스, 운영, 지원 및 유지 관리 비용이 증가합니다. 전체 TCO를 절감하려면 안정적인 고성능 백엔드 스토리지를 사용하여 상용 데이터베이스에서 오픈 소스 데이터베이스로 전환하는 것을 고려해 보십시오.</block>
  <block id="dcac08882e3396bd30210108baa1641d" category="paragraph">ONTAP는 말 그대로 데이터베이스를 위해 설계되었기 때문에 ONTAP은 이상적인 플랫폼입니다. 데이터베이스 워크로드의 요구사항을 해결하기 위해 랜덤 IO 지연 시간 최적화에서 고급 서비스 품질(QoS)과 같은 다양한 기능이 특별히 제작되었습니다.</block>
  <block id="1429a98a71e16287326edd7fc1f999fd" category="paragraph">무중단 업그레이드(스토리지 교체 포함)와 같은 추가 기능을 통해 중요 데이터베이스의 가용성을 보장합니다. MetroCluster를 통해 대규모 환경에서 즉시 재해 복구를 수행하거나 SnapMirror 활성 동기화를 사용하여 데이터베이스를 선택할 수도 있습니다.</block>
  <block id="8df3fb35ff15e02683bfb1bc7f852c93" category="paragraph">가장 중요한 것은 ONTAP가 고유한 요구사항에 맞게 솔루션을 사이징하는 능력과 함께 탁월한 성능을 제공한다는 것입니다. NetApp의 하이엔드 시스템은 마이크로초 단위의 지연 시간으로 1M IOPS 이상을 제공할 수 있지만, 100K IOPS만 필요한 경우, 동일한 스토리지 운영 체제를 실행하는 작은 컨트롤러로 스토리지 솔루션을 적정 크기로 조정할 수 있습니다.</block>
  <block id="97b4cda00dd31f5be69440f48c4da149" category="summary">ONTAP를 사용한 PostgreSQL 데이터베이스 구성</block>
  <block id="c4f52498c0db572381512887d7584e53" category="summary">PostgreSQL 데이터베이스 및 스토리지 스냅샷</block>
  <block id="b0792163c858a7c221b236d84619b5ef" category="summary">PostgreSQL 데이터베이스 NFS with ONTAP</block>
  <block id="189950ed46e5e8b7e92941531a5bb88b" category="doc">NFS 파일 시스템을 사용하는 PostgreSQL 데이터베이스</block>
  <block id="504cd1fb60a8eb7918484270e743ae3a" category="summary">PostgreSQL 데이터 보호 P</block>
  <block id="6cabd4dcf3582d38c441228705da3bda" category="doc">PostgreSQL 데이터 보호</block>
  <block id="383a6a5241ecfc558b9fec1d7cff5239" category="summary">PostgreSQL 테이블스페이스</block>
  <block id="20d0e2519b3555a0a2927c8914c17280" category="summary">PostgreSQL 데이터 보호 소프트웨어</block>
  <block id="29e2aec511a8e307ecceacbd86c22f14" category="summary">PostgreSQL 초기화 매개 변수입니다</block>
  <block id="55e3f073b1864d9281d074e5b23effca" category="doc">Oracle 성능 최적화 및 벤치마킹 절차</block>
  <block id="035ecd1be6cacde993302b440e396bc2" category="paragraph">이제 데이터베이스 고객의 대다수가 All-Flash 어레이를 선택하며 이 어레이에는 추가 고려사항이 수반됩니다. 예를 들어, 2노드 AFF A900 시스템에서 성능 테스트를 생각해 봅시다.</block>
  <block id="33f545d041b93838074263c0efd2e9da" category="list-text">80/20 읽기/쓰기 비율로 2개의 A900 노드는 지연 시간이 150µs 표시를 넘어가기도 전에 1M 이상의 랜덤 데이터베이스 IOPS를 제공할 수 있습니다. 이는 대부분의 데이터베이스에서 현재 요구되는 성능 수준을 훨씬 뛰어넘는 것이라 어느 정도로 개선될지를 예측하기 어렵습니다. 스토리지는 병목 현상에서 제외될 것입니다</block>
  <block id="0445195555faac96ebff962dbff126ea" category="summary">MySQL 구성 매개변수</block>
  <block id="c0b7708ffcd66fd65a9d2a4801091563" category="paragraph">NetApp은 최적의 성능을 얻기 위해 몇 가지 중요한 MySQL 구성 매개 변수를 권장합니다.</block>
  <block id="10eb8b7e75da1815860da31490513841" category="summary">NFS와 함께 MySQL을 사용합니다</block>
  <block id="5249e05857621fbfae51371a73006c44" category="summary">MySQL 및 NFSv3 슬롯 테이블</block>
  <block id="d058f95e3a8d4b7b46802139d6b95982" category="paragraph">Linux에서 NFSv3 성능은 라는 매개 변수에 따라 다릅니다<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="bf2bdc980948fb9084a63963398846b2" category="paragraph">ONTAP는 말 그대로 데이터베이스를 위해 설계되었기 때문에 ONTAP는 MySQL 데이터베이스에 이상적인 플랫폼입니다. 데이터베이스 워크로드의 요구사항을 해결하기 위해 랜덤 IO 지연 시간 최적화에서 고급 서비스 품질(QoS)과 같은 다양한 기능이 특별히 제작되었습니다.</block>
  <block id="1b3804b7e2292e18f5e66d54f7a9fafc" category="paragraph">가장 중요한 것은 ONTAP가 고유한 요구사항에 맞게 솔루션을 사이징하는 능력과 함께 탁월한 성능을 제공한다는 것입니다. NetApp의 하이엔드 시스템은 마이크로초 단위의 지연 시간으로 1M IOPS 이상을 제공할 수 있지만, 100K IOPS만 필요한 경우 정확히 동일한 스토리지 운영 체제를 실행하는 작은 컨트롤러로 스토리지 솔루션을 적절한 크기로 조정할 수 있습니다.</block>
  <block id="1339877637a3f7f59745a00e04f304fd" category="summary">MySQL 및 innodb_log_file_size</block>
  <block id="c1c4e722764621d56a075e42ce48d0c0" category="summary">MySQL 및 innodb_buffer_pool_size</block>
  <block id="ae14ab6d1e5edd0e782d8897d1721eb4" category="summary">MySQL 및 innodb_doublewrite</block>
  <block id="689c52e3f5db5d2dafccd7d93cf1abc4" category="summary">MySQL 및 innodb_flush_log_at_TRx_commi</block>
  <block id="639600080c225673dfdfa012fdbd6146" category="summary">MySQL 및 IO 스케줄러</block>
  <block id="32e3724e2b54692cbef969373fbfe040" category="doc">I/O 스케줄러 및 MySQL</block>
  <block id="72985ac51e91797345b2437088a4362e" category="summary">SAN과 함께 MySQL 제공</block>
  <block id="d5ef0a45fe252b03f538bfd134b168db" category="summary">MySQL 및 innodb_lRU_scan_depth</block>
  <block id="df657260453f6ef228ee0ca22dd7a415" category="summary">MySQL 컨테이너화</block>
  <block id="885b1b5a90f898c89b664ec58a42121c" category="doc">MySQL 컨테이너화</block>
  <block id="2cbac38815d492c0afc5e7d7229601df" category="doc">MySQL 및 InnoDB</block>
  <block id="1115aaa86f0065e0a105795d33ef4731" category="summary">MySQL 파일 설명</block>
  <block id="2828450fc6669c8df75f937e227996f1" category="doc">MySQL 파일 설명자</block>
  <block id="9420010a756fb6d3ddeadfa63d2170f6" category="paragraph">MySQL 서버를 실행하려면 파일 설명자가 필요하며 기본값이 충분하지 않습니다.</block>
  <block id="62414a5a9c0e2fc12a8d028ad29164b8" category="summary">MySQL 및 innodb_io_capacity</block>
  <block id="6219c45bc8c26437c0b7e1a69d4cbe58" category="summary">MySQL 및 innodb_flush_method</block>
  <block id="35d1a5d7b12999ec27f5233dccba043f" category="summary">MySQL 및 open_file_limits</block>
  <block id="c031febc35017c70bf3b526723756b2a" category="doc">iSCSI 및 NVMe/TCP</block>
  <block id="4da35d461815e71b97bda03476e89b7b" category="paragraph">iSCSI 또는 NVMe/TCP를 사용하는 호스트는 스토리지 시스템에 직접 연결하여 정상적으로 작동할 수 있습니다. 그 이유는 경로 지정입니다. 두 개의 서로 다른 스토리지 컨트롤러에 직접 연결되므로 데이터 흐름을 위한 두 개의 독립적 경로가 됩니다. 경로, 포트 또는 컨트롤러가 손실되어도 다른 경로가 사용되지 않습니다.</block>
  <block id="40715d81cea527f13cdf470773fc3a65" category="paragraph">직접 연결 NFS 스토리지를 사용할 수 있지만 중대한 제한 사항이 있는 경우 스크립팅의 상당한 노력 없이는 페일오버가 수행되지 않으며 고객의 책임입니다.</block>
  <block id="d0b13bfd23c05f64222869de30f81000" category="paragraph">직접 연결 NFS 스토리지에서 무중단 페일오버가 복잡해지는 이유는 로컬 OS에서 발생하는 라우팅입니다. 예를 들어, 호스트의 IP 주소가 192.168.1.1/24이고 IP 주소가 192.168.1.50/24인 ONTAP 컨트롤러에 직접 연결되어 있다고 가정합니다. 장애 조치 중에 192.168.1.50 주소는 다른 컨트롤러로 장애 조치될 수 있으며 호스트에서 사용할 수 있지만 호스트는 어떻게 그 존재를 감지합니까? 원래 192.168.1.1 주소는 더 이상 운영 체제에 연결되지 않는 호스트 NIC에 계속 존재합니다. 192.168.1.50으로 향하는 트래픽은 작동하지 않는 네트워크 포트로 계속 전송됩니다.</block>
  <block id="288a0a5ebbc70fb3b968ec58d36d71ab" category="paragraph">두 번째 OS NIC를 19로 구성할 수 있습니다 2.168.1.2 및 은 192.168.1.50을 통해 실패한 주소와 통신할 수 있지만, 로컬 라우팅 테이블은 기본적으로 192.168.1.0/24 서브넷과 통신하는 데 하나의 * 및 하나의 * 주소만 사용합니다. sysadmin은 실패한 네트워크 연결을 감지하고 로컬 라우팅 테이블을 변경하거나 인터페이스를 가동 및 중지시키는 스크립팅 프레임워크를 생성할 수 있습니다. 정확한 절차는 사용 중인 운영 체제에 따라 다릅니다.</block>
  <block id="d6ce8522932df7ae76aa0b963ad9ef7d" category="paragraph">실제로 NetApp 고객은 직접 연결 NFS를 가지고 있지만 일반적으로 페일오버 중에 IO가 일시 중지되는 워크로드에만 해당됩니다. 하드 마운트를 사용하는 경우 이러한 일시 중지 중에는 입출력 오류가 발생하지 않아야 합니다. 호스트의 NIC 간에 IP 주소를 이동하는 장애 복구 또는 수동 작업으로 인해 서비스가 복구될 때까지 입출력이 중단되어야 합니다.</block>
  <block id="3436a7073ac9f4071820b6720a7789fc" category="section-title">FC 직접 연결</block>
  <block id="b7981516813a09695906aa429b07f48f" category="paragraph">호스트를 FC 프로토콜을 사용하여 ONTAP 스토리지 시스템에 직접 연결할 수는 없습니다. NPIV를 사용하기 때문입니다. FC 네트워크에 대한 ONTAP FC 포트를 식별하는 WWN은 NPIV라는 가상화 유형을 사용합니다. ONTAP 시스템에 연결된 모든 디바이스가 NPIV WWN을 인식할 수 있어야 합니다. 현재 NPIV 타겟을 지원할 수 있는 호스트에 설치할 수 있는 HBA를 제공하는 HBA 공급업체는 없습니다.</block>
  <block id="97db606ac6781989ea3b189d7be28bf2" category="section-title">직접 연결 네트워킹</block>
  <block id="d078ae9a339971900f939db9e82f253d" category="paragraph">스토리지 관리자는 구성에서 네트워크 스위치를 제거하여 인프라를 단순화하기를 원할 수도 있습니다. 일부 시나리오에서는 이 기능이 지원될 수 있습니다.</block>
  <block id="14a07a9c146c886f1cf8b6ebd4b2b418" category="summary">ONTAP를 통한 직접 네트워크 연결</block>
  <block id="a4e0be5abb980518338c55619fbfa4df" category="doc">TCP/IP 및 FC 네트워크를 사용하여 직접 연결</block>
  <block id="e817ecc2f82a2b78d828ec8704031da3" category="section-title">직접 연결 네트워킹</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서는 ONTAP 스토리지 QoS 기능을 사용하여 파일, LUN, 볼륨 또는 전체 SVM과 같은 다양한 스토리지 개체에 대해 Mbps 또는 IOPS 단위로 처리량을 제한할 수 있습니다.</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">추가 정보와 함께 여러 문제 해결 리소스를 사용할 수 있습니다.</block>
  <block id="52d04863ac62a6fa67e1b49a31086928" category="paragraph">다음 섹션에서는 VMware SRM 및 ONTAP 스토리지에 대한 운영 Best Practice를 간략히 설명합니다.</block>
  <block id="30b34ee8f62b7bf57684faae3645acc4" category="summary">NetApp ONTAP를 사용하는 vSphere Metro Storage Cluster에 대해 자세히 알아보십시오</block>
  <block id="f24ef4a42850a2b3e3d77e610ae46fee" category="doc">계획되거나 계획되지 않은 이벤트에 대한 복원력</block>
  <block id="4bce11924453ef2ee7e40109f79dc66d" category="paragraph">NetApp MetroCluster 및 SnapMirror 활성 동기화는 NetApp 하드웨어 및 ONTAP ® 소프트웨어의 고가용성 및 무중단 운영을 개선하는 강력한 툴입니다.</block>
  <block id="52f49b6400100ac4558d31582b90ca4e" category="paragraph">이러한 툴은 전체 스토리지 환경에 대해 사이트 전체를 보호하여 데이터를 항상 사용할 수 있도록 보장합니다. NetApp 기술을 사용하면 독립 실행형 서버, 고가용성 서버 클러스터, Docker 컨테이너, 가상 서버 등 무엇을 사용하든 전력, 냉각 및 네트워크 연결이 끊어지고 스토리지 어레이 중단이나 운영 오류가 발생하여 전체 중단이 발생해도 스토리지 가용성을 원활하게 유지할 수 있습니다.</block>
  <block id="d267775072875ddbb24c16a41c22d8a2" category="paragraph">MetroCluster 및 SnapMirror 활성 동기화는 계획된 또는 계획되지 않은 이벤트가 발생할 경우 데이터 연속성을 위해 3가지 기본 방법을 제공합니다.</block>
  <block id="1d3027d09fc1db3087f05f2163af2cb7" category="list-text">이중 구성 요소로 단일 구성 요소 장애로부터 보호</block>
  <block id="f3b83f3b77289efe3b53cf537b7b77f5" category="list-text">단일 컨트롤러에 영향을 주는 이벤트에 대한 로컬 HA 테이크오버</block>
  <block id="b6ed0cba165f6f9664dc1e57ac3419ec" category="list-text">완벽한 사이트 보호 – 스토리지 및 클라이언트 액세스를 소스 클러스터에서 대상 클러스터로 이동하여 신속하게 서비스를 재개합니다</block>
  <block id="16afcbe8821dfa582521cd62c1ec130d" category="paragraph">즉, 단일 구성 요소 장애 발생 시 작업을 계속 원활하게 수행하고 장애가 발생한 구성 요소를 교체하면 자동으로 중복 작업으로 되돌아갑니다.</block>
  <block id="8fab78e8b214cad43d962b802bf568f8" category="paragraph">단일 노드 클러스터(일반적으로 ONTAP Select 같은 소프트웨어 정의 버전)를 제외한 모든 ONTAP 클러스터에는 Takeover 및 Giveback이라는 HA 기능이 내장되어 있습니다. 클러스터의 각 컨트롤러가 다른 컨트롤러와 페어링되어 HA 쌍을 형성합니다. 이러한 페어를 통해 각 노드가 스토리지에 로컬로 접속됩니다.</block>
  <block id="83e1749664841043ce8b1e894769a201" category="paragraph">Takeover는 한 노드가 다른 노드의 스토리지를 인수하여 데이터 서비스를 유지하는 자동화된 프로세스입니다. 반환 은 정상 작업을 복원하는 역 프로세스입니다. 하드웨어 유지 보수, ONTAP 업그레이드 수행 시 또는 계획되지 않은 노드 장애 또는 하드웨어 장애로 인해 테이크오버를 계획할 수 있습니다.</block>
  <block id="834d83f4ff04b7e3948831f336559b7c" category="paragraph">테이크오버 중 MetroCluster 구성의 NAS(Network Attached Storage 논리 인터페이스)는 자동으로 페일오버됩니다. 그러나 SAN LIF(Storage Area Network LIF)는 페일오버되지 않으며 LUN(논리 유닛 번호)에 대한 직접 경로를 계속 사용합니다.</block>
  <block id="0b0403a9258293da1f6a5fc84d24a18e" category="inline-link">HA 쌍 관리 개요</block>
  <block id="df5ca9bc3ee60e70aa9fd870a1ce1065" category="paragraph">HA 테이크오버 및 반환에 대한 자세한 내용은 를 참조하십시오<block ref="5a72801b431f75b7489a0e7de50680bf" category="inline-link-rx"></block>. 이 기능은 MetroCluster 또는 SnapMirror 활성 동기화에만 한정되지 않습니다.</block>
  <block id="cf654073ce9eb8f38d3f05292ed83cc5" category="paragraph">MetroCluster를 통한 사이트 전환은 한 사이트가 오프라인일 때 또는 사이트 전체 유지 관리를 위한 계획된 활동으로 수행됩니다. 나머지 사이트에서는 오프라인 클러스터의 스토리지 리소스(디스크 및 애그리게이트)를 소유합니다. 그러면 장애가 발생한 사이트의 SVM이 온라인으로 전환되고 재해 사이트에서 다시 시작되므로 클라이언트 및 호스트 액세스를 위해 전체 ID를 유지할 수 있습니다.</block>
  <block id="4dd2305dcb9d7412784238dd42dcdc21" category="paragraph">SnapMirror 액티브 동기화를 사용할 때는 두 복사본이 동시에 활발하게 사용되므로 기존 호스트가 계속 작동합니다. 사이트 페일오버가 올바르게 수행되도록 하려면 NetApp 중재자가 필요합니다.</block>
  <block id="823bd5c6c005e340599d915e134d851c" category="summary">VMware vSphere 솔루션 개요</block>
  <block id="be26d39d86de44047c65c1fed157d529" category="paragraph">VCSA(vCenter Server Appliance)는 관리자가 ESXi 클러스터를 효과적으로 운영할 수 있도록 지원하는 강력한 중앙 집중식 관리 시스템이자 vSphere용 단일 창입니다. VM 프로비저닝, vMotion 작업, HA(고가용성), DRS(Distributed Resource Scheduler), Tanzu Kubernetes Grid 등의 주요 기능을 지원합니다. VMware 클라우드 환경에서 필수적인 구성 요소이며 서비스 가용성을 고려하여 설계해야 합니다.</block>
  <block id="8ba8694e23f6560a60d85c4de549122b" category="section-title">vSphere 고가용성</block>
  <block id="4b5543b81af03f01e26fcb74614f7062" category="paragraph">VMware의 클러스터 기술은 ESXi 서버를 가상 시스템용 공유 리소스 풀로 그룹화하고 vSphere HA(High Availability)를 제공합니다. vSphere HA는 가상 머신에서 실행되는 애플리케이션에 사용하기 쉽고 고가용성을 제공합니다. 클러스터에서 HA 기능이 활성화된 경우 각 ESXi 서버는 다른 호스트와 통신을 유지하여 ESXi 호스트가 응답하지 않거나 격리될 경우 HA 클러스터는 클러스터의 남은 호스트 간에 해당 ESXi 호스트에서 실행 중이었던 가상 머신의 복구를 협상할 수 있습니다. 게스트 운영 체제에 장애가 발생할 경우 vSphere HA는 영향을 받는 가상 머신을 동일한 물리적 서버에서 다시 시작합니다. vSphere HA를 사용하면 계획된 다운타임을 줄이고, 예기치 않은 다운타임을 방지하며, 운영 중단으로부터 신속하게 복구할 수 있습니다.</block>
  <block id="01036edb3159652090a3f7149fe1ce2f" category="paragraph">vSphere HA 클러스터 장애가 발생한 서버에서 VM을 복구합니다.</block>
  <block id="15496c3917565cea1f21bbc7e6eba996" category="image-alt">vMSC 다이어그램</block>
  <block id="c1bb7aa3a002a819d935439c7e347826" category="paragraph">VMware vSphere는 NetApp MetroCluster 또는 SnapMirror 활성 동기화에 대한 지식이 없으며 호스트 및 VM 그룹 선호도 구성에 따라 vSphere 클러스터의 모든 ESXi 호스트를 HA 클러스터 작업에 적합한 호스트로 간주한다는 점을 이해하는 것이 중요합니다.</block>
  <block id="dcff37ab37f2cb6a72aeb3c30e3ed5aa" category="section-title">호스트 장애 감지</block>
  <block id="7069d861b63dd4095cfb7b2ee30587f5" category="paragraph">HA 클러스터가 생성되면 클러스터의 모든 호스트가 선택에 참여하며 호스트 중 하나가 마스터가 됩니다. 각 슬레이브는 네트워크 하트비트를 마스터로 수행하고, 마스터는 모든 슬레이브 호스트에서 네트워크 하트비트를 수행합니다. vSphere HA 클러스터의 마스터 호스트는 슬레이브 호스트의 장애를 감지합니다.</block>
  <block id="73b629afd8ef39d8d0147696412538c8" category="paragraph">감지된 장애 유형에 따라 호스트에서 실행 중인 가상 머신을 페일오버해야 할 수 있습니다.</block>
  <block id="e12cf4015a45ff29f1f84ae1a3ee0390" category="paragraph">vSphere HA 클러스터에서 세 가지 유형의 호스트 장애가 감지됩니다.</block>
  <block id="4eac346eb6cdd3a1a98ee9bc71ebccaa" category="list-text">실패 - 호스트의 작동이 중지됩니다.</block>
  <block id="3875a4c584a7715edf4a221ce53d45fc" category="list-text">격리 - 호스트가 네트워크를 격리합니다.</block>
  <block id="82fba11358d642111efbcf36273159f2" category="list-text">파티션 - 호스트와 마스터 호스트의 네트워크 연결이 끊깁니다.</block>
  <block id="5f72ceebd161159fe623ff01ac0cf1b4" category="paragraph">마스터 호스트는 클러스터의 슬레이브 호스트를 모니터링합니다. 이 통신은 네트워크 하트비트를 1초마다 교환하여 이루어집니다. 마스터 호스트가 슬레이브 호스트로부터 이러한 하트비트 수신을 중지하면 호스트가 실패했다고 선언하기 전에 호스트 활성 여부를 확인합니다. 마스터 호스트가 수행하는 활성 점검은 슬레이브 호스트가 데이터 저장소 중 하나와 하트비트를 교환하는지 여부를 확인하는 것입니다. 또한 마스터 호스트는 호스트가 관리 IP 주소로 전송된 ICMP 핑에 응답하여 호스트가 단순히 마스터 노드에서 격리되는지 아니면 네트워크에서 완전히 격리되는지 여부를 검사합니다. 기본 게이트웨이에 대해 ping을 수행하여 이 작업을 수행합니다. 하나 이상의 격리 주소를 수동으로 지정하여 격리 유효성 검사의 안정성을 향상시킬 수 있습니다.</block>
  <block id="5546466ab10e5cbfbc4b286cd60b8b4a" category="section-title">_모범 사례_</block>
  <block id="0456a7ce7bf92fb68980571fdd2defa1" category="paragraph">NetApp에서는 최소 2개의 추가 격리 주소를 지정하고 각 주소는 사이트-로컬 주소를 지정하는 것이 좋습니다. 이렇게 하면 격리 검증의 신뢰성이 향상됩니다.</block>
  <block id="19c262cd1e1bb07c491e359333f04a29" category="section-title">호스트 격리 응답</block>
  <block id="7a2723aad08de3c674693adf221e4a48" category="paragraph">격리 응답은 vSphere HA의 설정으로, vSphere HA 클러스터의 호스트에서 관리 네트워크 연결이 끊어지지만 계속 실행되는 경우 가상 시스템에서 트리거되는 작업을 결정합니다. 이 설정에는 "사용 안 함", "VM 종료 및 다시 시작", "VM 전원 끄기 및 다시 시작"이라는 세 가지 옵션이 있습니다.</block>
  <block id="715e310d886b45856c3ab0f69b06241b" category="paragraph">"시스템 종료"는 "전원 끄기"보다 낫습니다. 이는 디스크에 대한 가장 최근의 변경 사항을 플러시하거나 트랜잭션을 커밋하지 않습니다. 가상 시스템이 300초 내에 종료되지 않으면 전원이 꺼집니다. 대기 시간을 변경하려면 고급 옵션인 DAS.isolationshutdowntimeout을 사용합니다.</block>
  <block id="620b4ae663a26c98656d1c81bec1a6c2" category="paragraph">HA는 격리 응답을 시작하기 전에 먼저 vSphere HA 마스터 에이전트가 VM 구성 파일이 포함된 데이터 저장소를 소유하는지 확인합니다. 그렇지 않으면 VM을 다시 시작할 마스터가 없기 때문에 호스트가 격리 응답을 트리거하지 않습니다. 호스트는 정기적으로 데이터 저장소 상태를 확인하여 마스터 역할을 가진 vSphere HA 에이전트에서 데이터 저장소를 요청하는지 확인합니다.</block>
  <block id="6824ef1b1c5e58e8ea5ebc8b2cf94be2" category="paragraph">NetApp에서는 "호스트 격리 응답"을 사용 안 함으로 설정하는 것이 좋습니다.</block>
  <block id="6bd7b146f345eefac88b336a89aa3754" category="paragraph">호스트가 vSphere HA 마스터 호스트에서 격리 또는 파티션되고 마스터가 하트비트 데이터 저장소 또는 Ping을 통해 통신할 수 없는 경우 브레인 분할 상태가 발생할 수 있습니다. 마스터가 격리된 호스트를 작동하지 않음을 선언하고 클러스터의 다른 호스트에서 VM을 다시 시작합니다. 가상 시스템의 두 인스턴스가 실행 중이기 때문에 브레인 분할 조건이 존재합니다. 그 중 하나만 가상 디스크를 읽거나 쓸 수 있습니다. 이제 VM 구성 요소 보호(VMCP)를 구성하여 브레인 분할 조건을 방지할 수 있습니다.</block>
  <block id="df05a421ed8ba49f97f18dc085495ee4" category="section-title">VM 구성 요소 보호(VMCP)</block>
  <block id="1418d127ee81cc7f3e114029e9ba6856" category="paragraph">HA와 관련된 vSphere 6의 향상된 기능 중 하나는 VMCP입니다. VMCP는 블록(FC, iSCSI, FCoE) 및 파일 스토리지(NFS)에 대한 APD(All Path Down) 및 PDL(Permanent Device Loss) 조건에서 향상된 보호 기능을 제공합니다.</block>
  <block id="fc35e15d00ef5b037a1a56c77ef3e17c" category="section-title">영구적 장치 손실(PDL)</block>
  <block id="967b20f28092443585be2b9649d0ba93" category="paragraph">PDL은 저장소 장치가 영구적으로 실패하거나 관리자가 제거되어 반환되지 않을 때 발생하는 상태입니다. NetApp 스토리지 배열은 ESXi에 SCSI 감지 코드를 발행하여 디바이스가 영구적으로 손실되었음을 알립니다. vSphere HA의 Failure Conditions and VM Response 섹션에서 PDL 조건이 감지된 후 응답을 구성할 수 있습니다.</block>
  <block id="7cf4fdbfc8e1deb9f567848f2df19e91" category="paragraph">NetApp은 "PDL을 사용한 데이터 저장소 응답"을 " * VM 전원을 끄고 다시 시작 * "으로 설정할 것을 권장합니다. 이 상태가 감지되면 vSphere HA 클러스터 내의 정상 호스트에서 VM이 즉시 재시작됩니다.</block>
  <block id="6d623de2ea8c5007def6f2349d9ad8b9" category="section-title">모든 경로 다운(APD)</block>
  <block id="15d2d9b1f25022e7080482582e155265" category="paragraph">APD는 스토리지 디바이스가 호스트에 액세스할 수 없고 스토리지에 대한 경로를 사용할 수 없는 경우에 발생하는 상태입니다. ESXi는 이 문제가 디바이스의 일시적인 문제로 간주하여 다시 사용할 수 있게 될 것으로 예상하고 있습니다.</block>
  <block id="f89caca297ba86d190d90ef30c409ccf" category="paragraph">APD 조건이 감지되면 타이머가 시작됩니다. 140초 후에 APD 조건이 공식적으로 선언되고 장치가 APD 시간 초과로 표시됩니다. 140초가 지나면 HA는 VM 장애 조치 APD에 지정된 시간(분)을 계산하기 시작합니다. 지정된 시간이 경과하면 HA가 영향을 받는 가상 머신을 다시 시작합니다. 원하는 경우 다르게 응답하도록 VMCP를 구성할 수 있습니다(사용 안 함, 이벤트 발생 또는 VM 전원 끄기 및 재시작).</block>
  <block id="8f179a61d789dab9b994ecd0ca8c53cb" category="paragraph">NetApp은 “APD를 사용한 데이터 저장소에 대한 응답”을 “* VM 전원을 끄고 다시 시작(보수적)*”으로 구성할 것을 권장합니다.</block>
  <block id="76d29c3c5f57a16a7f080459356c3793" category="paragraph">보존적 은 HA가 VM을 다시 시작할 수 있는 가능성을 나타냅니다. 보존으로 설정하면 다른 호스트가 다시 시작할 수 있다는 것을 알고 있는 경우에만 HA가 APD의 영향을 받는 VM을 다시 시작합니다. 공격적인 경우 HA는 다른 호스트의 상태를 모르는 경우에도 VM을 다시 시작합니다. 따라서 해당 데이터 저장소에 액세스할 수 있는 호스트가 없는 경우 VM이 다시 시작되지 않을 수 있습니다.</block>
  <block id="c64ef72a18526e28efe7c08b3ff3889a" category="paragraph">APD 상태가 해결되고 제한 시간이 경과하기 전에 스토리지에 대한 액세스가 복구되는 경우, 사용자가 명시적으로 가상 머신을 구성하지 않으면 HA가 가상 머신을 불필요하게 다시 시작하지 않습니다. 환경이 APD 조건으로부터 복구된 경우에도 응답이 필요한 경우 APD 시간 초과 후 APD 복구에 대한 응답을 VM 재설정 으로 구성해야 합니다.</block>
  <block id="580bc3953adcf3e3a20c5497f67f8b2c" category="paragraph">NetApp에서는 APD 시간 초과 후 APD 복구에 대한 응답을 사용 안 함으로 구성하는 것이 좋습니다.</block>
  <block id="a067a9a0e98c97f62fba4698bde30edc" category="section-title">NetApp MetroCluster용 VMware DRS 구현</block>
  <block id="3bf3e67966e8b0e07b0812dae7b86ce7" category="paragraph">VMware DRS는 클러스터의 호스트 리소스를 집계하는 기능으로, 주로 가상 인프라스트럭처의 클러스터 내에서 로드 밸런싱을 수행하는 데 사용됩니다. VMware DRS는 주로 클러스터에서 로드 밸런싱을 수행하기 위한 CPU 및 메모리 리소스를 계산합니다. vSphere는 늘어난 클러스터링을 인식하지 못하므로 로드 밸런싱 시 두 사이트의 모든 호스트를 고려합니다. 사이트 간 트래픽을 방지하기 위해 NetApp에서는 VM의 논리적 분리를 관리하기 위해 DRS 선호도 규칙을 구성하는 것이 좋습니다. 따라서 전체 사이트 장애가 발생하지 않는 한 HA 및 DRS는 로컬 호스트만 사용합니다.</block>
  <block id="b9e04f46a88c8139fbb91780a2ff9064" category="paragraph">클러스터에 대한 DRS 선호도 규칙을 생성하는 경우 vSphere가 가상 머신 페일오버 중에 해당 규칙을 적용하는 방법을 지정할 수 있습니다.</block>
  <block id="f903d43a0acb7412db93e8201ab12be3" category="paragraph">vSphere HA 페일오버 동작을 지정할 수 있는 두 가지 규칙 유형이 있습니다.</block>
  <block id="a96c8bab3a450bb828e3093d16f7e32c" category="list-text">VM 반유사성 규칙은 페일오버 작업 중에 지정된 가상 머신이 서로 떨어져 있도록 합니다.</block>
  <block id="1fa3a04279011cbc6001c96c0f6f27fb" category="list-text">VM 호스트 선호도 규칙은 페일오버 작업 중에 특정 호스트 또는 정의된 호스트 그룹의 구성원에 지정된 가상 머신을 배치합니다.</block>
  <block id="225e3f7204b6e5bf6cd388af7bb16eb4" category="paragraph">VMware DRS의 VM 호스트 선호도 규칙을 사용하면 사이트 A와 사이트 B 간에 논리적 구분을 통해 VM이 지정된 데이터 저장소에 대한 운영 읽기/쓰기 컨트롤러로 구성된 스토리지와 동일한 사이트의 호스트에서 실행되도록 할 수 있습니다. 또한 VM 호스트 선호도 규칙을 통해 가상 머신이 스토리지에 로컬을 유지할 수 있으며, 이 경우 사이트 간에 네트워크 장애가 발생할 경우 가상 머신 연결을 확인할 수 있습니다.</block>
  <block id="db03e2255e35df6fa9719c800850c397" category="paragraph">다음은 VM 호스트 그룹 및 선호도 규칙의 예입니다.</block>
  <block id="6c9bd967c46984c9e5e0d8a6e5ec81a0" category="image-alt">컴퓨터 서버의 다이어그램 자동으로 생성된 설명</block>
  <block id="d400b2cf908bc5f979847146ff8ac816" category="paragraph">NetApp은 장애 발생 시 vSphere HA로 인해 위반되므로 "Must" 규칙 대신 "Must" 규칙을 적용하는 것이 좋습니다. "필수" 규칙을 사용하면 서비스가 중단될 수 있습니다.</block>
  <block id="e9503bc9ad84f6517ddc938c85541dd5" category="paragraph">서비스의 가용성은 항상 성과보다 우선해야 합니다. 전체 데이터 센터에 장애가 발생할 경우 "필수" 규칙은 VM 호스트 선호도 그룹에서 호스트를 선택해야 하며, 데이터 센터를 사용할 수 없으면 가상 시스템이 다시 시작되지 않습니다.</block>
  <block id="b3c45603f3738ac1e1f8e1e87569c00c" category="section-title">NetApp MetroCluster를 사용한 VMware Storage DRS 구축</block>
  <block id="b273633ed947791e90b7b83ad1bb2021" category="paragraph">VMware Storage DRS 기능을 사용하면 데이터 저장소를 단일 유닛으로 통합할 수 있으며 스토리지 입출력 제어 임계값을 초과할 경우 가상 머신 디스크의 균형을 조정할 수 있습니다.</block>
  <block id="4669dbcf4d42583b3fae1c79fa228078" category="paragraph">Storage DRS가 활성화된 DRS 클러스터에서는 스토리지 입출력 제어가 기본적으로 설정됩니다. 스토리지 I/O 제어를 통해 관리자는 I/O 정체 기간 동안 가상 시스템에 할당되는 스토리지 I/O 양을 제어할 수 있으므로 더 중요한 가상 시스템이 I/O 리소스 할당에 덜 중요한 가상 시스템보다 우선 순위를 가질 수 있습니다.</block>
  <block id="f06483bf36a941eebbb2f78a89b6bf68" category="paragraph">Storage DRS는 Storage vMotion을 사용하여 가상 머신을 데이터 저장소 클러스터 내의 다른 데이터 저장소로 마이그레이션합니다. NetApp MetroCluster 환경에서는 해당 사이트의 데이터 저장소 내에서 가상 머신 마이그레이션을 제어해야 합니다. 예를 들어, 사이트 A의 호스트에서 실행되는 가상 머신 A는 사이트 A의 SVM 데이터 저장소 내에서 마이그레이션하는 것이 이상적입니다 가상 디스크 읽기/쓰기가 사이트 간 링크를 통해 사이트 B에서 이루어지므로 가상 머신이 계속 작동하지만 성능이 저하됩니다.</block>
  <block id="e607d8c3dc392e521065e5494d8c85c6" category="paragraph">NetApp은 스토리지 사이트 선호도와 관련하여 데이터 저장소 클러스터를 생성하는 것이 좋습니다. 즉, 사이트 A에 대한 사이트 선호도를 갖는 데이터 저장소와 사이트 B에 대한 사이트 선호도를 갖는 데이터 저장소를 함께 사용하면 안 됩니다</block>
  <block id="63fe88e257ae2d072b6920d6dbcf0818" category="paragraph">Storage vMotion을 사용하여 가상 머신을 새로 프로비저닝하거나 마이그레이션할 때마다 NetApp는 해당 가상 머신과 관련된 모든 VMware DRS 규칙을 수동으로 업데이트하는 것이 좋습니다. 그러면 호스트와 데이터 저장소에 대한 사이트 레벨에서 가상 머신 선호도가 확인되므로 네트워크 및 스토리지 오버헤드가 줄어듭니다.</block>
  <block id="b6cd969550b5501b0f62a149fb7964ce" category="paragraph">ONTAP 9.8은 vSphere에서 FlexGroup 데이터 저장소를 지원하며, VMware vSphere 9.8 릴리즈용 ONTAP 툴도 추가로 지원합니다.</block>
  <block id="4adcd8d9323839ff088dc4f8f0bdcce2" category="paragraph">VM용 VVol 스토리지를 생성하는 단계는 여러 가지가 있습니다.</block>
  <block id="2438f6a80b933cf058ad052d26ac0703" category="paragraph">스토리지 객체를 클론 복제하면 추가 VM 프로비저닝, 백업/복구 작업 등과 같은 추가 사용을 위한 복사본을 빠르게 생성할 수 있습니다.</block>
  <block id="1a795345e422d7dbcca8fe38671a9371" category="summary">vMSC 설계 및 구현 지침.</block>
  <block id="b73deaadc37ea1c7a13ad17af6730c42" category="doc">vMSC 설계 및 구현 지침</block>
  <block id="3512760e2d3fc1a9dd2116e83bb0cada" category="paragraph">이 문서에서는 ONTAP 스토리지 시스템을 지원하는 vMSC에 대한 설계 및 구현 지침을 개략적으로 설명합니다.</block>
  <block id="556669df5b5073ab3d2ddcf638e942d9" category="section-title">NetApp 스토리지 구성</block>
  <block id="7f4d4fbe08a8a895671d05c4a82b0c85" category="inline-link">MetroCluster 문서</block>
  <block id="002eb41870df47521a2b59424d251f60" category="inline-link">SnapMirror 비즈니스 연속성 개요</block>
  <block id="008c17a2bb74d3d9706c0f2c88499240" category="paragraph">NetApp MetroCluster에 대한 설정 지침(MCC 구성이라고 함)은 에서 확인할 수 있습니다<block ref="2c736bccede87dae47dcf61108f083c4" category="inline-link-rx"></block>. SnapMirror 활성 동기화에 대한 지침은 에서도 확인할 수 있습니다<block ref="14203840309dd1b6e13f73373477bb9d" category="inline-link-rx"></block>.</block>
  <block id="447566f62201eb825a1f6fb7a570873f" category="paragraph">MetroCluster를 구성한 후에는 기존 ONTAP 환경을 관리하는 것과 같습니다. CLI(Command Line Interface), System Manager, Ansible과 같은 다양한 툴을 사용하여 SVM(스토리지 가상 머신)을 설정할 수 있습니다. SVM을 구성한 후 정상 작업에 사용할 클러스터에 논리 인터페이스(LIF), 볼륨 및 논리 유닛 번호(LUN)를 생성합니다. 이러한 오브젝트는 클러스터 피어링 네트워크를 사용하여 다른 클러스터로 자동으로 복제됩니다.</block>
  <block id="b5486be95ed9ae2e4681a39cf8fe8041" category="inline-link">일관성 그룹 개요</block>
  <block id="5440d8600dfca322be65444d14c4566f" category="paragraph">MetroCluster를 사용하지 않는 경우 SnapMirror 액티브 동기화를 사용하여 서로 다른 장애 도메인에 있는 여러 ONTAP 클러스터에서 데이터 저장소에 대한 세분화된 보호와 액티브-액티브 액세스를 제공할 수 있습니다. SnapMirror 액티브 동기화에서는 정합성 보장 그룹을 사용하여 하나 이상의 데이터 저장소 간에 쓰기 순서 일관성을 보장하고 애플리케이션 및 데이터 저장소 요구 사항에 따라 여러 정합성 보장 그룹을 생성할 수 있습니다. 일관성 그룹은 여러 데이터 저장소 간에 데이터를 동기화해야 하는 애플리케이션에 특히 유용합니다. 또한 SnapMirror 활성 동기화는 RDM(Raw Device Mappings) 및 게스트 내 iSCSI 초기자가 있는 게스트 연결 스토리지를 지원합니다. 일관성 그룹에 대한 자세한 내용은 에서 확인할 수 있습니다<block ref="8bba9b5b97dba092834d7a48a07f102d" category="inline-link-rx"></block>.</block>
  <block id="f9ac6f5e1bf01f1df914b714d5e6cb02" category="paragraph">SnapMirror 액티브 동기화를 사용하여 vMSC 구성을 관리하는 것은 MetroCluster와 비교하여 몇 가지 차이가 있습니다. 첫째, SAN 전용 구성이며 SnapMirror 활성 동기화로 NFS 데이터 저장소를 보호할 수 없습니다. 둘째, 두 장애가 발생한 도메인 모두에서 복제된 데이터 저장소를 액세스할 수 있도록 LUN의 두 복제본을 ESXi 호스트에 매핑해야 합니다.</block>
  <block id="c972b11c861e42787c05a2ee24828e3a" category="section-title">VMware vSphere HA</block>
  <block id="57166da54d8751e1ed084f00b3f169e3" category="section-title">vSphere HA 클러스터를 생성합니다</block>
  <block id="829006223e7bdcfd478d2261f1d5ac40" category="inline-link">docs.vmware.com 에서 vSphere Client에서 클러스터를 생성하고 구성하는 방법</block>
  <block id="2bbae4763835d2e2dd123c1b4b0ae73d" category="paragraph">vSphere HA 클러스터 생성은 에서 자세히 설명하는 다단계 프로세스입니다<block ref="dd51ccd863dd3c9fbca770681f8e68a9" category="inline-link-rx"></block>. 즉, 먼저 빈 클러스터를 생성한 다음 vCenter를 사용하여 호스트를 추가하고 클러스터의 vSphere HA 및 기타 설정을 지정해야 합니다.</block>
  <block id="d50e63b9f70efedde8dc093be8ec12b2" category="inline-link">VMware vSphere Metro Storage Cluster 권장 사례</block>
  <block id="33d532b774d7b67104f4749e25ba03ef" category="paragraph">* 참고: * 이 문서의 어떤 내용도 대체되지 않습니다<block ref="3a8301f60ad04eb873ae8dea15ee0495" category="inline-link-rx"></block></block>
  <block id="950954623b197b80e3ebb95b0adcc3de" category="paragraph">HA 클러스터를 구성하려면 다음 단계를 완료하십시오.</block>
  <block id="1073102bd8c6cbd17340f2a19043583f" category="list-text">vCenter UI에 연결합니다.</block>
  <block id="ebf69ea3a3e34739bde13d589e85ef10" category="list-text">호스트 및 클러스터 에서 HA 클러스터를 생성할 데이터 센터를 찾습니다.</block>
  <block id="d8fd85bbc0cd4746e5d80e291696b86c" category="list-text">데이터 센터 개체를 마우스 오른쪽 버튼으로 클릭하고 New Cluster를 선택합니다. 기본 사항에서 vSphere DRS 및 vSphere HA를 사용하도록 설정했는지 확인합니다. 마법사를 완료합니다.</block>
  <block id="f2c634ca704e26f96be1723db6dda32a" category="image-alt">자동으로 생성된 컴퓨터 설명 스크린샷</block>
  <block id="f4f59bf1e324854573172ca2b5070d45" category="list-text">클러스터를 선택하고 구성 탭으로 이동합니다. vSphere HA를 선택하고 Edit를 클릭합니다.</block>
  <block id="329c69e52a7de6215aa4dbfa19940f2d" category="list-text">호스트 모니터링 에서 호스트 모니터링 활성화 옵션을 선택합니다.</block>
  <block id="9fc231ac455a53f2fabc59f29ab537ad" category="list-text">오류 및 응답 탭에 있는 VM 모니터링에서 VM 모니터링만 옵션 또는 VM 및 애플리케이션 모니터링 옵션을 선택합니다.</block>
  <block id="58aea8c81a7e8b8160584574af309fbb" category="list-text">Admission Control에서 HA 승인 제어 옵션을 cluster resource reserve로 설정하고 50% CPU/MEM을 사용합니다.</block>
  <block id="d94a9f01bee7dcc2643864bf92ab4e59" category="list-text">"Ok"를 클릭합니다.</block>
  <block id="3f059eee365aa5c64c0be1d6dba81d69" category="list-text">DRS를 선택하고 편집을 클릭합니다.</block>
  <block id="7b5f9be03fd1421a9da56c2c7677ad69" category="list-text">응용 프로그램에서 요구하지 않는 한 자동화 수준을 수동으로 설정합니다.</block>
  <block id="a8ee10582e28e3623629963a88ff5ec9" category="image-alt">vMSC 3 5</block>
  <block id="256164bb48582e5267e408f2e67e1939" category="inline-link">docs.vmware.com</block>
  <block id="91fb89f03b846483f7108d3f1bfb0156" category="list-text">VM 구성 요소 보호를 활성화합니다. 을 참조하십시오<block ref="fc88c93ad20ad804a211f4e6fea63e56" category="inline-link-rx"></block>.</block>
  <block id="918c2d8e02dbd2c1f4cc3a0062690387" category="list-text">MCC가 있는 vMSC에는 다음과 같은 vSphere HA 설정이 추가로 권장됩니다.</block>
  <block id="d64ed3e9c10229648e069f56e32f4c8e" category="cell">응답</block>
  <block id="f3c1d0e4118d5d9501e1a7aeed19d224" category="cell">호스트 오류입니다</block>
  <block id="45d583cd5692c76d45e96536edce2a0e" category="cell">VM을 다시 시작합니다</block>
  <block id="1c3a7ae924920b573baede481becd22f" category="cell">호스트 격리</block>
  <block id="2e011e74abc75a2823c627b7ee9e22a7" category="cell">영구적 디바이스 손실(PDL)이 있는 데이터 저장소</block>
  <block id="49476a1ad365d5f8deb36464de7fe33b" category="cell">VM의 전원을 끄고 다시 시작합니다</block>
  <block id="e7bbd35db169028c75e7c8ae655bf6ae" category="cell">모든 경로가 다운된 데이터 저장소(APD)</block>
  <block id="e7480b00a5e3efd904a08ca88804de45" category="cell">손님이 마음을 아프지 않습니다</block>
  <block id="e8896c595f3effde37ef29d7c6233703" category="cell">VM을 재설정합니다</block>
  <block id="59695df3d45a3a21b8ff0bf57fda6a2b" category="cell">VM 다시 시작 정책</block>
  <block id="a150f56b87fd99bf9bf019f8447ba68b" category="cell">VM의 중요도에 따라 결정됩니다</block>
  <block id="370a480458a8c63a838940f1241e14ee" category="cell">호스트 격리에 대한 응답입니다</block>
  <block id="11f30f9be08cd4f9e500290222ddc552" category="cell">VM을 종료하고 다시 시작합니다</block>
  <block id="fb53fafa45c0de9bd41d368c7455c9f1" category="cell">PDL이 있는 데이터 저장소에 대한 응답입니다</block>
  <block id="d7c3b9f5568eb60f08076b29490afcaf" category="cell">APD가 있는 데이터 저장소에 대한 응답입니다</block>
  <block id="423b2d98eae113ae3391aa0b12f11935" category="cell">VM 전원 끄기 및 재시작(기본)</block>
  <block id="132bbe6dbceb01227dba5ab04db7202b" category="cell">APD에 대한 VM 장애 조치 지연</block>
  <block id="8d15ed7d27d83ed6229a66b1f44b7696" category="cell">3분</block>
  <block id="8c7b0644547f0ee3fe537e8ba441566d" category="cell">APD 시간 제한이 설정된 APD 복구에 대한 응답입니다</block>
  <block id="4dea08318b2824f845e9b889a6e17778" category="cell">VM 모니터링 민감도</block>
  <block id="f535a28adc173e28610c129d0dc578ae" category="cell">사전 설정 높음</block>
  <block id="83164803a765d1ea1f10d50dfdd26130" category="section-title">Heartbeating에 대한 데이터 저장소를 구성합니다</block>
  <block id="22c81b09ec3086b2dce8f68867a221e0" category="paragraph">vSphere HA는 관리 네트워크에 장애가 발생한 경우 데이터 저장소를 사용하여 호스트와 가상 머신을 모니터링합니다. vCenter가 하트비트 데이터 저장소를 선택하는 방법을 구성할 수 있습니다. 하트비팅을 위해 데이터 저장소를 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="64809e5386c9dc53f894f772f27d1b44" category="list-text">Datastore Heartbeating 섹션에서 Specified List 에서 Use datastores 를 선택하고 필요한 경우 자동으로 보완합니다.</block>
  <block id="fc66ba7317ceb4220dc88aa267db085d" category="list-text">vCenter가 두 사이트에서 사용할 데이터 저장소를 선택하고 OK를 누릅니다.</block>
  <block id="1d2b14769d080b9214d9e407dfc92a64" category="section-title">고급 옵션 구성</block>
  <block id="a22b9827e1a78c5fb9c939a78c116a05" category="paragraph">* 호스트 장애 감지 *</block>
  <block id="a9316d69e5abcfaffc56fc8f5e645412" category="paragraph">격리 이벤트는 HA 클러스터에 있는 호스트가 네트워크 또는 클러스터의 다른 호스트에 대한 연결이 끊어질 때 발생합니다. 기본적으로 vSphere HA는 관리 네트워크의 기본 게이트웨이를 기본 격리 주소로 사용합니다. 하지만 ping을 수행할 호스트에 대한 추가 격리 주소를 지정하여 격리 응답을 트리거할지 여부를 결정할 수 있습니다. 사이트당 하나씩 ping을 수행할 수 있는 두 개의 격리 IP를 추가합니다. 게이트웨이 IP를 사용하지 마십시오. 사용되는 vSphere HA 고급 설정은 DAS.isolationaddress입니다. 이러한 목적으로 ONTAP 또는 중재자 IP 주소를 사용할 수 있습니다.</block>
  <block id="102d7879ceca393c309ef492c958e19d" category="inline-link">core.vmware.com</block>
  <block id="27e2292ff6db48ed2e6d50b256eae43e" category="paragraph">을 참조하십시오<block ref="43057df4f3a6b5f2fffe8b7c5a490646" category="inline-link-rx"></block> 자세한 내용은 __.__</block>
  <block id="3f44bb4a3b9420d495e400b9afbda2c7" category="paragraph">das.heartbeatDsPerHost 라는 고급 설정을 추가하면 하트비트 데이터 저장소의 수가 증가할 수 있습니다. 사이트당 2개씩 4개의 하트비트 데이터 저장소(HB DSS)를 사용합니다. "목록에서 선택 하지만 칭찬" 옵션을 사용합니다. 한 사이트에 장애가 발생해도 두 개의 HB DSS가 필요하기 때문입니다. 하지만 MCC 또는 SnapMirror 액티브 동기화로 해당 데이터를 보호할 필요는 없습니다.</block>
  <block id="eaa1dfe3982e06655ce64e240c139b81" category="paragraph">NetApp MetroCluster용 VMware DRS Affinity</block>
  <block id="e32221c52eb3b0bbeb3ca79aad6c90f6" category="paragraph">이 섹션에서는 MetroCluster 환경의 각 사이트\클러스터에 대해 VM 및 호스트용 DRS 그룹을 생성합니다. 그런 다음 VM 호스트 규칙을 구성하여 VM 호스트 선호도를 로컬 스토리지 리소스에 맞춥니다. 예를 들어 사이트 A VM은 VM 그룹 SiteA_VMs에 속하고 사이트 A 호스트는 호스트 그룹 SiteA_HOSTS에 속합니다. 다음으로 VM\Host Rules에서는 SiteA_VMs가 SiteA_hosts의 호스트에서 실행되어야 한다고 설명합니다.</block>
  <block id="5bfa0d712f66aef47f8a2ea582bc0b72" category="list-text">NetApp은 그룹*의 호스트에서 실행해야 함*이 아니라 그룹*의 호스트에서 실행되어야 함*을 사용할 것을 적극 권장합니다. 사이트 A 호스트에 장애가 발생할 경우 사이트 A의 VM을 vSphere HA를 통해 사이트 B의 호스트에서 다시 시작해야 하지만, 후자의 사양에서는 하드 규칙이기 때문에 HA가 사이트 B에서 VM을 다시 시작할 수 없습니다. 이전 사양은 소프트 규칙이며 HA가 발생할 경우 위반되므로 성능보다 가용성이 향상됩니다.</block>
  <block id="cc6a363013bd2a8c1e05304f1c6abd79" category="inline-link">vSphere 모니터링 및 성능</block>
  <block id="db9540392e62211ad47ebec39232329e" category="paragraph">* 참고: * 가상 머신이 VM-호스트 선호도 규칙을 위반할 때 트리거되는 이벤트 기반 알람을 생성할 수 있습니다. vSphere Client에서 가상 머신에 대한 새 경고를 추가하고 이벤트 트리거로 "VM is behaving VM-Host Affinity Rule"을 선택합니다. 알람 생성 및 편집에 대한 자세한 내용은 을 참조하십시오<block ref="d28eed239632aed40803fe0ed2311ba6" category="inline-link-rx"></block> 문서화:</block>
  <block id="124de7d2bc72d75be9e481c1cc56ada2" category="section-title">DRS 호스트 그룹을 생성합니다</block>
  <block id="0759e9476d3bf1868f88356025adafb2" category="paragraph">사이트 A 및 사이트 B에만 해당하는 DRS 호스트 그룹을 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="a69dff3dd4b284f60243dfd62fa4e57f" category="list-text">vSphere 웹 클라이언트에서 인벤토리에서 클러스터를 마우스 오른쪽 버튼으로 클릭하고 설정 을 선택합니다.</block>
  <block id="a130b4af254ead99e9ea83044e54ea1d" category="list-text">VM\호스트 그룹 을 클릭합니다.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">추가 를 클릭합니다.</block>
  <block id="62c4d1538f957af2951f2c93ee191d0b" category="list-text">그룹의 이름을 입력합니다(예: SiteA_hosts).</block>
  <block id="df22605898fc890edbcb2a126aa202ce" category="list-text">유형 메뉴에서 호스트 그룹 을 선택합니다.</block>
  <block id="57c0028584902f6cee210dcc13bc9745" category="list-text">Add를 클릭하고 사이트 A에서 원하는 호스트를 선택한 다음 OK를 클릭합니다.</block>
  <block id="583e6d8c3b1006b0561d4b360e58994f" category="list-text">사이트 B에 대해 다른 호스트 그룹을 추가하려면 다음 단계를 반복합니다</block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">확인 을 클릭합니다.</block>
  <block id="154964ee7fc6d3261ec55811b0ff9972" category="section-title">DRS VM 그룹을 생성합니다</block>
  <block id="40c1eaba5f178f243c57b595b6af4d5e" category="paragraph">사이트 A 및 사이트 B에만 해당하는 DRS VM 그룹을 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="9a209a741c26968fc13ed8192523df15" category="list-text">그룹의 이름을 입력합니다(예: SiteA_VMs).</block>
  <block id="f947c7c9f173289b1c2565b3297095f0" category="list-text">유형 메뉴에서 VM 그룹 을 선택합니다.</block>
  <block id="40a2a21a084c8d16395113cb79a19ebb" category="list-text">추가 를 클릭하고 사이트 A에서 원하는 VM을 선택한 다음 확인 을 클릭합니다.</block>
  <block id="e2e7af699096077fe178ebf021fb2273" category="section-title">VM 호스트 규칙을 생성합니다</block>
  <block id="0a6075f3d3fdbe7c133268face0f5c82" category="paragraph">사이트 A 및 사이트 B에 고유한 DRS 선호도 규칙을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="df4f9bcca0ceb7a67ba25d886a18743b" category="list-text">VM\호스트 규칙을 클릭합니다.</block>
  <block id="876a25c102b5c301814921d1a9c0e625" category="list-text">규칙의 이름을 입력합니다(예: SiteA_affinity).</block>
  <block id="d4b5f57f4e2bd5c357ad9b1fbdc2cf8e" category="list-text">규칙 사용 옵션이 선택되어 있는지 확인합니다.</block>
  <block id="d1169f525bd934df7f1a7e3bcf401997" category="list-text">유형 메뉴에서 가상 머신을 호스트에 선택합니다.</block>
  <block id="77328c16c697ce1d6c036c3f950e7542" category="list-text">VM 그룹(예: SiteA_VMS)을 선택합니다.</block>
  <block id="b36943ce975d4c5c6e9481a4ca396270" category="list-text">호스트 그룹(예: SiteA_hosts)을 선택합니다.</block>
  <block id="32fbcb32cfae9a0656233943c28f7c94" category="list-text">이 단계를 반복하여 사이트 B에 대해 다른 VM\호스트 규칙을 추가합니다</block>
  <block id="ff0ded925b170243e5154c9a687bb925" category="section-title">NetApp MetroCluster용 VMware vSphere Storage DRS</block>
  <block id="b0cb5ad168b84040eff8132c70e41fdb" category="section-title">데이터 저장소 클러스터를 생성합니다</block>
  <block id="488f70e76f3c9ddf155b693e31c5a1e1" category="paragraph">각 사이트에 대해 데이터 저장소 클러스터를 구성하려면 다음 단계를 완료합니다.</block>
  <block id="1dfbc2b980c0b56a5d9889c6d9a25460" category="list-text">vSphere Web Client를 사용하여 Storage 아래에 HA 클러스터가 있는 데이터 센터로 이동합니다.</block>
  <block id="dfc332b252ad3de167b6a336d7e70d46" category="list-text">데이터 센터 개체를 마우스 오른쪽 버튼으로 클릭하고 스토리지 &gt; 새 데이터 저장소 클러스터 를 선택합니다.</block>
  <block id="7ce7f4ad7022187801efdf33d1fab92d" category="list-text">Turn on Storage DRS 옵션을 선택하고 Next를 클릭합니다.</block>
  <block id="6196801f8f77bab7132531adbb268512" category="list-text">모든 옵션을 자동화 안 함(수동 모드)으로 설정하고 다음을 클릭합니다.</block>
  <block id="cfcdd0a8a765af314fb460ad445fb375" category="list-text">NetApp는 관리자가 마이그레이션이 필요한 시기를 결정하고 제어할 수 있도록 Storage DRS를 수동 모드로 구성하는 것이 좋습니다.</block>
  <block id="dfffe1ce0daeb61f9fbc153ae4945fd4" category="image-alt">설명 텍스트가 자동으로 생성됩니다</block>
  <block id="51a3bc726f294f3376fcaa12ccdf8b3b" category="list-text">Enable I/O Metric for SDRS Recommendations 확인란이 선택되어 있는지 확인합니다. 메트릭 설정을 기본값으로 유지할 수 있습니다.</block>
  <block id="829b62dbd6a4923b66591b2bff38ed5b" category="list-text">HA 클러스터를 선택하고 Next를 클릭합니다.</block>
  <block id="30fe6cfa0a4c5fb23fccfe149cefc006" category="list-text">사이트 A에 속하는 데이터 저장소를 선택하고 Next를 클릭합니다.</block>
  <block id="4ea461b22638db4c94aa076d62a2065f" category="list-text">옵션을 검토하고 마침 을 클릭합니다.</block>
  <block id="7b79e97caff76847cf350f1197c49953" category="list-text">이 단계를 반복하여 사이트 B 데이터 저장소 클러스터를 생성하고 사이트 B의 데이터 저장소만 선택되어 있는지 확인합니다.</block>
  <block id="d8f83b09bd6b864f22076c109cfaae66" category="section-title">vCenter Server 가용성</block>
  <block id="605b8c1efcf2de9164e5d5425c67bdcd" category="paragraph">vCenter Server Appliance(VCSA)는 vCenter HA로 보호되어야 합니다. vCenter HA를 사용하면 액티브-패시브 HA 쌍에 VCSA 두 개를 구축할 수 있습니다. 각 장애 도메인에 1개 에서 vCenter HA에 대한 자세한 내용을 확인할 수 있습니다<block ref="173ca8434bdf39dd0a60efe576d066cd" category="inline-link-rx"></block>.</block>
  <block id="2b6203f34def274ff7424bf1d64a9bca" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 네트워크 설정을 구성하는 것은 다른 네트워크 구성과 마찬가지로 간단합니다.</block>
  <block id="70901a02a148fd2dfc1ff5736f4f5336" category="list-text">스토리지 네트워크 트래픽을 다른 네트워크와 분리합니다. 전용 VLAN 또는 스토리지에 개별 스위치를 사용하면 별도의 네트워크를 구축할 수 있습니다. 스토리지 네트워크가 업링크와 같은 물리적 경로를 공유하는 경우 충분한 대역폭을 확보하기 위해 QoS 또는 추가 업링크 포트가 필요할 수 있습니다. 호스트를 스토리지에 직접 연결하지 말고, 스위치를 사용하여 중복 경로를 확보하고 VMware HA가 개입 없이 작동할 수 있도록 하십시오. 을 참조하십시오 <block ref="2d54da766c3f840b00eab5923273fca5" category="inline-link-macro-rx"></block> 자세한 내용은 를 참조하십시오.</block>
  <block id="ed895c1c16c46a33c1fb8d980afb4d4b" category="list-text">현재 지원되는 모든 VMware vSphere 버전은 NFS v3 및 v4.1을 모두 사용할 수 있습니다. nconnect에 대한 공식 지원이 NFS v3용 vSphere 8.0 업데이트 2에 추가되었습니다. NFS v4.1의 경우 vSphere는 세션 트렁킹, Kerberos 인증 및 무결성을 통한 Kerberos 인증을 계속 지원합니다. 세션 트렁킹에는 ONTAP 9.14.1 이상 버전이 필요합니다.</block>
  <block id="83d007e105712dc05dcf363c7151dba1" category="paragraph">NFSv3과 NFSv4.1은 서로 다른 잠금 메커니즘을 사용한다는 점을 유의해야 합니다. NFSv3은 클라이언트 측 잠금을 사용하는 반면 NFSv4.1은 서버 측 잠금을 사용합니다. 두 프로토콜을 통해 ONTAP 볼륨을 내보낼 수 있지만 ESXi는 하나의 프로토콜을 통해서만 데이터 저장소를 마운트할 수 있습니다. 그러나 다른 ESXi 호스트가 다른 버전을 통해 동일한 데이터 저장소를 마운트할 수 없다는 의미는 아닙니다. 문제를 방지하려면 마운트할 때 사용할 프로토콜 버전을 지정하고 모든 호스트가 동일한 버전과 동일한 잠금 스타일을 사용하도록 해야 합니다. 여러 호스트에 NFS 버전을 혼합하여 사용하지 않는 것이 중요합니다. 가능한 경우 호스트 프로필을 사용하여 준수 여부를 확인합니다.
** NFSv3과 NFSv4.1 간에 자동 데이터 저장소가 변환되지 않으므로 새 NFSv4.1 데이터 저장소를 생성하고 Storage vMotion을 사용하여 VM을 새 데이터 저장소로 마이그레이션합니다.
** 의 NFS v4.1 상호 운용성 표 노트를 참조하십시오<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> 지원을 위해 필요한 특정 ESXi 패치 수준
* NFS 내보내기 정책은 vSphere 호스트의 액세스를 제어하는 데 사용됩니다. 여러 볼륨(데이터 저장소)에 하나의 정책을 사용할 수 있습니다. NFSv3에서 ESXi는 sys(UNIX) 보안 스타일을 사용하며 VM을 실행하려면 루트 마운트 옵션이 필요합니다. ONTAP에서 이 옵션을 수퍼 유저라고 하며, 수퍼유저 옵션을 사용할 때 익명 사용자 ID를 지정할 필요가 없습니다. 에 대해 다른 값을 사용하여 정책 규칙을 내보냅니다<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> 및<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> ONTAP 툴을 사용하여 SVM 검색 문제를 일으킬 수 있습니다. 샘플 정책은 다음과 같습니다.
** 액세스 프로토콜: NFS3
** 클라이언트 일치 사양: 192.168.42.21
** RO 액세스 규칙: sys
**RW 액세스 규칙: sys
** 익명 UID
** 수퍼 유저: sys
* VMware VAAI용 NetApp NFS 플러그인을 사용하는 경우 프로토콜을 로 설정해야 합니다<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> 엑스포트 정책 규칙이 생성되거나 수정된 경우 VAAI 복사 오프로드가 작동하고 프로토콜을 로 지정하려면 NFSv4 프로토콜이 필요합니다<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> 에서 NFSv3 및 NFSv4 버전을 모두 자동으로 포함합니다.
* NFS 데이터 저장소 볼륨은 SVM의 루트 볼륨에서 연결되므로 데이터 저장소 볼륨을 탐색하고 마운트하려면 ESXi에 루트 볼륨에 대한 액세스 권한도 있어야 합니다. 루트 볼륨 및 데이터 저장소 볼륨의 교차점이 중첩된 다른 볼륨에 대한 내보내기 정책에는 읽기 전용 액세스를 부여하는 ESXi 서버에 대한 규칙 또는 규칙이 포함되어야 합니다. 다음은 VAAI 플러그인을 사용하는 루트 볼륨에 대한 샘플 정책입니다.
** 액세스 프로토콜: NFS(NFS3 및 nfs4 모두 포함)
** 클라이언트 일치 사양: 192.168.42.21
** RO 액세스 규칙: sys
**RW 액세스 규칙: 없음(루트 볼륨에 대한 최상의 보안)
** 익명 UID
** superuser:sys(VAAI를 사용하는 루트 볼륨에도 필요)
* VMware vSphere용 ONTAP 툴 사용(가장 중요한 모범 사례):
** VMware vSphere용 ONTAP 툴을 사용하여 데이터 저장소를 프로비저닝할 수 있습니다. 내보내기 정책 관리가 자동으로 간소화되기 때문입니다.
** 플러그인을 사용하여 VMware 클러스터에 대한 데이터 저장소를 생성할 때 단일 ESX Server가 아닌 클러스터를 선택합니다. 이 옵션을 선택하면 데이터 저장소가 클러스터의 모든 호스트에 자동으로 마운트됩니다.
** 플러그인 마운트 기능을 사용하여 기존 데이터 저장소를 새 서버에 적용합니다.
** VMware vSphere용 ONTAP 툴을 사용하지 않을 경우, 모든 서버 또는 추가 액세스 제어가 필요한 각 서버 클러스터에 대해 단일 내보내기 정책을 사용하십시오.
* ONTAP는 접합을 사용하여 트리에서 볼륨을 배열할 수 있는 유연한 볼륨 네임스페이스 구조를 제공하지만 이 접근 방식은 vSphere에 아무런 가치가 없습니다. 스토리지의 네임스페이스 계층에 관계없이 데이터 저장소의 루트에 각 VM에 대한 디렉토리를 생성합니다. 따라서 가장 좋은 방법은 SVM의 루트 볼륨에서 vSphere의 볼륨에 대한 접합 경로를 마운트하는 것입니다. 이것이 바로 VMware vSphere용 ONTAP 툴이 데이터 저장소를 프로비저닝하는 방법입니다. 중첩된 연결 경로가 없다는 것은 루트 볼륨 이외의 볼륨에 종속되지 않으며 볼륨을 오프라인으로 전환하거나 의도적으로 파괴하더라도 다른 볼륨에 대한 경로에 영향을 주지 않는다는 것을 의미합니다.
* 4K의 블록 크기는 NFS 데이터 저장소의 NTFS 파티션에 적합합니다. 다음 그림에서는 vSphere 호스트에서 ONTAP NFS 데이터 저장소로의 접속을 보여 줍니다.</block>
  <block id="59cfc5aaa0678bcb883492b4397c71b8" category="cell">예(ONTAP 9.14.1)</block>
  <block id="f37fed71aa90eb80f77d4f14b0ee295b" category="summary">NetApp ONTAP이 포함된 vSphere Metro 스토리지 클러스터</block>
  <block id="a58c81d13cac4e9b37bba2bd7fc3a93d" category="paragraph">업계 최고 수준의 VMware vSphere 하이퍼바이저를 vMSC(vSphere Metro Storage Cluster)라고 하는 확장 클러스터로 구축할 수 있습니다.</block>
  <block id="e5239709587bb3ebb34629be6c41ac7b" category="paragraph">vMSC 솔루션은 NetApp ® MetroCluster ™ 및 SnapMirror 액티브 동기화(이전의 SnapMirror Business Continuity 또는 SMBC) 모두에서 지원되며, 하나 이상의 장애가 발생한 도메인이 총 운영 중단을 겪을 경우 고급 비즈니스 연속성을 제공합니다. 다양한 실패 모드에 대한 복원력은 선택한 구성 옵션에 따라 다릅니다.</block>
  <block id="e3224e391e08365c1593c07b9fe99cfa" category="section-title">vSphere 환경을 위한 무중단 가용성 솔루션</block>
  <block id="e724bf1a385b292b55017a9963682b40" category="paragraph">NetApp ONTAP 아키텍처는 데이터 저장소에 SAN(FCP, iSCSI 및 NVMe-oF) 및 NAS(NFS v3 및 v4.1) 서비스를 제공하는 유연하고 확장 가능한 스토리지 플랫폼입니다. NetApp AFF, ASA 및 FAS 스토리지 시스템은 ONTAP 운영 체제를 사용하여 S3 및 SMB/CIFS와 같은 게스트 스토리지 액세스를 위한 추가 프로토콜을 제공합니다.</block>
  <block id="ffa76ec5527e36c51f49fe091541cca6" category="paragraph">NetApp MetroCluster는 NetApp의 HA(컨트롤러 페일오버 또는 CFO) 기능을 사용하여 컨트롤러 장애로부터 보호합니다. 또한, 로컬 SyncMirror 기술, 재해 시 클러스터 페일오버(주문형 컨트롤러 페일오버 또는 CFOD), 하드웨어 이중화 및 지리적 분리를 통해 높은 수준의 가용성을 달성합니다. SyncMirror은 데이터를 두 플렉스에 기록하여 MetroCluster 구성의 두 부분에 걸쳐 동기식으로 데이터를 미러링합니다. 로컬 플렉스(로컬 쉘프에 있음)가 데이터를 능동적으로 제공하고 원격 플렉스(원격 쉘프에 있음)는 일반적으로 데이터를 제공하지 않음. 컨트롤러, 스토리지, 케이블, 스위치(패브릭 MetroCluster와 함께 사용), 어댑터와 같은 모든 MetroCluster 구성요소에 대해 하드웨어 이중화가 적용됩니다.</block>
  <block id="54823008c0a63d8491d2c84e13356f84" category="paragraph">NetApp SnapMirror 액티브 동기화는 FCP 및 iSCSI SAN 프로토콜을 통해 데이터 저장소의 세부적 보호 기능을 제공하므로 우선순위가 높은 워크로드만 선택적으로 보호할 수 있습니다. Active-Standby 솔루션인 NetApp MetroCluster과 달리 로컬 및 원격 사이트에 대한 액티브-액티브 액세스를 제공합니다. 현재 활성 동기화는 한 쪽이 다른 쪽보다 선호되는 비대칭 솔루션으로, 더 나은 성능을 제공합니다. 이 기능은 ESXi 호스트에 선호하는 컨트롤러를 자동으로 알려주는 ALUA(Asymmetric Logical Unit Access) 기능을 사용하여 달성할 수 있습니다. 하지만 NetApp는 액티브 동기화가 곧 완벽한 대칭 액세스를 활성화할 것이라고 발표했습니다.</block>
  <block id="d3e911c902a6b066f9c31d471d16fb21" category="paragraph">두 사이트에 걸쳐 VMware HA/DRS 클러스터를 생성하기 위해 ESXi 호스트는 VCSA(vCenter Server Appliance)에 의해 사용되고 관리됩니다. vSphere 관리, vMotion ® 및 가상 머신 네트워크는 두 사이트 간에 중복 네트워크를 통해 연결됩니다. HA/DRS 클러스터를 관리하는 vCenter Server는 두 사이트의 ESXi 호스트에 연결할 수 있으며 vCenter HA를 사용하여 구성해야 합니다.</block>
  <block id="da76be2bc20d4e043d9a2019b817214f" category="inline-link">vSphere Client에서 클러스터를 생성하고 구성하는 방법</block>
  <block id="e02f3e9258a23204655bd512ec53911d" category="paragraph">을 참조하십시오<block ref="c06ae090600e7aa086edfa28514435e7" category="inline-link-rx"></block> vCenter HA를 구성합니다.</block>
  <block id="bdd88c75f085534f6e2cdc7726cf1dd6" category="paragraph">또한 을 참조하십시오<block ref="3a8301f60ad04eb873ae8dea15ee0495" category="inline-link-rx"></block>.</block>
  <block id="38910d3dab2318849fd5f1a1dfbe0152" category="inline-link">VMware 스토리지 호환성 가이드 를 참조하십시오</block>
  <block id="eab65c9bc6c74eff9aee0d7f0c44276d" category="paragraph">vMSC(vSphere Metro Storage Cluster)는 VM(가상 머신) 및 컨테이너를 장애로부터 보호하는 인증 구성입니다. 이는 확장 스토리지 개념을 랙, 건물, 캠퍼스 또는 도시와 같은 여러 장애 도메인에 분산되는 ESXi 호스트 클러스터와 함께 사용하여 달성할 수 있습니다. NetApp MetroCluster 및 SnapMirror Active sync 스토리지 기술은 호스트 클러스터에 각각 RPO=0 또는 RPO=0 정도의 보호를 제공하는 데 사용됩니다. vMSC 구성은 완전한 물리적 또는 논리적 "사이트"에 장애가 발생하더라도 데이터를 항상 사용할 수 있도록 설계되었습니다. vMSC 구성에 포함된 스토리지 디바이스는 vMSC 인증 프로세스를 성공적으로 완료한 후 인증을 받아야 합니다. 지원되는 모든 저장 장치는 에서 찾을 수 있습니다<block ref="293ceee3268d7991d7fe245e02c1c5c9" category="inline-link-rx"></block>.</block>
  <block id="838b66b875df1b432ac420a98cba3db6" category="paragraph">vSphere Metro Storage Cluster의 설계 지침에 대한 자세한 내용은 다음 설명서를 참조하십시오.</block>
  <block id="07aaf2aebfd07b8763284018d1ebbf57" category="inline-link">VMware vSphere는 NetApp MetroCluster를 지원합니다</block>
  <block id="a4a5fd5b00daf98bd381d80257378acd" category="list-text"><block ref="a4a5fd5b00daf98bd381d80257378acd" category="inline-link-rx"></block></block>
  <block id="c3dc11e39d996a00b095022f4e56583d" category="inline-link">NetApp SnapMirror 비즈니스 연속성이 포함된 VMware vSphere 지원</block>
  <block id="8f675397d9c0ef95aa8b3f0ada9d601a" category="list-text"><block ref="f53214cfd764fa0267c92323be0d7337" category="inline-link-rx"></block> (현재 SnapMirror Active Sync라고 함)</block>
  <block id="ee0a206d2287c89b2a7b780e07929b81" category="paragraph">지연 시간 고려 사항에 따라 NetApp MetroCluster는 vSphere와 함께 사용할 수 있도록 두 가지 구성으로 구축할 수 있습니다.</block>
  <block id="b553530def78406c0977f70d5e90b9e8" category="list-text">MetroCluster를 확장합니다</block>
  <block id="2d90abe978ed8084d304295ad0a8c8fd" category="list-text">Fabric MetroCluster의 약어입니다</block>
  <block id="b03023e82bda6a71adc49c4834e3b6ab" category="paragraph">다음은 확장 MetroCluster의 상위 수준 토폴로지 다이어그램을 보여 줍니다.</block>
  <block id="b0c20dc8226bb49f35f0f68f7ef77bba" category="image-alt">MCC가 포함된 vMSC 다이어그램</block>
  <block id="119be031ef4485d20c7683d291d0e9f6" category="inline-link">MetroCluster 설명서</block>
  <block id="ad9122c6d75ebaa024669fde1c0bdfb8" category="paragraph">을 참조하십시오<block ref="d8a206747dbcec13122724b2aee18957" category="inline-link-rx"></block> MetroCluster에 대한 구체적인 설계 및 구축 정보를 확인하십시오.</block>
  <block id="b47354fcd7d17ab4fbb3283f71677efe" category="paragraph">SnapMirror Active Sync는 두 가지 방법으로 배포할 수도 있습니다.</block>
  <block id="314084a577b998d8089dff72c98c58b0" category="list-text">비대칭</block>
  <block id="40e2e641bad11918585c3dd4f76c2716" category="list-text">대칭(ONTAP 9.14.1의 비공개 미리보기)</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">NetApp 문서</block>
  <block id="1c71125ba0668792e46d93c17dc6c428" category="paragraph">을 참조하십시오<block ref="9ace5d3ebe2fe57037322de54ac9a869" category="inline-link-rx"></block> SnapMirror 액티브 동기화에 대한 특정 설계 및 구축 정보를 제공합니다.</block>
  <block id="bca8b52c503406abc3e9e50c5352d0a2" category="paragraph">이 문서에서는 VMware의 업계 최고 수준의 DR(재해 복구) 소프트웨어인 VMware SRM(Site Recovery Manager)용 ONTAP 솔루션에 대해 소개합니다. 최신 제품 정보와 Best Practice를 통해 배포를 간소화하고 위험을 줄이며 지속적인 관리를 간소화할 수 있습니다.</block>
  <block id="4f46fffb0ac7017fd2b42c10d6aa03fc" category="paragraph">VM을 백업하고 신속하게 복구하는 것은 ONTAP for vSphere의 탁월한 강점 중 하나로서, vCenter에서 VMware vSphere용 SnapCenter 플러그인을 사용하여 이러한 기능을 쉽게 관리할 수 있습니다.</block>
  <block id="3a021eaaeb6692340890af4de2f7514a" category="paragraph">다음 섹션에서는 VMware 및 ONTAP SRM에 대한 구축 Best Practice에 대해 설명합니다.</block>
  <block id="b69cd5a82aaf0c524a71d46ec6fdd29c" category="cell">NFS v4.1 세션 트렁킹에는 ONTAP 9.14.1 이상이 필요합니다</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">플러그인은 ONTAP용 VASA Provider의 다양한 기능을 위한 관리 인터페이스이기도 하여, VVOL을 통한 스토리지 정책 기반 관리를 지원합니다. VMware vSphere용 ONTAP 툴을 등록한 후 이를 사용하여 스토리지 기능 프로필을 생성하고 이를 스토리지에 매핑하며 시간이 지남에 따라 데이터 저장소가 프로파일을 준수하는지 확인합니다. VASA Provider는 VVOL 데이터 저장소를 생성하고 관리하는 인터페이스도 제공합니다.</block>
  <block id="d9c9eb44a58ee1ce90daa68527aa8930" category="summary">MCC가 있는 vMSC에 대한 실패 시나리오</block>
  <block id="e7c7574b0826c9074f480de76c889ba8" category="paragraph">다음 섹션에서는 vMSC 및 NetApp MetroCluster 시스템의 다양한 장애 시나리오에서 예상되는 결과를 간략하게 설명합니다.</block>
  <block id="c8a2eebb480fef69e6ed917ea7f7a9d3" category="section-title">단일 스토리지 경로 오류</block>
  <block id="b99e8e694b032f593bbd01f6205b4a98" category="paragraph">이 시나리오에서 HBA 포트, 네트워크 포트, 프런트엔드 데이터 스위치 포트 또는 FC 또는 이더넷 케이블과 같은 구성 요소에 장애가 발생하면 ESXi 호스트에서 스토리지 디바이스에 대한 특정 경로가 비활성 상태로 표시됩니다. HBA/네트워크/스위치 포트에서 복원력을 제공하여 스토리지 디바이스에 여러 경로를 구성한 경우 ESXi는 경로 전환을 수행하는 것이 가장 좋습니다. 이 기간 동안 스토리지 디바이스에 다중 경로를 제공하여 스토리지 가용성이 관리되기 때문에 가상 머신은 영향을 받지 않고 계속 실행됩니다.</block>
  <block id="1fff6650ef9c430da0f875c203d5dab0" category="paragraph">* 참고: * 이 시나리오에서는 MetroCluster 동작에 변화가 없으며 모든 데이터 저장소는 해당 사이트에서 그대로 유지됩니다.</block>
  <block id="80fc15dd1deb985234440745e8a78d4c" category="paragraph">NFS/iSCSI 볼륨이 사용되는 환경에서는 NetApp 표준 vSwitch의 NFS vmkernel 포트에 대해 두 개 이상의 네트워크 업링크를 구성하고 분산형 vSwitch에 대해 NFS vmkernel 인터페이스가 매핑된 포트 그룹에서 동일한 네트워크 업링크를 구성하는 것이 좋습니다. NIC 티밍은 Active-Active 또는 Active-Standby 중 하나로 구성할 수 있습니다.</block>
  <block id="0c8694e8ef7f8935edbfac605753bc95" category="paragraph">또한 iSCSI LUN의 경우 vmkernel 인터페이스를 iSCSI 네트워크 어댑터에 바인딩하여 다중 경로를 구성해야 합니다. 자세한 내용은 vSphere 스토리지 설명서를 참조하십시오.</block>
  <block id="0fc808fdb968eb089fbc5124c0a8e15a" category="paragraph">Fibre Channel LUN이 사용되는 환경에서는 NetApp HBA/포트 레벨에서 복원력을 보장하는 HBA를 2개 이상 사용하는 것이 좋습니다. 또한 NetApp은 조닝을 구성하는 모범 사례로서 단일 이니시에이터에 단일 타겟 조닝으로 권장합니다.</block>
  <block id="238c3d1c7bf8b5b42237392383a4c7ab" category="paragraph">모든 신규 및 기존 NetApp 스토리지 장치에 대한 정책을 설정하므로 VSC(가상 스토리지 콘솔)를 사용하여 다중 경로 정책을 설정해야 합니다.</block>
  <block id="217811709dfb096c78e73934de01271c" category="section-title">단일 ESXi 호스트 장애</block>
  <block id="93bc89a0478478dd84d8159a18f6c1a2" category="image-alt">단일 호스트 장애입니다.</block>
  <block id="15023af3b440b4004f509e961bfe1e30" category="paragraph">이 시나리오에서는 ESXi 호스트 장애가 있는 경우 VMware HA 클러스터의 마스터 노드가 더 이상 네트워크 하트비트를 수신하지 않기 때문에 호스트 장애를 감지합니다. 호스트가 실제로 다운되었는지 아니면 네트워크 파티션만 발생하는지 확인하기 위해 마스터 노드는 데이터 저장소 하트비트를 모니터링하고, 이 하트비트가 없는 경우 장애가 발생한 호스트의 관리 IP 주소를 ping하여 최종 점검을 수행합니다. 이러한 검사가 모두 음수이면 마스터 노드가 이 호스트에 장애가 발생한 호스트를 선언하고 장애가 발생한 이 호스트에서 실행 중이던 모든 가상 머신이 클러스터의 나머지 호스트에서 재부팅됩니다.</block>
  <block id="9a11158d52f71012ae8722b09bf8bf29" category="paragraph">DRS VM 및 호스트 선호도 규칙이 구성된 경우(VM 그룹 SiteA_VM의 VM은 호스트 그룹 SiteA_hosts에서 호스트를 실행해야 함), HA 마스터는 먼저 사이트 A에서 사용 가능한 리소스를 확인합니다 사이트 A에 사용 가능한 호스트가 없는 경우 마스터가 사이트 B의 호스트에서 VM을 다시 시작하려고 시도합니다</block>
  <block id="7922c92ff860eb0508dc8cc8aae3ffdd" category="paragraph">로컬 사이트에 리소스 제한이 있는 경우 다른 사이트의 ESXi 호스트에서 가상 머신을 시작할 수 있습니다. 그러나 가상 머신을 로컬 사이트의 정상적인 ESXi 호스트로 다시 마이그레이션하여 규칙을 위반하는 경우 정의된 DRS VM 및 호스트 선호도 규칙이 수정됩니다. DRS가 수동으로 설정된 경우 NetApp는 DRS를 호출하고 권장 사항을 적용하여 가상 머신 배치를 수정하는 것이 좋습니다.</block>
  <block id="387b5a49326be3a47e081682e75e19b4" category="paragraph">이 시나리오에서는 MetroCluster 동작에 변화가 없으며 모든 데이터 저장소가 해당 사이트에서 그대로 유지됩니다.</block>
  <block id="a11ffa7d20dab792fe5aa9c27017493e" category="section-title">ESXi 호스트 격리</block>
  <block id="17e01652089acd413e26ea89cf98a2b8" category="image-alt">ESXi 호스트 격리</block>
  <block id="8a4b746274e9d7129602d54434624806" category="paragraph">이 시나리오에서는 ESXi 호스트의 관리 네트워크가 다운된 경우 HA 클러스터의 마스터 노드가 하트비트를 수신하지 않으므로 이 호스트가 네트워크에서 격리됩니다. 마스터 노드가 데이터 저장소 하트비트를 모니터링하기 시작합니다. 호스트가 있는 경우 마스터 노드에 의해 격리된 것으로 선언됩니다. 구성된 격리 응답에 따라 호스트는 전원을 끄거나, 가상 시스템을 종료하거나, 가상 시스템의 전원을 계속 켜도록 선택할 수 있습니다. 격리 응답의 기본 간격은 30초입니다.</block>
  <block id="a070f7923919fed39772c5d3f91bf482" category="section-title">디스크 쉘프 오류입니다</block>
  <block id="e8acf0e4f25cdd641c9a047482d56ba5" category="paragraph">이 시나리오에서는 두 개 이상의 디스크에서 장애가 발생하거나 전체 쉘프에 장애가 발생합니다. 작동하는 플렉스에서 데이터 서비스를 중단하지 않고 데이터를 제공합니다. 디스크 장애가 로컬 또는 원격 플렉스에 영향을 줄 수 있습니다. 하나의 플렉스만 활성 상태이므로 애그리게이트가 성능 저하 모드로 표시됩니다. 장애가 발생한 디스크를 교체하면 영향을 받는 애그리게이트가 자동으로 다시 동기화되어 데이터를 재구축합니다. 다시 동기화하면 애그리게이트가 정상 미러링된 모드로 자동으로 돌아갑니다. 단일 RAID 그룹 내에서 두 개 이상의 디스크에 장애가 발생한 경우 플렉스를 처음부터 다시 구축해야 합니다.</block>
  <block id="4f90d34a41c7ebc83024a5e3ca35ff3a" category="image-alt">단일 디스크 쉘프 장애입니다.</block>
  <block id="8af0b36d49baf198133a234e76b06445" category="paragraph">*참고:* 이 기간 동안 가상 머신 I/O 작업에는 아무런 영향이 없지만 ISL 링크를 통해 원격 디스크 셸프에서 데이터에 액세스하므로 성능이 저하됩니다.</block>
  <block id="1c872dcd4bcebb1d7567f383901dfc0d" category="section-title">단일 스토리지 컨트롤러 장애</block>
  <block id="68badb604dbd29653979fdc7083cbffe" category="paragraph">이 시나리오에서는 두 스토리지 컨트롤러 중 하나가 한 사이트에서 장애가 발생합니다. 각 사이트에 HA 쌍이 있으므로 한 노드에 장애가 발생하면 운영에 영향을 미치지 않고 다른 노드에 대한 페일오버가 자동으로 트리거됩니다. 예를 들어 노드 A1에 장애가 발생하면 해당 스토리지 및 워크로드가 자동으로 노드 A2로 전송됩니다. 모든 플렉스를 사용할 수 있으므로 가상 머신은 영향을 받지 않습니다. 두 번째 사이트 노드(B1 및 B2)는 영향을 받지 않습니다. 또한 클러스터의 마스터 노드가 네트워크 하트비트를 계속 수신하므로 vSphere HA는 아무 작업도 수행하지 않습니다.</block>
  <block id="0ac25682ea568511724f2e0819127d89" category="image-alt">단일 노드 장애</block>
  <block id="e7b4c0523308b3fd46189b6ab4867fe5" category="paragraph">장애 조치가 롤링 재해의 일부인 경우(노드 A1이 A2로 장애 조치), A2의 후속 장애 또는 사이트 A의 전체 장애가 발생한 경우 사이트 B에서 재해가 발생한 후 전환이 발생할 수 있습니다</block>
  <block id="7b590b52d9f3d4d40cda67758ff92ba1" category="section-title">인터스위치 링크 오류</block>
  <block id="9df08f82abe35d87c6f7c96b18dab755" category="section-title">관리 네트워크에서 스위치 간 링크 오류</block>
  <block id="ed0711cbc7a050952e0e370bab079bff" category="image-alt">관리 네트워크에서 스위치 간 링크 장애 발생</block>
  <block id="a32c6c77bb8d407cf5825aec175bab4b" category="paragraph">이 시나리오에서 프런트엔드 호스트 관리 네트워크의 ISL 링크에 장애가 발생하면 사이트 A의 ESXi 호스트가 사이트 B의 ESXi 호스트와 통신할 수 없습니다 특정 사이트의 ESXi 호스트는 네트워크 하트비트를 HA 클러스터의 마스터 노드로 보낼 수 없기 때문에 이로 인해 네트워크 파티션이 발생합니다. 따라서 파티션으로 인해 두 개의 네트워크 세그먼트가 있으며 각 세그먼트에는 특정 사이트 내의 호스트 장애로부터 VM을 보호하는 마스터 노드가 있습니다.</block>
  <block id="36974534f1a2014a3e7e229d795ef51b" category="paragraph">* 참고: * 이 기간 동안 가상 머신은 계속 실행되고 있으며 이 시나리오에서는 MetroCluster 동작에 변화가 없습니다. 모든 데이터 저장소는 해당 사이트에서 그대로 유지됩니다.</block>
  <block id="628309883a8d1307131d205b200c56ae" category="section-title">스토리지 네트워크에서 스위치 간 링크 오류</block>
  <block id="a9da7e2a43bcea673a22b949355e619d" category="image-alt">스토리지 네트워크에서 스위치 간 링크 장애가 발생했습니다</block>
  <block id="625db96c5ee1e9b5197b6cb3c1715021" category="paragraph">이 시나리오에서는 백엔드 스토리지 네트워크의 ISL 링크에 장애가 발생하면 사이트 A의 호스트가 사이트 B의 클러스터 B의 스토리지 볼륨 또는 LUN에 액세스할 수 없게 되며, 그 반대의 경우도 마찬가지입니다. VMware DRS 규칙은 호스트-스토리지 사이트 선호도를 통해 사이트 내에서 아무런 영향을 받지 않고 가상 시스템을 실행할 수 있도록 정의됩니다.</block>
  <block id="8d9609f32cbee8fa5080f95d71a2a142" category="paragraph">이 기간 동안 가상 머신은 해당 사이트에서 계속 실행되고 있으며 이 시나리오에서는 MetroCluster 동작이 변경되지 않습니다. 모든 데이터 저장소는 해당 사이트에서 그대로 유지됩니다.</block>
  <block id="719831bfdda20be14c04e2b165cce85e" category="paragraph">어떤 이유로 선호도 규칙을 위반하는 경우(예: 디스크가 로컬 클러스터 A 노드에 있는 사이트 A에서 실행되어야 하는 VM1이 사이트 B의 호스트에서 실행), 가상 머신의 디스크는 ISL 링크를 통해 원격으로 액세스됩니다. ISL 링크 장애로 인해 사이트 B에서 실행되는 VM1은 스토리지 볼륨에 대한 경로가 다운되고 특정 가상 시스템이 다운되기 때문에 해당 디스크에 쓸 수 없습니다. 이러한 경우 VMware HA는 호스트가 심박동을 능동적으로 전송하기 때문에 아무 작업도 수행하지 않습니다. 이러한 가상 머신의 전원을 수동으로 끄고 해당 사이트에서 전원을 켜야 합니다. 다음 그림에서는 DRS 선호도 규칙을 위반하는 VM을 보여 줍니다.</block>
  <block id="09ba89b1ea49214c15fbf8ea6f129cb0" category="image-alt">DRS 선호도 규칙을 위반하는 VM은 ISL 장애 후 디스크에 쓸 수 없습니다</block>
  <block id="49f26967af2ad76cacf7888cbeeb0590" category="section-title">모든 인터스위치 오류 또는 전체 데이터 센터 파티션</block>
  <block id="bc331d84348670dff6731555166fa378" category="paragraph">이 시나리오에서는 사이트 간의 모든 ISL 링크가 다운되고 두 사이트가 서로 격리됩니다. 관리 네트워크 및 스토리지 네트워크에서 ISL 장애와 같은 이전 시나리오에서 설명한 것처럼 가상 머신은 완전한 ISL 장애에도 영향을 받지 않습니다.</block>
  <block id="a40e8cf2a5b5b1e22fec9f26cce85b9d" category="paragraph">ESXi 호스트가 사이트 간에 분할된 후 vSphere HA 에이전트는 데이터 저장소 하트비트를 확인하고 각 사이트에서 로컬 ESXi 호스트는 데이터 저장소 하트비트를 해당 읽기-쓰기 볼륨/LUN으로 업데이트할 수 있습니다. 사이트 A의 호스트는 네트워크/데이터 저장소 하트비트가 없기 때문에 사이트 B의 다른 ESXi 호스트에 장애가 발생한 것으로 가정합니다. 사이트 A의 vSphere HA는 사이트 B의 가상 머신을 다시 시작하려고 시도합니다. 스토리지 ISL 장애로 인해 사이트 B의 데이터 저장소에 액세스할 수 없기 때문에 결국 실패합니다. 비슷한 상황이 사이트 B에서 반복됩니다</block>
  <block id="3543d47d1f3a8dc6989a32f62ce3ea77" category="image-alt">모든 ISL 장애 또는 전체 데이터 센터 파티션</block>
  <block id="3a096ef571101010add81b37081d3276" category="paragraph">NetApp에서는 가상 시스템이 DRS 규칙을 위반했는지 여부를 확인하는 것이 좋습니다. 원격 사이트에서 실행되는 모든 가상 머신은 데이터 저장소에 액세스할 수 없으므로 작동이 중지되고 vSphere HA는 로컬 사이트에서 해당 가상 머신을 다시 시작합니다. ISL 링크가 다시 온라인 상태가 되면 동일한 MAC 주소로 실행되는 가상 시스템의 인스턴스가 두 개 있을 수 없으므로 원격 사이트에서 실행 중이던 가상 시스템이 종료됩니다.</block>
  <block id="87e9384cb464ff9a4ce385fc59a178a2" category="image-alt">VM1이 DRS 선호도 규칙을 위반한 데이터 센터 파티션</block>
  <block id="0951e388ebea20c49e71af25ef84947d" category="section-title">NetApp MetroCluster의 두 Fabric에서 스위치 간 링크 장애가 발생했습니다</block>
  <block id="1e9be78885a356d1a2ec0ab0d4a4cecb" category="paragraph">하나 이상의 ISL이 실패하는 경우 트래픽은 나머지 링크를 통해 계속됩니다. 두 Fabric의 모든 ISL에 장애가 발생하여 스토리지와 NVRAM 복제를 위해 사이트 간에 링크가 없는 경우, 각 컨트롤러는 계속해서 로컬 데이터를 제공합니다. ISL을 최소 한 개 이상 복구할 경우 모든 플렉스의 재동기화가 자동으로 수행됩니다.</block>
  <block id="715cbc6f6bcf5da6b73f10233847d3a1" category="paragraph">모든 ISL이 다운된 후에 발생하는 모든 쓰기는 다른 사이트로 미러링되지 않습니다. 따라서 구성이 이 상태일 때 재해 발생 시 전환이 이루어지면 동기화되지 않은 데이터가 손실됩니다. 이 경우 전환 후 복구를 위해 수동 개입이 필요합니다. 장기간 사용할 수 있는 ISL이 없을 경우 관리자는 모든 데이터 서비스를 종료하여 재해 발생 시 전환이 필요할 경우 데이터 손실 위험을 피할 수 있습니다. 이 작업을 수행하는 것은 하나 이상의 ISL을 사용할 수 있게 되기 전에 전환이 필요한 재해의 가능성과 비교해야 합니다. 또는 다중 구간 시나리오에서 ISL이 실패하는 경우 관리자가 모든 링크에 장애가 발생하기 전에 사이트 중 하나로 계획된 전환을 트리거할 수 있습니다.</block>
  <block id="89f375bfe8be0893bf175b89ce754b8e" category="image-alt">NetApp MetroCluster의 두 Fabric에서 스위치 간 링크 장애가 발생했습니다.</block>
  <block id="bc813a6fdbbeebf4d230b7e33d8c3a76" category="section-title">피어링된 클러스터 링크 장애</block>
  <block id="1919456d1613248a128c65a84b235fe5" category="paragraph">피어링된 클러스터 링크 장애 시나리오에서 패브릭 ISL은 여전히 활성 상태이므로 두 사이트에서 데이터 서비스(읽기 및 쓰기)가 두 플렉스에 계속 적용됩니다. 클러스터 구성 변경(예: 새 SVM 추가, 기존 SVM에서 볼륨 또는 LUN 프로비저닝)은 다른 사이트에 전파될 수 없습니다. 이러한 데이터는 로컬 CRS 메타데이터 볼륨에 보관되며 피어링된 클러스터 링크를 복원하면 자동으로 다른 클러스터로 전파됩니다. 피어링된 클러스터 링크를 복원하기 전에 강제 전환이 필요한 경우 전환 프로세스의 일부로 남아 있는 사이트에 있는 메타데이터 볼륨의 원격 복제 복사본에서 미결 클러스터 구성 변경 사항이 자동으로 재생됩니다.</block>
  <block id="77130a0b52e4379c6b6667cf7f8e155c" category="image-alt">피어링된 클러스터 링크 장애</block>
  <block id="9dc32d7afddc9a265c5c2713db55fc70" category="section-title">전체 사이트 오류입니다</block>
  <block id="d0d6a03c382bc5412f1822e5c97d5142" category="paragraph">전체 사이트 A 장애 시나리오에서 사이트 B에 있는 ESXi 호스트는 사이트 A의 ESXi 호스트에서 다운되었기 때문에 네트워크 하트비트를 가져오지 않습니다. 사이트 B의 HA 마스터는 데이터 저장소 하트비트가 없는지 확인하고, 사이트 A의 호스트가 실패하도록 선언한 다음 사이트 B의 가상 머신을 재시작합니다 이 기간 동안 스토리지 관리자는 스위치오버를 수행하여 장애가 발생한 사이트의 노드 서비스를 재개하고 사이트 B에 있는 사이트 A의 모든 스토리지 서비스를 복구합니다 사이트 B에서 사이트 A 볼륨 또는 LUN을 사용할 수 있게 되면 HA 마스터 에이전트가 사이트 B에서 사이트 A 가상 머신을 재시작합니다</block>
  <block id="23e5761401326cc21bcf9d108b9e3e7f" category="paragraph">vSphere HA 마스터 에이전트의 VM 재시작 시도(등록 및 전원 켜기 포함)가 실패하면 지연 후 재시작됩니다. 다시 시작 사이의 지연은 최대 30분까지 구성할 수 있습니다. vSphere HA는 최대 시도 횟수(기본적으로 6회 시도)에 대해 이러한 재시작을 시도합니다.</block>
  <block id="641031c1f370e06434afd215f8610dae" category="paragraph">* 참고: * HA 마스터는 배치 관리자가 적합한 스토리지를 찾을 때까지 재시작 시도를 시작하지 않으므로 사이트 전체에 장애가 발생할 경우 전환이 수행된 후가 됩니다.</block>
  <block id="085a4a3eba6c30fa589bfee20eb0c294" category="paragraph">사이트 A가 페일오버된 경우 정상 사이트 B 노드 중 하나의 후속 장애 조치를 통해 정상적인 노드로 원활하게 처리할 수 있습니다. 이 경우 4개 노드의 작업은 현재 하나의 노드에서만 수행됩니다. 이 경우 복구는 로컬 노드로의 반환 수행으로 구성됩니다. 그런 다음 사이트 A가 복구되면 구성의 안정적 상태 작업을 복원하기 위한 스위치백 작업이 수행됩니다.</block>
  <block id="2b9b713afb0d80ef371a0b55e58366b6" category="image-alt">전체 사이트 장애</block>
  <block id="e6364c2f5314a32cd95be04b4c2112e6" category="paragraph">다음 섹션에서는 ONTAP 스토리지에서 VMware VVOL을 사용하기 위한 절차 및 모범 사례를 간략히 설명합니다.</block>
  <block id="a9da618400fb93b20c20f5343efaefa7" category="sidebar">ONTAP이 지원되는 VMware vSphere Metro 스토리지 클러스터</block>
  <block id="2f58fa882a22b5af5f0741f03abaf611" category="sidebar">ONTAP이 포함된 vSphere Metro 스토리지 클러스터</block>
  <block id="4a884da785a62e8b1758932191ff42de" category="paragraph">VMware, Oracle OLVM 또는 KVM을 통한 데이터베이스 가상화는 미션 크리티컬한 데이터베이스도 가상화를 선택한 NetApp 고객에게 점점 더 많이 사용되고 있습니다.</block>
  <block id="3a8ba1ff8824968961222d6b447b4973" category="section-title">지원 가능성</block>
  <block id="3231d83af741101eb02b16e5d7a6dffc" category="paragraph">가상화를 위한 Oracle 지원 정책, 특히 VMware 제품 관련 정책에 관해 많은 오해가 있습니다. Oracle Induight가 가상화를 지원하지 않는다는 말은 흔히 들립니다. 이는 틀린 생각이고, 가상화의 이점을 얻을 수 있는 기회를 놓치게 되는 결과를 낳습니다. Oracle Doc ID 249212.1은 실제 요구사항을 설명하며 고객이 관심사로 간주하는 경우는 거의 없습니다.</block>
  <block id="722bd611ee4f38780607b400c8a604c0" category="paragraph">가상화된 서버에서 문제가 발생했고 이전에 Oracle Support에서 이 문제를 알려지지 않은 경우 고객은 물리적 하드웨어에서 문제를 재현하도록 요청받을 수 있습니다. 제품의 최첨단 버전을 실행하는 Oracle 고객은 지원 가능성 문제 때문에 가상화를 사용하려 하지 않을 수 있지만 일반적으로 제공되는 Oracle 제품 버전을 사용하는 가상화 고객의 경우에는 현실이 아니었습니다.</block>
  <block id="c8a4476ecddeda66dbd2c354c8fb2c6b" category="paragraph">데이터베이스 가상화를 고려하는 고객은 비즈니스 요구사항을 근거로 스토리지 관련 결정을 내려야 합니다. 이는 모든 IT 결정에 있어 일반적으로 적용되는 사항이지만 요구 사항의 규모와 범위가 상당히 다르기 때문에 데이터베이스 프로젝트에서 특히 중요합니다.</block>
  <block id="835ce293f862d9fb74e50f4cf928c56d" category="paragraph">스토리지 프레젠테이션에는 다음과 같은 세 가지 기본 옵션이 있습니다.</block>
  <block id="327813abbc0ae1e9d3abe282303bf00c" category="list-text">하이퍼바이저 데이터 저장소의 가상화된 LUN</block>
  <block id="1a1af5efffda8c766ead9f73fc782e0e" category="list-text">VM에 의해 마운트되는 NFS 파일 시스템(NFS 기반 데이터 저장소가 아님)</block>
  <block id="f9bf9489147891f7ee7ba15126a27fda" category="list-text">직접 장치 매핑 VMware RDM은 고객이 선호하지 않지만 물리적 디바이스는 KVM 및 OLVM 가상화와 유사하게 직접 매핑되는 경우가 많습니다.</block>
  <block id="69b0ac6bf6ea8e1ab4e4fc896294da01" category="paragraph">가상 게스트에 스토리지를 제공하는 방법은 일반적으로 성능에 영향을 미치지 않습니다. 호스트 OS, 가상화 네트워크 드라이버, 하이퍼바이저 데이터 저장소 구현은 모두 고도로 최적화되어 있으며 기본 모범 사례를 따르는 한 하이퍼바이저와 스토리지 시스템 간에 사용 가능한 FC 또는 IP 네트워크 대역폭을 모두 사용할 수 있습니다. 어떤 경우에는 다른 스토리지 프레젠테이션 방식에 비해 한 가지 스토리지 프레젠테이션 방식을 사용하면 최적의 성능을 얻는 것이 약간 더 쉬울 수 있지만 결과는 비슷해야 합니다.</block>
  <block id="a2e8fb5328f6558e3a119d8c224a1897" category="paragraph">가상화된 게스트에 스토리지를 제공하는 방법을 결정하는 핵심 요소는 관리 능력입니다. 올바른 방법이나 잘못된 방법이 없습니다. 최상의 접근 방식은 IT 운영 요구사항, 기술 및 선호도에 따라 달라집니다.</block>
  <block id="e4919ac0a074fa1bba5303f596a5f591" category="paragraph">고려해야 할 요소는 다음과 같습니다.</block>
  <block id="c422e10bbf04c180f4c47f81ed9a1f7a" category="list-text">* 투명성. * VM이 파일 시스템을 관리할 때 데이터베이스 관리자나 시스템 관리자가 데이터에 대한 파일 시스템의 소스를 쉽게 식별할 수 있습니다. 파일 시스템 및 LUN은 물리적 서버와 달리 액세스됩니다.</block>
  <block id="42de52ad09be3101fc535dea2aedce1d" category="list-text">* 정합성 보장. * VM이 파일 시스템을 소유하는 경우 하이퍼바이저 계층을 사용하거나 사용하지 않는 것은 관리 용이성에 영향을 미칩니다. 가상화 및 비가상화 환경 모두를 포함한 전체 자산에 걸쳐 프로비저닝, 모니터링, 데이터 보호 등에 같은 절차를 사용할 수 있습니다.</block>
  <block id="0562446bc5eefe9a584e23ffb3061cbf" category="paragraph">반면에 100% 가상화된 데이터 센터라면 앞에서 언급한 것처럼 전체 설치 공간 전반에서 데이터 저장소 기반 스토리지를 사용하는 것이 더 나을 것입니다. 일관성 - 프로비저닝, 보호, 조정 및 데이터 보호에 대해서도 동일한 절차를 사용할 수 있는 능력입니다.</block>
  <block id="7269a37b557c66664c0377693f62ec8a" category="list-text">* 안정성 및 문제 해결. * VM이 파일 시스템을 소유할 때 VM에 전체 스토리지 스택이 있기 때문에 우수하고 안정적인 성능 및 문제 해결이 간단해집니다. 여기서 하이퍼바이저는 FC 또는 IP 프레임을 운반하는 역할만 합니다. 데이터 저장소가 구성에 포함된 경우 시간 초과, 매개 변수, 로그 파일, 잠재적 버그 문제가 발생하여 구성이 복잡해집니다.</block>
  <block id="c160b6d86853c20a432e2407b82866e6" category="list-text">* 공급업체 종속. * 데이터 저장소에 데이터를 배치한 후에는 다른 하이퍼바이저를 사용하거나 가상화된 환경에서 데이터를 완전히 가져오는 것이 어려워집니다.</block>
  <block id="a42abd01a1e0c89cfa2112dc09378967" category="list-text">* Snapshot Enablement. * 상대적으로 제한된 대역폭으로 인해 가상화 환경의 기존 백업 절차가 문제가 될 수 있습니다. 예를 들어, 4포트 10GbE 트렁크는 여러 가상화 데이터베이스의 일상적인 성능 요구를 충분히 지원할 수 있지만 RMAN 또는 데이터의 전체 크기 복사본 스트리밍이 필요한 기타 백업 제품을 사용하여 백업을 수행하기에는 불충분합니다. 그 결과 점점 더 통합되는 가상화 환경에서 스토리지 스냅샷을 통해 백업을 수행해야 합니다. 따라서 백업 윈도우에서 순수하게 대역폭과 CPU 요구사항을 지원하기 위해 하이퍼바이저 구성을 오버 빌드할 필요가 없습니다.</block>
  <block id="86c36175331b4a95c083fabdcca8b8a0" category="paragraph">게스트 소유 파일 시스템을 사용하면 보호가 필요한 스토리지 오브젝트를 더 쉽게 타겟팅할 수 있기 때문에 스냅샷 기반 백업과 복원을 활용하기가 어려울 수 있습니다. 그러나 데이터 저장소 및 스냅샷과 잘 통합되는 가상화 데이터 보호 제품이 점점 더 많아지고 있습니다. 가상화된 호스트에 스토리지를 제공하는 방법을 결정하기 전에 백업 전략을 완전히 고려해야 합니다.</block>
  <block id="8c19dda4c4cab5e52edf9463f196b97d" category="section-title">데이터 저장소 스트라이핑</block>
  <block id="8fa77493c52e71f201ccdb67db26446d" category="paragraph">데이터 저장소와 함께 데이터베이스를 사용할 때는 성능 스트라이핑과 관련하여 고려해야 할 중요한 한 가지 요소가 있습니다.</block>
  <block id="53ab623a905e6ec84d908f0b99a8d1c8" category="paragraph">VMFS와 같은 데이터 저장소 기술은 여러 LUN을 확장할 수 있지만 스트라이핑된 디바이스는 아닙니다. LUN이 연결됩니다. 결과적으로 LUN 핫스팟이 될 수 있습니다. 예를 들어, 일반적인 Oracle 데이터베이스의 경우 8-LUN ASM 디스크 그룹이 있을 수 있습니다. 8개의 가상화된 LUN을 모두 8개의 LUN VMFS 데이터 저장소에 프로비저닝할 수 있지만 데이터가 상주할 LUN은 보장할 수 없습니다. 그 결과 VMFS 데이터 저장소 내에서 단일 LUN을 차지하는 8개의 가상화된 LUN이 모두 구성될 수 있습니다. 이로 인해 성능 병목 현상이 발생합니다.</block>
  <block id="e6bb99e411f5495b03c1e0a4e75a1434" category="paragraph">일반적으로 스트라이핑이 필요합니다. KVM을 비롯한 일부 하이퍼바이저에서는 설명된 대로 LVM 스트라이핑을 사용하여 데이터 저장소를 구축할 수 있습니다 <block ref="dd0ff2598ebb26feb9ff73a59186b79f" category="inline-link-macro-rx"></block>. VMware를 사용하면 아키텍처가 조금 다르게 보입니다. 각 가상화된 LUN은 서로 다른 VMFS 데이터 저장소에 배치해야 합니다.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">예를 들면 다음과 같습니다.</block>
  <block id="6ec151851a31c86edd358bc49f80908c" category="paragraph"><block ref="6ec151851a31c86edd358bc49f80908c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ff2667d6b190dea65bae42217aa310" category="paragraph">이 접근 방식의 주요 동인은 ONTAP가 아닙니다. 단일 VM 또는 하이퍼바이저 LUN이 병렬로 처리할 수 있는 작업 수의 내재적 제한 때문입니다. 일반적으로 단일 ONTAP LUN은 호스트가 요청할 수 있는 것보다 훨씬 더 많은 IOPS를 지원할 수 있습니다. 단일 LUN 성능 제한은 거의 보편적으로 호스트 운영 체제의 결과입니다. 그 결과 대부분의 데이터베이스에서 성능 요구를 충족하기 위해 4~8개의 LUN이 필요합니다.</block>
  <block id="59f9d8d1b212a8ff6bd3476975e17620" category="paragraph">VMware 아키텍처는 데이터 저장소 및/또는 LUN 경로 최대화가 이 접근 방식에서 발생하지 않도록 아키텍처를 신중하게 계획해야 합니다. 또한 모든 데이터베이스에 대해 고유한 VMFS 데이터 저장소 집합이 필요하지 않습니다. 각 호스트에 가상 LUN에서 스토리지 시스템 자체의 백엔드 LUN으로 연결되는 4-8개의 깨끗한 입출력 경로 세트가 있어야 합니다. 드문 경우지만 더 많은 데이터토어가 진정한 성능 요구 사항에 도움이 될 수 있지만 일반적으로 전체 데이터베이스의 95%에 대해 4-8개의 LUN으로 충분합니다. 8개의 LUN이 포함된 단일 ONTAP 볼륨은 일반적인 OS/ONTAP/네트워크 구성에서 최대 250,000개의 랜덤 Oracle 블록 IOPS를 지원할 수 있습니다.</block>
  <block id="622b235a9123d972c612737c81eb55a1" category="inline-link">NFSv3 nConnect 기능을 지원하는 NetApp 및 VMware</block>
  <block id="ee7dab8e6be0e4b3085e8fb1df295146" category="list-text">VMware와 NetApp는 현재 ONTAP 9.14.1부터 NFSv4.1 세션 트렁킹을 지원합니다. 구체적인 버전에 대한 자세한 내용은 NetApp NFS 4.1 상호 운용성 매트릭스 참고 사항을 참조하십시오. NFSv3은 볼륨에 대한 여러 물리적 경로를 지원하지 않지만, vSphere 8.0U2부터 nconnect는 지원합니다. nconnect에 대한 자세한 내용은 를 참조하십시오<block ref="2668e8271f58131cbbe97dab01f83475" category="inline-link-rx"></block>. ONTAP 9.8을 사용하는 FlexGroup의 경우 VMware vSphere용 ONTAP 툴이 FlexGroup를 생성하도록 하는 것이 좋습니다. 그런 다음 마운트 해제하고 라운드 로빈 DNS를 사용하여 다시 마운트하여 클러스터에 로드를 분산해야 합니다. ONTAP 툴에서는 데이터 저장소를 마운트할 때 하나의 LIF만 사용합니다. 데이터 저장소를 다시 마운트한 후 ONTAP 툴을 사용하여 데이터 저장소를 모니터링하고 관리할 수 있습니다.</block>
  <block id="7564f732469e12963d8b416572cf4efb" category="section-title">vSphere Metro Storage Cluster란 무엇입니까?</block>
  <block id="830d984ea50f71fa76636d0524167a3a" category="doc">vSphere 데이터 저장소 및 프로토콜 기능 개요</block>
  <block id="7bbcbf5b4bf3f23dc1b710dfd65de967" category="list-text">VMware는 vSphere 8.0U2부터 NFSv3을 사용하여 nconnect를 지원합니다. nconnect에 대한 자세한 내용은 를 참조하십시오<block ref="2668e8271f58131cbbe97dab01f83475" category="inline-link-rx"></block></block>
  <block id="1d1d9d816e63b6c7d3057732579e8889" category="list-text">VMware VAAI용 NetApp NFS 플러그인을 사용하는 경우 프로토콜을 로 설정해야 합니다<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> 대신<block ref="61a52f7a75745796f63ec9e3ea2547b4" prefix=" " category="inline-code"></block> 엑스포트 정책 규칙이 생성되거나 수정된 경우 VAAI 복사본 오프로드 기능을 사용하려면 데이터 프로토콜이 NFSv3인 경우에도 NFSv4 프로토콜이 작동되어야 합니다. 프로토콜을 로 지정합니다<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> NFSv3 및 NFSv4 버전을 모두 포함합니다.</block>
  <block id="cc0f7f705e4495c607aea288505e31bf" category="sidebar">vMSC 개요</block>
  <block id="de9a829f775bc333b77fdacbc333f7a1" category="sidebar">vSphere HA 솔루션</block>
  <block id="70b29c8dabeb7a16884003c35e163f96" category="sidebar">vMSC 설계</block>
  <block id="6c4755219197ce467bf892a552c8663a" category="sidebar">vMSC 복원력</block>
  <block id="13376e3e9b02a56731aa64aeb10947b2" category="sidebar">MCC와 vMSC 시나리오</block>
</blocks>